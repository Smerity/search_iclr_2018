{"notes":[{"tddate":null,"ddate":null,"tmdate":1515083301420,"tcdate":1515083301420,"number":6,"cdate":1515083301420,"id":"SytmUAi7M","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"Hy-UWWjff","signatures":["ICLR.cc/2018/Conference/Paper729/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/Authors"],"content":{"title":"MTCNN results","comment":"Here are some preliminary results of our approach on MTCNN. Note that due to the time allotted,  we did not fully explored all variations of our training process. We are currently performing more experiments, especially on the structure of the underlying networks PNet, RNet and ONet, and on the hard negative data generation process (we used the provided hyper-parameters from the authors of the MTCNN-Tensorflow github project, which may have been fine-tuned for the original MTCNN).\n\nWe used as training datasets Sun’s et al. dataset (LFW+Net) for landmarks and the Wider face dataset for face recognition. We test on the Celeba test set, which contains 19962 images. Here are the results that we obtained:\n\nMTCNN original (ran ourselves)\n\n    Number of face detection failures: 44\n    Mean dists: 8.1124\n    Median dists: 3.9281\n    Mean landmark failure rate: 0.2201\n\nOurs\n\n    Number of face detection failures: 16\n    Mean dists: 8.5217\n    Median dists: 2.8076\n    Mean landmark failure rate: 0.1258\n\nWith our approach, MTCNN has fewer face detection failures (16 vs 44) and a lower landmark failure rate (0.1258 vs 0.2201). The mean distance is however larger (8.5217 vs 8.1124), but the median is lower (2.8076 vs  3.9281). We are currently running experiments on the MTFL dataset to see if we obtain similar improvements. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1513980232570,"tcdate":1513980232570,"number":5,"cdate":1513980232570,"id":"Hy-UWWjff","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"HJDRBqufM","signatures":["ICLR.cc/2018/Conference/Paper729/AnonReviewer3"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/AnonReviewer3"],"content":{"title":"Thanks for the response","comment":"Thank you for the detailed clarification. \n\nFor the test settings, thank you for the clarification. It is clear now. \nI agree that it is hard to fully replicate previous methods and retrain the models with an up-to-date neural network. However, without that results, the experiments seem a bit not solid enough. \nThe explanations of the other limitations are reasonable, but they do not resolve the actual limitation. I would like to just take these limitations. \n\nSome of my concerns are addressed, and there is a chance for the authors to provide an updated MTCNN results. I would like to slightly increase the rating."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1513821647511,"tcdate":1513821647511,"number":4,"cdate":1513821647511,"id":"HJDRBqufM","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"ryXDrc_fG","signatures":["ICLR.cc/2018/Conference/Paper729/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/Authors"],"content":{"title":"Average error performance","comment":"These are the values that we obtained (in %):\n\n1. MTFL\n\n1.1 Underlying Network: AlexNet\n\n1.1.1 Not pre-trained\nAN-S: 9.474, AN: 9.435, ANx: 9.356, HF: 9.548, TCDCN: unknown, XS: 9.379, Ours: 8.423\n\n1.1.2 Pre-trained\nAN-S: 9.473, AN: 9.395, HF: 9.426, TCDCN: unknown, XS: 9.377, Ours: 8.500\n\n1.2 Underlying Network: ResNet\n\n1.2.1 Not pre-trained\nRN-S: 8.692, RN: 8.571, RNx: 8.236, XS: 8.456, Ours: 8.007\n\n1.2.2 Pre-trained\nRN-S: 8.262, RN: 8.170, XS: 7.953, Ours: 7.845\n\n2. AFW\n\n2.1 Underlying Network: AlexNet\n\n2.1.1 Not pre-trained\nAN-S: 16.04, AN: 16.06, ANx: 16.68, HF: 16.34, XS: 18.24, Ours: 15.14\n\n2.1.2 Pre-trained\nAN-S: 17.24, AN: 17.15, HF: 16.34, XS: 17.78, Ours: 16.95\n\n2.2 Underlying Network: ResNet\n\n2.2.1 Not pre-trained\nRN-S: 16.15, RN: 15.71, RNx: 14.81, XS: 15.78, Ours: 14.14\n\n2.2.2 Pre-trained\nRN-S: 14.73, RN: 14.97, XS: 15.70, Ours: 14.27\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1513821530634,"tcdate":1513821530634,"number":3,"cdate":1513821530634,"id":"ryXDrc_fG","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"ry0lbHclz","signatures":["ICLR.cc/2018/Conference/Paper729/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/Authors"],"content":{"title":"Answer to AnonReviewer3","comment":"1. What is missing is the comparison with other methods...\n\nWe would like to first clarify some elements that seem to be confusing. The authors of the TCDCN approach, Zhang et al., 2014, first introduced the MTFL dataset in their paper ( http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html). This dataset was created by merging two datasets together, one for training and one for testing. The training is Sun’s et al. dataset, which itself is constituted of two datasets: LFW dataset and their proposed Net dataset. As for the test set, Zhang et al., 2014 randomly selected 3000 images from the AFLW dataset.\n\nThe performance of 25% by TCDCN therefore correspond to the accuracy on the test set of MTFL. As can be seen in Figure 3, we already compared ourselves to TCDCN.\n\nThe results in Figure 5 are for a different test set. We still train on the training dataset of MTFL (LFW + Net), but this time we test on the AFW dataset from Zhu et al. 2012.\n\nWe would have liked to compare ourselves to TCDCN on AlexNet (initialized at random) and ResNet, but the authors did not yet provide the training code. There is an open issue in their Github project: https://github.com/zhzhanp/TCDCN-face-alignment/issues/7 \n\nRegarding MTCNN, we are currently running experiments using the MTCNN-Tensorflow github project. We implemented our collaborative block and incorporated it to the network. The results should be available in the following 2 weeks or so, but already look promising.\n\n2. In addition, many papers take the average error as the performance metric.\n\nWe did not include the average error since we thought the metric error was sufficient. However, we agree that it would be more comprehensive to show them. We will put them in a following comment.\n\n3. The proposed architecture is a bit huge...\n\nOur main contribution is the collaborative block, which connects task-specific networks in a soft parameter sharing MTL setting. The linear increase with the number of tasks is a limitation of this setting, which is well-known in the MTL community. The effective increase of our collaborative block is in itself limited two conv layers for the central aggregation, and two conv layers for each task-specific aggregation.\n\nWhen using ResNet18 as underlying network, we used 5 collaborative blocks. With 4 tasks in total, the size of each block (in order of depth) was 234,752, 234,752, 936,448, 3,740,672 and 14,952,448. The single-task ResNet18 has 11,176,512 parameters, so the five tasks soft-parameter network has 55,882,560 parameters. For ResNet18, that increase may be large, but note that it does not scale with depth. Using a ResNet101 with 44,549,160 parameters, the five tasks soft-parameter network would have 222,745,800. The relative parameter increase of our approach would be lower.\n\n4. It is also not straightforward to add new tasks to finetune a trained model.\n\nIn our soft-parameter sharing multi-task setting, finetuning on a new task can be done by simply connecting a new task-specific network to the other networks. In the case where we do not have access (during finetuning) to the original tasks on which the network was trained on, it is always possible to freeze the weights of the pre-trained task-specific networks. This has the advantage of avoiding catastrophic forgetting, where the features learned from the previous tasks are removed during finetuning. This is in contrast with hard-parameter sharing, where only the fully connected layers are separated. In that case, the network must be finetuned using all previous tasks, otherwise the shared intermediate layers can experiment catastrophic forgetting.\n\n5. In Figure 5 (left), it is a bit weird that the pretrained model underperforms the nonpretrained one.\n\nFor this experiment, the networks were pretrained on ImageNet, fine-tuned on MTFL, then tested on AFW. In other words, the networks were pretrained on a first domain, finetuned on a second domain then tested on a third domain. We believe that, in order to develop good domain adaptation abilities during finetuning, it was harder for the networks to adjust its features learned on ImageNet than learned them from a random initialisation start. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1513819702901,"tcdate":1513819702901,"number":2,"cdate":1513819702901,"id":"HyyB0FuGf","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"Bylfi7tez","signatures":["ICLR.cc/2018/Conference/Paper729/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/Authors"],"content":{"title":"Answer to AnonReviewer2","comment":"1. The novelty of this submission seems a little limited.\n\nSeveral advances in deep learning from the past 5 years have shown that simple approaches sometimes yield large improvements. One of the most striking example is the use of identity skip connection in Residual Network. The novelty of simply adding the feature map at a lower layer to the feature map at a higher layer could be viewed as limited. Other contributions that could be seen as limited also include batch normalisation, the  squeeze and excitation block from the winners of ImageNet 2017 competition (feature map calibration by global average pooling and scaling), DenseNet (change the sum in ResNet by a concatenation) and even the ReLU. The novelty of all these approaches may seem limited, but this is because they are fairly simple to understand.\n\nOne crucial advantage of simple contributions is the possibility of straightforward integration into existing projects. As an example, AnonReviewer3 asked us to include MTCNN in our experiments. We found the following Tensorflow github project https://github.com/AITTSMD/MTCNN-Tensorflow that implements and trains MTCNN. It took use little time to implement our collaborative block in Tensorflow, and integrate it to their network. We have included our code at the end of our comment. This is a key advantage of our contribution, that it can be incorporated into existing projects without difficulties.\n\n# Tensorflow python implementation of our collaborative block\n\ndef collaborative_block(inputs, nf, training, scope):\n    def conv2d(x, nf, fs):\n        y = slim.conv2d(x, nf, [fs, fs], 1, 'SAME', activation_fn=None,       \n                        weights_initializer=slim.xavier_initializer(),\n                        biases_initializer=None,\n                        weights_regularizer=slim.l2_regularizer(0.0005))\n        return y\n\n    def bn(x, training):\n        y = slim.batch_norm(x, 0.999, True, True, 1e-5, is_training=training)\n         return y\n\n    def aggregation(x, n_out, training):\n        with tf.variable_scope('aggregation'):\n            z = x\n            z = conv2d(z, n_out, 1)\n            z = bn(z, training)\n            z = tf.nn.relu(z)\n            z = conv2d(z, n_out, 3)\n            z = bn(z, training)\n        return z\n\n    def central_aggregation(inputs, n_out, training):\n        with tf.variable_scope('central'):\n            z = tf.concat(inputs, axis=-1)\n            z = aggregation(z, n_out, training)\n            z = tf.nn.relu(z)\n        return z\n\n    def local_aggregation(x, z, n_out, pos, training):\n        with tf.variable_scope('local_{}'.format(pos)):\n            y = tf.concat([x, z], axis=-1)\n            y = x + aggregation(y, n_out, training)\n        return y\n\n    with tf.variable_scope(scope):\n        n_inputs = len(inputs)\n        z = central_aggregation(inputs, nf * n_inputs // 4, training)\n        outputs = [local_aggregation(x, z, nf, i, training)\n                   for i, x in enumerate(inputs)]\n    return outputs\n\n\n2. The target task utilized in this paper is too simple, which only detects 5 facial landmarks. It is hard to say this proposed work can still work when facing more challenging tasks, for example, 60+ facial landmarks prediction.\n\nIt is true that we only predict 5 facial landmarks in our experiments on the MTFL and AFW datasets. However, we predict 21 facial landmarks in our experiment on the AFLW dataset. This is a substantially harder task. As we write in table 1 in section 4.4, the results show that our approach outperforms both the standard multi-task setting (hard-parameter sharing) and the cross-stitch approach (soft-parameter sharing).  \n\n\n3. \"Also, one drawback of HyperFace is that the proposed feature fusion is specific to AlexNet,\" In the original submission, HyperFace is based on AlexNet, but does this mean it can only work on AlexNet?\n\nIn the version of their paper what we read on arXiv, i.e. version 2, they wrote that they propose “a novel CNN architecture” as one of their contributions. They did not elaborate on how to adapt their approach on other network architectures. At that time, it was not clear for us how to make it work on other network. However, the authors recently (December 6, 2017) updated their arXiv paper to version 3, with a network architecture based on residual connections (see https://arxiv.org/abs/1603.01249). They call it the HyperFace-ResNet, in contrast to their original HyperFace network using AlexNet. Since now they show how to adapt their approach to another network, we agree that it is no longer a drawback that it is only specific to AlexNet. We will therefore remove our sentence."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1513819386416,"tcdate":1513819386416,"number":1,"cdate":1513819386416,"id":"S1MZTYuzG","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Comment","forum":"r17Q6WWA-","replyto":"SyuPmP3lM","signatures":["ICLR.cc/2018/Conference/Paper729/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper729/Authors"],"content":{"title":"Answer to AnonReviewer1","comment":"1.  We decided to perform our multi-task experiments on facial landmark detection because several previous approaches have shown that training on face orientation regression, along with gender, smile and glasses classification, can help better detect facial landmarks. We wanted to first demonstrate that our approach could leverage domain-specific information from tasks that we know were related. In particular, this allowed our ablation study in section 4.5 to provide empirical and easily interpretable evidence that our approach could indeed take advantage of high level face profile features to boost facial landmark detection.\n\nHowever, we agree that including experiments in other domains would further improve diversity. In that sense, we started working immediately after submission on tasks unrelated to faces, to precisely test the universality of our approach. So far, all conducted experiments were positive. For instance, we have an ongoing project on tree species identification from images of bark. This yet unpublished dataset contains 750,000+ unique crops from close-up pictures of bark for 22 different tree species, along with their trunk diameter (DBH). This is a multi-task setting where the tasks are less related. Indeed, different types of trees can have the same DBH, and inversely, trees from the same category can have different DBH (reflecting for instance their age). Using our approach, we could improve the classification accuracy from 93,09% to 94,46%. We can add this result in a new section to provide additional evidence that our approach can also work in a multi-task setting where tasks are less related.\n\nWe also looked at using our collaborative block on a standard object recognition problem. Instead of connecting task-specific networks to perform multi-task learning, we create a network by repeating our collaborative block to perform single-task learning. The network processes the input image using multiple connected branches, and outputs a feature vector at the end of the convolutional layers (before the fully connected layer) that is the concatenation of the features computed by each branch. In this setting, our approach goes in line with current works that try to alleviate large processing time by trading depth for width, i.e. by using fewer layers with more weights. Our current preliminary results have shown that increasing width by having more collaborative branches is an effective way to achieve similar error rates, while using fewer weights. On the CIFAR-10 dataset, with standard data augmentation (horizontal flip and ±4 pixels translation), we obtained 3.96% classification error using only 6,988,986 parameters. In comparison to recent approaches that explored trading depth for width, our approach has the lowest number of weights (relatively to obtaining around 4% error rate), as seen below:\n\nWide ResNet\n4.00% with 36,479,194 parameters (https://github.com/szagoruyko/wide-residual-networks)\n\nResNeXt\n4.00% with around 9.2M parameters (estimated from the curve in Fig. 7 of their arxiv paper https://arxiv.org/pdf/1611.05431.pdf)\n\nAOGNet-BN\n3.99 with 8.0M parameters (https://arxiv.org/pdf/1711.05847.pdf)\n\nOurs:\n3.96 % with 6,988,986 parameters\n\nWe are currently performing more experiments, but we could include this result on CIFAR-10.\n\n\n2.  We started with smaller datasets because we wanted to test several networks. For instance, the results in Figure 5 took us around one month to obtain with our single GPU architecture. This is because we used two underlying networks, which can either be pre-trained or not, and trained them in either a single-task setting or one of the different multi-task settings. We wanted to compare our approach to many other networks before going on larger datasets. \n\nHowever, we agree that it would be best to have larger datasets. In that sense, our current work on multi-task tree classification mentioned above could be considered a more large scale experiment, as it contains 750,000+ unique crops of 224x224 pixels. Moreover, we are currently implementing our approach on the MTCNN facial landmark detection approach. The network is trained to perform both face detection and landmarks detection. For face detection, we are using the WIDER dataset (http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/) containing 393,703 face images, and for facial landmark detection, we are using the celebA dataset (http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) containing 202,599 face images. The results of this experiment should be available in the next 2 weeks or so, but are already looking promising. See my answer to AnonReviewer3 for more details."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1515642498588,"tcdate":1511973728449,"number":3,"cdate":1511973728449,"id":"SyuPmP3lM","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Review","forum":"r17Q6WWA-","replyto":"r17Q6WWA-","signatures":["ICLR.cc/2018/Conference/Paper729/AnonReviewer1"],"readers":["everyone"],"content":{"title":"The authors propose a collaborative block that can be inserted in any deep network for multi-task learning and evaluate the method on multiple tasks related to Faces","rating":"6: Marginally above acceptance threshold","review":"The collaborative block that authors propose is a generalized module that can be inserted in deep architectures for better multi-task learning. The problem is relevant as we are pushing deep networks to learn representation for multiple tasks. The proposed method while simple is novel. The few places where the paper needs improvement are:\n\n1. The authors should test their collaborative block on multiple tasks where the tasks are less related. Ex: Scene and object classification. The current datasets where the model is evaluated is limited to Faces which is a constrained setting. It would be great if Authors provide more experiments beyond Faces to test the universality of the proposed approach.\n2. The Face datasets are rather small. I wonder if the accuracy improvements hold on larger datasets and if authors can comment on any large scale experiments they have done using the proposed architecture. \n\nIn it's current form I would say the experiment section and large scale experiments are two places where the paper falls short.  ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1515642498656,"tcdate":1511833846146,"number":2,"cdate":1511833846146,"id":"ry0lbHclz","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Review","forum":"r17Q6WWA-","replyto":"r17Q6WWA-","signatures":["ICLR.cc/2018/Conference/Paper729/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting method; better to do comparison with previous methods","rating":"6: Marginally above acceptance threshold","review":"\n\nThis paper proposes a multi-pathway neural network for facial landmark detection with multitask learning. In particular, each pathway corresponds to one task, and the intermediate features are fused at multiple layers. The fused features are added to the task-specific pathway using a residual connection (the input of the residual connection are the concatenation of the task-specific features and the fuse features). The residual connection allows each pathway to selectively use the information from other pathways and focus on its own task.\n\nThis paper is well written. The proposed neural network architectures are reasonable. \n\nThe residual connection can help each pathway to focus on its own task (suggested by Figure 8). This phenomenon is not guaranteed by the training objective but happens automatically due to the architecture, which is interesting. \n\nThe proposed model outperforms several baseline models. On MTFL, when using the AlexNet, the improvement is significant; when using the ResNet18, the improvement is encouraging but not so significant. On AFLW (trained on MTFL), the improvements are significant in both cases. \n\nWhat is missing is the comparison with other methods (besides the baseline). For examples, it will be helpful to compare with existing non-multitask learning methods, like TCDCN (Zhang et al., 2014) (it seems to achieve 25% failure rate on AFLW, which is lower than the numbers in Figure 5), and  multi-task learning method, like MTCNN (Zhang et al., 2016). It is important to show that proposed multitask learning method is useful in practice. \nIn addition, many papers take the average error as the performance metric. Providing results in the average error can make the experiments more comprehensive.\n\nThe proposed architecture is a bit huge. It scales linearly with the number of tasks, which is not quite preferable. It is also not straightforward to add new tasks to finetune a trained model. \n\nIn Figure 5 (left), it is a bit weird that the pretrained model underperforms the nonpretrained one. \n\nI am likely to change the rating based on the comparison with other methods.\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1515642498697,"tcdate":1511762696231,"number":1,"cdate":1511762696231,"id":"Bylfi7tez","invitation":"ICLR.cc/2018/Conference/-/Paper729/Official_Review","forum":"r17Q6WWA-","replyto":"r17Q6WWA-","signatures":["ICLR.cc/2018/Conference/Paper729/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This paper proposed a new block to combine domain-specific information from related tasks, in order to improve generalization of the target tasks. Although the relative improvement seems high (24.31%), its novelty is a little limited, and the target task in this submission(5 landmarks detection) is too simple to prove the effectiveness. ","rating":"5: Marginally below acceptance threshold","review":"Pros:\n1. This paper proposed a new block which can aggregate features from different tasks. By doing this, it can take advantage of common information between related tasks and improve the generalization of target tasks.\n\n2. The achievement in this paper seems good, which is 24.31%.\n\nCons:\n1. The novelty of this submission seems a little limited.\n\n2. The target task utilized in this paper is too simple, which only detects 5 facial landmarks. It is hard to say this proposed work can still work when facing more challenging tasks, for example, 60+ facial landmarks prediction.\n\n3. \" Also, one drawback of HyperFace is that the proposed feature fusion is specific to AlexNet,\" In the original submission, HyperFace is based on AlexNet, but does this mean it can only work on AlexNet?","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]}},{"tddate":null,"ddate":null,"tmdate":1509739136718,"tcdate":1509133595054,"number":729,"cdate":1509739134065,"id":"r17Q6WWA-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r17Q6WWA-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection","abstract":"Convolutional neural networks (CNN) have become the most successful and popular approach in many vision-related domains. While CNNs are particularly well-suited for capturing a proper hierarchy of concepts from real-world images, they are limited to domains where data is abundant. Recent attempts have looked into mitigating this data scarcity problem by casting their original single-task problem into a new multi-task learning (MTL) problem. The main goal of this inductive transfer mechanism is to leverage domain-specific information from related tasks, in order to improve generalization on the main task. While recent results in the deep learning (DL) community have shown the promising potential of training task-specific CNNs in a soft parameter sharing framework, integrating the recent DL advances for improving knowledge sharing is still an open problem. In this paper, we propose the Deep Collaboration Network (DCNet), a novel approach for connecting task-specific CNNs in a MTL framework. We define connectivity in terms of two distinct non-linear transformation blocks. One aggregates task-specific features into global features, while the other merges back the global features with each task-specific network. Based on the observation that task relevance depends on depth, our transformation blocks use skip connections as suggested by residual network approaches, to more easily deactivate unrelated task-dependent features. To validate our approach, we employed facial landmark detection (FLD) datasets as they are readily amenable to MTL, given the number of tasks they include. Experimental results show that we can achieve up to 24.31% relative improvement in landmark failure rate over other state-of-the-art MTL approaches. We finally perform an ablation study showing that our approach effectively allows knowledge sharing, by leveraging domain-specific features at particular depths from tasks that we know are related.","pdf":"/pdf/e2ce2f1a8545df021b3fee8845c65b4cdc86ca12.pdf","TL;DR":"We propose a novel approach for connecting task-specific networks in a multi-task learning setting based on recent residual network advances.","paperhash":"anonymous|multitask_learning_by_deep_collaboration_and_application_in_facial_landmark_detection","_bibtex":"@article{\n  anonymous2018multi-task,\n  title={Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r17Q6WWA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper729/Authors"],"keywords":["multi-task learning","soft parameter sharing","facial landmark detection"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}