{"notes":[{"tddate":null,"ddate":null,"tmdate":1512111156394,"tcdate":1512109780399,"number":11,"cdate":1512109780399,"id":"B1nRUuAgG","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["~zihang_zou1"],"readers":["everyone"],"writers":["~zihang_zou1"],"content":{"title":"Should compare with LS-GAN gradient penalty","comment":"I suggest this paper should compare its performance with LS-GAN in experiments.\n\nIn Chapter 2.4, this paper refers to LS-GAN and its theorem. Worth to mention that LS-GAN has gradient penalty, which is very flexible since it does not require the norm of gradient to be close to 1 as required in the dual of Wasserstein distance. Instead LS-GAN directly penalizes the gradient as a surrogate of Lipschitz constant derived from its generalization theorem. This makes the gradient penalty different both in theory and in algorithm from that of WGAN-GP. The conclusion in experiments on WGAN-GP thus cannot generalize to LS-GAN. So a direct comparison with LS-GAN is necessary.\n\nYou can find the code here, https://github.com/zzzucf/lsgan-gp."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1512222677101,"tcdate":1511610288102,"number":3,"cdate":1511610288102,"id":"Hkd3vAUeG","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Review","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["ICLR.cc/2018/Conference/Paper505/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Lack of the main point","rating":"3: Clear rejection","review":"This paper contains a collection of ideas about Generative Adversarial Networks (GAN) but it is very hard for me to get the main point of this paper. I am not saying ideas are not interesting, but I think the author needs to choose the main point of the paper, and should focus on delivering in-depth studies on the main point.\n\n1. On the game theoretic interpretations \n\nThe paper, Generative Adversarial Nets, NIPS 2014, already presented the game theoretic interpretations to GANs, so it's hard for me to think what's new in the section. Best response dynamics is not used in the conventional GAN training, because it's very hard to find the global optimal of inner minimization and outer maximization.\nThe convergence of online primal-dual gradient descent method in the minimax game is already well-known, but this analysis cannot be applied to the usual GAN setting because the objective is not convex-concave. I found this analysis would be very interesting if the authors can find the toy example when GAN becomes convex-concave by using different model parameterizations and/or different f-divergence, and conduct various studies on the convergence and stability on this problem.\n\nI also found that the hypothesis on the model collapsing has very limited connection to the convex-concave case. It is OK to form the hypothesis and present an interesting research direction, but in order to make this as a main point of the paper, the author should provide more rigorous arguments or experimental studies instead of jumping to the hypothesis in two sentences. For example, if the authors can provide the toy example where GAN becomes convex-concave vs. non-convex-concave case, and how the loss function shape or gradient dynamics are changing, that will provide very valuable insights on the problem. \n\n2. DRAGAN\n\nAs open commenters pointed out, I found it's difficult to find why we want to make the norm of the gradient to 1.\nWhy not 2? why not 1/2? Why 1 is very special?\nIn the WGAN paper, the gradient is clipped to a number less than 1, because it is a sufficient condition to being 1-Lipshitz, but this paper provides no justification on this number.\nIt's OK not to have the theoretical answers to the questions but in that case the authors should provide ablation experiments. For example, sweeping gradient norm target from 10^-3, 10^-2, 10^-1, 1.0, 10.0, etc and their impact on the performance.\nAlso scheduling regularization parameter like reducing the size of lambda exponentially would be interesting as well.\nMost of those studies won't be necessary if the theory is sound. However, since this paper does not provide a justification on the magic number \"1\", I think it's better to include some form of ablation studies.\n\nNote that the item 1 and item 2 are not strongly related to each other, and can be two separate papers. I recommend to choose one direction and provide in-depth study on one topic. Currently, this paper tries to present interesting ideas without very deep investigations, and I cannot recommend this paper to be published.\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1512222677149,"tcdate":1511607408697,"number":2,"cdate":1511607408697,"id":"SyYO2aIlG","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Review","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["ICLR.cc/2018/Conference/Paper505/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Rather incremental work, I doubt the scientific contribution is significant","rating":"4: Ok but not good enough - rejection","review":"This paper addresses the well-known stability problem encountered when training GANs. As many other papers, they suggest adding a regularization penalty on the discriminator which penalizes the gradient with respect to the data, effectively linearizing the data manifold.\n\nRelevance: Although I think some of the empirical results provided in the paper are interesting, I doubt the scientific contribution of this paper is significant. First of all, the penalty the author suggest is the same as the one suggest by Gulrajani for Wasserstein GAN (there the motivation behind this penalty comes from the optimal transport plan). In this paper, the author apply the same penalty to the GAN objective with the alternative update rule which is also a lower-bound for the Wasserstein distance.\n\nJustification: The authors justify the choice of their regularization saying it linearizes the objective along the data manifold and claim it reduces the number of non-optimal fixed points. This might be true in the data space but the GAN objective is optimized over the parameter space and it is therefore not clear to me their argument hold w.r.t to the network parameters. Can you please comment on this?\n\nRegularizing the generator: Can the authors motivate their choice for regularizing the discriminator only, and not the generator? Following their reasoning of linearizing the objective, the same argument should apply to the generator.\n\nComparison to existing work: This is not the first paper that suggests adding a regularization. Given that the theoretical aspect of the paper are rather weak, I would at least expect a comparison to existing regularization methods, e.g.\nStabilizing training of generative adversarial networks through regularization. NIPS, 2017\n\nChoice of hyper-parameters: The authors say that the suggested value for lambda is 10. Can you comment on the choice of this parameter and how it affect the results? Have you tried  annealing lambda? This is a common procedure in optimization (see e.g. homotopy or continuation methods).\n\nBogonet score: I very much like the experiment where the authors select 100 different architectures to compare their method against the vanilla GAN approach. I here have 2 questions:\n- Did you do a deeper examination of your results, e.g. was there some architectures for which none of the method performed well?\n- Did you try to run this experiment on other datasets?\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1512222677194,"tcdate":1510339359074,"number":1,"cdate":1510339359074,"id":"ByPQQOX1G","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Review","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["ICLR.cc/2018/Conference/Paper505/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A simple regularization term for training GANs is introduced, with good numerical performance.","rating":"8: Top 50% of accepted papers, clear accept","review":"Summary\n========\nThe authors present a new regularization term, inspired from game theory, which encourages the discriminator's gradient to have a norm equal to one. This leads to reduce the number of local minima, so that the behavior of the optimization scheme gets closer to the optimization of a zero-sum games with convex-concave functions.\n\n\nClarity\n======\nOverall, the paper is clear and well-written. However, the authors should motivate better the regularization introduced in  section 2.3.\n\n\nOriginality\n=========\nThe idea is novel and interesting. In addition, it is easy to implement it for any GANs since it requires only an additional regularization term. Moreover, the numerical experiments are in favor of the proposed method.\n\n\nComments\n=========\n- Why should the norm of the gradient should to be equal to 1 and not another value? Is this possible to improve the performance if we put an additional hyper-parameter instead?\n\n- Are the performances greatly impacted by other value of lambda and c (the suggested parameter values are lambda = c = 10)?\n\n- As mentioned in the paper, the regularization affects the modeling performance. Maybe the authors should add a comparison between different regularization parameters to illustrate the real impact of lambda and c on the performance.\n\n- GANs performance is usually worse on very big dataset such as Imagenet. Does this regularization trick makes their performance better?","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426309,"tcdate":1509816727253,"number":8,"cdate":1509816727253,"id":"Hy1sFOsRW","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"r184LvsCZ","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"We do need more research into the GAN game and how regularization helps","comment":"We make no claims that our regularization term helps find the optimal critic. In fact, we clearly mention that constraints on D actually \"hurt\" the performance. So, one should use vanilla GANs whenever possible but if you encounter instability, then some form of constraint will help. And we show that DRAGAN can achieve this without losing too much in performance. See end of section 2.4.\n\n1. GAN structure is responsible for the good performance, and the constraints are only to improve stability in hard cases. \n\n2. We show that DRAGAN helps make the underlying game \"easier\" in some sense. So, it works with any objective function (see section 3.3), although it might require small amount of hyperparameter tuning.\n\n3. There's no easy answer to this. Depends on the game, how strong the players are, domain space and many other factors. But yes, there's need for more research into understanding this and developing better forms of regularization.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509811758453,"tcdate":1509811758453,"number":9,"cdate":1509811758453,"id":"r184LvsCZ","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"S1GEAvq0Z","signatures":["~Leon_Boellmann1"],"readers":["everyone"],"writers":["~Leon_Boellmann1"],"content":{"title":"Thanks and suggestions for future research","comment":" I agree that if we downplay the parameter lambda, it will definitely help in this simple case, because it is becoming the original GAN. I think it raises the following questions that need more investigation:\n\n1. Does the GAN structure itself or the regularization term play a more important role in the good performance? This is also one of the objective of our course project and the issue raised in the paper of \"Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step\".\n\n2. Does a certain regularization only make sense for particular GAN structures or it can be universally used on top of all existing GAN structures? For this question, it seems the regularization in DRAGAN and the one in the other paper \"ON THE REGULARIZATION OF WASSERSTEIN GANS\" may only work for WGAN.\n\n3. What is a systematic way of weighing the regularization term and the original objective function, instead of heuristic parameter tuning?\n\n4. What are the pros and cons for all these different kinds of regularizations?\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1511217060155,"tcdate":1509748266018,"number":7,"cdate":1509748266018,"id":"S1GEAvq0Z","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"HyVsPP5CZ","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"Thanks for noting that observation (Edited)","comment":"1. DRAGAN's regularization is a simple constraint on the discriminator that is used to improve stability. It comes at a cost though! However, as we write at the end of section 2.4, by carefully choosing how you regularize, you can gain stability without losing too much performance. \n\nAnd though we suggest a hyperparameter setting for mostly image datasets in our paper, it doesn't work for all the distributions possible in all domains. Some tuning is required especially if your domain changes too much (from pixel space) or if the game/players are simple enough, I suggest also reducing the regularization intensity. I think the problem you observed is caused by this (see point 2). \n\n(In hindsight, we should have added a couple of points in Algorithm section to help practitioners use it. We will do so in the final version.)\n\n2. We show experiments on simple toy datasets in our paper without any issues. Since your domain is [-1,1] (not pixel space) and you are using small networks, I suggest not using default hyperparameters. Reduce 'c' first to something less than 0.1 (say). Further, if you want the best performance, I suggest tuning 'lambda' as well. Understanding what these hyperparameters are doing is essential to use DRAGAN to your advantage - c (size of local regions) and lambda (how much you want to bias). I can take a look at your code or share sample code after the review process :)\n\nEdit: I just realized your training data is uniform in [-1,1]. Your perturbations will be on the manifold in this case, which explains the issue.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509747010635,"tcdate":1509746587936,"number":8,"cdate":1509746587936,"id":"HyVsPP5CZ","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["~Leon_Boellmann1"],"readers":["everyone"],"writers":["~Leon_Boellmann1"],"content":{"title":"Not working for simple cases","comment":" I was taking a graduate level machine learning class. In the final course project, we tried to investigate the effects of different regularizations on GAN and WGAN. The two main regularization methods include the one proposed as DRAGAN in this paper and the one proposed in \"ON THE REGULARIZATION OF WASSERSTEIN GANS\" (referred to as w_reg in the following).\n\nWe mainly investigated the following methods: 1a. WGAN with weight clipping, 1b. WGAN with gradient penalty, 1c. WGAN with DRAGAN regularization, 1d. WGAN with w_reg; 2a. GAN, 2b. GAN with DRAGAN regularization.\n\nSince the generated images can only be judged with visualization, besides the image experiments, we also did some experiments on some simple synthetic cases. One exercise is to generate a [-1,1] uniform distribution from a Gaussian distribution. We observed the following results: all the methods 1a-2a are good at generating this simple distribution. However, GAN with the DRAGAN regularization does not. What we observed is that D(x) converges to a function with a hump and therefore all the generated samples are concentrated on a small region, instead of uniform distribution. We adopt a sample code from github. The generator has 2 layers and the discriminator has 1 layer.  The lambda is 10.\n\nWe got stuck in the observation for a long time. Later we find out the reason is the regularization term pushes the function to have some slope at the data support, which results in the hump shape. Therefore, the generated samples are mostly concentrated in the region with a large D(x).\n\nI am wondering if the authors have similar experience with the synthetic data experiments? Sometimes, the quality of generated images are hard to judge. Some synthetic data experiments are also needed to verify the performance. Probably I made some mistakes in the code experiments, would be great if the authors can share the code and insights after the review process. My email is leonboellmann0110@gmail.com. Thanks!\n\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658160048,"tcdate":1509654497567,"number":7,"cdate":1509654497567,"id":"HkcJxbYRb","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"Sk8vLeK0b","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Thanks!","comment":"Thanks!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426402,"tcdate":1509652062211,"number":6,"cdate":1509652062211,"id":"Sk8vLeK0b","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"r1nCXkK0Z","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"Wasserstein distance is if we use infinite family of 1-Lip functions","comment":"Wasserstein distance is if we use infinite family of 1-Lip (norm of gradient <=1) functions. \n\nBut, wgan-gp forces norm-1 gradients between all real and fake pairs. So, there is little connection to Wasserstein duality theory here (asymptotic or otherwise).\n\nI agree that more theoretical investigation is needed in the community. But this process of using only asymptotic intuitions to develop algorithms can go wrong as there are many moving pieces in GAN framework. \n\nAnd your question of whether we should require our algorithm to work in limit case..yes, absolutely! But do we understand what the right notion is? Density ratio was one way to think about this as suggested by original Goodfellow's paper. But this breaks the moment infinite data assumption is relaxed. So, we are yet to find a way to nicely reason about limit case and until we have it, using such narratives is overly restrictive. In our paper, we see D as some entity that can tell real images vs everything else and hence, our penalty makes sense."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658146463,"tcdate":1509647316090,"number":6,"cdate":1509647316090,"id":"r1nCXkK0Z","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"HkxbyyKCb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Thanks for your clarification","comment":"I understand that your analysis suggests that we should add the norm regularization in the local areas around real examples. This is clearly an improvement over WGAN-GP. However, this norm~=1 only holds for the case of Wasserstein distance. This is also what motivates Gulrajani et al to introduce this regularization term in the objective function.\n\nHowever, for other variants of GANs based on general f-divergence, the optimal D* should not have a norm~=1. That is what puzzling me and want to seek for theoretical insights.\n\nI agree that in practical training of GANs. We do not have infinite data samples, the network may not have enough capacity, and the neural networks are not convex/concave over its parameters. But when we design our algorithm, should we design one that at least works for the ideal simplest case when we have the true expectation, the network has enough capacity and the global optimum points can be reached? I think we should at least guarantee the algorithm works for the ideal case and then think about how to make it robust for practice. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426444,"tcdate":1509646071749,"number":5,"cdate":1509646071749,"id":"HkxbyyKCb","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"BJlRh0dC-","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"WGAN-GP is a great heuristic but it is just motivated/inspired by KR duality","comment":"1. \"A differentiable function is 1-Lipschtiz if and only if it has gradients with norm at most 1 everywhere\", but WGAN-GP doesnt do this.\n\n2. Read our section 2.4 where we show WGAN-GP has little to do with Wasserstein duality. In fact, our game-theoretic arguments could be the basis for why it works to some extent.\n\n3. Most of other such GAN variants come up with techniques by applying asymptotic arguments or sometimes those that don't hold in practice! Our paper is trying to counter that and we just follow the game.\n\nOur section 2.3 is the starting point for theory you are looking for. However, I suggest to carefully think about assumptions made in the development of each algorithm \n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658135554,"tcdate":1509645512407,"number":5,"cdate":1509645512407,"id":"BJlRh0dC-","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"HkXuRauAZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Look forward to more theoretical insights in future!","comment":" Thanks a lot for your explanations!\n\nActually if you look at the WGAN-GP paper, they have a strong theoretical support for adding the norm regularization term, because \". A differentiable function is 1-Lipschtiz if and only if it has gradients with norm at most 1 everywhere\". \n\nFor your paper, there is no doubt that the regularization brings improvement in the experiments. The paper is very well written. Besides the good experiment performance, I am looking for similar theoretical insights of adding this regularization for other variants of GANs. Instead of knowing that it works, I am more interested in knowing why it works, because obtaining the theoretical insights will lead to more effective algorithms that can be generalized. Hopefully, we will obtain more theoretical insights from future works, if more practitioners build more algorithms on this.  "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426487,"tcdate":1509641834924,"number":4,"cdate":1509641834924,"id":"HkXuRauAZ","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"Bk-qS6_RW","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"Arora et al is a great paper which supports what I said...how it's misleading to apply asymptotic intuitions in practice.","comment":"Arora et al's is a great paper which supports what I said...how it's misleading to apply asymptotic intuitions in practice.\n\nFrom a game-theoretic perspective, yes, any form of gradient norm regularization should improve stability. Our goal was to demonstrate this idea and foster research in this direction. \n\nWe didn't explore all possibilities or claim to have the best answer here, this is beyond the scope of our work. In fact, we didn't even explore all numerical possibilities to optimize for performance! And yet we beat the state-of-the-art wgan-gp. Hopefully, practitioners will build off our work and develop better algorithms."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658125363,"tcdate":1509639561077,"number":4,"cdate":1509639561077,"id":"Bk-qS6_RW","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"ryIPRnuCb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"any norm regularization works?","comment":" I see. Actually, quite a few people consider D(x) as the density ration estimation:\nM Uehara, \"Generative Adversarial Nets from a Density Ratio Estimation Perspective\"\nB. Poole et al. , \"Improved generator objectives for GANs\". \nAnd the analysis for the case with finite sample data is also aligned with this perspective.  See Arora et al, \"Generalization and Equilibrium in Generative Adversarial Nets (GANs)\"\nProbably you are right, in actual training, it may be misleading to consider from this perspective. \n\nFollowing the logic, does it imply that the any gradient norm regularization should work? So the constant \"1\" is chosen heuristically based on experiment results? Is there any general guideline to choose the norm regularization constant, should it be always \"1\"?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426543,"tcdate":1509637726267,"number":3,"cdate":1509637726267,"id":"ryIPRnuCb","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"S1yaH2dAb","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"Misleading to use the intuition that D* actually represents the ratio of densities in practice.","comment":"1. Goodfellow et.al show D*(x)=1/2 as we converge to P_real, when we have infinite data and large (maybe infinite) capacity networks. This isn't a realistic setting and it can be misleading to use the intuition that D* actually represents the ratio of densities in practice.\n\nSo, D*(x) need not have zero gradient w.r.t X, in general. \n\n2. Now, the generator learns from D in GAN framework. All G cares about is getting high scores and all D cares about is providing high scores to only real samples! What happens at noise doesn't matter as long as they get strictly lower scores. \n\nIf you use vanishing numbers, then you encourage the generator to learn noise and I think you are suggesting to slowly remove the regularization, which is a good idea in the limit case."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658111450,"tcdate":1509635511454,"number":3,"cdate":1509635511454,"id":"S1yaH2dAb","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"rJ91vcOCb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Why D* does not have zero gradient w.r.t. X","comment":"Dear authors,\nI am new to this area, so I have quite a few questions. I understand that the experiments show that adding this norm regularization makes the performance good and stable. The paper is very well written and the results are actually very impressive. I just want to step back and seek for a theoretical explanation of why this regularization makes sense. \n\n1. If we look at the original minimax problem of GAN, the optimal D* is indeed D*(x) = 1/2. Why is it not correct to assume D* has zero gradient w.r.t. X? \n\n2.  Let us first step back and assume the minimax problem is convex/concave in theta_d/theta_g. When we design the algorithm, we should find one that at least works for the ideal case, and then think about how to make it robust for the general case, when the problem is not convex/concave in theta_d/theta_g. I understand that adding the norm regularization in the data support would definitely alleviate mode collapse, because it artificially adds gradients to encourage the generator to generate the data samples. My question is  why should we restrict the norm to be close to \"1\" instead of some other small numbers (or some vanishing numbers), which would make your D' hopefully most closely to D*? "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426593,"tcdate":1509627617877,"number":2,"cdate":1509627617877,"id":"rJ91vcOCb","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"rJxYq4uAZ","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"D* won't have zero gradient w.r.t X in general. ","comment":"It is incorrect to assume that D* will have zero gradient w.r.t X, which means that D* will be a constant function and there's no reason to believe this will happen. However, w.r.t theta, gradient will be zero as its optimal.\n\nNow, let's talk about D* vs D'. You are right that D' can be worse than D*, however, as we discuss in the paper, getting to D* is a perilous journey fraught with local equilibria/instabilities. But, add the regularization term and you get D' which we show isn't that worse off. But now, you get significantly improved stability!\n\nThe generated distribution isn't close to P_real in both the cases, atleast we have no reason to believe so, expect using visual inspection (which can be a slippery slope). But w.r.t metrics we have (inception score, visual inspection), D' and D* are almost the same in our experiments. \n\nThe explanation could be that constraining to have norm-k gradients is actually reasonable (perturbed images should get strictly smaller probability than actual images) and P_real itself satisfies this condition. So, with large enough data D' -> P_real just as D*-> P_real, except that with DRAGAN, we are more likely to reach there due to stability."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658100263,"tcdate":1509603960501,"number":2,"cdate":1509603960501,"id":"rJxYq4uAZ","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"S1EGL-uC-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"follow up question","comment":" \nThere is one thing that is puzzling me. Suppose D* is the optimal to the original GAN without the regularization term. The gradient of D* with respect to x should be zero. Suppose we let D' be the optimal point for the new objective function with the regularization term. If the regularization term dominates, the converging point D' would have a gradient whose norm is close to 1. In this case, D' may be very different from the original D*, and the generated distribution pg may be very different from data distribution. My question is why do we require the norm of the gradient to be close to 1, instead of any other number? For example, if the regularization requires the norm of the gradient to be close to some small constant, would the converging D' be more close to D*?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1510092426642,"tcdate":1509590540079,"number":1,"cdate":1509590540079,"id":"S1EGL-uC-","invitation":"ICLR.cc/2018/Conference/-/Paper505/Official_Comment","forum":"ryepFJbA-","replyto":"ByD_wguCW","signatures":["ICLR.cc/2018/Conference/Paper505/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper505/Authors"],"content":{"title":"Thanks for your feedback!","comment":"1. As we explain at the end of section 2.4, one can constrain D in multiple ways and still improve stability. It should be clear from our paper that stability requires trading off modeling performance as flexible models come with game-theoretic problems.\n\nWe chose this specific form using our intuitions so as to have the least negative impact on modeling performance. Hence, we only apply constraints near real samples unlike other approaches. Next, we wanted that D be \"smooth\" in x-space to help the generator learn better and change gradually w.r.t theta so that game dynamics improves (see why FTRL works in previous section for intuitions regarding this). \n\nLet's see why our constraint achieves both of these. It is reasonable to expect that almost any small pixel-wise perturbation will make a given image less realistic. So we want that D(x) and D(x') to be different and to somewhat depend on how far x and x' themselves are. Thus, gradient should be greater than zero or the generator cannot learn to tell real images and the noise apart. Of course, you can play around with that parameter but we found that it doesn't matter much (atleast for stability). The gradual change in D w.r.t theta happens as these local perturbations act as auxiliary data points holding D down (in some sense) to prevent rapid changes.  \n\n2. To answer your second question, please look back to our section 2.3 where we outline the possibilities for theta and phi in non-convex settings. They can:\n\n-> Converge to an equilibrium (can be local)\n-> Cycle s.t averages converge\n-> Don't converge at all\n\nIf D(x) converges to optimal, notice that this means we are \"almost\" in a local equilibria. The cost function for G is now fixed and he will perform SGD updates until reaching a local minima mostly. This is usual deep learning and so, there's no question of instability due to the game! Whether this result is optimal depends on well-posedness of the game. This is where our paper comes in :) As we explain in our conclusion, the dynamics of GANs are not understood in the right perspective yet. Thinking of them as consistently estimating and minimizing JS-divergence or Wasserstein distance is not appropriate.\n\n "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509658079611,"tcdate":1509586798986,"number":1,"cdate":1509586798986,"id":"ByD_wguCW","invitation":"ICLR.cc/2018/Conference/-/Paper505/Public_Comment","forum":"ryepFJbA-","replyto":"ryepFJbA-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Intuition of the regularization","comment":" This paper is very well written. It is very easy to follow. It takes me less than 10 mins to read the whole paper. I have a question on the regularization term. Why does it require the norm of gradient to be close to 1? When D(x) approaches the optimal, the gradient should be zero, then this additional regularization term would make the training unstable or not converge to the optimal?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]}},{"tddate":null,"ddate":null,"tmdate":1509739266212,"tcdate":1509124536175,"number":505,"cdate":1509739263540,"id":"ryepFJbA-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ryepFJbA-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"On Convergence and Stability of GANs","abstract":"We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions. ","pdf":"/pdf/ed40d324e408a59a0f238c3d6eeeeec67fda3a33.pdf","TL;DR":"Analyzing convergence in GANs to improve training stability ","paperhash":"anonymous|on_convergence_and_stability_of_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On Convergence and Stability of GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryepFJbA-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper505/Authors"],"keywords":["GAN","Generative Adversarial Networks","Mode collapse","Stability","Game Theory"]},"nonreaders":[],"replyCount":21,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}