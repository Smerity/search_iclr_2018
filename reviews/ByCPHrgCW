{"notes":[{"tddate":null,"ddate":null,"tmdate":1515035179292,"tcdate":1515035179292,"number":4,"cdate":1515035179292,"id":"S174cGs7z","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Comment","forum":"ByCPHrgCW","replyto":"ByCPHrgCW","signatures":["ICLR.cc/2018/Conference/Paper255/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper255/Authors"],"content":{"title":"Changes made to paper","comment":"This comment provides a summary of all changes we have made to the paper.\n\nWe have fixed the AND table in Figure 4.\n\nWe have added brackets to Figure 2, and updated Figure 3 to show the Homomorphic Encryption process more clearly.\n\nWe have updated the “Activation Functions” subsection of the design section, to discuss the square activation in more detail.\n\nWe have updated the results section to better clarify why we did not include decryption timings.\n\nWe have updated the problem scenario to reduce ambiguity, to more clearly state that the server does not reveal the model or weights to the client (as opposed to the server explicitly securing the weights), and to more clearly explain what we consider to be a “complete implementation”.\n\nWe have added a short “Privacy-Preserving Model Training” subsection to the background section, to reference some related works, and better clarify why we do not consider model training.\n\nWe have added a short “Privacy-Preserving Deep Learning” subsection to the background section, to reference some works which do not use homomorphic encryption, and the trade-offs which result from this.\n\nWe have changed \"Both deep learning and FHE are relatively recent paradigms\" to “Both deep learning and FHE have seen significant advances in the past ten years”, reflecting that this work is built upon advances in the past decade.\n\nFor the sentence \"In theory, this system alone could be used to compute anything securely.\" We have changed the end to “compute any arithmetic circuit”, better reflecting what Gentry's cryptosystem does.\n\nFor the sentence \"However in practice the operations were incredibly slow, taking up to 30 minutes in some cases.\" We have clarified that this was for the bootstrapping operation in an implementation of Gentry's cryptosystem, and added a reference.\n\nWe have updated the end of the results section, to better clarify the comparison between our work and Cryptonets, with regards to model size, depth and efficiency.\n\nWe have updated the “Hybrid Homomorphic Encryption” subsection of the design section, to explain that this hybrid approach is why we consider our approach to be efficient and simple.\n\nWe have also updated the abstract, using the language “no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption”, and “efficiently implementing many deep learning functions with bootstrapped homomorphic encryption”. This should more cleanly cover the advantages of our work, compared to related literature, to the best of our knowledge."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1514942264413,"tcdate":1514942264413,"number":3,"cdate":1514942264413,"id":"BJxS1hFXG","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Comment","forum":"ByCPHrgCW","replyto":"rJhC64Olf","signatures":["ICLR.cc/2018/Conference/Paper255/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper255/Authors"],"content":{"title":"Reply to AnonReviewer3","comment":"Thank you for your constructive review!\n\nIt is fair to challenge our claims that “there has been no complete implementation of established deep learning approaches”, because there have been some implementations of deep learning models whereby a server can perform inference, including SecureML, Cryptonets [A] and MiniONN [C]. With this in mind, it is important that we clarify our problem scenario. The server does not want to reveal the model to the client, and the client does not want to reveal the input to the server. While all of the given approaches secure the client input, only Cryptonets and our paper secure the model structure from a client, who may wish to reverse-engineer the model. MiniONN proposes obfuscating the model to alleviate this issue, but an implementation of this for arbitrary architectures is not given, would not be trivial, and would increase the number of client-server exchanges. \n\nBecause SecureML and MiniONN are related works, we have updated the background section in our paper to discuss these works. We have also updated the problem scenario to more clearly explain what we consider to be a “complete implementation”.\n\nWe agree that for a shallow model using message packing, leveled FHE could be faster than binary FHE, and conversely a leveled FHE would become impractical for sufficiently deep models. \n\nIt is also important to note that Cryptonets uses the square activation instead of ReLU, and they present some disadvantages to this approach, in particular the unbounded derivative, making training difficult and limiting model depth. The square activation is also one of the most expensive operations in their network, because two ciphertexts must be multiplied. \nMiniONN can perform ReLU, but it does not use FHE, leading to other tradeoffs as discussed.\n\nWe have updated the end of the results section, to better clarify the comparison between our work and Cryptonets, with regards to model size, depth and efficiency.\n\nWe considered our circuits efficient in that they were much faster using a hybrid approach, compared to using only ciphertexts, and also that they allowed for an simpler implementation by abstracting plaintext, ciphertext and hybrid adders into a single unit. We have updated the “Hybrid Homomorphic Encryption” subsection of the design section, to better clarify that this is why we considered our approach efficient and simple.\n\nWe have also updated the abstract, with the intention of toning down our claims, by using the language “no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption”, and “efficiently implementing many deep learning functions with bootstrapped homomorphic encryption”. This should more cleanly cover the advantages of our work, compared to related literature, to the best of our knowledge.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1514941898182,"tcdate":1514941898182,"number":2,"cdate":1514941898182,"id":"ryMApotmG","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Comment","forum":"ByCPHrgCW","replyto":"Sy52MUdgG","signatures":["ICLR.cc/2018/Conference/Paper255/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper255/Authors"],"content":{"title":"Reply to AnonReviewer2","comment":"Thank you for your detailed review!\n\nWe chose not to use a garbled circuit approach for our work, because this would reveal at least in part, the structure of the model. Part of our problem scenario is that the server does not wish to reveal the model to the client, and by extension the model’s structure.\n\nWe do make comparisons between our work and Cryptonets, under the reference “Dowlin et al. (2016)”. It is fair to compare our paper with theirs, since they share a common goal. Their paper discusses three activation functions: sigmoid, ReLU and square. They do not attempt to implement sigmoid and ReLU, and instead use the square activation exclusively. Their paper presents the disadvantages to the square activation, in particular the unbounded derivative, making training difficult and limiting the depth of any model using this approach. It is also one of the most expensive operations in their network, because they must multiply two ciphertexts together. We have updated the “Activation Functions” subsection of the design section, to discuss the square activation in more detail.\n\nBecause we use binary circuits, our approach can exactly replicate the ReLU activation, and a piecewise linear approximation of sigmoid. We implement both of these, however we did not feel that it was necessary to implement the square activation, because this was used in Cryptonets as a replacement for ReLU, to solve a problem unique to arithmetic circuits.\n\nWe did not include decryption times in our results, because they were executing in less than a microsecond. Because our system only requires decryption at the very end of the process, it is a negligible cost compared to overall execution time. We have updated the results section to better clarify why we did not include these measurements.\n\nWe did not feel that securely training a neural network, such as with SecureML, would be of benefit for our problem scenario. If a model is securely trained, all weights are restricted to those clients which provided training data, leading to a different scenario where the server hosts the model structure, the client provides the training data, and neither party has access to the weights. If the server chose to give the weights to the client, then the client could reconstruct the model and run it in plaintext, removing the need for the server. \nSimilarly with “Privacy-preserving deep learning”, their goal is to have multiple parties collaboratively train a model, without revealing their respective training data. This is also leads to a different scenario, where each client has a local model. \nWe have added a short “Privacy-Preserving Model Training” subsection to the background section, to reference these works and better clarify why we do not consider model training.\n\nIt is fair to challenge the novelty of our work. As discussed, there have been a number of works which implement neural networks, and secure client inputs. However we feel that under our problem scenario, where the server does not wish to reveal the model to the client, and the client does not wish to reveal the input to the server, our approach is novel because it permits important functionality that is not present in Cryptonets, and allows the server to keep its model completely private, unlike SecureML and “Privacy-preserving deep learning”. We have updated the problem scenario, to hopefully prevent any ambiguity over what our goals were for this work.\n\nTo address the minor details:\n\nBy “weight privacy”, the intended message was that under our problem scenario, the server does not have to reveal the model structure or weights to the client. While they could encrypt their weights in our framework, it would substantially slow down operations as shown in our comparison between hybrid and ciphertext multipliers. We suggest that the weights are unencrypted, but are kept internal to the server. We have updated the problem scenario to more clearly state that the server does not reveal the model or weights to the client, as opposed to the server explicitly securing the weights.\n\n\"Both deep learning and FHE are relatively recent paradigms\". It is reasonable to consider deep learning and fully homomorphic encryption to be old paradigms. We have changed this sentence to “Both deep learning and FHE have seen significant advances in the past ten years”, reflecting that this work is built upon advances in the past decade.\n\n\"In theory, this system alone could be used to compute anything securely.\" Indeed their system would not solve the halting problem! We have changed this to “compute any arithmetic circuit”.\n\n\"However in practice the operations were incredibly slow, taking up to 30 minutes in some cases.\" We were referring to the time needed to run one bootstrapping operation, using an early implementation of Gentry’s FHE scheme. We have now clarified and referenced this.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1514941365187,"tcdate":1514941365187,"number":1,"cdate":1514941365187,"id":"B1p3soF7z","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Comment","forum":"ByCPHrgCW","replyto":"HkCG-X5lG","signatures":["ICLR.cc/2018/Conference/Paper255/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper255/Authors"],"content":{"title":"Reply to AnonReviewer1","comment":"Thank you for your positive comments!\n\nTo clarify, our work can extend both TFHE, FHEW, or any system implementing Fully Homomorphic Encryption over binary. As part of our results, we compare TFHE and FHEW, to help show that advances in this field will continue to benefit our work directly, since we can support any new system with minimal effort. We have updated the start of the design section in our paper, to make this statement more carefully.\n\nTo address the notes:\n\nWe have fixed the AND table in Figure 4, thank you for pointing this out.\n\nFor Figure 2, we meant to show the operations getting applied in a linear order, but indeed 1+2*2=5. We have added brackets to Figure 2, and updated Figure 3 to show the process more clearly. Thank you again for finding this.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1516216926304,"tcdate":1511825686146,"number":3,"cdate":1511825686146,"id":"HkCG-X5lG","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Review","forum":"ByCPHrgCW","replyto":"ByCPHrgCW","signatures":["ICLR.cc/2018/Conference/Paper255/AnonReviewer1"],"readers":["everyone"],"content":{"title":"This paper proposes a hybrid Homomorphic  encryption system that is well suited for privacy-sensitive data inference applications with the deep learning paradigm. The research methodology is well organized, its rationale well explained and supports the stated problem resolution, the obtained results are interesting  and the paper is well written (commendable). ","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a hybrid Homomorphic encryption system that is well suited for privacy-sensitive data inference applications with the deep learning paradigm. \nThe paper presents a well laid research methodology that shows a good decomposition of the problem at hand and the approach foreseen to solve it. It is well reflected in the paper and most importantly the rationale for the implementation decisions taken is always clear.\n\nThe results obtained (as compared to FHEW) seem to indicate well thought off decisions taken to optimize the different gates' operations as clearly explained in the paper. For example, reducing bootstrapping operations by two-complementing both the plaintext and the ciphertext, whenever the number of 1s in the plain bit-string is greater than the number of 0s (3.4/Page 6).\n\nResult interpretation is coherent with the approach and data used and shows a good understanding of the implications of the implementation  decisions made in the system and the data sets used.\nOverall, fine work, well organized, decomposed, and its rationale clearly explained. The good results obtained support the design decisions made.\nOur main concern is regarding thorough comparison to similar work and provision of comparative work assessment to support novelty claims.\n\nNota: \n     - In Figure 4/Page 4: AND Table A(1)/B(0), shouldn't  A And B be 0?\n     - Unlike Figure 3/Page 3, in Figure 2/page 2, shouldn't  operations' precedence prevail (No brackets), therefore 1+2*2=5?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1515642418527,"tcdate":1511707313611,"number":2,"cdate":1511707313611,"id":"Sy52MUdgG","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Review","forum":"ByCPHrgCW","replyto":"ByCPHrgCW","signatures":["ICLR.cc/2018/Conference/Paper255/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review of \"Deep Learning Inferences with Hybrid Homomorphic Encryption\"","rating":"4: Ok but not good enough - rejection","review":"The paper presents a means of evaluating a neural network securely using homomorphic encryption. A neural network is already trained, and its weights are public. The network is to be evaluated over a private input, so that only the final outcome of the computation-and nothing but that-is finally learned.\n\nThe authors take a binary-circuit approach: they represent numbers via a fixed point binary representation, and construct circuits of secure adders and multipliers, based on homomorphic encryption as a building block for secure gates. This allows them to perform the vector products needed per layer; two's complement representation also allows for an \"easy\" implementation of the ReLU activation function, by \"checking\" (multiplying by) the complement of the sign bit. The fact that multiplication often involves public weights is used to speed up computations, wherever appropriate. A rudimentary  experimental evaluation with small networks is provided.\n\nAll of this is somewhat straightforward; a penalty is paid by representing numbers via fixed point arithmetic, which is used to deal with ReLU mostly. This is somewhat odd: it is not clear why, e.g., garbled circuits where not used for something like this, as it would have been considerably faster than FHE.\n\nThere is also a work in this area that the authors do not cite or contrast to, bringing the novelty into question; please see the following papers and references therein:\n\nGILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K., NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In Proceedings of The 33rd International Conference on Machine Learning (2016), pp. 201–210.\n\nSecureML: A System for Scalable Privacy-Preserving Machine Learning\nPayman Mohassel and Yupeng Zhang\n\nSHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning. In\nProceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), ACM, pp. 1310–1321.\n\nThe first paper is the most related, also using homomorphic encryption, and seems to cover a superset of the functionalities presented here (more activation functions, a more extensive analysis, and faster decryption times). The second paper uses arithmetic circuits rather than HE, but actually implements training an entire neural network securely.\n\n Minor details:\n\nThe problem scenario states that the model/weights is private, but later on it ceases to be so (weights are not encrypted).\n\n\"Both deep learning and FHE are relatively recent paradigms\". Deep learning is certainly not recent, while Gentry's paper is now 7 years old.\n\n\"In theory, this system alone could be used to compute anything securely.\" This is informal and incorrect. Can it solve the halting problem?\n\n\"However in practice the operations were incredibly slow, taking up to 30 minutes in some cases.\" It is unclear what operations are referred to here.\n\n\n\n\n\n\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1515642418598,"tcdate":1511701971758,"number":1,"cdate":1511701971758,"id":"rJhC64Olf","invitation":"ICLR.cc/2018/Conference/-/Paper255/Official_Review","forum":"ByCPHrgCW","replyto":"ByCPHrgCW","signatures":["ICLR.cc/2018/Conference/Paper255/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","rating":"4: Ok but not good enough - rejection","review":"Summary:\nThis paper proposes a framework for private deep learning model inference using FHE schemes that support fast bootstrapping.\nThe main idea of this paper is that in the two-party computation setting, in which the client's input is encrypted while the server's deep learning model is plain.\nThis \"hybrid\" argument enables to reduce the number of necessary bootstrapping, and thus can reduce the computation time.\nThis paper gives an implementation of adder and multiplier circuits and uses them to implement private model inference.\n\nComments:\n1. I recommend the authors to tone down their claims. For example, the authors mentioned that \"there has been no complete implementation of established deep learning approaches\" in the abstract, however, the authors did not define what is \"complete\". Actually, the SecureML paper in S&P'17 should be able to privately evaluate any neural networks, although at the cost of multi-round information exchanges between the client and server.\n\nAlso, the claim that \"we show efficient designs\" is very thin to me since there are no experimental comparisons between the proposed method and existing works. Actually, the level FHE can be very efficient with a proper use of message packing technique such as [A] and [C]. For a relatively shallow model (as this paper has used), level FHE might be faster than the binary FHE.\n\n2. I recommend the author to compare existing adder and multiplier circuits with your circuits to see in what perspective your design is better. I think the hybrid argument (i.e., when one input wire is plain) is a very common trick that used in the circuit design field, such as garbled circuit [B], to reduce the depth of the circuit. \n\n3. I appreciate that optimizations such as low-precision and point-wise convolution are discussed in this paper. Such optimizations are very common in deep learning field while less known in the field of security.\n\n[A]: Dowlin et al. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy.\n[B]: V. Kolesnikov et al. Improved garbled circuit: free xor gates and applications. \n[C]: Liu et al. Oblivious Neural Network Predictions via MiniONN transformations.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1514940608803,"tcdate":1509082470435,"number":255,"cdate":1509739398729,"id":"ByCPHrgCW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ByCPHrgCW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Deep Learning Inferences with Hybrid Homomorphic Encryption","abstract":"When deep learning is applied to sensitive data sets, many privacy-related implementation issues arise. These issues are especially evident in the healthcare, finance, law and government industries. Homomorphic encryption could allow a server to make inferences on inputs encrypted by a client, but to our best knowledge, there has been no complete implementation of common deep learning operations, for arbitrary model depths, using homomorphic encryption. This paper demonstrates a novel approach, efficiently implementing many deep learning functions with bootstrapped homomorphic encryption. As part of our implementation, we demonstrate Single and Multi-Layer Neural Networks, for the Wisconsin Breast Cancer dataset, as well as a Convolutional Neural Network for MNIST. Our results give promising directions for privacy-preserving representation learning, and the return of data control to users.\n\n","pdf":"/pdf/43dae54cad481416104f335c5fb25cd47ca4a89d.pdf","TL;DR":"We made a feature-rich system for deep learning with encrypted inputs, producing encrypted outputs, preserving privacy.","paperhash":"anonymous|deep_learning_inferences_with_hybrid_homomorphic_encryption","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning Inferences with Hybrid Homomorphic Encryption},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByCPHrgCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper255/Authors"],"keywords":["deep learning","homomorphic encryption","hybrid homomorphic encryption","privacy preserving","representation learning","neural networks"]},"nonreaders":[],"replyCount":7,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}