{"notes":[{"tddate":null,"ddate":null,"tmdate":1512371235026,"tcdate":1512321048095,"number":5,"cdate":1512321048095,"id":"Byeml2ZWM","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Comment","forum":"ByS1VpgRZ","replyto":"BJSIkW61f","signatures":["ICLR.cc/2018/Conference/Paper412/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper412/Authors"],"content":{"title":"Response to AnonReviewer3","comment":"\n> 1) Spatial resolution. What spatial resolution is the model generating images at?\n \nWe are sorry for the lack of the spatial resolution information. The model generates at \"128x128\" spatial resolution. \n\n\n> 1) Spatial resolution,  3) Conditional batch normalization,\n\nThe goal of our paper is to show the efficacy of our \"projection\" model for the discriminator, so all our experiments use same architecture for the generator.  In all our experiments, we are equipping the generator with conditional BN. This includes our experiments with \"AC-GANs\", as well as \"concat\" model and \"projection\" model.  \nWe can indeed explore the same result with generators equipped with a different way to introduce the conditional information (such as label concatenation); however, we intend not to make this (generator structure) the focus of our paper. On the base of our theoretical motivations, (Section 3) we also believe that our way will perform well even with a different way of label conditionalization of the generator.  \nWe would also like to emphasize that our projection model is prevailing on the super-resolution task as well, suggesting that our success is not the model and task specific. \nLastly, as interesting as it is, we would not find a way to include the dependence of the performance on the image resolution into the scope of our paper. \n\n\n>2) \n>FID in real data. The numbers in Table 1 appear favorable to the projection model. Please add error bars (based on Figure 4, I would imagine they are quite large).\n\nWe are sorry, but we are little confused about this suggestion. First of all, we are dealing with images from different classes in our experiments. The difficulty of image generation differs across each class, and the intra FID shall depend on the dataset of each class.  We, therefore, found no particular need for showing the size of its variance (error bar) in this experiment.  The goal of our Figure 4 here is to simply show that our projection method outperforms \"concat\" and \"AC-GANs\" on \"most of the classes\",  and we felt it more appropriate to visualize our claim with scatter plot. \n\n\n>Additionally, would it be possible to compute this statistic for *real* images? I would be curious to know what the FID looks like as a 'gold standard.'\n\nPlease take a look at the definition of FID(p5, (Heusel et al., 2017)) .  FID is a measure of a difference between two distributions. If there are infinitely many 'real' images, the FID between 'real' images against 'real' images is trivially 0.  In our paper, we are comparing the empirical distribution of generated samples over 5000 samples against the that of the training 'real' images.  If we compute the empirical distribution of 'real' images against another empirical distribution of the 'real' images,  we are bound to observe some nonzero FID value.  However, we find no particular importance in computing such value.  \n\n\n> Minor comments:\n>- I believe you have the incorrect reference for conditional batch normalization on Page 5.\n>- Please enlarge images in Figure 5-8. Hard to see the detail of 128x128 images.\n>- Please add citations for Figures 1a-1b. Do these correspond with some known models?\n\nThanks for pointing out the incorrect references! We would revise the designated citations accordingly. We would also like to modify the figure images to improve the visuality.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512339665846,"tcdate":1512319775679,"number":4,"cdate":1512319775679,"id":"HJd7sibbz","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Comment","forum":"ByS1VpgRZ","replyto":"rkyTeFweM","signatures":["ICLR.cc/2018/Conference/Paper412/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper412/Authors"],"content":{"title":"Response to AnonReviewer1","comment":"We are very glad to hear that you enjoy our manuscript!\n\n> While the paper admittedly leaves theoretical work for future work, the paper would be much stronger if the authors could perform an ablation study to provide readers with more intuition on why this work. One experiment could be: sticking y to every hidden layer of D before the current projection layer, and removing these y's increasingly and seeing how performance changes.\n>While the contribution is significant, more experiments providing more intuition into why this projection works so well would make the paper much stronger.\n\nAblation study was in fact a vexing issue in our paper, and we are still unsure of a way to theoretically back up our results. We may attempt your suggestion, and meanwhile continue looking for still other convincing experiments.\n\n\n> Should explicitly define p, q, r upfront before Equation 1 (or between Eq1 and Eq2).\n> PPG should be PPGNs.\n\nThanks for pointing out the mistakes! We will make changes accordingly in the revised version.\n  \n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512324826550,"tcdate":1512319569271,"number":3,"cdate":1512319569271,"id":"BJYUqi--G","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Comment","forum":"ByS1VpgRZ","replyto":"SynfBlcgf","signatures":["ICLR.cc/2018/Conference/Paper412/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper412/Authors"],"content":{"title":"Response to AnonReviewer2","comment":">What bothers me is mostly that, while hyperparameters are stated (and thank you for that), they seem to be optimized for the candidate method rather than the baseline. In particular, Beta1 = 0 for the Adam momentum coefficient seems like a bold choice based on my experience. \n\nWe did not perform any hyper-parameter optimization for the Adam optimizer and the number of critic updates, etc… \nWe just used the same hyper-parameters used in Gulrajani et al. (2017, https://github.com/igul222/improved_wgan_training/blob/master/gan_cifar_resnet.py ), because we adopted the practically the same architecture used in the very paper.   \nWe must admit that we simply could not spare enough time for the parameter search for the ImageNet experiments.  However, we plan to do the search for (beta1, alpha of Adam) on CIFAR 10 or CIFAR 100 and compare the performance against \"AC-GANs\", \"concat\" and \"projection\".\n\n>The sentence containing \"assume that the network model can be shared\" had me puzzled for a few minutes. I think what is meant here is just that we can parameterize the log density ratio directly (including some terms that belong to the data distribution to which we do not have explicit access). This could be clearer.\n\nThank you very much! We concur with you in your views and we will reflect the suggestion on this part of the revision.   \n \n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512319099718,"tcdate":1512319064094,"number":2,"cdate":1512319064094,"id":"ByeD_ibZz","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Comment","forum":"ByS1VpgRZ","replyto":"ByS1VpgRZ","signatures":["ICLR.cc/2018/Conference/Paper412/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper412/Authors"],"content":{"title":"Thank you so much for the reviews!","comment":"We thank all three reviewers for thorough reading of our manuscript and their comments and suggestions.\nWe responded to all the suggestions and made corrections for each reviewer’s comment separately."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1511965135231,"tcdate":1511965135231,"number":1,"cdate":1511965135231,"id":"HJP0Zr3ef","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Comment","forum":"ByS1VpgRZ","replyto":"r1-ygQixf","signatures":["ICLR.cc/2018/Conference/Paper412/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper412/Authors"],"content":{"title":"Thanks for pointing out the mistake!","comment":"We were clearly making typos in the reference. \nThe reference you mentioned is the very reference we intended to cite.  \nAs for the use of the word  “FiLM”, we would like to stick for now to the “conditional batch normalization” to make it easy for the readers to readily catch the framework of our algorithm.  "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1511890904853,"tcdate":1511890904853,"number":1,"cdate":1511890904853,"id":"r1-ygQixf","invitation":"ICLR.cc/2018/Conference/-/Paper412/Public_Comment","forum":"ByS1VpgRZ","replyto":"ByS1VpgRZ","signatures":["~Florian_Strub1"],"readers":["everyone"],"writers":["~Florian_Strub1"],"content":{"title":"Confusion in References ","comment":"In the paper, the authors use Conditional Batch Normalization and refer to the following paper:\nVincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropietro, and Aaron Courville. Adversarially learned inference. In ICLR, 2017.\nAlthough this paper is related to adversarial learning, it is not related to Conditional Batch Normalization.\n\nI believe there may be some confusion in the references. The following papers may be more relevant as they both introduce Conditional Normalization in different contexts:\nDumoulin, V., Shlens, J., and Kudlur, M. A learned representation for artistic style. In ICLR, 2017.\nde Vries, H., Strub, F., Mary, J., Larochelle, H., Pietquin, O., and Courville, A. Modulating early visual processing by language. In NIPS, 2017.\n\nInterestingly, subsequent work has shown that the effect of this form of conditioning can be decorrelated from normalization layers, thus referring to the method as Feature-wise Linear Modulation, or FiLM:\nPerez E., Strub F., de Vries H., Dumoulin V., Courville A. FiLM: Visual Reasoning with a General Conditioning Layer. In AAAI, 2018.\n\nIt may also be worthwhile to consider updating the name used in the paper from Conditional Batch Normalization to FiLM, to follow the latest literature on this method.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512222647560,"tcdate":1511814419597,"number":3,"cdate":1511814419597,"id":"SynfBlcgf","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Review","forum":"ByS1VpgRZ","replyto":"ByS1VpgRZ","signatures":["ICLR.cc/2018/Conference/Paper412/AnonReviewer2"],"readers":["everyone"],"content":{"title":"An unusually thorough GAN paper.","rating":"6: Marginally above acceptance threshold","review":"This manuscript makes the case for a particular parameterization of conditional GANs, specifically how to add conditioning information into the network.  It motivates the method by examining the form of the log density ratio in the continuous and discrete cases.\n\nThis paper's empirical work is quite strong, bringing to bare nearly all of the established tools we currently have for evaluating implicit image models (MS-SSIM, FID, Inception scores). \n\nWhat bothers me is mostly that, while hyperparameters are stated (and thank you for that), they seem to be optimized for the candidate method rather than the baseline. In particular, Beta1 = 0 for the Adam momentum coefficient seems like a bold choice based on my experience. It would be an easier sell if hyperparameter search details were included and a separate hyperparameter search were conducted for the candidate and control, allowing the baseline to put its best foot forward.\n\nThe sentence containing \"assume that the network model can be shared\" had me puzzled for a few minutes. I think what is meant here is just that we can parameterize the log density ratio directly (including some terms that belong to the data distribution to which we do not have explicit access). This could be clearer.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512222647600,"tcdate":1511653559376,"number":2,"cdate":1511653559376,"id":"rkyTeFweM","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Review","forum":"ByS1VpgRZ","replyto":"ByS1VpgRZ","signatures":["ICLR.cc/2018/Conference/Paper412/AnonReviewer1"],"readers":["everyone"],"content":{"title":"simple, interesting GAN modification; great results","rating":"7: Good paper, accept","review":"The paper proposes a simple modification to conditional GANs, obtaining impressive results on both the quality and diversity of samples on ImageNet dataset. Instead of concatenating the condition vector y to the input image x or hidden layers of the discriminator D as in the literature, the authors propose to project the condition y onto a penultimate feature space V of D (by simply taking an inner product between y and V) . This implementation basically restricts the conditional distribution p(y|x) to be really simple and seems to be posing a good prior leading to great empirical results.\n\n+ Quality:\n- Simple method leading to great results on ImageNet!\n- While the paper admittedly leaves theoretical work for future work, the paper would be much stronger if the authors could perform an ablation study to provide readers with more intuition on why this work. One experiment could be: sticking y to every hidden layer of D before the current projection layer, and removing these y's increasingly and seeing how performance changes.\n- Appropriate comparison with existing conditional models: AC-GANs and PPGNs.\n- Appropriate (extensive) metrics were used (Inception score/accuracy, MS-SSIM, FID)\n\n+ Clarity:\n- Should explicitly define p, q, r upfront before Equation 1 (or between Eq1 and Eq2).\n- PPG should be PPGNs.\n\n+ Originality:\nThis work proposes a simple method that is original compared existing GANs.\n\n+ Significance:\nWhile the contribution is significant, more experiments providing more intuition into why this projection works so well would make the paper much stronger.\n\nOverall, I really enjoy reading this paper and recommend for acceptance!\n\n\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1512222647643,"tcdate":1510965068580,"number":1,"cdate":1510965068580,"id":"BJSIkW61f","invitation":"ICLR.cc/2018/Conference/-/Paper412/Official_Review","forum":"ByS1VpgRZ","replyto":"ByS1VpgRZ","signatures":["ICLR.cc/2018/Conference/Paper412/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Review of cGAN with projection discriminator","rating":"6: Marginally above acceptance threshold","review":"The authors describe a new variant of a generative adversarial network (GAN) for generating images. This model employs a 'projection discriminator' in order to incorporate image labels and demonstrate that the resulting model outperforms state-of-the-art GAN models.\n\nMajor comments:\n1) Spatial resolution. What spatial resolution is the model generating images at? The AC-GAN work performed an analysis to assess how information is being introduced at each spatial resolution by assessing the gains in the Inception score versus naively resizing the image. It is not clear how much the gains of this model is due to generating better lower resolution images and performing simple upscaling. It would be great to see the authors address this issue in a serious manner.\n\n2) FID in real data. The numbers in Table 1 appear favorable to the projection model. Please add error bars (based on Figure 4, I would imagine they are quite large). Additionally, would it be possible to compute this statistic for *real* images? I would be curious to know what the FID looks like as a 'gold standard'.\n\n3) Conditional batch normalization.  I am not clear how much of the gains arose from employing conditional batch normalization versus the proposed method for incorporating the projection based discriminator. The former has been seen to be quite powerful in accomodating multi-modal tasks (e.g. https://arxiv.org/abs/1709.07871, https://arxiv.org/abs/1610.07629\n). If the authors could provide some evidence highlighting the marginal gains of one technique, that would be extremely helpful.\n\nMinor comments:\n- I believe you have the incorrect reference for conditional batch normalization on Page 5.\nA Learned Representation For Artistic Style\nDumoulin, Shlens and Kudlur (2017)\nhttps://arxiv.org/abs/1610.07629\n\n- Please enlarge images in Figure 5-8. Hard to see the detail of 128x128 images.\n\n- Please add citations for Figures 1a-1b. Do these correspond with some known models?\n\nDepending on how the authors respond to the reviews, I would consider upgrading the score of my review.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]}},{"tddate":null,"ddate":null,"tmdate":1509739318596,"tcdate":1509114845034,"number":412,"cdate":1509739315914,"id":"ByS1VpgRZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ByS1VpgRZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"cGANs with Projection Discriminator","abstract":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. \nThis approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. \nWith this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (ImageNet) dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. \nWe were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. \nThis new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator.","pdf":"/pdf/f4da5ede8da8acd0eeebe9f4e6acca184acb23be.pdf","TL;DR":"We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model.","paperhash":"anonymous|cgans_with_projection_discriminator","_bibtex":"@article{\n  anonymous2018cgans,\n  title={cGANs with Projection Discriminator},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByS1VpgRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper412/Authors"],"keywords":["Generative Adversarial Networks","GANs","conditional GANs","Generative models","Projection"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}