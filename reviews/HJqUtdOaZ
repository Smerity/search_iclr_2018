{"notes":[{"tddate":null,"ddate":null,"tmdate":1515642434448,"tcdate":1511860530647,"number":3,"cdate":1511860530647,"id":"r1o4FsqgM","invitation":"ICLR.cc/2018/Conference/-/Paper34/Official_Review","forum":"HJqUtdOaZ","replyto":"HJqUtdOaZ","signatures":["ICLR.cc/2018/Conference/Paper34/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This work does not have the quality to be accepted at ICLR.","rating":"2: Strong rejection","review":"The main issue is the scientific quality. What the authors call \"intelligent mapping and combining system\" for the proposed system is simply a fully connected neural network. Such systems have been largely investigated in the literature. The use of genetic algorithms has also been considered. Moreover, mapping features to some appropriate feature space has been widely investigated, including the choice of appropriate mapping. We didn't find anything \"intelligent\" in the proposed mapping. \n\nThere are many spelling and grammatical errors.\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES","abstract":"Automatic classification of objects is one of the most important tasks in engineering\nand data mining applications. Although using more complex and advanced\nclassifiers can help to improve the accuracy of classification systems, it can be\ndone by analyzing data sets and their features for a particular problem. Feature\ncombination is the one which can improve the quality of the features. In this paper,\na structure similar to Feed-Forward Neural Network (FFNN) is used to generate an\noptimized linear or non-linear combination of features for classification. Genetic\nAlgorithm (GA) is applied to update weights and biases. Since nature of data sets\nand their features impact on the effectiveness of combination and classification\nsystem, linear and non-linear activation functions (or transfer function) are used\nto achieve more reliable system. Experiments of several UCI data sets and using\nminimum distance classifier as a simple classifier indicate that proposed linear and\nnon-linear intelligent FFNN-based feature combination can present more reliable\nand promising results. By using such a feature combination method, there is no\nneed to use more powerful and complex classifier anymore.","pdf":"/pdf/6688e99d4fcae355db8ba20fe76081f0346fd525.pdf","TL;DR":"A method for enriching and combining features to improve classification accuracy","paperhash":"anonymous|enrichment_of_features_for_classification_using_an_optimized_linearnonlinear_combination_of_input_features","_bibtex":"@article{\n  anonymous2018enrichment,\n  title={ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJqUtdOaZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper34/Authors"],"keywords":["Classification","Feature Combination","Feature Mapping","Feed-Forward Neural Network","Genetic Algorithm","Linear Transfer Function","Non-Linear Transfer Function"]}},{"tddate":null,"ddate":null,"tmdate":1515642434487,"tcdate":1511814479414,"number":2,"cdate":1511814479414,"id":"rkvIrecgG","invitation":"ICLR.cc/2018/Conference/-/Paper34/Official_Review","forum":"HJqUtdOaZ","replyto":"HJqUtdOaZ","signatures":["ICLR.cc/2018/Conference/Paper34/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Unclear what contributions are","rating":"3: Clear rejection","review":"This paper proposes using a feedforward neural network (FFNN) to extract intermediate features which are input to a 1NN classifier. The parameters of the FFNN are updated via a genetic algorithm with a fitness function defined as the error on the downstream classification, on a held-out set. The performance of this approach is measured on several UCI datasets and compared with baselines.\n– The paper’s main contribution seems to be a neural network with a GA optimization for classification that can learn “intelligent combinations of features”, which can be easily classified by a simple 1NN classifier. But isn't this exactly what neural networks do – learn intelligent combinations of features optimized (in this case, via GA) for a downstream task? This has already been successfully applied in multiple domains eg. in computer vision (Krizhevsky et al, NIPS 2011), NLP (Bahdanau et al 2014), image retrieval (Krizhevsky et al. ESANN 2011) etc, and also studied comprehensively in autoencoding literature. There also exists prior work on optimizing neural nets via GA (Leung, Frank Hung-Fat et al., IEEE Transactions on Neural networks 2003). However, this paper claims both as novelties while not offering any improvement / comparison. \n– The claim “there is no need to use more powerful and complex classifier anymore” is unsubstantiated, as the paper’s approach still entails using a complex classifier (a FFNN) to learn an optimal intermediate representation.\n– The choice of activations is not motivated, and performance on variants is not reported. For instance, why is that particular sigmoid formulation used? \n– The use for a genetic algorithm for optimization is not motivated, and no comparison is made to the performance and efficiency of other approaches (like standard backpropagation). So it is unclear why GA makes for a better choice of optimization, if at all.\n– The primary baselines compared to are unsupervised methods (PCA and LDA), and so demonstrating improvements over those with a supervised representation does not seem significant or surprising. It would be useful to compare with a simple neural network baseline trained for K-way classification with standard backpropagation (though the UCI datasets may potentially be too small to achieve good performance).\n– The paper is poorly written, containing several typos and incomplete, unintelligible sentences, incorrect captions (eg. Table 4) etc.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES","abstract":"Automatic classification of objects is one of the most important tasks in engineering\nand data mining applications. Although using more complex and advanced\nclassifiers can help to improve the accuracy of classification systems, it can be\ndone by analyzing data sets and their features for a particular problem. Feature\ncombination is the one which can improve the quality of the features. In this paper,\na structure similar to Feed-Forward Neural Network (FFNN) is used to generate an\noptimized linear or non-linear combination of features for classification. Genetic\nAlgorithm (GA) is applied to update weights and biases. Since nature of data sets\nand their features impact on the effectiveness of combination and classification\nsystem, linear and non-linear activation functions (or transfer function) are used\nto achieve more reliable system. Experiments of several UCI data sets and using\nminimum distance classifier as a simple classifier indicate that proposed linear and\nnon-linear intelligent FFNN-based feature combination can present more reliable\nand promising results. By using such a feature combination method, there is no\nneed to use more powerful and complex classifier anymore.","pdf":"/pdf/6688e99d4fcae355db8ba20fe76081f0346fd525.pdf","TL;DR":"A method for enriching and combining features to improve classification accuracy","paperhash":"anonymous|enrichment_of_features_for_classification_using_an_optimized_linearnonlinear_combination_of_input_features","_bibtex":"@article{\n  anonymous2018enrichment,\n  title={ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJqUtdOaZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper34/Authors"],"keywords":["Classification","Feature Combination","Feature Mapping","Feed-Forward Neural Network","Genetic Algorithm","Linear Transfer Function","Non-Linear Transfer Function"]}},{"tddate":null,"ddate":null,"tmdate":1515642434527,"tcdate":1511604584642,"number":1,"cdate":1511604584642,"id":"rkbO-pIgf","invitation":"ICLR.cc/2018/Conference/-/Paper34/Official_Review","forum":"HJqUtdOaZ","replyto":"HJqUtdOaZ","signatures":["ICLR.cc/2018/Conference/Paper34/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Very poorly written paper that optimises a two layer neural network for feature generation using genetic algorithms.","rating":"1: Trivial or wrong","review":"The paper presents a method for feature projection which uses a two level neural network like structure to generate new features from the input features. The weights of the NN like structure are optimised using a genetic search algorithm which optimises the cross-validation error of a nearest neighbor classifier. The method is tested on four simple UCI datasets. There is nothing interesting or novel about the paper. It is not clear whether the GA optimisation takes place on the level of cross validation error estimation or within an internal validation set as it should have been the case. The very high accuracies reported seem to hint the latter, which is a serious methodological error. The poor language and presentation does not help in clearing that, as it does not help in general. ","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES","abstract":"Automatic classification of objects is one of the most important tasks in engineering\nand data mining applications. Although using more complex and advanced\nclassifiers can help to improve the accuracy of classification systems, it can be\ndone by analyzing data sets and their features for a particular problem. Feature\ncombination is the one which can improve the quality of the features. In this paper,\na structure similar to Feed-Forward Neural Network (FFNN) is used to generate an\noptimized linear or non-linear combination of features for classification. Genetic\nAlgorithm (GA) is applied to update weights and biases. Since nature of data sets\nand their features impact on the effectiveness of combination and classification\nsystem, linear and non-linear activation functions (or transfer function) are used\nto achieve more reliable system. Experiments of several UCI data sets and using\nminimum distance classifier as a simple classifier indicate that proposed linear and\nnon-linear intelligent FFNN-based feature combination can present more reliable\nand promising results. By using such a feature combination method, there is no\nneed to use more powerful and complex classifier anymore.","pdf":"/pdf/6688e99d4fcae355db8ba20fe76081f0346fd525.pdf","TL;DR":"A method for enriching and combining features to improve classification accuracy","paperhash":"anonymous|enrichment_of_features_for_classification_using_an_optimized_linearnonlinear_combination_of_input_features","_bibtex":"@article{\n  anonymous2018enrichment,\n  title={ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJqUtdOaZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper34/Authors"],"keywords":["Classification","Feature Combination","Feature Mapping","Feed-Forward Neural Network","Genetic Algorithm","Linear Transfer Function","Non-Linear Transfer Function"]}},{"tddate":null,"ddate":null,"tmdate":1509739519891,"tcdate":1508571473756,"number":34,"cdate":1509739517234,"id":"HJqUtdOaZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJqUtdOaZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES","abstract":"Automatic classification of objects is one of the most important tasks in engineering\nand data mining applications. Although using more complex and advanced\nclassifiers can help to improve the accuracy of classification systems, it can be\ndone by analyzing data sets and their features for a particular problem. Feature\ncombination is the one which can improve the quality of the features. In this paper,\na structure similar to Feed-Forward Neural Network (FFNN) is used to generate an\noptimized linear or non-linear combination of features for classification. Genetic\nAlgorithm (GA) is applied to update weights and biases. Since nature of data sets\nand their features impact on the effectiveness of combination and classification\nsystem, linear and non-linear activation functions (or transfer function) are used\nto achieve more reliable system. Experiments of several UCI data sets and using\nminimum distance classifier as a simple classifier indicate that proposed linear and\nnon-linear intelligent FFNN-based feature combination can present more reliable\nand promising results. By using such a feature combination method, there is no\nneed to use more powerful and complex classifier anymore.","pdf":"/pdf/6688e99d4fcae355db8ba20fe76081f0346fd525.pdf","TL;DR":"A method for enriching and combining features to improve classification accuracy","paperhash":"anonymous|enrichment_of_features_for_classification_using_an_optimized_linearnonlinear_combination_of_input_features","_bibtex":"@article{\n  anonymous2018enrichment,\n  title={ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJqUtdOaZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper34/Authors"],"keywords":["Classification","Feature Combination","Feature Mapping","Feed-Forward Neural Network","Genetic Algorithm","Linear Transfer Function","Non-Linear Transfer Function"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}