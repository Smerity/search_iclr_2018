{"notes":[{"tddate":null,"ddate":null,"tmdate":1514999852435,"tcdate":1514999852435,"number":2,"cdate":1514999852435,"id":"HJVVl5q7M","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Comment","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper592/Authors"],"content":{"title":"Update","comment":"The latest submission has the following updates:\n\n1. Added captions to Figures 3 and 4 in Section 1\n2. Fixed typos as pointed out by reviewer3 in sections 2.3.1, 3.1 and 4\n3. Reworded a few phrases in Sections 4 and A\n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1514428936321,"tcdate":1514428936321,"number":4,"cdate":1514428936321,"id":"HJgG5RbXM","invitation":"ICLR.cc/2018/Conference/-/Paper592/Public_Comment","forum":"HymYLebCb","replyto":"r1jbeZ9xM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Response","comment":"Thank you for your review.\n\n1. We have moved the extra details about datasets and classifiers from the methodology section to the Appendix in the interest of space. Is there any specific detail the reviewer expects to be included in this section?\n\n2. We have fixed the other issues you have raised."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1514426334489,"tcdate":1514426334489,"number":3,"cdate":1514426334489,"id":"SyLJxCbXG","invitation":"ICLR.cc/2018/Conference/-/Paper592/Public_Comment","forum":"HymYLebCb","replyto":"SJBw7As1f","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Response","comment":"Thank you for your comments. We address the main comments separately.\n\n1. \"It is surprising that the method works and it is unprincipled.\" The whole purpose of input representation is to find the right input representation such that a SIMPLE model with access to little data can perform good test prediction. It is not surprising that the method works since the encoding of the graph into the image is LOSSLESS. It is surprising that the graph image-feature works with simple models, that is the whole point of the paper. We do not understand in what sense the feature is unprincipled. The feature suitably reorders the vertices in the graph so that structural information information of the graph can be represented by spatial organization within the image. In the same vein, one could say that convolutional features which represent image information at different scales are unprincipled.\n\n2. \"but this doesn't really suggest a generalizable method.\" We showed results of blindly applying the feature to 9 different networks drawn from various application domains ranging from social networks to physical networks like road networks. The performance of this feature consistently outperforms all  other methods, which suggests that the method is generalizable.\n\n3. \"I didn't spot exactly what the classification task was\" We tried to make this clear in Figure 1: Given a small subgraph, identify what type of parent graph it came from.\n\n4. \"I'm not sure how relevant this graph classification task is.\" Graph and subgraph classification is a large domain with a large amount of research ranging from standard learning methods based on classical graph features to kernel methods and so on. The specific task considered in this paper is merely a formalization of this task in which the class of a graph is determined by its parent graph.\n\nThe intuition behind this work: Deep learning models are highly capable of classifying structured real world images. We leverage this strength to classify subgraphs using the structured image embeddings we obtain that are a lossless representation of graphs. We also show that even when using a model (Caffe) that was trained in a completely different domain (real world images - ImageNet), the structured representation is powerful enough to provide more than meaningful results. You mention \"... the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs ...\" in your review. We think that you are conflating the two very different approaches we are proposing in this paper.\n\n5. \"In particular the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs.\" We believe the reviewer missed this part of the paper. We demonstrated the valuused the image feature in TWO ways:\n\n  (a) (The main way) To train a classifier to classify graphs from scratch in a standard machine learning framework. Here we used several different learning models, including deep networks, kernels and standard models like regression based on classical graph features. Performance of our image feature is impressive (our opinion) compared to all other traditional features, and deep networks performed best.\n\n  (b) (The secondary way) In a pure transfer learning setting, we simply used the Caffe classifier trained on image-Net with NO further training except for applying a k-NN on the Caffe output. This mode of classification shows that the image can be treated as a traditional image since Caffe is trained on traditional images, and further, the performance is impressive, which means that this transfer setting can be used when there is limited training data in the original graph domain.\n\nWe hope that we have addressed the concerns of the reviewer."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1514425555682,"tcdate":1514425555682,"number":2,"cdate":1514425555682,"id":"HyhR2pZmf","invitation":"ICLR.cc/2018/Conference/-/Paper592/Public_Comment","forum":"HymYLebCb","replyto":"ry9izvnlf","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Response","comment":"Thank you for your review.\nWe emphasize that the main focus of the paper is to present the power of the image feature created by lossless \"embedding\" of the adjacency matrix as an image. We use this image feature in two ways:\n1. To train a classifier from scratch in a standard machine learning framework. Here we used several different models, including deep networks. Performance of this feature is impressive compared to other traditional features, and deep networks performed best.\n2. In a pure transfer learning setting we simply used the Caffe classifier trained on image-Net with NO further training except for applying a k-NN on the Caffe output. This mode of classification shows that the image can be treated as a traditional image and can be used when there is limited training data.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1515642475925,"tcdate":1511973538483,"number":3,"cdate":1511973538483,"id":"ry9izvnlf","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"readers":["everyone"],"content":{"title":"interesting idea","rating":"6: Marginally above acceptance threshold","review":"This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I do not understand the intuition behind the success of analogizing graph with images.\n\nFundamentally, a convolutional filter stands for a operation within a small neighborhood on the image. However, it is unclear how it means for the graph representation. Is the neighborhood predefined? Are the graph nodes pre-ordered? \n\nI am also curious with the effect of pre-trained model from ImageNet. Since the graph presentation does not use color channels,  pre-trained model is used different from what it was designed to. I would imagine the benefit of using ImageNet is just to bring a random, high-dimensional embedding.  In addition, I wonder whether it will help to fine-tune the model on the graph classification data. Could this submission show some fine-tune experiments?","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1515642475962,"tcdate":1511817219465,"number":2,"cdate":1511817219465,"id":"r1jbeZ9xM","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Good paper","rating":"6: Marginally above acceptance threshold","review":"The paper proposed a subgraph image representation and validate it in image classification and transfer learning problems. The image presentation is a minor extension based on a method of producing permutation-invariant adjacency matrix. The experimental results supports the claim.\n\nIt is very positive that the figures are very helpful for delivering the information.\n\nThe work seems to be a little bit incremental. The proposed image representation is mainly based on a previous work of permutation-invariant adjacency matrix. A novelty of this work seems to be transforming a graph into an image. By the proposed representation, the authors are able to apply image classification methods (supervised or unsupervised) to subgraph classification. \n\nIt will be better if the authors could provide more details in the methodology or framework section.\n\nThe experiments on 9 networks support the claims that the image embedding approaches with their image representation of the subgraph outperform the graph kernel and classical features based methods. It seem to be promising when using transfer learning.\n\nThe last two process figures in 1.1 can be improved. No caption or figure number is provided.\n\nIt will be better to make the notations easy to understand and avoid any notation in a sentence without explanation nearby.\nFor example:\n\"the test example is correctly classified if and only if its ground truth matches C.\"(P5)\n\"We carry out this exercise 4 times and set n to 8, 16, 32 and 64 respectively.\"(P6)\n\nSome minor issues:\n\"Zhu et al.(2011) discuss heterogeneous transfer learning where in they use...\"(P3)\n\"Each label vector (a tuple of label, label-probability pairs).\" (incomplete sentence?P5)","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1511650758810,"tcdate":1511650758810,"number":1,"cdate":1511650758810,"id":"rJyCr_Pef","invitation":"ICLR.cc/2018/Conference/-/Paper592/Public_Comment","forum":"HymYLebCb","replyto":"ry6_ZhLgM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Response","comment":"Thanks for the comment. Please see the responses below.\n\n1. what is the physical meaning of CNN filters respond to the graph representation?\n- I'm not sure I understood your question correctly. I'm assuming you meant image embeddings by \"graph representation\". From CNN's perspective, the structured image embeddings are like any other images. The fact that these structured image embeddings were obtained from adjacency matrices has no effect on CNN. \n\n2. for images from ImageNet, each pixel is represented by 3 color channels (RGB). Will the adjacent matrices representation use such channels?\n\n- Caffe (trained on ImageNet) takes in black & white/grayscale images as input as well. The structured image embeddings of the adjacency matrices do not have to be modified in any way.\n\n3. if we shuffle the order of graph nodes,  the rows/columns  in adjacent matrix will exchange. Will the image based classification result be the same?\n\n- Yes. The shuffling of the order of the nodes in the adjacency matrices does not affect classification. This is because we apply a structuring process on the matrices before we obtain the image embeddings. This ensures that no matter the arrangement of the nodes, the image embedding produces the same structure for a given adjacency matrix. It's permutation invariant. See Section 2.1 for details.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1511600500802,"tcdate":1511600500802,"number":1,"cdate":1511600500802,"id":"ry6_ZhLgM","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Comment","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"content":{"title":"what does the image filter mean for adjacent matrices?","comment":"This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I have difficulty to understand the intuition behind the success of analogizing graph with images. More specifically,  I wonder\n\n1. what is the physical meaning of CNN filters respond to the graph representation?\n\n2. for images from ImageNet, each pixel is represented by 3 color channels (RGB). Will the adjacent matrices representation use such channels?\n\n3. if we shuffle the order of graph nodes,  the rows/columns  in adjacent matrix will exchange. Will the image based classification result be the same?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1515642475999,"tcdate":1510888284682,"number":1,"cdate":1510888284682,"id":"SJBw7As1f","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Surprising that the method works, but the method is too unprincipled for me to really see the value of it.","rating":"3: Clear rejection","review":"The paper proposes to use 2-d image representation techniques as a means of learning representations of graphs via their adjacency matrices. The adjacency matrix (or a subgraph of it) is first re-ordered to produce some canonical ordering which can then be fed into an image representation method. This can then be fed into a classifier.\n\nThis is a little too unprincipled for my taste. In particular the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs. Perhaps this is due to a lack of available graph training data, but it doesn't seem to make a lot of sense.\n\nMaybe I missed or overlooked some detail, but I didn't spot exactly what the classification task was. I think the goal is to identify which of the graphs a subgraph belongs to? I'm not sure how relevant this graph classification task is. \n\nThe method does prove that the Caffe reference model maintains some information that can be used for classification, but this doesn't really suggest a generalizable method that we could confidently use for a variety of tasks. It's surprising that it works at all, but ultimately doesn't reveal a big scientific finding that could be re-used.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1514999463581,"tcdate":1509127803175,"number":592,"cdate":1509739210680,"id":"HymYLebCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HymYLebCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/014b12dd6f73eb2b858c6b1799fda34223702a76.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}