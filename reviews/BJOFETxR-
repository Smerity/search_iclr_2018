{"notes":[{"tddate":null,"ddate":null,"tmdate":1512402404016,"tcdate":1512402404016,"number":1,"cdate":1512402404016,"id":"Hy3kAkmZM","invitation":"ICLR.cc/2018/Conference/-/Paper415/Public_Comment","forum":"BJOFETxR-","replyto":"BJOFETxR-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Missing related work and incorrect claims","comment":"While the overall direction is promising, there are several serious issues with this paper which affect the novelty and validity of its results:\n\n1) It achieves significantly worse results than state-of-the-art without comparing to it.\n\nFor the variable naming task, the state-of-the-art approach achieves 79.1% for Obfuscated Android applications [1] (source code available online at http://nice2predict.org/). In comparison, this work achieves accuracy 19.3% which is 4x lower. These results are however not even mentioned in the paper. Worse, prior work considers a more difficult task in which all program identifiers are initially unknown. In contrast, the task considered here renames each variable separately, while knowing the correct names of all other variables.\n\nIncorrect claims made in the paper:\n\n2) [Introduction] Existing models of source code capture its shallow, textual structure while this work is the first to use source code semantics by incorporating data-flow and type hierarchy information.\n\nThis is not true.  The whole point of many recent works is exactly to not learn over shallow syntactic representations but to leverage semantic information. For example,  [1][2] introduce semantic relations between program elements (including data-flow, e.g., initialized-by, read-before, wrote-before, and others), [3,8] use semantic analysis to extract sequences of method calls on a given object,  [4,5] use both structural dependencies extracted from AST and data dependencies computed via semantic analysis, graph based approaches such as [7], etc. [6] even tries to learn such semantic dependencies automatically instead of providing it by hand as part of the model.  \n\n3) [Related Work] We are not aware of any model that does use data flow information.\n\nSee above -- many works in this domain use data flow information. \n\n4) [Introduction] Our key insight is that exposing these semantics explicitly as structured input to a machine learning model lessens the requirements on amounts of training data, model capacity and training regime.\n\nThis is not a new insight and has been done before across various applications in modeling source code. For example, in [3] the authors quantify the information provided by alias analysis enables the model to be learned with 10x less data while achieving the same accuracy (for API completion task).  Similarly, in [8].\n\n5) [Introduction] Exposing these semantics explicitly as structured input allows us to solve tasks that are beyond the current state of the art.\n\nThis is again not true. Quite the opposite, the model presented here has 4x worse accuracy than state-of-the-art for variable renaming. \n\nComments:\n6) Variable misuse task problem formulation is problematic.\n\nThe formulation purely based on a probabilistic model is problematic â€” a probabilistic model cannot differentiate between code that is wrong from code that is rare or simply less likely (which is what the proposed model does).  As a result, even if a probabilistic model is trained on a corpus that has no bugs, it will not achieve 100% prediction accuracy. For any large codebase such model will inherently report a large amount of benign warnings even if the model is 99% accurate. This is the reason why existing bug finding tools use additional forms of specification extracted either from language semantics (e.g., null pointer checks, out of bounds checks, type safety) or provided by a user (pre/post conditions and invariants). It would be interesting to see if having a prior over possible bug locations (which is what the probabilistic model computes) can help these existing techniques to work more efficiently, but this is not discussed in the paper.\n\nReferences:\n[1] Statistical Deobfuscation of Android Applications. Bichsel et.al., ACM CCS'16\n[2] Predicting Program Properties from \"Big Code\". Raychev et.al., ACM POPL'15 \n[3] Code Completion with Statistical Language Models. Raychev. et. al., ACM PLDI'14\n[4] A statistical semantic language model for source code. Nguyen et al. ACM ESEC/FSE'13\n[5] Using web corpus statistics for program analysis. Hsiao et. al. ACM OOPSLA'14\n[6] Program Synthesis for Character Level Language Modeling, Bielik et. al., ICLR'17\n[7] Graph-Based Statistical Language Model for Code. Ngyuen et. al. ICSE'15\n[8] Estimating Types in Binaries using Predictive Modeling, Kata et. al., ACM POPL'16"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to Represent Programs with Graphs","abstract":"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.","pdf":"/pdf/2eaa0cafc46d88234facadff3fb91c1f10598930.pdf","TL;DR":"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs","paperhash":"anonymous|learning_to_represent_programs_with_graphs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to Represent Programs with Graphs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJOFETxR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper415/Authors"],"keywords":["programs","source code","graph neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1512222648026,"tcdate":1512191795431,"number":3,"cdate":1512191795431,"id":"H1oEvnkWM","invitation":"ICLR.cc/2018/Conference/-/Paper415/Official_Review","forum":"BJOFETxR-","replyto":"BJOFETxR-","signatures":["ICLR.cc/2018/Conference/Paper415/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting software mining application with substantial validation","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper presents a novel application of machine learning using Graph NN's on ASTs to identify incorrect variable usage and predict variable names in context. It is evaluated on a corpus of 29M SLOC, which is a substantial strength of the paper.\n\nThe paper is to be commended for the following aspects:\n1) Detailed description of GGNNs and their comparison to LSTMs\n2) The inclusion of ablation studies to strengthen the analysis of the proposed technique\n3) Validation on real-world software data\n4) The performance of the technique is reasonable enough to actually be used.\n\nIn reviewing the paper the following questions come to mind:\n1) Is the false positive rate too high to be practical?  How should this be tuned so developers would want to use the tool?\n2) How does the approach generalize to other languages? (Presumably well, but something to consider for future work.)\n\nDespite these questions, though, this paper is a nice addition to deep learning applications on software data and I believe it should be accepted.\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to Represent Programs with Graphs","abstract":"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.","pdf":"/pdf/2eaa0cafc46d88234facadff3fb91c1f10598930.pdf","TL;DR":"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs","paperhash":"anonymous|learning_to_represent_programs_with_graphs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to Represent Programs with Graphs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJOFETxR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper415/Authors"],"keywords":["programs","source code","graph neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1512222648065,"tcdate":1512032116318,"number":2,"cdate":1512032116318,"id":"rkhdDBalz","invitation":"ICLR.cc/2018/Conference/-/Paper415/Official_Review","forum":"BJOFETxR-","replyto":"BJOFETxR-","signatures":["ICLR.cc/2018/Conference/Paper415/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Creative and interesting","rating":"8: Top 50% of accepted papers, clear accept","review":"The paper introduces an application of Graph Neural Networks (Li's Gated Graph Neural Nets, GGNNs, specifically) for reasoning about programs and programming. The core idea is to represent a program as a graph that a GGNN can take as input, and train the GGNN to make token-level predictions that depend on the semantic context. The two experimental tasks were: 1) identifying variable (mis)use, ie. identifying bugs in programs where the wrong variable is used, and 2) predicting a variable's name by consider its semantic context.\n\nThe paper is generally well written, easy to read and understand, and the results are compelling. The proposed GGNN approach outperforms (bi-)LSTMs on both tasks. Because the tasks are not widely explored in the literature, it could be difficult to know how crucial exploiting graphically structured information is, so the authors performed several ablation studies to analyze  this out. Those results show that as structural information is removed, the GGNN's performance diminishes, as expected. As a demonstration of the usefulness of their approach, the authors ran their model on an unnamed open-source project and claimed to find several bugs, at least one of which potentially reduced memory performance.\n\nOverall the work is important, original, well-executed, and should open new directions for deep learning in program analysis. I recommend it be accepted.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to Represent Programs with Graphs","abstract":"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.","pdf":"/pdf/2eaa0cafc46d88234facadff3fb91c1f10598930.pdf","TL;DR":"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs","paperhash":"anonymous|learning_to_represent_programs_with_graphs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to Represent Programs with Graphs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJOFETxR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper415/Authors"],"keywords":["programs","source code","graph neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1512222648104,"tcdate":1511832943807,"number":1,"cdate":1511832943807,"id":"ryuuTE9gG","invitation":"ICLR.cc/2018/Conference/-/Paper415/Official_Review","forum":"BJOFETxR-","replyto":"BJOFETxR-","signatures":["ICLR.cc/2018/Conference/Paper415/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Beautiful application, nicely evaluated.  Evaluation could be a bit better, but easily fixed.","rating":"8: Top 50% of accepted papers, clear accept","review":"Summary:  The paper applies graph convolutions with deep neural networks to the problem of \"variable misuse\" (putting the wrong variable name in a program statement) in graphs created deterministically from source code.  Graph structure is determined by program abstract syntax tree (AST) and next-token edges, as well as variable/function name identity, assignment and other deterministic semantic relations.  Initial node embedding comes from both type and tokenized name information.  Gated Graph Neural Networks (GGNNs, trained by maximum likelihood objective) are then run for 8 iterations at test time.\n\nThe evaluation is extensive and mostly very good.  Substantial data set of 29m lines of code.  Reasonable baselines.  Nice ablation studies.  I would have liked to see separate precision and recall rather than accuracy.  The current 82.1% accuracy is nice to see, but if 18% of my program variables were erroneously flagged as errors, the tool would be useless.  I'd like to know if you can tune the threshold to get a precision/recall tradeoff that has very few false warnings, but still catches some errors.\n\nNice work creating an implementation of fast GGNNs with large diverse graphs.  Glad to see that the code will be released.  Great to see that the method is fast---it seems fast enough to use in practice in a real IDE.\n\nThe model (GGNN) is not particularly novel, but I'm not much bothered by that.  I'm very happy to see good application papers at ICLR.  I agree with your pair of sentences in the conclusion: \"Although source code is well understood and studied within other disciplines such as programming language research, it is a relatively new domain for deep learning. It presents novel opportunities compared to textual or perceptual data, as its (local) semantics are well-defined and rich additional information can be extracted using well-known, efficient program analyses.\"  I'd like to see work in this area encouraged.  So I recommend acceptance.  If it had better (e.g. ROC curve) evaluation and some modeling novelty, I would rate it higher still.\n\nSmall notes:\nThe paper uses the term \"data flow structure\" without defining it.\nYour data set consisted of C# code.  Perhaps future work will see if the results are much different in other languages.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to Represent Programs with Graphs","abstract":"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.","pdf":"/pdf/2eaa0cafc46d88234facadff3fb91c1f10598930.pdf","TL;DR":"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs","paperhash":"anonymous|learning_to_represent_programs_with_graphs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to Represent Programs with Graphs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJOFETxR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper415/Authors"],"keywords":["programs","source code","graph neural networks"]}},{"tddate":null,"ddate":null,"tmdate":1509739316941,"tcdate":1509115008385,"number":415,"cdate":1509739314289,"id":"BJOFETxR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJOFETxR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning to Represent Programs with Graphs","abstract":"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\n\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.","pdf":"/pdf/2eaa0cafc46d88234facadff3fb91c1f10598930.pdf","TL;DR":"Programs have structure that can be represented as graphs, and graph neural networks can learn to find bugs on such graphs","paperhash":"anonymous|learning_to_represent_programs_with_graphs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to Represent Programs with Graphs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJOFETxR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper415/Authors"],"keywords":["programs","source code","graph neural networks"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}