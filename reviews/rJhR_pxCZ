{"notes":[{"tddate":null,"ddate":null,"tmdate":1512689793730,"tcdate":1512689793730,"number":2,"cdate":1512689793730,"id":"Sy9KgIP-G","invitation":"ICLR.cc/2018/Conference/-/Paper421/Official_Comment","forum":"rJhR_pxCZ","replyto":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference/Paper421/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper421/Authors"],"content":{"title":"Thanks to the reviewers for the helpful comments ","comment":"We greatly appreciate the detailed feedback from the reviewers, and will look into refocusing our paper on the interpretability aspects.\n\nWe updated the pdf to fix the bug mentioned in our earlier comment, but made no other changes at this time, pending the refocusing described above. \n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]}},{"tddate":null,"ddate":null,"tmdate":1512059798176,"tcdate":1512059798176,"number":1,"cdate":1512059798176,"id":"rJ09X3Tlf","invitation":"ICLR.cc/2018/Conference/-/Paper421/Official_Comment","forum":"rJhR_pxCZ","replyto":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference/Paper421/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper421/Authors"],"content":{"title":"Correction of calculations of log-likelihood results","comment":"We recently discovered a numerical error of calculation of KL-divergence, which impacted final calculation of log-likelihood of our models SVAE and C+VAE.  Our updated bounds for log-likelihood are -102.77 for SVAE and -110.12 for C+VAE.  (Classification results were unchanged.)\n\nIn the new version we plan to upload soon, we also updated the discussion to reflect that, while our models no longer greatly improve over more complex, state-of-the-art models in terms of log-likelihood, SVAE still improves over an unmodified VAE (which uses the same encoder-decoder pair that we use), and C+VAE is comparable to an unmodified VAE when simultaneously optimizing for both classification and generative performance.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]}},{"tddate":null,"ddate":null,"tmdate":1515642446524,"tcdate":1511691680590,"number":3,"cdate":1511691680590,"id":"HktiHfugG","invitation":"ICLR.cc/2018/Conference/-/Paper421/Official_Review","forum":"rJhR_pxCZ","replyto":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference/Paper421/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interpretable classifier via deep learning is an important topic, but the work in this paper is not a substantial contribution.","rating":"5: Marginally below acceptance threshold","review":"This paper addresses a method of building an interpretable model for classification, where two key ingredients are (1) supervised variational autoencoder and (2) differentiable decision tree. Recently one important line of research is to build interpretable models which have more modeling capacity while maintaining interpretability, over existing models such as linear models or decision trees. In this sense, the current work is timely research. A few contributions are claimed in this paper: (1) differentiable decision tree which allows for gradient-based optimization; (2) supervised VAE where class-specific Gaussian prior is used for the probabilistic decoder in the VAE; (3) combination of these two models. Regarding the differentiable decision tree, I am not an expert in decision tree. However, I understand that there have been various work on probabilistic decision tree, Bayesian decision tree, and Mondrian tree. More literature survey might be needed to pin-point what's new and what's common with previous work. Regarding the supervised VAE, the term \"supervised VAE\" is misleading. To me, the current model is nothing but VAE with class-specific Gaussian prior. (3)  Regarding the combination of supervised VAE and DDT, it would be much better to show us a graphical illustration of the model to improve the readability. I see the encoder is common for both the decoder and DDT. However, it is not clear how DDT is coupled with the encoder. It seems that DDT takes the output of the encoder as input but the output of DDT is not coupled with VAE.  ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]}},{"tddate":null,"ddate":null,"tmdate":1515642446561,"tcdate":1511540223400,"number":2,"cdate":1511540223400,"id":"H1v-LprxG","invitation":"ICLR.cc/2018/Conference/-/Paper421/Official_Review","forum":"rJhR_pxCZ","replyto":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference/Paper421/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Some comments on the evaluation and results","rating":"4: Ok but not good enough - rejection","review":"The paper tries to build an interpretable and accurate classifier via stacking a supervised VAE (SVAE) and a differentiable decision tree (DTT). The problem is important and interesting. The authors list the contributions of each part but it seems that only the final contribution, i.e. analysis of the interpretability, is interesting and should be further extended and emphasized. Here with the detailed comments.\n\n1. I think Table 2 does not make sense at all. This is not only because the authors use the label information but also because the authors compare different quantities. The the previous methods evaluate log p(x) while the proposed method evaluates log p(x, y) which should be much lower as the proposed method potentially trains a separated model for each class of the x for evaluation.\n\n2. The generation results of the SVAE shown in Figure 7 in Appendix A seem strange as the diversity of the samples is much less than those from the vanilla VAEs. Could the authors explain this mode collapse phenomenon? \n\n3. The results in Table 1 are not interesting.  It is most useful to interpret the state-of-the-art classifier while the results of the proposed methods are far from the state-of-the-art even on such simple MNIST dataset.\n\n4. The most interesting results of this paper are shown in Figure 1. However, I think the results on the interpretability should be further extended. Several questions are as follows: \n\nWhy other dimensions are not so interpretable, compared with 21?\n\nCan we also interpret a VAE given labels by varying each dimension of the latent variables without jointly training a DTT? I personally think some of the dimensions of the latent variables of the vanilla VAEs can also be interpreted via interpolation in each dimension. \n\nCan these results be generalized to other datasets, consisting of natural images? \n\nOverall, this paper is below the acceptance threshold.\n ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]}},{"tddate":null,"ddate":null,"tmdate":1515642446601,"tcdate":1510863270387,"number":1,"cdate":1510863270387,"id":"SJCjWdiJG","invitation":"ICLR.cc/2018/Conference/-/Paper421/Official_Review","forum":"rJhR_pxCZ","replyto":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference/Paper421/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review: Interesting hybrid model, but weak experiments (MNIST only)","rating":"3: Clear rejection","review":"\nSummary\n\nThis paper proposes a hybrid model (C+VAE)---a variational autoencoder (VAE) composed with a differentiable decision tree (DDT)---and an accompanying training scheme.  Firstly, the prior is specified as a mixture distribution with one component per class (SVAE).  During training, the ELBO’s KL term uses the component that corresponds to the known label.  Secondly, the DDT’s leaves are parametrized with the encoder distribution q(z|x), and thus gradient information flows back through the DDT into the posterior approximations in order to make them more discriminative.  Lastly, the VAE and DDT are trained together by alternating optimization of each component (plus a ridge penalty on the decoder means).  Experiments are performed on MNIST, demonstrating tree classification performance, (supervised) neg. log likelihood performance, and latent space interpretability via the DDT.  \n\n\nEvaluation\n\nPros:  Giving the VAE discriminative capabilities is an interesting line of research, and this paper provides another take on tree-based VAEs, which are challenging to define given the discrete nature of the former and continuous nature of the latter.  Thus, I applaud the authors for combining the two in a way that admits efficient training.  Moreover, I like the qualitative experiment (Figure 2) in which the tree is used to vary a latent dimension to change the digit’s class.  I can see this being used for dataset augmentation or adversarial example generation, for instance.\n\nCons:  An indefensible flaw in the work is that the model is evaluated on only MNIST.  As there is no strong theory in the paper, this limited experimental evaluation is reason enough for rejection.  Yet, moreover, the negative log likelihood comparison (Table 2) is not an informative comparison, as it speaks only to the power of adding supervision.  Lastly, I do not think the interpretability provided by the decision tree is as great as the authors seem to claim.  Decision trees provide rich and interpretable structure only when each input feature has clear semantics.  However, in this case, the latent space is being used as input to the tree.  As the decision tree, then, is merely learning hard, class-based partitioning rules for the latent space, I do not see how the tree is representing anything especially revealing.  Taking Figure 2 as an example (which I do like the end result of), I could generate similar results with a black-box classifier by using gradients to perturb the latent ‘4’ mean into a latent ‘7’ mean (a la DeepDream).  I could then identify the influential dimension(s) by taking the largest absolute values in the gradient vector.  Maybe there is another use case in which a decision tree is superior; I’m just saying Section 4.3 doesn’t convince me to the extent that was promised earlier in the paper (and by the title).\n\nComment:  It's easier to make a latent variable model interpretable when the latent variables are given clear semantics in the model definition, in my opinion.  Otherwise, the semantics of the latent space become too entangled.  Could you, somehow, force the tree to encode an identifiable attribute at each node, which would then force that attribute to be encoded in a certain dimension of latent space?      \n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]}},{"tddate":null,"ddate":null,"tmdate":1512690332286,"tcdate":1509116115607,"number":421,"cdate":1509739310058,"id":"rJhR_pxCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rJhR_pxCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees","abstract":"As deep learning-based classifiers are increasingly adopted in real-world applications, the importance of understanding how a particular label is chosen grows. Single decision trees are an example of a simple, interpretable classifier, but are unsuitable for use with complex, high-dimensional data. On the other hand, the variational autoencoder (VAE) is designed to learn a factored, low-dimensional representation of data, but typically encodes high-likelihood data in an intrinsically non-separable way.  We introduce the differentiable decision tree (DDT) as a modular component of deep networks and a simple, differentiable loss function that allows for end-to-end optimization of a deep network to compress high-dimensional data for classification by a single decision tree.  We also explore the power of labeled data in a  supervised VAE (SVAE) with a Gaussian mixture prior, which leverages label information to produce a high-quality generative model with improved bounds on log-likelihood.  We combine the SVAE with the DDT to get our classifier+VAE (C+VAE), which is competitive in both classification error and log-likelihood, despite optimizing both simultaneously and using a very simple encoder/decoder architecture. ","pdf":"/pdf/6a030c0381f495193d9f5c56d6f8ddb12b53aed4.pdf","TL;DR":"We combine differentiable decision trees with supervised variational autoencoders to enhance interpretability of classification. ","paperhash":"anonymous|interpretable_classification_via_supervised_variational_autoencoders_and_differentiable_decision_trees","_bibtex":"@article{\n  anonymous2018interpretable,\n  title={Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJhR_pxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper421/Authors"],"keywords":["interpretable classification","decision trees","deep learning","variational autoencoder"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}