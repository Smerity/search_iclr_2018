{"notes":[{"tddate":null,"ddate":null,"tmdate":1512447589320,"tcdate":1512447589320,"number":4,"cdate":1512447589320,"id":"S1pvRc7bM","invitation":"ICLR.cc/2018/Conference/-/Paper675/Official_Review","forum":"Sk7cHb-C-","replyto":"Sk7cHb-C-","signatures":["ICLR.cc/2018/Conference/Paper675/AnonReviewer4"],"readers":["everyone"],"content":{"title":"Good motivation and promising results on celebA, but very poor model description","rating":"4: Ok but not good enough - rejection","review":"The paper proposes a hierarchical probabilistic model that learns both static representations and the dynamics of the data. The model iteratively updates its latent representations of the data in order to improve its generative power. The model is applicable to both static images (iterative improvements of the samples) and videos (predictive coding like repesentations).\n\nPros:\n\n-- the motivation for the work and its connections to the cognitive/philosophical models of concepts and predictive coding is very interesting\n-- the iterative improvements in the celebA samples in Fig. 3 and the corresponding improvements in the log-likelihood in Tbl. 1 vs the vanilla VAE baseline are promising and suggest that the approach has potential\n\nCons:\n\n-- The major problem with this paper in my opinion is that the methods section is very confusing:\n    1) The section is too brief and there is absolutely no description of the model until page 4\n    2) The figures are hard to understand and the annotations are not informative (e.g. what is the difference between Fig.1 and Fig.2?) \n    3) The notation is unconventional and keeps changing (e.g. the generator is referred to as either \\varphi_A, \\varphi_X,  \\varphi_X(Z_t), X_t|Z_t, or \\mu_X; \\sigma_X... the dimensionality of the image is denoted as i, N * c or Nc... I can go on).  \n    4) The rescaling of the latent parameters seems engineered and arbitrary (e.g. \\beta scaling factor in Eq. 8 is chosen so that the sigmoid reaches 0.75 when the value is 0.5\\sigma of the threshold).\n\nDue to the points above I failed to fully understand the model despite trying hard to do so. In particular, I did not understand the most important part of the paper addressing the iterative update of the latents vs backprop update of the generative weights. \n\nMinor points:\n-- The introduction is too long and repetitive. The space saved should be used to describe the model more precisely.\n-- The parametrisation of S_t should be described when it is first introduced, not 2 paragraphs later.\n-- How does an inner product of two vectors result in a matrix (Sec. 3.3)?\n-- GANs also do not have an encoder network (despite what the authors claim in Sec. 4.1) and should be used as a baseline\n-- Why does the VAE baseline have a different decoder architecture than the proposed model?\n-- What is the pre-processing done for CelebA?\n-- What is the ground truth that was supposed to be matched by \\mu_S_t in the dynamic dataset?\n-- Figs. 4-5 are hard to understand. What do the different colours of the lines mean? The time stamps where the behaviours are changing should be marked in the plot (not just described in the text).\n\nTo conclude, the authors are advised to shorten the introduction and literature review sections and use the extra space to re-write and expand the methods section to make it very clear how their model works using the standard notation used in the literature. The results section detailing the dynamic setup of their approach needs to be made more clear as well. In the current form the paper is not ready for publication.\n\n\n\n\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Representing dynamically: An active process for describing sequential data","abstract":"We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\nThe method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.","pdf":"/pdf/7a54a09d06726a6a8bc786b636d7280da6644d5f.pdf","TL;DR":"A method that build representations of sequential data and its dynamics through generative models with an active process","paperhash":"anonymous|representing_dynamically_an_active_process_for_describing_sequential_data","_bibtex":"@article{\n  anonymous2018representing,\n  title={Representing dynamically: An active process for describing sequential data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk7cHb-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper675/Authors"],"keywords":["Generative Models","Latent representations","Predictive coding","Recurrent networks","Sequential data"]}},{"tddate":null,"ddate":null,"tmdate":1512222718232,"tcdate":1511823444947,"number":3,"cdate":1511823444947,"id":"BypLdzcxf","invitation":"ICLR.cc/2018/Conference/-/Paper675/Official_Review","forum":"Sk7cHb-C-","replyto":"Sk7cHb-C-","signatures":["ICLR.cc/2018/Conference/Paper675/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Tackles important sequential data modeling problem; however, no clear difference over GANs; lacks technically clarity and evaluation is inadequate","rating":"4: Ok but not good enough - rejection","review":"Summary:\n\nThe paper proposed an Bayesian network model, realized as a neural network, that learns\n1. latent representation of observed data (images in the paper).\n2. dynamics of interaction in sequential data in the form of a linear dynamical system w.r.t. latent representation, controlled by secondary latent variables.\n\nThe model is evaluated in two scenarios:\n1. Static images on CelebA dataset, where it shows that iterative guided updates of the latent representation improve reconstruction quality, compared to VAE.\n2. Sequential data experiment, the authors show that the interaction states can be used for semantic action segmentation.\n\n-------------------------------------------------------\nPros:\n1. The proposed model is unsupervised, and it can iteratively improve the latent representation and consequently the systhesized output, given more observations at inference.\n\n2. The paper proposes novel strategies to update the latent distributions' parameters.\n\n-------------------------------------------------------\nCons:\n1. The problem fornulation with Z, X and S are not clearly defined at the beginning, the reviewer must read further into page 4 and 5 to understand. Brief description should be provided in/around Fig 1. Furthermore, the log likelihood loss is not clearly defined before Eq (1).\n\n2. The proposed updates to mu_z, sigma_z, mu_s and sigma_s in Eq (2,3,6,9) and their convergence properties as well as stability are not justified by actual experiments and analysis.\n\n3. The overall training procedure is unclear: do the hidden layer weights get updated given repeated observations in the case of static model?\n\n4. In the static image experiment, why the authors did not compare to at least GAN (or better if GLO [Bojsnowski et al. 2017] is included)?\nThe iterative updates clearly give the proposed model advantage over VAE. VAE also relies on reconstruction loss, hence the synthesized output are often blurry.\nGAN, which can generate high quality images, should provide a better benchmark. One can use the same method as this paper, backpropagating the reconstruction error of GAN generator to the input layer to find the suitable noise vector of an image, then synthesize the image with the generator from that noise input.\n\n5. One the two objectives of the paper, image reconstruction in sequence, is not evaluated in the dynamic experiment. The paper does not provide any analysis for A, Z and \\hat{X} in the dynamic setting.\nInstead, the secondary latent states S are used for sequence segmentation. Why is it not compared to HMM baseline at least, in that case?\nFurthermore, the paper does not provide a standard methodology to segment actions from video, but rather, the reviewer must look at the plot in Fig 4 & 5 and read the description in page 8 to see the correspondence between the variation of S and the action switch in the video.\nIn addition, the segmentation is only carried out on one video in the paper.\nMoreover, the paper only experiments with S of length 2. Given the limited evaluation, the authors can try and report the results with different lengths of S (e.g. 1 or 3, 4).","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Representing dynamically: An active process for describing sequential data","abstract":"We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\nThe method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.","pdf":"/pdf/7a54a09d06726a6a8bc786b636d7280da6644d5f.pdf","TL;DR":"A method that build representations of sequential data and its dynamics through generative models with an active process","paperhash":"anonymous|representing_dynamically_an_active_process_for_describing_sequential_data","_bibtex":"@article{\n  anonymous2018representing,\n  title={Representing dynamically: An active process for describing sequential data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk7cHb-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper675/Authors"],"keywords":["Generative Models","Latent representations","Predictive coding","Recurrent networks","Sequential data"]}},{"tddate":null,"ddate":null,"tmdate":1512222718272,"tcdate":1511804990039,"number":2,"cdate":1511804990039,"id":"By8SeCYez","invitation":"ICLR.cc/2018/Conference/-/Paper675/Official_Review","forum":"Sk7cHb-C-","replyto":"Sk7cHb-C-","signatures":["ICLR.cc/2018/Conference/Paper675/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Poorly written paper, authors clearly confusing terminology etc. ","rating":"3: Clear rejection","review":"This paper, to me, is a clear rejection from these basic observations:\n\nA *model* is not a computation graph and should never be presented that way. \nCalling a computation graph a Bayesian network without even writing down how *inference* can ever result in such a computation graph is a basic error. \nThe authors claim this: \"So, no encoder or inference models are used since the generators also serve as their inverse transformations.\" Well, then this is not a Bayesian network. \nThe authors spend a lot of time analyzing constant inputs theoretically, and I'm not sure why this is even relevant. ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Representing dynamically: An active process for describing sequential data","abstract":"We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\nThe method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.","pdf":"/pdf/7a54a09d06726a6a8bc786b636d7280da6644d5f.pdf","TL;DR":"A method that build representations of sequential data and its dynamics through generative models with an active process","paperhash":"anonymous|representing_dynamically_an_active_process_for_describing_sequential_data","_bibtex":"@article{\n  anonymous2018representing,\n  title={Representing dynamically: An active process for describing sequential data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk7cHb-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper675/Authors"],"keywords":["Generative Models","Latent representations","Predictive coding","Recurrent networks","Sequential data"]}},{"tddate":null,"ddate":null,"tmdate":1512222718309,"tcdate":1511451967636,"number":1,"cdate":1511451967636,"id":"r1OraDNgf","invitation":"ICLR.cc/2018/Conference/-/Paper675/Official_Review","forum":"Sk7cHb-C-","replyto":"Sk7cHb-C-","signatures":["ICLR.cc/2018/Conference/Paper675/AnonReviewer1"],"readers":["everyone"],"content":{"title":"The authors propose an architecture and generative model for static images and video sequences, with the purpose of generating an image that looks as similar as possible to the one that is (or will be) supplied. They combine neural networks trained offline and linked Gaussian distributions learned online to make the architecture both expressive and adaptive.","rating":"6: Marginally above acceptance threshold","review":"The authors propose an architecture and generative model for static images and video sequences, with the purpose of generating an image that looks as similar as possible to the one that is supplied. This is useful for for example frame prediction in video and detection of changes in video as a consequence to changes in the dynamics of objects in the scene.\nThe architecture minimizes the error between the generated image(s) and the supplied image(s) by refining the generated image over time when the same image is shown and by adapting when the image is changed. The model consists of three neural networks (F_Zµ, F_Zsigma, f_X|Z) and three multivariate Gaussian distributions P(S_t), P(Z_t) and P(X_t,Z_t) with diagonal covariances. The NNs do not change over time but they relate the three Gaussian distributions in different ways and these distributions are changing over time in order to minimize the error of the generated image(s).\n\nThe paper took a while to understand due to its structure and how it is written. A short overview of the different components of Figure 1 giving the general idea and explaining\n* what nodes are stochastic variables and NNs\n* what is trained offline/online\nIt would also help the structure if the links/arrows/nodes had numbers corresponding to the relevant equations defining the relations/computations. Some of these relations are defined with explicit equation numbers, others are baked into the text which makes it difficult to jump around in the paper when reading it and trying to understand the architecture.\n\nThere are also numerous language errors in the paper and many of them are grammatical. For example:\n  Page 5, second paragraph: \"osculations\" -> \"oscillations\"\n  Page 5, fourth paragraph: \"Defining .. is defined as..\"\n\nThe results seem impressive and the problem under consideration is important and have several applications. There is however not much in terms of discussion nor analysis of the two experiments.\nI find the contribution fairly significant but I lack some clarity in the presentation as well as in the experiments section.\nI do not find the paper clearly written. The presentation can be improved in several chapters, such as the introduction and the method section.\nThe paper seem to be technically correct. I did not spot any errors.\n\nGeneral comments:\n- Why is 2 a suitable size of S?\n- Why use two by two encoding instead of stride for the VAE baseline? How does this affect the experiments?\n- How is S_0 and the Z_0 prior set (initialized) in the experiments?\n- It would improve the readability of the paper, not least for a broader audience, if more details are added on how the VAE baseline architecture differ from the proposed architecture.\n\n- In the first experiment: \n-- How many iterations does it take for your method to beat VAE?\n-- What is the difference between the VAE basline and your approach that make VAE perform better than your approach initially (or even after a few iterations)? \n-- What affect does the momentum formulation have on the convergence rate (number of iterations necessary to reach VAE and your methods result at t=10)?  \n\n- In the second experiment and Figure 5 in particular it was observed that some actions are clearly detected while others are not. It is mentioned that those that are not detected by the approach are more similar. In what sense are the actions more similar, which are the most prominent (from a humans perspective) such actions, what is making the model not detecting them and what can be done (within your approach) in order to improve or adjust the detection fidelity?\n\nPlease add more time labels under the time axis in Figure 4 and Figure 5. Also please annotate the figures at the time points where the action transitions are according to the ground truth.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Representing dynamically: An active process for describing sequential data","abstract":"We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\nThe method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.","pdf":"/pdf/7a54a09d06726a6a8bc786b636d7280da6644d5f.pdf","TL;DR":"A method that build representations of sequential data and its dynamics through generative models with an active process","paperhash":"anonymous|representing_dynamically_an_active_process_for_describing_sequential_data","_bibtex":"@article{\n  anonymous2018representing,\n  title={Representing dynamically: An active process for describing sequential data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk7cHb-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper675/Authors"],"keywords":["Generative Models","Latent representations","Predictive coding","Recurrent networks","Sequential data"]}},{"tddate":null,"ddate":null,"tmdate":1509739167063,"tcdate":1509131659457,"number":675,"cdate":1509739164405,"id":"Sk7cHb-C-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Sk7cHb-C-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Representing dynamically: An active process for describing sequential data","abstract":"We propose an unsupervised method for building dynamic representations of sequential data, particularly of observed interactions. The method simultaneously acquires representations of input data and its dynamics. It is based on a hierarchical generative model composed of two levels. In the first level, a model learns representations to generate observed data. In the second level, representational states encode the dynamics of the lower one. The model is designed as a Bayesian network with switching variables represented in the higher level, and which generates transition models. The method actively explores the latent space guided by its knowledge and the uncertainty about it. That is achieved by updating the latent variables from prediction error signals backpropagated to the latent space. So, no encoder or inference models are used since the generators also serve as their inverse transformations.\nThe method is evaluated in two scenarios, with static images and with videos. The results show that the adaptation over time leads to better performance than with similar architectures without temporal dependencies, e.g., variational autoencoders. With videos, it is shown that the system extracts the dynamics of the data in states that highly correlate with the ground truth of the actions observed.","pdf":"/pdf/7a54a09d06726a6a8bc786b636d7280da6644d5f.pdf","TL;DR":"A method that build representations of sequential data and its dynamics through generative models with an active process","paperhash":"anonymous|representing_dynamically_an_active_process_for_describing_sequential_data","_bibtex":"@article{\n  anonymous2018representing,\n  title={Representing dynamically: An active process for describing sequential data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk7cHb-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper675/Authors"],"keywords":["Generative Models","Latent representations","Predictive coding","Recurrent networks","Sequential data"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}