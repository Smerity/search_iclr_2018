{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222691131,"tcdate":1511843642251,"number":3,"cdate":1511843642251,"id":"SkzSPDqlM","invitation":"ICLR.cc/2018/Conference/-/Paper560/Official_Review","forum":"rk8rMgZAW","replyto":"rk8rMgZAW","signatures":["ICLR.cc/2018/Conference/Paper560/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The authors propose a very interesting approach for multitask and few shot learning. However there are some improvements which will make this work more amenable for publication.","rating":"5: Marginally below acceptance threshold","review":"The authors propose techniques for multitask and few shot learning, where the number of tasks is potentially very large, and the different tasks might have different output spaces. Prior techniques which can address some of these aspects do not necessarily work with deep learning, which is a key focus of the paper. The authors suggest computing a similarity matrix amongst the tasks. Given such a matrix, they propose to do multitask learning by clustering the similarity matrix, and learning a single model for each cluster. If the tasks in a cluster have different output spaces, then a separate output layer is learned for each task in the cluster following a common encoding module.\nTo deal with the large number of tasks, the authors further propose computing a few randomly sampled entries of the similarity matrix, and then using ideas from robust matrix completion to induce the full matrix. The resulting algorithm is evaluated on a standard amazon reviews benchmark from multitask learning, as well as two datasets from intent classification in dialog systems.\n\nI think there are some interesting ideas in this paper, and the use of matrix completion techniques to deal with a large number of tasks is nice. But I believe there are important drawbacks in the framing and basic methodology and evaluation which make the paper unfit for publication in its current form.\n\n1. The prior works which do task clustering and multitask learning typically focus on how one might induce clusters which work well with the multitask learning methods used (see e.g. Kang et al. which is cited, as well as Kshirsagar et al. in ECML 2017 as two examples). In this paper, on the other hand, the clusters are obtained in a manner which only accounts for pairwise similarities of tasks, using a pairwise similarity metric which is quite different from how the cluster is eventually used. This seems quite suboptimal.\n2. The pairwise similarity measure appears to be one that might have a high false negative rate. That is, it might rate many tasks as dissimilar even when they are not. This is because you train individual model on i and apply it to j. It is possible that this model does not do well, but there is an equally good model for i which also does well on j. Such a model would indeed be found if i and j are put in the same cluster, but the method would fail to do so, leading to high fragmentation.\n3. I do not see how you apply the model from task i to task j when the two have different output spaces. Since this is a major motivation of the paper, I actually do not see how the setup makes sense!\n4. It seems odd to put absolute errors on task j instead of regret to the model trained on j in the similarity matrix.\n5. The inducing of edges in the Y matrix by comparing to a mean and standard deviation is completely baseless. Without good reasoning from the authors, I see no reason why the entries in the row of a matrix should have a normal-like distribution. Furthermore, in the matrix completion scenario, you have O(log^2n) entries per row on average, which means with high probability few rows should have a constant number of entries. In this case, the means are standard deviations do not even make sense to me. At the very least, I would consider using regret to the model of the task, and compute some quantiles on that which is still suspect in the matrix completion setting.\n6 .In the evaluation, why are just 12 tasks used in the Amazon dataset? Why don't you present evaluation results on all tasks in the multitask setting?\n7. Why is average accuracy the right thing? If the error rates are different for different tasks, it is not sensible to measure raw accuracies.\n\nThe authors also seem to miss a potentially relevant baseline in Cross-Stitch Networks (https://arxiv.org/abs/1604.03539)\n\nBesides these major issues, there are also a few minor issues I have with the paper. I do not see why there's need for a proof for the matrix completion result. This appears to be a direct application of Chandrasekaran et al, and in fact matrix completion has been used for clustering before (https://arxiv.org/abs/1104.4803). Given this, the presentation in the paper makes the idea look more novel than it is. I also think that the authors might benefit from dropping the whole few-shot learning angle here, and instead do a more thorough job of evaluating their multitask learning method.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning","abstract":"We investigate task clustering for deep learning-based multi-task and few-shot learning in the settings with large numbers of diverse tasks. Our method measures task similarities using cross-task transfer performance matrix. Although this matrix provides us critical information regarding similarities between tasks, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. Moreover, when the number of tasks is large, generating the full transfer performance matrix can be very time consuming. To overcome these limitations, we propose a novel task clustering algorithm to estimate the similarity matrix based on the theory of matrix completion. The proposed algorithm can work on partially-observed similarity matrices based on only sampled task-pairs with reliable scores, ensuring its efficiency and robustness. Our theoretical analysis shows that under mild assumptions, the reconstructed matrix perfectly matches the underlying “true” similarity matrix with an overwhelming probability. The final task partition is computed by applying an efficient spectral clustering algorithm to the recovered matrix. Our results show that the new task clustering method can discover task clusters that benefit both multi-task learning and few-shot learning setups for sentiment classification and dialog intent classification tasks.","pdf":"/pdf/6aec790d32d3b0956e7c3e859a1b3ef0e1a536a1.pdf","TL;DR":"We propose a matrix-completion based task clustering algorithm for deep multi-task and few-shot learning in the settings with large numbers of diverse tasks.","paperhash":"anonymous|robust_task_clustering_for_deep_and_diverse_multitask_and_fewshot_learning","_bibtex":"@article{\n  anonymous2018robust,\n  title={Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk8rMgZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper560/Authors"],"keywords":["task clustering","matrix completion","multi-task learning","few-shot learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222691173,"tcdate":1511749538519,"number":2,"cdate":1511749538519,"id":"rkcivxFgG","invitation":"ICLR.cc/2018/Conference/-/Paper560/Official_Review","forum":"rk8rMgZAW","replyto":"rk8rMgZAW","signatures":["ICLR.cc/2018/Conference/Paper560/AnonReviewer1"],"readers":["everyone"],"content":{"title":"The proposed method is based on completing and clustering a performance matrix, which can be very noisy. Theoretical and experimental comparisons with other clustered MTL methods are lacking.","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a method for multitask and few-shot learning by completing a performance matrix (which measures how well the classifier for task i performs on task j).\n\nThe matrix completion approach is based on robust PCA. When used for multitask learning (MTL) with N tasks, the method has to first train one classifier for each task (and so train a total of N classifiers), and then evaluate the performance of each classifier on each and every task (and so involves N^2 testing rounds). This can be computationally demanding.\n\nThe key assumption in the paper is that task classifier i that performs well on task j means tasks i and j belong to the same cluster, and if task classifier i does not perform well on task j, then tasks i and j belong to different cluster. The proposed algorithm then uses these performance values to perform task clustering. However, in MTL, we usually assume that there are not enough samples to learn each task, and so this performance matrix may not be reliable.\n\nThere have been a number of MTL methods based on task clustering. For example,\n[1] A convex formulation for learning task relationships in multi-task learning (UAI)\n[2] A dirty model for multi-task learning (NIPS)\n[3] Clustered multi-task learning: A convex formulation (NIPS)\n[4] Convex multitask learning with flexible task clusters (ICML)\n[5] Integrating low-rank and group-sparse structures for robust multi-task learning (KDD)\n[6] Learning incoherent sparse and low-rank patterns from multiple tasks (KDD)\nIn particular, [5] assumes that the combined weight matrix (for all the tasks) follows the robust PCA model. This is thus very similar to the proposed method (which assumes that the performance matrix follows the robust PCA model). However, a disadvantage of the proposed method is that it is a two-step approach (first perform task clustering, then re-learn the cluster weights), while [5] is not.\n\nFor few-shot learning, the authors mentioned that the \\alpha's are adaptable parameters but did not mention how they are adapted.\n\nExperimental results are not convincing.\n- Comparison with existing clustered MTL methods mentioned above are missing.\n- As mentioned above, the proposed method can be computationally expensive (when used for MTL), but no timing results are reported.\n- As the authors mentioned in section 4.2, most of the tasks have a significant amount of training data (and single-task baselines achieve good results), and so this is not a good benchmark dataset for MTL.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning","abstract":"We investigate task clustering for deep learning-based multi-task and few-shot learning in the settings with large numbers of diverse tasks. Our method measures task similarities using cross-task transfer performance matrix. Although this matrix provides us critical information regarding similarities between tasks, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. Moreover, when the number of tasks is large, generating the full transfer performance matrix can be very time consuming. To overcome these limitations, we propose a novel task clustering algorithm to estimate the similarity matrix based on the theory of matrix completion. The proposed algorithm can work on partially-observed similarity matrices based on only sampled task-pairs with reliable scores, ensuring its efficiency and robustness. Our theoretical analysis shows that under mild assumptions, the reconstructed matrix perfectly matches the underlying “true” similarity matrix with an overwhelming probability. The final task partition is computed by applying an efficient spectral clustering algorithm to the recovered matrix. Our results show that the new task clustering method can discover task clusters that benefit both multi-task learning and few-shot learning setups for sentiment classification and dialog intent classification tasks.","pdf":"/pdf/6aec790d32d3b0956e7c3e859a1b3ef0e1a536a1.pdf","TL;DR":"We propose a matrix-completion based task clustering algorithm for deep multi-task and few-shot learning in the settings with large numbers of diverse tasks.","paperhash":"anonymous|robust_task_clustering_for_deep_and_diverse_multitask_and_fewshot_learning","_bibtex":"@article{\n  anonymous2018robust,\n  title={Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk8rMgZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper560/Authors"],"keywords":["task clustering","matrix completion","multi-task learning","few-shot learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222691217,"tcdate":1511694829068,"number":1,"cdate":1511694829068,"id":"rkSlfXOef","invitation":"ICLR.cc/2018/Conference/-/Paper560/Official_Review","forum":"rk8rMgZAW","replyto":"rk8rMgZAW","signatures":["ICLR.cc/2018/Conference/Paper560/AnonReviewer3"],"readers":["everyone"],"content":{"title":"a paper with limited novelty","rating":"5: Marginally below acceptance threshold","review":"The idea of using cross-task transfer performance to do task clustering is not new. Please refer to the paper “Discovering structure in multiple learning tasks: The TC algorithm” published in ICML 1996. One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks. For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other. So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning.\n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature. I don’t see much novelty. Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2). Based on previous works such as “Multi-task Sparse Structure Learning with Gaussian Copula Models” and “Learning Sparse Task Relations in Multi-Task Learning”, when the number of tasks is large, the task relation exhibits the sparse structure. I don’t know whether the low-rank structure does exist in the cross-task transfer performance or not.\n\nThe two parts in this paper are not new. The combination of the two parts seems a bit incremental and does not bring much novelty.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning","abstract":"We investigate task clustering for deep learning-based multi-task and few-shot learning in the settings with large numbers of diverse tasks. Our method measures task similarities using cross-task transfer performance matrix. Although this matrix provides us critical information regarding similarities between tasks, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. Moreover, when the number of tasks is large, generating the full transfer performance matrix can be very time consuming. To overcome these limitations, we propose a novel task clustering algorithm to estimate the similarity matrix based on the theory of matrix completion. The proposed algorithm can work on partially-observed similarity matrices based on only sampled task-pairs with reliable scores, ensuring its efficiency and robustness. Our theoretical analysis shows that under mild assumptions, the reconstructed matrix perfectly matches the underlying “true” similarity matrix with an overwhelming probability. The final task partition is computed by applying an efficient spectral clustering algorithm to the recovered matrix. Our results show that the new task clustering method can discover task clusters that benefit both multi-task learning and few-shot learning setups for sentiment classification and dialog intent classification tasks.","pdf":"/pdf/6aec790d32d3b0956e7c3e859a1b3ef0e1a536a1.pdf","TL;DR":"We propose a matrix-completion based task clustering algorithm for deep multi-task and few-shot learning in the settings with large numbers of diverse tasks.","paperhash":"anonymous|robust_task_clustering_for_deep_and_diverse_multitask_and_fewshot_learning","_bibtex":"@article{\n  anonymous2018robust,\n  title={Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk8rMgZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper560/Authors"],"keywords":["task clustering","matrix completion","multi-task learning","few-shot learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739235708,"tcdate":1509126717785,"number":560,"cdate":1509739232995,"id":"rk8rMgZAW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rk8rMgZAW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning","abstract":"We investigate task clustering for deep learning-based multi-task and few-shot learning in the settings with large numbers of diverse tasks. Our method measures task similarities using cross-task transfer performance matrix. Although this matrix provides us critical information regarding similarities between tasks, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. Moreover, when the number of tasks is large, generating the full transfer performance matrix can be very time consuming. To overcome these limitations, we propose a novel task clustering algorithm to estimate the similarity matrix based on the theory of matrix completion. The proposed algorithm can work on partially-observed similarity matrices based on only sampled task-pairs with reliable scores, ensuring its efficiency and robustness. Our theoretical analysis shows that under mild assumptions, the reconstructed matrix perfectly matches the underlying “true” similarity matrix with an overwhelming probability. The final task partition is computed by applying an efficient spectral clustering algorithm to the recovered matrix. Our results show that the new task clustering method can discover task clusters that benefit both multi-task learning and few-shot learning setups for sentiment classification and dialog intent classification tasks.","pdf":"/pdf/6aec790d32d3b0956e7c3e859a1b3ef0e1a536a1.pdf","TL;DR":"We propose a matrix-completion based task clustering algorithm for deep multi-task and few-shot learning in the settings with large numbers of diverse tasks.","paperhash":"anonymous|robust_task_clustering_for_deep_and_diverse_multitask_and_fewshot_learning","_bibtex":"@article{\n  anonymous2018robust,\n  title={Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk8rMgZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper560/Authors"],"keywords":["task clustering","matrix completion","multi-task learning","few-shot learning"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}