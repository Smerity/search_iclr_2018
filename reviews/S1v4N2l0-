{"notes":[{"tddate":null,"ddate":null,"tmdate":1512424260142,"tcdate":1512424260142,"number":1,"cdate":1512424260142,"id":"BJnH7HQWz","invitation":"ICLR.cc/2018/Conference/-/Paper387/Public_Comment","forum":"S1v4N2l0-","replyto":"HyCI-CKeG","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Results of Table 3","comment":"I do not agree with the point 2 of the reviewer. The authors show the fine-tuning results on PASCAL with high performance. The experiment of Table 3 with frozen layers make a lot of sense to evaluate the learned features.  \n\nHowever,  the results of table 3 are not valid in my view. The authors are using different settings than the one is used in the evaluation of other methods. More precisely, the others use batch normalisation and removing drop out which is not clear how will influence the other methods including supervised learning. To have a fair comparison, the author need to freeze the conv layers and reinitialise and retrain the remainibg layers with the same architecture and settings of AlexNet."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Unsupervised Representation Learning by Predicting Image Rotations","abstract":"Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their  unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. \nWe demonstrate both qualitative and quantitative that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning.  We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them remarkably good performance. Even more, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art, thus they significantly close the gap between unsupervised and supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of $54.4\\%$ that is only 2.4 points lower from the supervised case. Similar striking results we get when transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, and CIFAR-10 classification.","pdf":"/pdf/961b1b17788954a27dcfd389a828ea6858b107ea.pdf","paperhash":"anonymous|unsupervised_representation_learning_by_predicting_image_rotations","_bibtex":"@article{\n  anonymous2018unsupervised,\n  title={Unsupervised Representation Learning by Predicting Image Rotations},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1v4N2l0-}\n}","keywords":["Unsupervised representation learning"],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper387/Authors"]}},{"tddate":null,"ddate":null,"tmdate":1512222633476,"tcdate":1511805270172,"number":2,"cdate":1511805270172,"id":"HyCI-CKeG","invitation":"ICLR.cc/2018/Conference/-/Paper387/Official_Review","forum":"S1v4N2l0-","replyto":"S1v4N2l0-","signatures":["ICLR.cc/2018/Conference/Paper387/AnonReviewer3"],"readers":["everyone"],"content":{"title":"remarkably simple but effective strategy, some missing experiments, awkward writing","rating":"6: Marginally above acceptance threshold","review":"Strengths:\n* Very simple strategy for unsupervised learning of deep image features. Simplicity of approach is a good quality in my view.\n* The rationale for the effectiveness of the approach is explained well.\n* The representation learned from unlabeled data is shown to yield strong results on image categorization (albeit mostly in scenarios where the unsupervised features have been learned from the *same* dataset where classification is performed -- more on this below).\n* The image rotations are implemented in terms of flipping and transposition, which do not create visual artifacts easily recognizable by deep models.\n\nWeaknesses:\n* There are several obvious additional experiments that, in my view, would greatly strengthen this work:\n1. Nearly all of the image categorization results (with the exception of those in Table 4) are presented for the contrived scenario where the unsupervised representation is learned from the same training set as the one used for the final supervised training of the categorization model. This is a useless application scenario. If labels for the training examples are available, why not using them for feature learning given that this leads to improved performance (see results in Tables)? More importantly, this setup does not allow us to understand how general the unsupervised features are. Maybe they are effective  precisely because they have been learned from images of the 10 classes that the final classifier needs to distinguish... I would have liked to see some results involving unsupervised learning from a dataset that may contain classes different from those of the final test classification or, even better, from a dataset of randomly selected images that lack categorical coherence (e.g., photos randomly picked from the Web, such as Flickr pics).\n2. In nearly all the experiments, the classifier is built on top of the frozen unsupervised features. This is in contrast with the common practice of finetuning the entire pretrained unsupervised net on the supervised task. It'd be good to know why the authors opted for the different setup and to see in any case some supervised finetuning results.\n3. It would be useful to see the accuracy per class both when using unsupervised features as well as fully-supervised features. There are many objects that have a canonical pose/rotation in the world. Forcing the unsupervised features to distinguish rotations of such objects may affect the recognition accuracy for these classes. Thus, my request for seeing how the unsupervised learning affects class-specific accuracy.\n4. While the results in Table 2 are impressive, it appears that the different unsupervised learning methods reported in this table are based on different architectures. This raises the question of whether performance gains are due to the better mechanism for unsupervised learning or rather the better network architecture.\n5. I do understand that using only 0, 90, 180 and 270 degree rotations eliminates the issue of potentially recognizable artifacts. Nevertheless, it'd be interesting to see what happens empirically when the number of discrete rotations is increased, e.g., by including 45, 135, 225 and 315 degree rotations. And what happens if you use only 0 and 180? Or only 90 and 270?\n* While the paper is easy to understand, at times the writing is poor and awkward (e.g., opening sentence of intro, first sentence in section 2.2).","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Unsupervised Representation Learning by Predicting Image Rotations","abstract":"Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their  unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. \nWe demonstrate both qualitative and quantitative that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning.  We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them remarkably good performance. Even more, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art, thus they significantly close the gap between unsupervised and supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of $54.4\\%$ that is only 2.4 points lower from the supervised case. Similar striking results we get when transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, and CIFAR-10 classification.","pdf":"/pdf/961b1b17788954a27dcfd389a828ea6858b107ea.pdf","paperhash":"anonymous|unsupervised_representation_learning_by_predicting_image_rotations","_bibtex":"@article{\n  anonymous2018unsupervised,\n  title={Unsupervised Representation Learning by Predicting Image Rotations},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1v4N2l0-}\n}","keywords":["Unsupervised representation learning"],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper387/Authors"]}},{"tddate":null,"ddate":null,"tmdate":1512222633523,"tcdate":1511640290421,"number":1,"cdate":1511640290421,"id":"HJ91THweG","invitation":"ICLR.cc/2018/Conference/-/Paper387/Official_Review","forum":"S1v4N2l0-","replyto":"S1v4N2l0-","signatures":["ICLR.cc/2018/Conference/Paper387/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting discovery, good results, but not a lot of content.","rating":"6: Marginally above acceptance threshold","review":"The paper proposes a simple classification task for learning feature extractors without requiring manual annotations: predicting one of four rotations that the image has been subjected to: by 0, 90, 180 or 270º. Then the paper shows that pre-training on this task leads to state-of-the-art results on a number of popular benchmarks for object recognition, when training classifiers on top of the resulting representation.\n\nThis is a useful discovery, because generating the rotated images is trivial to implement by anyone. It is a special case of the approach by Agrawal et al 2015, with more efficiency.\n\nOn the negative side, this line of work would benefit from demonstrating concrete benefits. The performance obtained by pre-training with rotations is still inferior to performance obtained by pre-training with ImageNet, and we do have ImageNet so there is no reason not to use it. It would be important to come up with tasks for which there is not one ImageNet, then techniques such as that proposed in the paper would be necessary. However rotations are somewhat specific to images. There may be opportunities with some type of medical data.\n\nAdditionally, the scope of the paper is a little bit restricted, there is not that much to take home besides the the following information: \"predicting rotations seems to require a lot of object category recognition\".\n\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Unsupervised Representation Learning by Predicting Image Rotations","abstract":"Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their  unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. \nWe demonstrate both qualitative and quantitative that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning.  We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them remarkably good performance. Even more, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art, thus they significantly close the gap between unsupervised and supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of $54.4\\%$ that is only 2.4 points lower from the supervised case. Similar striking results we get when transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, and CIFAR-10 classification.","pdf":"/pdf/961b1b17788954a27dcfd389a828ea6858b107ea.pdf","paperhash":"anonymous|unsupervised_representation_learning_by_predicting_image_rotations","_bibtex":"@article{\n  anonymous2018unsupervised,\n  title={Unsupervised Representation Learning by Predicting Image Rotations},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1v4N2l0-}\n}","keywords":["Unsupervised representation learning"],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper387/Authors"]}},{"tddate":null,"ddate":null,"tmdate":1509739330738,"tcdate":1509110830992,"number":387,"cdate":1509739328078,"id":"S1v4N2l0-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"S1v4N2l0-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Unsupervised Representation Learning by Predicting Image Rotations","abstract":"Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their  unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. \nWe demonstrate both qualitative and quantitative that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning.  We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them remarkably good performance. Even more, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art, thus they significantly close the gap between unsupervised and supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of $54.4\\%$ that is only 2.4 points lower from the supervised case. Similar striking results we get when transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, and CIFAR-10 classification.","pdf":"/pdf/961b1b17788954a27dcfd389a828ea6858b107ea.pdf","paperhash":"anonymous|unsupervised_representation_learning_by_predicting_image_rotations","_bibtex":"@article{\n  anonymous2018unsupervised,\n  title={Unsupervised Representation Learning by Predicting Image Rotations},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1v4N2l0-}\n}","keywords":["Unsupervised representation learning"],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper387/Authors"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}