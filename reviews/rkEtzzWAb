{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222768368,"tcdate":1511728482557,"number":2,"cdate":1511728482557,"id":"S1owSiOeM","invitation":"ICLR.cc/2018/Conference/-/Paper794/Official_Review","forum":"rkEtzzWAb","replyto":"rkEtzzWAb","signatures":["ICLR.cc/2018/Conference/Paper794/AnonReviewer1"],"readers":["everyone"],"content":{"title":"A very general formulation without real theoretical or empirical support","rating":"4: Ok but not good enough - rejection","review":"This paper introduces a family of \"parametric adversarial divergences\" and argue that they have advantages over other divergences in generative modelling, specially for structured outputs. \n\nThere's clear value in having good inductive biases (e.g. expressed in the form of the discriminator architecture) when defining divergences for practical applications. However, I think that the paper would be much more valuable if its focus shifted from presenting a new notion of divergence to deep-diving into the effect of inductive biases and presenting more specific results (theoretical and / or empirical) in structured prediction or other problems.  In its current form the paper doesn't seem particularly strong for either the divergence or GAN literatures. Some reasons below:\n\n* There are no specific results on properties of the divergences, or axioms that justify them. I think that presenting a very all-encompassing formulation without a strong foundation does not add value. \n* There's abundant literature on f-divergences which show that there's a 1-1 relationship between divergences and optimal (Bayes) risks of classification problems (e.g. Reid at al. Information, Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al. Divergences and Risks for Multiclass Experiments in COLT).  This disproves the point that the authors make that it's not possible to encode information about the final task in the divergence. If the loss for the task is proper, then it's well known how to construct a divergence which coincides with the optimal risk.\n* The divergences presented in this work are different from the above since the risk is minimised over a parametric class instead of over the whole set of integrable functions. However, practical estimators of f-divergences also reduce the optimization space (e.g. unit ball in a RKHS as in Nguyen et al.  Estimating Divergence Functionals and the\nLikelihood Ratio by Convex Risk Minimization or Ruderman et al. Tighter Variational Representations of f-Divergences via Restriction to Probability Measures). So, given the lack of strong foundation for the formulation, \"parametric adversarial divergences\" feel more like estimators of other divergences than a relevant new family.\n* There are many estimators for f-divergences (like the ones cited above and many others based e.g. on nearest-neighbors) that are sample-based and thus correspond to the \"implicit\" case that the authors discuss. They don't necessarily need to use the dual form. So table 1 and the first part of Section 3.1 are not accurate.\n* The experiments are few and too specific, specially given that the paper presents a very general framework. The first experiment just shows that Wasserstein GANs don't perform well in an specific dataset and use that to validate a point about those GANs not being good for high dimensions due to their sample complexity. That feels like confirmation bias and also does not really say anything about the parametric adversarial GANs, which are the focus of the paper.\n\nIn summary, I like the authors idea to explore the restriction of the function class of dual representations to produce useful-in-practice divergences, but the paper feels a bit middle of the road. The theory is not strong and the experiments don't necessary support the intuitive claims made in the paper.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Parametric Adversarial Divergences are Good Task Losses for Generative Modeling","abstract":"Generative modeling of high dimensional data like images is a notoriously difficult and ill-defined problem. In particular, how to evaluate a learned generative model is unclear.\nIn this paper, we argue that *adversarial learning*, pioneered with generative adversarial networks (GANs), provides an interesting framework to implicitly define more meaningful task losses for unsupervised tasks, such as for generating \"visually realistic\" images. By relating GANs and structured prediction under the framework of statistical decision theory, we put into light links between recent advances in structured prediction theory and the choice of the divergence in GANs. We argue that the insights about the notions of \"hard\" and \"easy\" to learn losses can be analogously extended to adversarial divergences. We also discuss the attractive properties of parametric adversarial divergences for generative modeling, and perform experiments to show the importance of choosing a divergence that reflects the final task.","pdf":"/pdf/a5bfbf4b82421ebfd5b0cbafc4f83ab32d7ade50.pdf","TL;DR":"Parametric adversarial divergences implicitly define more meaningful task losses for generative modeling, we make parallels with structured prediction to study the properties of these divergences and their ability to encode the task of interest.","paperhash":"anonymous|parametric_adversarial_divergences_are_good_task_losses_for_generative_modeling","_bibtex":"@article{\n  anonymous2018parametric,\n  title={Parametric Adversarial Divergences are Good Task Losses for Generative Modeling},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkEtzzWAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper794/Authors"],"keywords":["parametric","adversarial","divergence","generative","modeling","gan","neural","network","task","loss","structured","prediction"]}},{"tddate":null,"ddate":null,"tmdate":1512222768413,"tcdate":1511292939841,"number":1,"cdate":1511292939841,"id":"H1EMeWfgz","invitation":"ICLR.cc/2018/Conference/-/Paper794/Official_Review","forum":"rkEtzzWAb","replyto":"rkEtzzWAb","signatures":["ICLR.cc/2018/Conference/Paper794/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting way to think about GANs","rating":"6: Marginally above acceptance threshold","review":"This paper is in some sense a \"position paper,\" giving a framework for thinking about the loss functions implicitly used by the generator of GAN-type models. It advocates thinking about the loss in a way similar to how it is considered in structured prediction. It also proposes that approximating the dual formulation of various divergences with functions from a parametric class, as is typically done in GAN-type setups, is not only more tractable (computationally and in sample complexity) than the full nonparametric estimation, but also gives a better actual loss.\n\nOverall, I like the argument here, and think that it is a useful framework for thinking about these things. My main concern is that the practical contribution on top of Liu et al. (2017) might be somewhat limited.\n\nA few small points:\n\n- f-divergences can actually be nonparametrically estimated purely from samples, e.g. with the k-nearest neighbor estimator of https://arxiv.org/abs/1411.2045, or (for certain f-divergences) the kernel density based estimator of https://arxiv.org/abs/1402.2966. These are unlikely to lead to a practical learning algorithm, but could be mentioned in Table 1.\n\n- The discussion of MMD in the end of section 3.1 is a little off. MMD is fundamentally defined by the kernel choice; Dziugaite et al. (2015) only demonstrated that the Gaussian RBF kernel is a poor choice for MNIST modeling, while the samples of Li et al. (2015) simply by using a mixture of Gaussian kernels were much better. No reasonable fixed kernel is likely to yield good results on a harder image modeling problem, but that is a slightly different message than the one this paragraph conveys.\n\n- It would be interesting to replicate the analysis of Danihelka et al. (2017) on the Thin-8 dataset. This might help clarify which of the undesirable effects observed in the VAE model here are due to likelihood, and which due to other aspects of VAEs (like the use of the lower bound).","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Parametric Adversarial Divergences are Good Task Losses for Generative Modeling","abstract":"Generative modeling of high dimensional data like images is a notoriously difficult and ill-defined problem. In particular, how to evaluate a learned generative model is unclear.\nIn this paper, we argue that *adversarial learning*, pioneered with generative adversarial networks (GANs), provides an interesting framework to implicitly define more meaningful task losses for unsupervised tasks, such as for generating \"visually realistic\" images. By relating GANs and structured prediction under the framework of statistical decision theory, we put into light links between recent advances in structured prediction theory and the choice of the divergence in GANs. We argue that the insights about the notions of \"hard\" and \"easy\" to learn losses can be analogously extended to adversarial divergences. We also discuss the attractive properties of parametric adversarial divergences for generative modeling, and perform experiments to show the importance of choosing a divergence that reflects the final task.","pdf":"/pdf/a5bfbf4b82421ebfd5b0cbafc4f83ab32d7ade50.pdf","TL;DR":"Parametric adversarial divergences implicitly define more meaningful task losses for generative modeling, we make parallels with structured prediction to study the properties of these divergences and their ability to encode the task of interest.","paperhash":"anonymous|parametric_adversarial_divergences_are_good_task_losses_for_generative_modeling","_bibtex":"@article{\n  anonymous2018parametric,\n  title={Parametric Adversarial Divergences are Good Task Losses for Generative Modeling},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkEtzzWAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper794/Authors"],"keywords":["parametric","adversarial","divergence","generative","modeling","gan","neural","network","task","loss","structured","prediction"]}},{"tddate":null,"ddate":null,"tmdate":1509739097435,"tcdate":1509134972421,"number":794,"cdate":1509739094776,"id":"rkEtzzWAb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rkEtzzWAb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Parametric Adversarial Divergences are Good Task Losses for Generative Modeling","abstract":"Generative modeling of high dimensional data like images is a notoriously difficult and ill-defined problem. In particular, how to evaluate a learned generative model is unclear.\nIn this paper, we argue that *adversarial learning*, pioneered with generative adversarial networks (GANs), provides an interesting framework to implicitly define more meaningful task losses for unsupervised tasks, such as for generating \"visually realistic\" images. By relating GANs and structured prediction under the framework of statistical decision theory, we put into light links between recent advances in structured prediction theory and the choice of the divergence in GANs. We argue that the insights about the notions of \"hard\" and \"easy\" to learn losses can be analogously extended to adversarial divergences. We also discuss the attractive properties of parametric adversarial divergences for generative modeling, and perform experiments to show the importance of choosing a divergence that reflects the final task.","pdf":"/pdf/a5bfbf4b82421ebfd5b0cbafc4f83ab32d7ade50.pdf","TL;DR":"Parametric adversarial divergences implicitly define more meaningful task losses for generative modeling, we make parallels with structured prediction to study the properties of these divergences and their ability to encode the task of interest.","paperhash":"anonymous|parametric_adversarial_divergences_are_good_task_losses_for_generative_modeling","_bibtex":"@article{\n  anonymous2018parametric,\n  title={Parametric Adversarial Divergences are Good Task Losses for Generative Modeling},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkEtzzWAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper794/Authors"],"keywords":["parametric","adversarial","divergence","generative","modeling","gan","neural","network","task","loss","structured","prediction"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}