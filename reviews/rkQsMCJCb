{"notes":[{"tddate":null,"ddate":null,"tmdate":1515642405986,"tcdate":1512025429323,"number":3,"cdate":1512025429323,"id":"Sy686Qplz","invitation":"ICLR.cc/2018/Conference/-/Paper187/Official_Review","forum":"rkQsMCJCb","replyto":"rkQsMCJCb","signatures":["ICLR.cc/2018/Conference/Paper187/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Potentially interesting combination with little of its own novelty.","rating":"4: Ok but not good enough - rejection","review":"This manuscript proposes the use of \"adaptive convolutions\", previously proposed elsewhere, in GAN generators. The authors motivate this combination as allowing for better modeling of finer structure, conditioning the filter used for upsampling on the local neighbourhood beforehand.\n\nWhile Inception scores were the only proposed metric available for a time, other metrics have now been introduced in the literature (AIS log likelihood bounds, MS-SSIM, FID) and reporting Inception scores (with all of their problems) falls short for this reviewer. Because this is just the combination of two existing ideas, a more detailed analysis is warranted. Not only is the quantitative analysis lacking but also absent is any qualitative analysis of what exactly these adaptive convolutions are learning, whether this additional modeling power is well used, etc.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generative Adversarial Networks using Adaptive Convolution","abstract":"Most existing GANs architectures that generate images use transposed convolution or resize-convolution as their upsampling algorithm from lower to higher resolution feature maps in the generator. We argue that this kind of fixed operation is problematic for GANs to model objects that have very different visual appearances. We propose a novel adaptive convolution method that learns the upsampling algorithm based on the local context at each location to address this problem. We modify a baseline GANs architecture by replacing normal convolutions with adaptive convolutions in the generator. Experiments on CIFAR-10 dataset show that our modified models improve the baseline model by a large margin. Furthermore, our models achieve state-of-the-art performance on CIFAR-10 and STL-10 datasets in the unsupervised setting.","pdf":"/pdf/8040a0125d10dc2976df2465fe66a49790c37911.pdf","TL;DR":"We replace normal convolutions with adaptive convolutions to improve GANs generator.","paperhash":"anonymous|generative_adversarial_networks_using_adaptive_convolution","_bibtex":"@article{\n  anonymous2018generative,\n  title={Generative Adversarial Networks using Adaptive Convolution},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkQsMCJCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper187/Authors"],"keywords":["Generative Adversarial Networks","Unsupervised Learning","GANs"]}},{"tddate":null,"ddate":null,"tmdate":1515642406029,"tcdate":1512015143361,"number":2,"cdate":1512015143361,"id":"H1JNBZTef","invitation":"ICLR.cc/2018/Conference/-/Paper187/Official_Review","forum":"rkQsMCJCb","replyto":"rkQsMCJCb","signatures":["ICLR.cc/2018/Conference/Paper187/AnonReviewer2"],"readers":["everyone"],"content":{"title":"limited experiments","rating":"4: Ok but not good enough - rejection","review":"The paper proposes to use Adaptive Convolution (Niklaus 2017) in the context of GANs. A simple paper with: idea, motivation, experiments\n\nIdea:\nIt proposes a block called AdaConvBlock that replaces a regular Convolution with two steps:\nstep 1: regress convolution weights per pixel location conditioned on the input\nstep 2: do the convolution using these regressed weights\nSince local convolutions are generally expensive ops, it provides a few modifications to the size and shape of convolutions to make it efficient (like using depthwise)\n\nMotivation:\n- AdaConvBlock gives more local context per kernel weight, so that it can generate locally flexible objects / pixels in images\n\nMotivation is hand-wavy, the claim would need good experiments.\n\nExperiments:\n- Experiments are very limited, only overfit to inception score.\n- The experiments are not constructed to support the motivation / claim, but just to show that model performance improves.\n\nInception score experiments as the only experiments of a paper are woefully inadequate. The inception score is computed using a pre-trained imagenet model. It is not hard to overfit to.\nThe experiments need to support the motivation / claim better.\nIdeally the experiments need to show:\n- inception score improvements\n- actual samples showing that this local context helped produced better local regions / shapes\n- some kind of human evaluation supporting claims\n\nThe paper's novelty is also quite limited.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generative Adversarial Networks using Adaptive Convolution","abstract":"Most existing GANs architectures that generate images use transposed convolution or resize-convolution as their upsampling algorithm from lower to higher resolution feature maps in the generator. We argue that this kind of fixed operation is problematic for GANs to model objects that have very different visual appearances. We propose a novel adaptive convolution method that learns the upsampling algorithm based on the local context at each location to address this problem. We modify a baseline GANs architecture by replacing normal convolutions with adaptive convolutions in the generator. Experiments on CIFAR-10 dataset show that our modified models improve the baseline model by a large margin. Furthermore, our models achieve state-of-the-art performance on CIFAR-10 and STL-10 datasets in the unsupervised setting.","pdf":"/pdf/8040a0125d10dc2976df2465fe66a49790c37911.pdf","TL;DR":"We replace normal convolutions with adaptive convolutions to improve GANs generator.","paperhash":"anonymous|generative_adversarial_networks_using_adaptive_convolution","_bibtex":"@article{\n  anonymous2018generative,\n  title={Generative Adversarial Networks using Adaptive Convolution},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkQsMCJCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper187/Authors"],"keywords":["Generative Adversarial Networks","Unsupervised Learning","GANs"]}},{"tddate":null,"ddate":null,"tmdate":1515642406069,"tcdate":1511799836938,"number":1,"cdate":1511799836938,"id":"SkzQ2hFxf","invitation":"ICLR.cc/2018/Conference/-/Paper187/Official_Review","forum":"rkQsMCJCb","replyto":"rkQsMCJCb","signatures":["ICLR.cc/2018/Conference/Paper187/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Review","rating":"4: Ok but not good enough - rejection","review":"The paper operates under the hypothesis that the rigidity of the convolution operator is responsible in part for the poor performance of GANs on diverse visual datasets. The authors propose to replace convolutions in the generator with an Adaptive Convolution Block, which learns to generate the convolution weights and biases of the upsampling operation adaptively for each pixel location. State-of-the-art Inception scores are presented for the CIFAR-10 and STL-10 datasets.\n\nI think the idea of leveraging adaptive convolutions in decoder-based models is compelling, especially given its success in video frame interpolation, which makes me wonder why the authors chose to restrict themselves to GANs. Wouldn't the arguments used to justify replacing regular convolutions in the generator with adaptive convolution blocks apply equally well to any other decoder-based generative model, like a VAE, for instance?\n\nI find the paper lacking on the evaluation front. The evaluation of GANs is still very much an open research problem, which means that making a compelling case for the effectiveness of a proposed method requires nuance and contextualization. The authors claim a state-of-the-art Inception score but fail to explain what argument this claim supports. This is important, because the Inception score is not a universal measure of GAN performance: it provides a specific view on the ability of a generator to cover human-defined modes in the data distribution, but it does not inform on intra-class mode coverage and is blind to things like the generator collapsing on one or a few template samples per class.\n\nI am also surprised that the relationship with HyperNetworks [1] is not outlined, given that both papers leverage the idea of factoring network parameters through a second neural network.\n\nSome additional comments:\n\n- Figure 1 should be placed much earlier in the paper, preferably above Section 3. In its current state, the paper provides a lot of mathematical notation to digest without any visual support.\n- \"[...] a transposed convolution is equivalent to a convolution [...]\": This is inaccurate. A convolution's backward pass is a transposed convolution and vice versa, but they are not equivalent (especially when non-unit strides are involved).\n- \"The difficulties of training GANs is well known\": There is a grammatical error in this sentence.\n- \"If [the discriminator] is too strong, log(1 - D(G(z))) will be close to zero and there would be almost no gradient [...]\": This is only true for the minimax GAN objective, which is almost never used in practice. The non-saturating GAN objective does not exhibit this issue, as [2] re-iterated recently.\n- \"Several works have been done [...]\": There is a grammatical error here.\n- The WGAN-GP citation is wrong (Danihelka et al. rather than Gulrajani et al.).\n\nOverall, the paper's lack of sufficient convincing empirical support prevents me from recommending its acceptance.\n\nReferences:\n\n[1] Ha, D., Dai, A., and Le, Q. V. (2016). HyperNetworks. arXiv:1609.09106.\n[2] Fedus, W., Rosca, M., Lakshminarayanan, B., Dai, A. M., Mohamed, S., and Goodfellow, I. (2017). Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step. arXiv:1710.08446.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generative Adversarial Networks using Adaptive Convolution","abstract":"Most existing GANs architectures that generate images use transposed convolution or resize-convolution as their upsampling algorithm from lower to higher resolution feature maps in the generator. We argue that this kind of fixed operation is problematic for GANs to model objects that have very different visual appearances. We propose a novel adaptive convolution method that learns the upsampling algorithm based on the local context at each location to address this problem. We modify a baseline GANs architecture by replacing normal convolutions with adaptive convolutions in the generator. Experiments on CIFAR-10 dataset show that our modified models improve the baseline model by a large margin. Furthermore, our models achieve state-of-the-art performance on CIFAR-10 and STL-10 datasets in the unsupervised setting.","pdf":"/pdf/8040a0125d10dc2976df2465fe66a49790c37911.pdf","TL;DR":"We replace normal convolutions with adaptive convolutions to improve GANs generator.","paperhash":"anonymous|generative_adversarial_networks_using_adaptive_convolution","_bibtex":"@article{\n  anonymous2018generative,\n  title={Generative Adversarial Networks using Adaptive Convolution},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkQsMCJCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper187/Authors"],"keywords":["Generative Adversarial Networks","Unsupervised Learning","GANs"]}},{"tddate":null,"ddate":null,"tmdate":1509739438082,"tcdate":1509053082707,"number":187,"cdate":1509739435425,"id":"rkQsMCJCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rkQsMCJCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Generative Adversarial Networks using Adaptive Convolution","abstract":"Most existing GANs architectures that generate images use transposed convolution or resize-convolution as their upsampling algorithm from lower to higher resolution feature maps in the generator. We argue that this kind of fixed operation is problematic for GANs to model objects that have very different visual appearances. We propose a novel adaptive convolution method that learns the upsampling algorithm based on the local context at each location to address this problem. We modify a baseline GANs architecture by replacing normal convolutions with adaptive convolutions in the generator. Experiments on CIFAR-10 dataset show that our modified models improve the baseline model by a large margin. Furthermore, our models achieve state-of-the-art performance on CIFAR-10 and STL-10 datasets in the unsupervised setting.","pdf":"/pdf/8040a0125d10dc2976df2465fe66a49790c37911.pdf","TL;DR":"We replace normal convolutions with adaptive convolutions to improve GANs generator.","paperhash":"anonymous|generative_adversarial_networks_using_adaptive_convolution","_bibtex":"@article{\n  anonymous2018generative,\n  title={Generative Adversarial Networks using Adaptive Convolution},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rkQsMCJCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper187/Authors"],"keywords":["Generative Adversarial Networks","Unsupervised Learning","GANs"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}