{"notes":[{"tddate":null,"ddate":null,"tmdate":1515189542825,"tcdate":1515189542825,"number":4,"cdate":1515189542825,"id":"BkJNS_6Xf","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Comment","forum":"BywyFQlAW","replyto":"BkbPVPzgG","signatures":["ICLR.cc/2018/Conference/Paper232/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper232/Authors"],"content":{"title":"Newly added convergence bounds as functions of hyperparameters and fixed number of weight updates p, minors/typos revised","comment":"In the new revision, we've added a 4.5-page analysis to show the convergence speed of both outer-loop and the whole algorithm. A summary of the newly added analysis can be found in our new uploaded comments.\n\nReply to Comments:\n\nTheorem 3 analyzes the convergence rate of the whole algorithm presented in Algorithm 1 with a fixed number of weight updates $p$ in each inner-loop. The first term in the bound exponentially decreases with power $p$. \n\nThe convergence bounds in both Theorem 2 and Theorem 3 are functions of all hyperparameters $\\lambda$, $\\Delta$ and $p$. They show that exponentially decreasing $\\lambda$ is sufficient to guarantee a linear rate of convergence, while choosing small $\\Delta$ and $p$ make the algorithm efficient in computation. These theoretical analysis allows us to tune the hyperparameters in relatively small ranges.\n\nInstead of representing the whole cluster by the centroid everywhere, we only represent the hardness of a cluster by the loss on its centroid. By setting the number of clusters to be a large value, e.g., 1000 clusters for 50000 samples in our experiments, this hardness representation is accurate enough. It not only saves computation spent on submodular maximization in practice, but also makes the algorithm more robust to outliers, because it avoids selecting a single (or a few number of) outliers with extremely large loss.\n\nReply to Minor/typos:\n\nG(j|G\\j) contains a typo, it should be G(j|V\\j)=G(V)-G(V\\j), the marginal gain of element j conditioned on all the other elements in ground set V except j. Thanks for pointing this out! \n\nIn the revision, 1) we changed all citations to Anonymous (2018) to specific sections in Appendix; 2) we define V in Theorem 1 and all other Theorems; 3) for simplicity of representation, we use g() without subscript when it causes no confusion. For example, Theorem 1 and Lemma 2 holds for any iteration in outer-loop, so we ignore the subscript of g(). When discussing relationship between different iterations of outer-loop, we add subscript to w in g(w) (e.g., in proof of Theorem 2) or add subscipt to g() (e.g., in proof of Theorem 3). "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515189511559,"tcdate":1515189511559,"number":3,"cdate":1515189511559,"id":"H1xfB_TXM","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Comment","forum":"BywyFQlAW","replyto":"H1-u-QCef","signatures":["ICLR.cc/2018/Conference/Paper232/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper232/Authors"],"content":{"title":"Newly added theoretical analysis provides complete analysis of the whole algorithm, instructions on hyperparameter tuning, and supports the intuition behind the objective function","comment":"In the new revision, we add 4.5-page analysis to show the convergence speed for both the outer-loop and the whole algorithm. A summary of the newly added analysis can be found in our new uploaded comments.\n\nReply to Cons:\n\nTheorem 3 in the new revision gives the convergence analysis for the whole algorithm, each of whose inner-loop uses fixed number of updates to approximately solve a minimax problem. It does not only show convergence, but also shows convergence rate for both the inner-loop and outer-loop. \n\nIn Theorem 2 and Theorem 3, we show convergence bounds as functions of all hyperparameters. These results give strong intuition for how to choose the hyperparameters. They show that exponentially decreasing $\\lambda$ is sufficient to guarantee a linear rate of convergence, while choosing small $\\Delta$ and $p$ make the algorithm efficient computationally. In practice, we use grid search with small ranges to achieve the hyperparameters used in experiments.\n\nThe intuitions behind the objetive function can be found in the two paragraphs above Section 1.1, the last two paragraphs of Section 1.1, and the first paragraph of Section 2. In these places, we provide evidence based on the nature of machine learning model/algorithms, the similarity to the human teaching/learning process, and the comparison to previous works. In addition, the objective function has nice theoretical properties. Our newly added theoretical analysis supports that decreasing diversity weight $\\lambda$ and increasing hardness $k$ can improve the convergence bound. This provides further theoretical support.\n\nOur experiments verify several advantages of the proposed minimax curriculum learning across three different models and datasets. Our basic goal is to prove the idea of decreasing diversity and increasing hardness for general machine learning problems. This idea has never been studied before, either theoretically or empirically, as far as we know. We are working on experiments for much larger datasets such as ImageNet and COCO, and will make the results available as soon as we can."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515189885571,"tcdate":1515189425664,"number":2,"cdate":1515189425664,"id":"BJcnVd6mG","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Comment","forum":"BywyFQlAW","replyto":"HkO3F9EbM","signatures":["ICLR.cc/2018/Conference/Paper232/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper232/Authors"],"content":{"title":"Newly added 4.5-page theoretical to the convergence rate of the whole algorithm, extend Theorem 1 to show outer-loop convergence rate","comment":"Thanks for your positive comments about the theoretical analysis and helpful suggestions to extend Theorem 1! In the new revision, we've added a 4.5-page analysis to show the convergence speed for both the outer-loop and the whole algorithm, and show bounds as functions of hyperparameters. The results support our scheduling strategy for $\\lambda$ and $k$. A summary of the newly added analysis can be found in our new uploaded comments above your review comments.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515189375221,"tcdate":1515189375221,"number":1,"cdate":1515189375221,"id":"SyPKEdpQM","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Comment","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper232/Authors"],"content":{"title":"Summary of newly added 4.5-page complete theoretical analysis to the convergence rate of the whole algorithm and hyperparameters","comment":"We note that both Reviewer2 and Reviewer3 wish to see an analysis of the whole algorithm, and more details on hyperparameter tuning issues. Reviewer1 also provides helpful suggestions on how to strengthen Theorem 1's result. In fact, more complete theoretical analysis is the main concern of all reviewers. In the new revision, we've added a 4.5-page mathematical analysis giving a convergence rate of the whole algorithm with the scheduling of $k$ and $\\lambda$. The result also shows how to set hyperparameters to change the convergence. Here is a summary.\n\n1) Theorem 2 shows that either decreasing $\\lambda$ exponentially or increasing $k$ exponentially results in a linear convergence rate for the outer-loop of our algorithm. It also shows that using a scheduling with decreasing $\\lambda$ or/and increasing $k$ can gradually improve the bound. This supports our intuition of decreasing diversity and increasing hardness.\n\n2) Theorem 3 gives the convergence rate of the whole algorithm (each inner-loop runs only $p$ iterations). It shows linear convergence rate for both the inner-loop and outer-loop. The bound has two terms, one decreases exponentially with power $p$ (#iterations for inner-loop) and the other decreases exponentially with power $T$ (#iterations for outer-loop). \n\n3) Convergence bounds in both Theorem 2 and Theorem 3 contains all the hyperparameters $\\gamma$, $\\Delta$ and $p$. They show how the bounds change with these hyperparameters, and can help to choose hyperparameters in practice. For example, they show that exponentially decreasing $\\lambda$ is sufficient to guarantee a linear rate of convergence, while choosing small $\\Delta$ (the additive $k$ increment) and $p$ make the algorithm efficient in computation.\n\n4) Potentially interesting to future analysis of more general continuous-combinatorial optimization: The constant factors in Theorem 2 implies that $\\kappa_F/\\beta$ (ratio between the curvature of submodular term and the strongly-convex constant of loss term) and $c_1$ (the minimal ratio between loss and singular gain over all samples) are two important quantities in analyzing convex-submodular hybrid optimization. The constant factor $c$ in Theorem 3 is a weighted sum of the optimal objective value of the minimax problem without the submodular term, and the maximal value for the submodular term only. It relates the convergence bound to the solutions of the two extreme cases of Eq.(2)."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515642413825,"tcdate":1512511920945,"number":3,"cdate":1512511920945,"id":"HkO3F9EbM","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Review","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Good theoretical result on combining submodular set optimization with curriculum learning","rating":"6: Marginally above acceptance threshold","review":"The main strength of this paper, I think, is the theoretical result in Theorem 1. This result is quite nice. I wish the authors actually concluded with the following minor improvement to the proof that actually strengthens the result further.\n\nThe authors ended the discussion on thm 1 on page 7 (just above Sec 2.3) by saying what is sufficiently close to w*. If one goes back to (10), it is easy to see that what converges to w* when one of three things happen (assuming beta is fixed once loss L is selected).\n\n1) k goes to infinity\n2) alpha goes to 1\n3) g(w*) goes to 0\n\nThe authors discussed how alpha is close to 1 by virtue of submodular optimization lower bounds there for what is close to w*. In fact this proof shows the situation is much better than that. \n\nIf we are really concerned about making what converge to w*, and if we are willing to tolerate the increasing computational complexity associated solving submodular problems with larger k, we can schedule k to increase over time which guarantees that both alpha goes to 1 and g(w*) goes to zero. \n\nThere is also a remark that G(A) tends to be modular when lambda is small which is useful.\nFrom the algorithm, it seems clear that the authors recognized these two useful aspects of the objective and scheduled lambda to decrease exponentially and k to increase linearly.\n\nIt would be really nice to complete the analysis of Thm1 with a formal analysis of convergence speed for ||what-w*|| as lambda and k are scheduled in this fashion. Such an analysis would help practitioners make better choices for the hyper parameters gamma and Delta.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515642413861,"tcdate":1512087912920,"number":2,"cdate":1512087912920,"id":"H1-u-QCef","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Review","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Good theoretical results, but would have liked a stronger empirical story","rating":"6: Marginally above acceptance threshold","review":"This paper introduces MiniMax Curriculum learning, as an approach for adaptively train models by providing it different subsets of data. The authors formulate the learning problem as a minimax problem which tries to choose diverse example and \"hard\" examples, where the diversity is captured via a Submodular Loss function and the hardness is captured via the Loss function. The authors formulate the problem as an iterative technique which involves solving a minimax objective at every iteration. The authors argue the convergence results on the minimax objective subproblem, but do not seem to give results on the general problem. The ideas for this paper are built on existing work in Curriculum learning, which attempts to provide the learner easy examples followed by harder examples later on. The belief is that this learning style mimics human learners.\n\nPros:\n- The analysis of the minimax objective is novel and the proof technique introduces several interesting ideas.\n- This is a very interesting application of joint convex and submodular optimization, and uses properties of both to show the final convergence results\n- Even through the submodular objective is only approximately solvable, it still translates into a convergence result\n- The experimental results seem to be complete for the most part. They argue how the submodular optimization does not really affect the performance and diversity seems to empirically bring improvement on the datasets tried.\n\nCons:\n- The main algorithm MCL is only a hueristic. Though the MiniMax subproblem can converge, the authors use this in somewhat of a hueristic manner.\n- It seems somewhat hand wavy in the way the authors describe the hyper parameters of MCL, and it seems unclear when the algorithm converge and how to increase/decrease it over iterations\n- The objective function also seems somewhat non-intuitive. Though the experimental results seem to indicate that the idea works, I think the paper does not motivate the loss function and the algorithm well.\n- It seems to me the authors have experimented with smaller datasets (CIFAR, MNIST, 20NewsGroups). This being mainly an empirical paper, I would have expected results on a few larger datasets (e.g. ImageNet, CelebFaces etc.), particularly to see if the idea also scales to these more real world larger datasets.\n\nOverall, I would like to see if the paper could have been stronger empirically. Nevertheless, I do think there are some interesting ideas theoretically and algorithmically. For this reason, I vote for a borderline accept. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1515642413897,"tcdate":1511318617320,"number":1,"cdate":1511318617320,"id":"BkbPVPzgG","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Review","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Choosing diverse and hard training examples with submodular optimization.","rating":"5: Marginally below acceptance threshold","review":"Overview:\nThis paper proposes an approach to curriculum learning, where subsets of examples to train on are chosen during the training process. The proposed method is based on a submodular set function over the examples, which is intended to capture diversity of the included examples and is added to the training objective (eq. 2). The set is optimized to be as hard as possible (maximize loss), which results in a min-max problem. This is in turn optimized (approximately) by alternating between gradient-based loss minimization and submodular maximization. The theoretical analysis shows that if the loss is strongly convex, then the algorithm returns a solution which is close to the optimal solution. Empirical results are presented for several benchmarks.\nThe paper is mostly clear and the idea seems nice. On the downside, there are some limitations to the theoretical analysis and optimization scheme (see comments below).\n\nComments:\n- The theoretical result (thm. 1) studies the case of full optimization, which is different than the proposed algorithm (running a fixed number of weight updates). It would be interesting to show results on sensitivity to the number of updates (p).\n- The algorithm requires tuning of quite a few hyperparameters (sec. 3).\n- Approximating a cluster with a single sample (sec. 2.3) seems rather crude. There should be some theoretical and/or empirical study of its effect on quality of the solution.\n\nMinor/typos:\n- what is G(j|G\\j) in eq. (9)?\n- why cite Anonymous (2018) instead of Appendix...?\n- define V in Thm. 1.\n- in eq. (4) it may be clearer to denote g_k(w). Likewise in eq. (6) \\hat{g}_\\hat{A}(w), and in eq. (14) \\tilde{g}_{\\cal{A}}(w).\n- figures readability can be improved.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1514664152191,"tcdate":1509075166844,"number":232,"cdate":1509739412871,"id":"BywyFQlAW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/8976e2ac9e3fc1e9f3ce36226524d2c3056fb285.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]},"nonreaders":[],"replyCount":7,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}