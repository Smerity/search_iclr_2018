{"notes":[{"tddate":null,"ddate":null,"tmdate":1512401955539,"tcdate":1512401955539,"number":3,"cdate":1512401955539,"id":"ryjXhymZM","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Review","forum":"SJn0sLgRb","replyto":"SJn0sLgRb","signatures":["ICLR.cc/2018/Conference/Paper275/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting finding","rating":"6: Marginally above acceptance threshold","review":"The paper reports that averaging pairs of training images improves image classification generalization in many datasets. \nThis is quite interesting. The paper is also straightforward to read and clear, which is positive. Overall i think the finding is of sufficient interest for acceptance.\n\nThe paper would benefit from adding some speculation on reasons why this phenomenon occurs.\nThere are a couple of choices that would benefit from more explanation / analysis:  a) averaging, then forcing the classifier to pick one of the two classes present; why not pick both? b) the choice of hard-switching between sample pairing and regular training - it would be interesting if sample-pairing as an augmentation meshed better with other augmentations implementation-wise, so that it could be easier to integrate in other frameworks.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1511929162323,"tcdate":1511929162323,"number":4,"cdate":1511929162323,"id":"HyMUHnsez","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Comment","forum":"SJn0sLgRb","replyto":"SJXiG2oeM","signatures":["ICLR.cc/2018/Conference/Paper275/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper275/Authors"],"content":{"title":"Re: Re: Clarification","comment":"Each image is cropped and random flipped differently for each epoch based on random numbers, not only once before training."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1511928475241,"tcdate":1511928475241,"number":2,"cdate":1511928475241,"id":"SJXiG2oeM","invitation":"ICLR.cc/2018/Conference/-/Paper275/Public_Comment","forum":"SJn0sLgRb","replyto":"H1kIxTqxM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Re: Re: Clarification","comment":"Thanks for the quick and detailed reply!\n\nJust to make sure: were each of 50000 images randomly flipped and cropped (28x28 patch) at a random place before being introduced to the network for each epoch? In other words, are each of the training images slightly altered and therefore different for each non-SamplePairing epoch? Or were each of the 50000 images randomly flipped and cropped before training occured and so that the training set is identical for each non-SamplePairing epoch?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1511866438905,"tcdate":1511866438905,"number":3,"cdate":1511866438905,"id":"H1kIxTqxM","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Comment","forum":"SJn0sLgRb","replyto":"r1dM9S5xf","signatures":["ICLR.cc/2018/Conference/Paper275/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper275/Authors"],"content":{"title":"Re: Clarification","comment":"In the above network structure, all convolutions are 3x3 size with padding to keep the size. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222610710,"tcdate":1511838597771,"number":2,"cdate":1511838597771,"id":"S1CYm85gM","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Review","forum":"SJn0sLgRb","replyto":"SJn0sLgRb","signatures":["ICLR.cc/2018/Conference/Paper275/AnonReviewer1"],"readers":["everyone"],"content":{"title":"simple technique with nice results, could be analyzed a little deeper","rating":"5: Marginally below acceptance threshold","review":"The paper investigates a method of data augmentation for image classification, where two images from the training set are averaged together as input, but the label from only one image is used as a target.  Since this scheme is asymmetric and uses quite unrealistic input images, a training scheme is used where the technique is only enabled in the middle of training (not very beginning or end), and in an alternating on-off fashion.  This improves classification performance nicely on a variety of datasets.\n\nThis is a simple technique, and the paper is concise and to the point.  However, I would have liked to see a few additional comparisons.\n\nFirst, this augmentation technique seems to have two components:  One is the mixing of inputs, but another is the effective dropping of labels from one of the two images in the pair.  Which of these are more important, and can they be separated?  What if some of the images' labels are changed at random, for half the images in a minibatch, for example?  This would have the effect of random label changes, but without the input mixing.  Likewise, what if both labels in the pair are used as targets (with 0.5 assigned to each in the softmax target)?  This would mix the images, but keep targets intact.\n\nSecond, the bottom of p.3 says that multiple training procedures were evaluated, but I'd be interested to see the results of some of these.  In particular, is it important to alternate enabling and disabling SamplePairing, or does it also work to mix samples with and without it in each minibatch (e.g. 3/4 of the minibatch with pairing augmentation, and 1/4 without it)?\n\nI liked the experiment mixing images from within a restricted training set composed of a subset of the CIFAR images, compared to mixing these images with CIFAR training set images outside the restricted sample (p.5 and Fig 5).  This suggests to me, however, that it's possible the label manipulations may play an important role.  Or, is an explanation why this performs not as well that the network will train these mixing images to random targets (that of the training image in the pair), and never see this example again, whereas by using the training set alone, the mixing image is likely to be repeated with its correct label?  Some more discussion on this would be nice.\n\nOverall, I think this is an interesting technique that appears to achieve nice results.  It could be investigated deeper at some key points.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1511836176086,"tcdate":1511836176086,"number":2,"cdate":1511836176086,"id":"r1dM9S5xf","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Comment","forum":"SJn0sLgRb","replyto":"SyEr_7ceG","signatures":["ICLR.cc/2018/Conference/Paper275/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper275/Authors"],"content":{"title":"Re: Clarification","comment":"Thank you so much for your effort!\n\n> Structure of the network\n(input 28x28x3)\nBatchNorm\nConv 64\nRELU\nBatchNorm\nConv 96\nRELU\nMaxPool 2x2\nBatchNorm\nConv 96\nRELU\nBatchNorm\nConv 128\nRELU\nMaxPool 2x2\nBatchNorm\nConv 128\nRELU\nBatchNorm\nConv 192\nRELU\nMaxPool 2x2\nBatchNorm\nDropOut 40% dropped\nFullConnect 512\nRELU\nDropOut 30% dropped\nFullConnect 10 (100 for CIFAR-100)\nSoftMax\n\n> What fraction of the training data was put aside for the validation set?\nFor CIFAR-10, I used 50,000 images included in data_batch_* for training (except for experiments shown in Figure 5). For validation set, I used 10,000 images in test_batch.\n\n> Was the training set fabricated by fully using the two basic augmentation techniques (e.g. N samples -> 2048N samples)?\nYes. When we test validation images, we extract 28x28 patch from center of the image without ensembling.\n\n> For training on the CIFAR-10 dataset, how many images were used during each SamplePairing epoch and each non-SamplePairing epoch?\nFor each epoch (with or without SamplePairing), all 50,000 training images were fed into the training for CIFAR datasets.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1511827516078,"tcdate":1511827516078,"number":1,"cdate":1511827516078,"id":"SyEr_7ceG","invitation":"ICLR.cc/2018/Conference/-/Paper275/Public_Comment","forum":"SJn0sLgRb","replyto":"SJn0sLgRb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Clarification","comment":"I am attempting to reproduce the results described in this paper. \nI have a few questions:\nWhat is the exact structure of the network trained on the CIFAR-10 dataset?\nWhat fraction of the training data was put aside for the validation set?\nWas the training set fabricated by fully using the two basic augmentation techniques (e.g. N samples -> 2048N samples)?\nFor training on the CIFAR-10 dataset, how many images were used during each SamplePairing epoch and each non-SamplePairing epoch?\n\nThank you."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222610753,"tcdate":1511747536359,"number":1,"cdate":1511747536359,"id":"ryOCyetxf","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Review","forum":"SJn0sLgRb","replyto":"SJn0sLgRb","signatures":["ICLR.cc/2018/Conference/Paper275/AnonReviewer2"],"readers":["everyone"],"content":{"title":"interesting, but limited contribution","rating":"4: Ok but not good enough - rejection","review":"The paper proposes a new data augmentation technique based on picking random image pairs and producing \na new average image which is associated with the label of one of the two original samples. The experiments show\nthat this strategy allows to reduce the risk of overfitting especially in the case of a limited amount of training \nsamples or in experimental settings with a small number of categories.\n\n+ The paper is easy to read: the method and the experiments are explained clearly.\n\n- the method is presented as a heuristic technique. \n1) The training process has some specific steps with the Sample Pairing intermittently disabled. \nThe number of epochs with enabled or disabled Sample Pairing changes depending on the dataset.\nHow much si the method robust/sensitive to variations on these choices?\n2) There is no specific analysis on the results besides showing the validation and training errors: would it\nbe possible to see the results per class? Would the confusion matrices reveal something more about the\neffect of the method?  Does Sample Pairing help to differentiate similar categories even if they are mixed\nat trainign time?\n3)  Would it be possible to better control the importance of each sample label rather\nthan always choosing one of the two as ground truth? \n\nThe paper misses an in-depth analysis of the proposed practical strategy.\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1510092427121,"tcdate":1509966390126,"number":1,"cdate":1509966390126,"id":"BkCNMpTA-","invitation":"ICLR.cc/2018/Conference/-/Paper275/Official_Comment","forum":"SJn0sLgRb","replyto":"SJn0sLgRb","signatures":["ICLR.cc/2018/Conference/Paper275/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper275/Authors"],"content":{"title":"related submission in ICLR 2018","comment":"I found there is another submission discussing a quite similar technique.\nmixup: Beyond Empirical Risk Minimization\nhttps://openreview.net/forum?id=r1Ddp1-Rb&noteId=r1Ddp1-Rb\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]}},{"tddate":null,"ddate":null,"tmdate":1509739391035,"tcdate":1509088212111,"number":275,"cdate":1509739388376,"id":"SJn0sLgRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SJn0sLgRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Data Augmentation by Pairing Samples for Images Classification","abstract":"Data augmentation is a widely used technique in many machine learning tasks, such as image classification, to virtually enlarge the training dataset size and avoid overfitting. Traditional data augmentation techniques for image classification tasks create new samples from the original training data by, for example, flipping, distorting, adding a small amount of noise to, or cropping a patch from an original image. In this paper, we introduce a simple but surprisingly effective data augmentation technique for image classification tasks. With our technique, named SamplePairing, we synthesize a new sample from one image by overlaying another image randomly chosen from the training data (i.e., taking an average of two images for each pixel). By using two images randomly selected from the training set, we can generate N^2 new samples from N training samples. This simple data augmentation technique significantly improved classification accuracy for all the tested datasets; for example, the top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show that our SamplePairing technique largely improved accuracy when the number of samples in the training set was very small. Therefore, our technique is more valuable for tasks with a limited amount of training data, such as medical imaging tasks.\n","pdf":"/pdf/0c137ee36d92831a5f4af5436646af58d24b59e8.pdf","paperhash":"anonymous|data_augmentation_by_pairing_samples_for_images_classification","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation by Pairing Samples for Images Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJn0sLgRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper275/Authors"],"keywords":["Data augmentation","Image classification"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}