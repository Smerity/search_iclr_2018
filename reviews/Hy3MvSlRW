{"notes":[{"tddate":null,"ddate":null,"tmdate":1515789250145,"tcdate":1515789250145,"number":5,"cdate":1515789250145,"id":"SJ5ajc8EG","invitation":"ICLR.cc/2018/Conference/-/Paper256/Official_Comment","forum":"Hy3MvSlRW","replyto":"S11ZS2CWz","signatures":["ICLR.cc/2018/Conference/Paper256/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper256/AnonReviewer1"],"content":{"title":"Read the rebuttal","comment":"I have read authors' rebuttal and I am still keeping my scores same."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial reading networks for machine comprehension","abstract":"Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results.","pdf":"/pdf/4cff208c5bfa9edb6dcb0c3490095ae3761e823d.pdf","paperhash":"anonymous|adversarial_reading_networks_for_machine_comprehension","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial reading networks for machine comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hy3MvSlRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper256/Authors"],"keywords":["machine reading","adversarial training"]}},{"tddate":null,"ddate":null,"tmdate":1515642420139,"tcdate":1511955414075,"number":3,"cdate":1511955414075,"id":"Sy0AiMnef","invitation":"ICLR.cc/2018/Conference/-/Paper256/Official_Review","forum":"Hy3MvSlRW","replyto":"Hy3MvSlRW","signatures":["ICLR.cc/2018/Conference/Paper256/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The root idea is interesting but the paper has significant issues.","rating":"5: Marginally below acceptance threshold","review":"The main idea of this paper is to automate the construction of adversarial reading comprehension problems in the spirit of Jia and Liang, EMNLP 2017.  In that work a \"distractor sentence\" is manually added to a passage to superficially, but not logically, support an incorrect answer.  It was shown that these distractor sentences largely fool existing reading comprehension systems although they do not fool human readers.\n\nThis paper replaces the manual addition of a distractor sentence with a single word replacement where a \"narrator\" is trained adversarially to select a replacement to fool the question answering system.  This idea seems interesting but very difficult to evaluate.  An adversarial word replacement my in fact destroy the factual information needed to answer the question and there is no control for this.  The performance of the question answering system in the presence of this adversarial narrator is of unclear significance and the empirical results in the paper are very difficult to interpret.  No comparisons with previous work are given (and perhaps cannot be given).\n\nA better model would be the addition of a distractor sentence as this preserves the information in the original passage.  A language model could probably be used to generate a compelling distractor.  But we want that the corrupted passage has the same correct answer as the uncorrupted passage and this difficult to guarantee.  A trained \"narrator\" could learn to actually change the correct answer.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial reading networks for machine comprehension","abstract":"Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results.","pdf":"/pdf/4cff208c5bfa9edb6dcb0c3490095ae3761e823d.pdf","paperhash":"anonymous|adversarial_reading_networks_for_machine_comprehension","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial reading networks for machine comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hy3MvSlRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper256/Authors"],"keywords":["machine reading","adversarial training"]}},{"tddate":null,"ddate":null,"tmdate":1515642420179,"tcdate":1511817960039,"number":2,"cdate":1511817960039,"id":"BJggQbceG","invitation":"ICLR.cc/2018/Conference/-/Paper256/Official_Review","forum":"Hy3MvSlRW","replyto":"Hy3MvSlRW","signatures":["ICLR.cc/2018/Conference/Paper256/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Paper needs significant revision","rating":"5: Marginally below acceptance threshold","review":"Summary:\n\nThis paper proposes an adversarial learning framework for machine comprehension task. Specifically, authors consider a reader network which learns to answer the question by reading the passage and a narrator network which learns to obfuscate the passage so that the reader can fail in its task. Authors report results in 3 different reading comprehension datasets and the proposed learning framework results in improving the performance of GMemN2N.\n\n\nMy Comments:\n\nThis paper is a direct application of adversarial learning to the task of reading comprehension. It is a reasonable idea and authors indeed show that it works.\n\n1. The paper needs a lot of editing. Please check the minor comments.\n\n2. Why is the adversary called narrator network? It is bit confusing because the job of that network is to obfuscate the passage.\n\n3. Why do you motivate the learning method using self-play? This is just using the idea of adversarial learning (like GAN) and it is not related to self-play.\n\n4. In section 2, first paragraph, authors mention that the narrator prevents catastrophic forgetting. How is this happening? Can you elaborate more?\n\n5. The learning framework is not explained in a precise way. What do you mean by re-initializing and retraining the narrator? Isn’t it costly to reinitialize the network and retrain it for every turn? How many such epochs are done? You say that test set also contains obfuscated documents. Is it only for the validation set? Can you please explain if you use obfuscation when you report the final test performance too? It would be more clear if you can provide a complete pseudo-code of the learning procedure.\n\n6. How does the narrator choose which word to obfuscate? Do you run the narrator model with all possible obfuscations and pick the best choice?\n\n7. Why don’t you treat number of hops as a hyper-parameter and choose it based on validation set? I would like to see the results in Table 1 where you choose number of hops for each of the three models based on validation set.\n\n8. In figure 2, how are rounds constructed? Does the model sees the same document again and again for 100 times or each time it sees a random document and you sample documents with replacement? This will be clear if you provide the pseudo-code for learning.\n\n9. I do not understand author's’ justification for figure-3. Is it the case that the model learns to attend to last sentences for all the questions? Or where it attends varies across examples?\n\n10. Are you willing to release the code for reproducing the results?\n\nMinor comments:\n\nPage 1, “exploit his own decision” should be “exploit its own decision”\nIn page 2, section 2.1, sentence starting with “Indeed, a too low percentage …” needs to be fixed.\nPage 3, “forgetting is compensate” should be “forgetting is compensated”.\nPage 4, “for one sentences” needs to be fixed.\nPage 4, “unknow” should be “unknown”.\nPage 4, “??” needs to be fixed.\nPage 5, “for the two first datasets” needs to be fixed.\nTable 1, “GMenN2N” should be “GMemN2N”. In caption, is it mean accuracy or maximum accuracy?\nPage 6, “dataset was achieves” needs to be fixed.\nPage 7, “document by obfuscated this word” needs to be fixed.\nPage 7, “overall aspect of the two first readers” needs to be fixed.\nPage 8, last para, references needs to be fixed.\nPage 9, first sentence, please check grammar.\nSection 6.2, last sentence is irrelevant.\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial reading networks for machine comprehension","abstract":"Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results.","pdf":"/pdf/4cff208c5bfa9edb6dcb0c3490095ae3761e823d.pdf","paperhash":"anonymous|adversarial_reading_networks_for_machine_comprehension","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial reading networks for machine comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hy3MvSlRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper256/Authors"],"keywords":["machine reading","adversarial training"]}},{"tddate":null,"ddate":null,"tmdate":1515642420220,"tcdate":1510800756119,"number":1,"cdate":1510800756119,"id":"HynOT_5Jz","invitation":"ICLR.cc/2018/Conference/-/Paper256/Official_Review","forum":"Hy3MvSlRW","replyto":"Hy3MvSlRW","signatures":["ICLR.cc/2018/Conference/Paper256/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting idea, unconvincing results","rating":"4: Ok but not good enough - rejection","review":"The paper aims to improve the accuracy of reading model on question answering dataset by playing against an adversarial agent (which is called narrator by the authors) that \"obfuscates\" the document, i.e. changing words in the document. The authors mention that word dropout can be considered as its special case which randomly drops words without any prior. Then the authors claim that smartly choosing the words to drop can make a stronger adversarial agent, which in turn would improve the performance of the reader as well. Hence the adversarial agent is trained and is architecturally similar to the reader but just has a different last layer, which predicts the word that would make the reader fail if the word is obfuscated.\n\nI think the idea is interesting and novel. While there have been numerous GAN-like approaches for language understanding, very few, if any, have shown worthy results. So if this works, it could be an impactful achievement. \n\nHowever, I am concerned with the experimental results.\n\nFirst, CBT: NE and CN numbers are too low. Even a pure LSTM achieves (no attention, no memory) 44% and 45%, respectively (Yu et al., 2017). These are 9% and 6% higher than the reported numbers for adversarial GMemN2N. So it is very difficult to determine if the model is appropriate for the dataset in the first place, and whether the gain from the non-adversarial setting is due to the adversarial setup or not.\n\nSecond, Cambridge dialogs: the dataset's metric is not accuracy-based (while the paper reports accuracy), so I assume some preprocessing and altering have been done on the dataset. So there is no baseline to compare. Though I understand that the point of the paper is the improvement via the adversarial setting, it is hard to gauge how good the numbers are.\n\nThird, TripAdvisor: the dataset paper by Wang et al. (2010) is not evaluated on accuracy (rather on ranking, etc.). Did you also make changes to the dataset? Again, this makes the paper less strong because there is no baseline to compare.\n\nIn short, the only comparable dataset is CBT, which has too low accuracy compared to a very simple baseline.\nIn order to improve the paper, I recommend the authors to evaluate on more common datasets and/or use more appropriate reading models.\n\n---\n\nTypos:\npage 1 first para: \"One the first hand\" -> \"On the first hand\"\npage 1 first para: \"minimize to probability\" -> \"minimize the probability\"\npage 3 first para: \"compensate\" -> \"compensated\"\npage 3 last para: \"softmaxis\" -> \"softmax is\"\npage 4 sec 2.4: \"similar to the reader\" -> \"similarly to the reader\"\npage 4 sec 2.4: \"unknow\" -> \"unknown\"\npage 4 sec 3 first para: missing reference at \"a given dialog\"\npage 5 first para: \"Concretly\" -> \"Concretely\"\nTable 1: \"GMenN2N\" -> \"GMemN2N\"\nTable 1: what is difference between \"mean\" and \"average\"?\npage 8 last para: missing reference at \"Iterative Attentive Reader\"\npage 9 sec 6.2 last para: several citations missing, e.g. which paper is by \"Tesauro\"?\n\n\n[Yu et al. 2017] Adams Wei Yu, Hongrae Kim, and Quoc V. Le. Learning to Skim Text. ACL 2017\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial reading networks for machine comprehension","abstract":"Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results.","pdf":"/pdf/4cff208c5bfa9edb6dcb0c3490095ae3761e823d.pdf","paperhash":"anonymous|adversarial_reading_networks_for_machine_comprehension","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial reading networks for machine comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hy3MvSlRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper256/Authors"],"keywords":["machine reading","adversarial training"]}},{"tddate":null,"ddate":null,"tmdate":1513262863041,"tcdate":1509082900280,"number":256,"cdate":1509739398177,"id":"Hy3MvSlRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Hy3MvSlRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Adversarial reading networks for machine comprehension","abstract":"Machine reading has recently shown remarkable progress thanks to differentiable\nreasoning models. In this context, End-to-End trainable Memory Networks\n(MemN2N) have demonstrated promising performance on simple natural language\nbased reasoning tasks such as factual reasoning and basic deduction. However,\nthe task of machine comprehension is currently bounded to a supervised setting\nand available question answering dataset. In this paper we explore the paradigm\nof adversarial learning and self-play for the task of machine reading comprehension.\nInspired by the successful propositions in the domain of game learning, we\npresent a novel approach of training for this task that is based on the definition\nof a coupled attention-based memory model. On one hand, a reader network is\nin charge of finding answers regarding a passage of text and a question. On the\nother hand, a narrator network is in charge of obfuscating spans of text in order\nto minimize the probability of success of the reader. We experimented the model\non several question-answering corpora. The proposed learning paradigm and associated\nmodels present encouraging results.","pdf":"/pdf/4cff208c5bfa9edb6dcb0c3490095ae3761e823d.pdf","paperhash":"anonymous|adversarial_reading_networks_for_machine_comprehension","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial reading networks for machine comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hy3MvSlRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper256/Authors"],"keywords":["machine reading","adversarial training"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}