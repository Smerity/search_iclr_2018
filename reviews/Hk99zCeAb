{"notes":[{"tddate":null,"ddate":null,"tmdate":1515579117789,"tcdate":1515578963355,"number":5,"cdate":1515578963355,"id":"B1oIUPX4M","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Comment","forum":"Hk99zCeAb","replyto":"r1YixQVZM","signatures":["ICLR.cc/2018/Conference/Paper447/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper447/AnonReviewer1"],"content":{"title":"Anonymity","comment":"I totally agree with the last point: it would have been great if the organizers provided a more detailed CFP and recommended best practices.\n\nHowever, I disagree with the other two points:\nFirst, I know arxiv, talks, blogs, etc are permitted. But directly linking the author list from the paper is generally not. \nSecond, there are ways to host data anonymously and many ICLR authors (including myself) found some. If in doubt, the right way would be to ask the organizers, not breach the anonymity directly.\n\nIn the end, the decision is on ACs and PCs."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1513253852410,"tcdate":1513253852410,"number":4,"cdate":1513253852410,"id":"B1N1nJxGf","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Comment","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference/Paper447/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper447/Authors"],"content":{"title":"Revised PDF","comment":"We have uploaded a new revision of the paper, addressing the concerns brought up in the reviews. The detailed list of changes is as follows:\n\n- Revise the nearest neighbors in Figure 10 by using VGG feature-space distance and showing 5 best matches for each generated image.\n- Report average CIFAR10 inception score over 10 random initializations in Table 3, in addition to the highest achieved score.\n- Add discussion of [Denton et al. 2015], [Huang et al. 2016], and [Zhang et al. 2017] in Section 2.\n- Fix [Anonymous 2017], [Rabin et al. 2011], and [Radford et al. 2015] references.\n- Update \"(h) Converged\" case in Table 1 and Figure 3, as well as LSUN images in Figures 12-17 using networks that were trained longer.\n- Report SWD numbers for CelebA-HQ and LSUN categories in Figures 11-17.\n- Typo fixes and minor clarifications.\n\nWe would like to thank the reviewers again for useful feedback."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1512480929187,"tcdate":1512480929187,"number":3,"cdate":1512480929187,"id":"r1YixQVZM","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Comment","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference/Paper447/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper447/Authors"],"content":{"title":"We thank the reviewers for accurate reviews","comment":"We will fix all the references and add related discussion to the paper. \n\nWe have, in fact, obtained more sensible nearest-neighbor results using a feature-space distance metric for image comparison. We will update Fig. 10 accordingly and include multiple nearest neighbors for each generated image. The conclusion still stands that the generated images have no obvious source images in the training set. The hyperparameter changes related to Table 1 (d) are listed in Appendix A.2. \n\nWe acknowledge R1’s concerns about anonymity and feel a few words are in order.\n\nFirst, the call for papers explicitly states that arXiv and other such public forums are permitted. While we agree that full anonymity is valuable, we feel that one cannot realistically expect to achieve it perfectly, because so many potential reviewers subscribe to the arXiv announce list and articles from that list are inevitably discussed in social media.\n\nSecond, the OpenReview submission site does not allow supplemental videos or code, forcing one to use services like YouTube and GitHub, neither of which allows anonymous submissions. In our opinion, that leaves two possibilities: 1) fake accounts, or 2) breach of anonymity. We thought about this long and hard and chose #2 because #1 seems fraught with many more problems -- and would perhaps also seem like a strange requirement. While we anonymized the paper and the video to the extent possible within these bounds, we regrettably forgot a full author list in the readme at GitHub. We sincerely apologize for this oversight.\n\nIn order to avoid this kind of awkwardness in the future, we feel that explicit guidance in the CFP -- including suggested best practices for submitting videos, code, and data -- would be helpful and greatly facilitate the review process."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1515642450138,"tcdate":1512059505645,"number":3,"cdate":1512059505645,"id":"S15uG36lG","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Review","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference/Paper447/AnonReviewer2"],"readers":["everyone"],"content":{"title":"-","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper proposes a number of ideas for improving GANs for image generation, highlighting in particular a curriculum learning strategy to progressively increase the resolution of the generated images, resulting in GAN generators capable of producing samples with unprecedented resolution and visual fidelity.\n\n\nPros:\n\nThe paper is well-written and the results speak for themselves! Qualitatively they’re an impressive and significant improvement over previous results from GANs and other generative models.  The latent space interpolations shown in the video (especially on CelebA-HQ) demonstrate that the generator can smoothly transition between modes and convince me that it isn’t simply memorizing the training data. (Though I think this issue could be addressed a bit better -- see below.) Though quantification of GAN performance is difficult and rapidly evolving, there is a lot of quantitative analysis all pointing to significant improvements over previous methods.\n\nA number of new tricks are proposed, with the ablation study (tab 1 + fig 3) and learning curves (fig 4) giving insight into their effects on performance.  Though the field is moving quickly, I expect that several of these tricks will be broadly adopted in future work at least in the short to medium term.\n\nThe training code and data are released.\n\n\nCons/Suggestions:\n\nIt would be nice to see overfitting addressed and quantified in some way.  For example, the proposed SWD metric could be recomputed both for the training and for a held-out validation/test set, with the difference between the two scores measuring the degree of overfitting.  Similarly, Danihelka et al. [1] show that an independently trained Wasserstein critic (with one critic trained on G samples vs. train samples, and another trained on G samples vs. val samples) can be used to measure overfitting.  Another way to go could be to generate a large number of samples and show the nearest neighbor for a few training set samples and for a few val set samples.  Doing this in pixel space may not work well especially at the higher resolutions, but maybe a distance function in the space of some high-level hidden layer of a trained discriminator could show good semantic nearest neighbors.\n\nThe proposed SWD metric is interesting and computationally convenient, but it’s not clear to me that it’s an improvement over previous metrics like the independent Wasserstein critic proposed in [1].  In particular the use of 7x7 patches would seem to limit the metric’s ability to capture the extent to which global structure has been learned, even though the patches are extracted at multiple levels of the Laplacian pyramid.\n\nThe ablation study (tab 1 + fig 3) leaves me somewhat unsure which tricks contribute the most to the final performance improvement over previous work.  Visually, the biggest individual improvement is easily when going from (c) to (d), which adds the “Revised training parameters”, with the improvement from (a) to (b) which adds the highlighted progressive training schedule appearing relatively minor in comparison.  However, I realize the former large improvement is due to the arbitrary ordering of the additions in the ablation study, with the small minibatch addition in (c) crippling results on its own.  Ablation studies with large numbers of tweaks are always difficult and this one is welcome and useful despite the ambiguity.\n\nOn a related note, it would be nice if there were more details on the “revised training hyperparameters” improvement ((d) in the ablation study) -- which training hyperparameters are adjusted, and how?\n\n“LAPGAN” (Denton et al., 2015) should be cited as related work: LAPGAN’s idea of using a separate generator/discriminator at each level of a Laplacian pyramid conditioned on the previous level is quite relevant to the progressive training idea proposed here.  Currently the paper is only incorrectly cited as “DCGAN” in a results table -- this should be fixed as well.\n\n\nOverall, this is a well-written paper with striking results and a solid effort to analyze, ablate, and quantify the effect of each of the many new techniques proposed. It’s likely that the paper will have a lot of impact on future GAN work.\n\n\n[1] Danihelka et al., “Comparison of Maximum Likelihood and GAN-based training of Real NVPs” https://arxiv.org/abs/1705.05263","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1511955679858,"tcdate":1511955679858,"number":2,"cdate":1511955679858,"id":"Bk_JafhgM","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Comment","forum":"Hk99zCeAb","replyto":"rk0s9ajgM","signatures":["ICLR.cc/2018/Conference/Paper447/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper447/Authors"],"content":{"title":"Re: Minor Correction","comment":"We apologize that the source code is somewhat convoluted in this regard.\n\nOur implementation performs weight initialization in two distinct phases. It first initializes the weights using Lasagne's standard He initializer and then rescales them in accordance to Section 4.1. For example, consider the following line in network.py (http://bit.ly/2zykV3P#L471):\n\n471  net = PN(BN(WS(Conv2DLayer(net, name='G1b', num_filters=nf(1), filter_size=3, pad=1, nonlinearity=act, W=iact))))\n\nHere, we create a standard Conv2DLayer and apply equalized learning rate (WS) as well as pixelwise feature vector normalization (PN) on top of it. Note that batch normalization (BN) is disabled in most of our experiments. When the Conv2DLayer is first instantiated, the weights are initialized according to W=iact, which in turn is defined as lasagne.init.HeNormal('relu') on lines 459 and 32. We apply equalized learning rate by latching a custom WScaleLayer (line 278) onto the Conv2DLayer. When the WScaleLayer is instantiated, it estimates the elementwise standard deviation of the weights and normalizes them accordingly:\n\n281  W = incoming.W.get_value()\n282  scale = np.sqrt(np.mean(W ** 2))\n283  incoming.W.set_value(W / scale)\n\nThe value on line 281 corresponds to $\\hat{w}_i$ in the paper, line 282 corresponds to $c$, and line 283 to $w_i$. In other words, this part of the code undoes the effect of He's initializer and brings the weights back to trivial N(0,1) initialization."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1511934629671,"tcdate":1511934629671,"number":2,"cdate":1511934629671,"id":"rk0s9ajgM","invitation":"ICLR.cc/2018/Conference/-/Paper447/Public_Comment","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Minor Correction","comment":"In Section 4.1 you mention that you are initializing the network weights by sampling from the normal distribution. In your code, it appears you are using the stock Lasagne weight initialization, which uses the Xavier Glorot uniform distribution. Or has this changed in some newer version of Lasagne?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1515642450183,"tcdate":1511627476517,"number":2,"cdate":1511627476517,"id":"rJ205zPlG","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Review","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference/Paper447/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Mixed - great results on image generation, but not properly anonymized","rating":"1: Trivial or wrong","review":"Before the actual review I must mention that the authors provide links in the paper that immediately disclose their identity (for instance, the github link). This is a violation of double-blindness, and in any established double-blind conference this would be a clear reason for automatic rejection. In case of ICLR, double-blindness is new and not very well described in the call for papers, so I guess it’s up to ACs/PCs to decide. I would vote for rejection. I understand in the age of arxiv and social media double-blindness is often violated in some way, but here the authors do not seem to care at all. \n\n—\n\nThe paper proposes a collections of techniques for improving the performance of Generative Adversarial Networks (GANs). The key contribution is a principled multi-scale approach, where in the process of training both the generator and the discriminator are made progressively deeper and operate on progressively larger images. The proposed version of GANs allows generating images of high resolution (up to 1024x1024) and high visual quality.\n\nPros:\n1) The visual quality of the results is very good, both on faces and on objects from the LSUN dataset. This is a large and clear improvement compared to existing GANs.\n2) The authors perform a thorough quantitative evaluation, demonstrating the value of the proposed approach. They also introduce a new metric - Sliced Wasserstein Distance.\n3) The authors perform an ablation study illustrating the value of each of the proposed modifications.\n\nCons:\n1) The paper only shows results on image generation from random noise. The evaluation of this task is notoriously difficult, up to impossible (Theis et al., ICLR 2016). The authors put lots of effort in the evaluation, but still:\n- it is unclear what is the average quality of the samples - a human study might help\n- it is unclear to which extent the images are copied from the training set.  The authors show some nearest neighbors from the training set, but very few and in the pixel space, which is known to be pointless (again, Theis et al. 2016). Interpolations in the latent space is a good experiment, but in fact the interpolations do not look that great on LSUN\n- it is unclear if the model covers the full diversity of images (mode collapse)\nIt would be more convincing to demonstrate some practical results, for instance inpainting, superresolution, unsupervised or semi-supervised learning, etc.\n2) The general idea of multi-scale generation is not new, and has been investigated for instance in LapGAN (Denton et al., ICLR 2015) or StackGAN (Zhang et al., ICCV2017, arxiv 2017). The authors should properly discuss this. \n3) The authors mention “unhealthy competition” between the discriminator and the generator several times, but it is not quite clear what exactly they mean - a more specific definition would be useful.\n\n(This conclusion does not take the anonymity violation into account. Because of the violation I believe the paper should be rejected. Of course I am open to discussions with ACs/PCs.) \nTo conclude, the paper demonstrates a breakthrough in the quality and resolution of images generated with a GAN. The experimental evaluation is thorough, to the degree allowed by the poorly defined task of generating images from random noise. Results on some downstream tasks, such as inpainting, image processing or un-/semi-supervised learning would make the paper more convincing. Still, the paper should definitely be accepted for publication. Normally, I would give the paper a rating of 8.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1515642450229,"tcdate":1511137326305,"number":1,"cdate":1511137326305,"id":"BJ8NesygM","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Review","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference/Paper447/AnonReviewer3"],"readers":["everyone"],"content":{"title":"good paper, accept","rating":"8: Top 50% of accepted papers, clear accept","review":"The paper describes a number of modifications of GAN training that enable synthesis of high-resolution images. The modifications also support more automated longer-term training, and increasing variability in the results.\n\nThe key modification is progressive growing. First, a GAN is trained for image synthesis at very low resolution. Then a layer that refines the resolution is progressively faded in. (More accurately, a corresponding pair of layers, one in the generation and one in the discriminator.) This progressive fading in of layers is repeated, one octave at a time, until the desired resolution is reached.\n\nAnother modification reported in the paper is a simple parameter-free minibatch summary statistic feature that is reported to increase variation. Finally, the paper describes simple schemes for initialization and feature normalization that are reported to be more effective than commonly used initializers and batchnorm.\n\nIt's a very nice paper. It does share the \"bag of tricks\" nature of many GAN papers, but as such it is better than most of the lot. I appreciate that some of the tricks actually simplify training, and most are conceptually reasonable. The paper is also very well written.\n\nMy quibbles are minor. First, I would discuss [Huang et al., CVPR 2017] and the following paper more prominently:\n\n[Zhang et al., ICCV 2017] H. Zhang, T. Xu, H. Li, S. Zhang, X. Wang, X. Huang, and D. Metaxas. StackGAN: Text to photo-realistic image synthesis with stacked generative adversarial networks. In ICCV, 2017.\n\nI couldn't find a discussion of [Huang et al., CVPR 2017] at all, although it's in the bibliography. (Perhaps I overlooked the discussion.) And [Zhang et al., ICCV 2017] is quite closely related, since it also tackles high-resolution synthesis via multi-scale refinement. These papers don't diminish the submission, but they should be clearly acknowledged and the contribution of the submission relative to these prior works should be discussed.\n\nAlso, [Rabin et al., 2011] is cited in Section 5 but I couldn't find it in the bibliography.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1510750761632,"tcdate":1510750761632,"number":1,"cdate":1510750761632,"id":"rJGV53FyM","invitation":"ICLR.cc/2018/Conference/-/Paper447/Official_Comment","forum":"Hk99zCeAb","replyto":"SJqOmCHJf","signatures":["ICLR.cc/2018/Conference/Paper447/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper447/Authors"],"content":{"title":"Answers","comment":"1.\nYes, assuming that the question refers to the exponential running average that we use for visualizing the generated images.\n\nWe have observed that the best results are generally obtained using a relatively high learning rate, which in turn leads to significant variation in terms of network weights between consecutive training iterations. Any instantaneous snapshot of the generator is likely to be slightly off or exaggerated in terms of various image features such as color, brightness, sharpness, shape of the mouth, amount of hair, color of the eyes, etc. The exponential running average reduces this variation, leading to considerably more consistent results.\n\nIntuitively speaking, we can say that the generator and discriminator are constantly exploring a large neighborhood of different solutions around the current average solution, even though the average solution itself evolves relatively slowly. According to our experiments, such exploration seems to be highly beneficial in terms of eventually converging towards a good local optimum.\n\n2.\nWe have tried increasing the minibatch size in our CIFAR-10 runs, but we have not observed an increase in the inception scores.\n\nThe performance degradation associated with small minibatch size is largely limited to configurations that rely heavily on batch normalization (rows a-c in Table 1). Perhaps surprisingly, we have observed that smaller minibatches actually produce slightly better results in configurations where batch normalization is not present (rows d-h).\n\n3.\nWe did explore different network architectures in the early stages of the project. In general, it does not seem to make a big difference whether we start at 2x2, 4x4, 8x8, or 16x16 resolution. We chose 4x4 mainly because it is the most natural fit for our specific network architecture. We have also observed that it is beneficial to have roughly the same structure and capacity in both networks, as well as matching upsampling and downsampling operators.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1510495183246,"tcdate":1510495090129,"number":1,"cdate":1510495090129,"id":"SJqOmCHJf","invitation":"ICLR.cc/2018/Conference/-/Paper447/Public_Comment","forum":"Hk99zCeAb","replyto":"Hk99zCeAb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Questions","comment":"1. Was performance degrading actually observed when smoothing was not used?\n\n2. It seems that the reported Inception score of CIFAR is based on minibatch size of 16 because you wanted to show that the performance degrading of small minibatch could be remedied by that. Have you found a significant increase in score when the size is 64 and when you use all the techniques you used to remedy the aforementioned performance degrading? If so, I think the degree of the increase in score would indicate the size of this bottleneck. \n\n3. Did you do any other architecture exploration such as beginning from first block having 2x2 output instead of 4x4?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]}},{"tddate":null,"ddate":null,"tmdate":1513171322840,"tcdate":1509118609550,"number":447,"cdate":1509739296360,"id":"Hk99zCeAb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Hk99zCeAb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Progressive Growing of GANs for Improved Quality, Stability, and Variation","abstract":"We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.\n","pdf":"/pdf/adb9f52be84187f86cf03bf5d69e13f27c9d2d2b.pdf","TL;DR":"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.","paperhash":"anonymous|progressive_growing_of_gans_for_improved_quality_stability_and_variation","_bibtex":"@article{\n  anonymous2018progressive,\n  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk99zCeAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper447/Authors"],"keywords":["generative adversarial networks","unsupervised learning","hierarchical methods"]},"nonreaders":[],"replyCount":10,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}