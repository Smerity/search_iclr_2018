{"notes":[{"tddate":null,"ddate":null,"tmdate":1514919429803,"tcdate":1514919429803,"number":7,"cdate":1514919429803,"id":"Hy0bIIFQf","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"General comment to all reviewers","comment":"We thank all three reviewers for their thorough analysis and extremely insightful comments. Following up on their input, we added new content to the paper, ran new experiments, clarified missing points and adjusted misleading statements.\n\nOn top of smaller edits, these are the major additions:\n\n* A paragraph in the related work section (Sec. 2) about disentangling factors of variation and non-linear independent component analysis.\n* A paragraph discussing new experiments on sample efficiency for the canonical distribution, where we obtained almost identical results using only 64 examples instead of 30'000 (Sec. 5, end of page 8).\n* We changed the incorrect claim (in Sec. 3, “Concrete protocol for neural networks”) that standard autoencoders could be used as well for c. However, VAEs do work, confirming that adversarial training is not a necessary component of our method.\n* We ran new experiments for different single net baselines --- smaller learning rate for the discriminator, with and without identity initialization, larger receptive field --- confirming that it is not straightforward to learn all tasks with a single net (extending paragraph \"A simple single-net baseline\" in Sec. 5).\n* We ran new experiments for experts with larger capacity, to test how specialization is affected (paragraph \"Specialization occurs also with higher capacity experts.\" in Sec. 5).\n\nWe believe the paper has greatly benefited from the reviewers' questions, and we encourage them to read the others' comments as well. We welcome further feedback and are happy to expand our comments if anything remains unclear. Finally, we kindly ask the reviewers to consider re-evaluating their final scores taking into account the new edits and added material.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1514919338731,"tcdate":1514919338731,"number":6,"cdate":1514919338731,"id":"ryQnSLtXM","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"rJAS034ez","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"Answer","comment":"] My main concern with this work is that I don't see any mechanism in the framework that prevents an expert  (or few of them) to win all examples except its own learning capacities. \n\nThis is correct. If the experts have unlimited capacity and the data is unlimited, then a single network can learn the whole thing. Having limited capacity and finite data, on the other hand, favors specialization into independent modules, together with the way we set up the method:\n1) the experts start from a similar ground (all initialized approximately as identity), \n2) they compete for data (only the winning expert is trained on a given example),\n3) the mechanisms are independent\n\nIn practice, as a mechanism starts to specialize on one task, it tends to get worse on the other tasks (at least, worse than other modules initialized to the identity). In our experience, experts usually fail to specialize if there are too many experts for the number of mechanisms present in the dataset, or if they are not initialized to the identity, both of which make perfect sense.\n\n] p7 authors have also noticed that several experts fail to specialize and I bet that is the reason why.\n\nAt page 7 the case where several fail is the one where they are initialized randomly (not with identity), which explains why they fail. Winning a few examples in the beginning will make the output of this lucky expert look “better” (more like MNIST digits) than the (random) outputs of the remaining experts. Hence such a “lucky” expert will likely continue to win almost all examples.\n\n] Thus, authors should analyze how well we can have all/most experts specialize in a pool vs expert capacity/architecture.\n\nWe ran new experiments with experts that have more capacity both in terms of number of filters --- 128 instead of 32 --- and in terms of size of the overall receptive field by adding two downsampling (2x2 average pooling) and two upsampling layers (2x2 nearest neighbor).\nFor more filters, the results and the training curves are almost identical to the ones obtained with smaller experts, with 9 or 10 experts specializing in every run.\nFor a larger receptive field there are still only isolated occurrences of up to two experts trying to specialize on up two tasks each.\n\n] It would also be great to integrate a direct regularization mechanism in the cost  in order to do so. Like for example a penalty in how many examples a expert has won.\n\nThis would be a good way to incorporate prior knowledge on the tasks. In order to do this one would need to know approximately how many mechanisms are at play and what is the prior probability to choose any of them. \nIn our setting we assume we do not have such prior knowledge.\n\n] Moreover, the discrimator D  (which is trained to discriminate between real or fake examples) seems to be directly used to tell if an example is throw from the targeted distribution. It is not the same task. How D will handle an example far from fake or real ones ? Why will D answer negatively (or positively) on this example ? \n\nIt is true that in general, even when training standard GANs, the behavior of a discriminator outside of the domain of the real and fake data is undefined, and one should not expect it to be meaningful (not even for the 'perfect' discriminator).\n\nIn our case, the discriminator is trained on all outputs from all experts (see page 6: \"In order to encourage the expert to specialize, the discriminator is also explicitly trained against the outputs of the losing experts\" and in the Algorithm, line 5).\n\nFrom the standard i.i.d. assumption, we then conclude that the discriminator can be used directly to judge any example coming from any of the experts. If the i.i.d. assumption is invalid, the discriminator will indeed give a meaningless answer, unless training continues on the non-i.i.d. data as well.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1514919182178,"tcdate":1514919182178,"number":5,"cdate":1514919182178,"id":"rkUzBUKXz","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"S12z02uez","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"Answer pt1","comment":"] The fact that these different inverse maps arise under these conditions is interesting --- and Figure 5 is quite convincing in showing how each expert generalizes.  However, I think the experimental conditions are very limited:  Only one collection of transformations is studied, and on MNIST digits only.  In particular, I found the fact that only one of ten transformations can be applied at a time (as opposed to a series of multiple transforms) to be restrictive.  This is touched on in the conclusion, but to me it seems fundamental, as any real-world new example will undergo significantly more complex processes with many different variables all applied at once.\n\nWe believe the way to approach this will be to consider local mechanisms that can be iterated to generate complex transformations. This will require recurrency, and it may be linked to early work on Lie groups in visual perception. It’s an exciting prospect but beyond the scope of this paper. Right now, the paper should not be judged as a complete solution to the problem of image transformations - we think it’s an intriguing direction, but not the final story yet.\n\n] Another direction I think would be interesting, is how few examples are needed in the canonical distribution?  For example, in MNIST, could the canonical distribution P be limited to just one example per digit (or just one example per mode / style of digit, e.g. \"2\" with loop, and without loop)?  The different handwriters of the digits, and sampling and scanning process, may themselves constitute in-the-wild transformations that might be inverted to single (or few) canonical examples --- Is this possible with this mechanism?\n\nThis is indeed a very interesting question that we have also given some thought to. We believe this will be easier to do once we can combine local mechanisms, hence we have postponed it for the time being.\nIn particular, if there are intrinsic factors of variation (such as handwriting style) the problem again becomes one of disentangling simultaneously present transformations, rather than inverting individual mechanisms.\nConcerning sample efficiency, we followed up with a simple experiment: We still obtain very good results with down to 64 images for the canonical distribution (instead of 30k) and still 30k transformed images (roughly 3k independent images per mechanism). The images produced by the experts are not as clean, but the accuracy reached by the pre-trained classifier still increases from 40% to 96% and the experts still specialize on one mechanism each. Of course the discriminator starts to overfit sooner, and the performance decreases if it is trained long enough.\nFor even fewer examples (32), we start to observe overfitting of the discriminator before reaching very good performance of the experts.\nWe updated the paper with these results about sample sizes.\n\nOverall, it is nice to see the different inverse maps arise naturally in this setting.  But I find the single setting limiting, and think the investigation could be pushed further into less restricted settings, a couple of which I mention above.\n\n] Other comments:\n] \n] - c is first described to be any distribution model, e.g. the autoencoder described on p.5.  But it seems that using such a fixed, predefined c like the autoencoder may lead to collapse:  What is preventing an expert from learning a single constant mode that has high c value?  The adversarially trained c doesn't suffer from this, because presumably the discriminator will be able to learn the difference between a single constant mode output and the distribution P.  But if this is the case, it seems a critical part of the system, not a simple implementation choice as the text seems to say.\n \nWe adjust the statement on page 5, since following up on the reviewer's comment we ran experiments with standard autoencoders, confirming the concern of the reviewer. All experts collapsed to output black images (which are usually perfectly reconstructed by an autoencoder). \n\nWe expected VAEs not to suffer from the same problem, and indeed they produced promising results, despite still somewhat inferior to an adversarially trained discriminator. Hence while we can use a distribution model that is not adversarially trained, we agree that the standard autoencoder is not a suitable one and changed the text on page 5 accordingly."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1514919142446,"tcdate":1514919142446,"number":4,"cdate":1514919142446,"id":"rJR1r8FQf","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"S12z02uez","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"Answer pt2","comment":"] - The single-net baseline is good, but I'd like to get a clearer picture of its results.  p.8 says this didn't manage to \"learn more than one inverse mechanism\" --- Does that mean it learns to invert a single mechanism (that is always translates up, for example, when presented an image)?  Or that it learned some mix of transforms that didn't seem to generalize as well?  Or does it have some other behavior?  Also, I'm not entirely clear on how it was trained wrt c --- is argmax(c(E(x)) always just the single expert?  Is c also trained adversarially?  And if so, is the approximate identity initialization used?\n\nThe single net baseline learns a mix of transformations that do not generalize well: while color inversion is often correctly learned, the other mechanisms are mapped to odd looking shapes or digits outlines.\nTo answer the specific questions:\n- the argmax in this case is indeed the only net\n- c is still trained adversarially\n- we do use the identity initialization.\n\nFollowing up on the reviewer's comment we also tried the following extra configurations for the single net baseline:\n- not use the identity initialization\n- reduce the learning rate of the discriminator by a factor of 10\n- add two downsampling (2x2 average pooling) and two upsampling layers (2x2 nearest neighbor)\nNone of these improved the performance of the single net baseline."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1514918809666,"tcdate":1514918809666,"number":2,"cdate":1514918809666,"id":"SkzjmUKXG","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"SkiVnWtxM","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"Answer","comment":"] 1) Besides samples from distributions that are results of applying independent\n] mechanisms, samples from the canonical distribution are also required to learn\n] the model. Are the samples from the canonical distribution always available in\n] practice? Since the canonical samples are needed for training, this problem \n] setup seems not to be totally \"unsupervised\".\n\n\nWe agree that having samples from both the canonical distribution and the transformed distribution helps learn the mechanisms. Note that the examples are not paired to original examples, so the signal is a weak one. Moreover, one could imagine that one could identify a subset of canonical examples from a larger distribution, i.e., that we construct the canonical distribution from a wider distribution containing transformed images.\nFurthermore, when trying to reconstruct a canonical distribution only from the transformed distributions, we found it hard to identify a “good” or unique criterion. For example, if the only transformations are “up” and “up-right”, it’s not clear why there should be a unique location for the “centered” digits.\n\nWe encourage the reviewer to look at the similar comment made by reviewer 2, and our answer with new results using a much more limited amount of examples from the canonical distribution (64 instead of 30'000).\n\n] 2) The authors only run experiments on the MNIST data, where 1) the mechanisms are\n] simulated and relatively simple, and 2) samples from the canonical distribution\n] are also available. Did the authors run experiments on other datasets?\n\nWe have so far only considered the MNIST problem.\n\n] 3) This work seems to be related to the work on 1) disentangling factors of\n] variation; and 2) non-linear independent component analysis. Could the authors\n] add discussions to illustrate the difference between the proposed work and\n] those topics?\n\nIndeed there are close relations to the work on disentangling factors of variation and also non-linear ICA. In our work, causal mechanisms play the role of ‘factors of variation’ which we believe is a fruitful view of this problem. We added a discussion about related works on DFV and non-linear ICA to Section 2 of the paper.\nThe causal point of view also builds a bridge to the field of domain adaptation. \nFinally, note that our approach currently recovers inverse mechanisms, as independent and modular parts (in our experiments a separate net for each mechanism), while typically in DFV one is interested in obtaining a joint low dimensional representation of the data without explicit separate paths for each factor.\n\n\n] 4) This work is motivated from the objective of causal inference, therefore it\n] might be helpful to add empirical results to show how the proposed method can\n] be used for causal inference.\n\nThe approach is not applicable to standard causal structure learning problems in the current form. We do believe, however, that it can play a role for learning multi-task structural causal models whose structure mimics the mechanistic structure of the data generating process, so ultimately it will also be linked to structure learning. Currently, the influence goes the other way round: the causal view inspires our machine learning approach.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1515642407340,"tcdate":1511754802582,"number":3,"cdate":1511754802582,"id":"SkiVnWtxM","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Review","forum":"SJky6Ry0W","replyto":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference/Paper197/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting problem setup, more empirical results and discussions on related works would improve the paper","rating":"5: Marginally below acceptance threshold","review":"Summary:\nGiven data from a canonical distribution P and data from distributions that are\nindependent transformations (mechanisms) applied on P, this paper aims to learn\n1) those independent transformations; and 2) inverse transformations that map\ndata from transformed distributions to their corresponding canonical\ndistribution.\n\nThis is achieved by training a mixture of experts, where each expert is assumed to\nmodel a single inverse transformation. Each expert can be seen as the generator\nof a conditional GAN. The discriminator is trained to distinguish samples from\nthe canonical distribution P and those transformed distributions.\n\nExperiments on MNIST data shows that in the end of training, each expert wins\nalmost all samples from one transformation and no other, which confirms that\neach expert model a single inverse transformation.\n\nComments:\n1) Besides samples from distributions that are results of applying independent\nmechanisms, samples from the canonical distribution are also required to learn\nthe model. Are the samples from the canonical distribution always available in\npractice? Since the canonical samples are needed for training, this problem \nsetup seems not to be totally \"unsupervised\".\n\n2) The authors only run experiments on the MNIST data, where 1) the mechanisms are\nsimulated and relatively simple, and 2) samples from the canonical distribution\nare also available. Did the authors run experiments on other datasets?\n\n3) This work seems to be related to the work on 1) disentangling factors of\nvariation; and 2) non-linear independent component analysis. Could the authors\nadd discussions to illustrate the difference between the proposed work and\nthose topics?\n\n4) This work is motivated from the objective of causal inference, therefore it\nmight be helpful to add empirical results to show how the proposed method can\nbe used for causal inference.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1515642407398,"tcdate":1511734804332,"number":2,"cdate":1511734804332,"id":"S12z02uez","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Review","forum":"SJky6Ry0W","replyto":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference/Paper197/AnonReviewer2"],"readers":["everyone"],"content":{"title":"limited setting, but exhibits interesting behavior","rating":"5: Marginally below acceptance threshold","review":"This paper describes a setting in which a system learns collections of inverse-mapping functions that transform altered inputs to their unaltered \"canonical\" counterparts, while only needing unassociated and separate sets of examples of each at training time.  Each inverse map is an \"expert\" E akin to a MoE expert, but instead of using a feed-forward gating on the input, an expert is selected (for training or inference) based on the value of a distribution-modeling function c applied to the output of all experts:  The expert with maximum value c(E(x)) is selected.  When c is an adversarially trained discriminator network, the experts learn to model the different transformations that map altered images back to unaltered ones.  This is demonstrated using MNIST with a small set of synthetic translations and noise.\n\nThe fact that these different inverse maps arise under these conditions is interesting --- and Figure 5 is quite convincing in showing how each expert generalizes.  However, I think the experimental conditions are very limited:  Only one collection of transformations is studied, and on MNIST digits only.  In particular, I found the fact that only one of ten transformations can be applied at a time (as opposed to a series of multiple transforms) to be restrictive.  This is touched on in the conclusion, but to me it seems fundamental, as any real-world new example will undergo significantly more complex processes with many different variables all applied at once.\n\nAnother direction I think would be interesting, is how few examples are needed in the canonical distribution?  For example, in MNIST, could the canonical distribution P be limited to just one example per digit (or just one example per mode / style of digit, e.g. \"2\" with loop, and without loop)?  The different handwriters of the digits, and sampling and scanning process, may themselves constitute in-the-wild transformations that might be inverted to single (or few) canonical examples --- Is this possible with this mechanism?\n\nOverall, it is nice to see the different inverse maps arise naturally in this setting.  But I find the single setting limiting, and think the investigation could be pushed further into less restricted settings, a couple of which I mention above.\n\n\n\nOther comments:\n\n- c is first described to be any distribution model, e.g. the autoencoder described on p.5.  But it seems that using such a fixed, predefined c like the autoencoder may lead to collapse:  What is preventing an expert from learning a single constant mode that has high c value?  The adversarially trained c doesn't suffer from this, because presumably the discriminator will be able to learn the difference between a single constant mode output and the distribution P.  But if this is the case, it seems a critical part of the system, not a simple implementation choice as the text seems to say.\n\n- The single-net baseline is good, but I'd like to get a clearer picture of its results.  p.8 says this didn't manage to \"learn more than one inverse mechanism\" --- Does that mean it learns to invert a single mechanism (that is always translates up, for example, when presented an image)?  Or that it learned some mix of transforms that didn't seem to generalize as well?  Or does it have some other behavior?  Also, I'm not entirely clear on how it was trained wrt c --- is argmax(c(E(x)) always just the single expert?  Is c also trained adversarially?  And if so, is the approximate identity initialization used?\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1511687797014,"tcdate":1511687797014,"number":1,"cdate":1511687797014,"id":"HypuI-dxG","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Comment","forum":"SJky6Ry0W","replyto":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference/Paper197/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper197/Authors"],"content":{"title":"Appendix D, Eq. 4, page 12","comment":"On page 12, Appendix D, a minus sign was not rendered on Equation 4 and the line above. The correct equations are:\nI( x : y ) := K( x ) + K( y ) - K( x , y )\nI( x : y ) = K( y ) - K( y | x )\nThe typo has been fixed and won't appear in the revision."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1515799568391,"tcdate":1511472709778,"number":1,"cdate":1511472709778,"id":"rJAS034ez","invitation":"ICLR.cc/2018/Conference/-/Paper197/Official_Review","forum":"SJky6Ry0W","replyto":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference/Paper197/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Review for Learning Independent Causal Mechanisms","rating":"6: Marginally above acceptance threshold","review":"This paper presents a framework to recover a set of independent mechanisms. In order to do so it uses a set of experts each one made out of a GAN.\n\nMy main concern with this work is that I don't see any mechanism in the framework that prevents an expert  (or few of them) to win all examples except its own learning capacities. p7 authors have also noticed that several experts fail to specialize and I bet that is the reason why.\nThus, authors should analyze how well we can have all/most experts specialize in a pool vs expert capacity/architecture.\nIt would also be great to integrate a direct regularization mechanism in the cost  in order to do so. Like for example a penalty in how many examples a expert has catched.\n\nMoreover, the discrimator D  (which is trained to discriminate between real or fake examples) seems to be directly used to tell if an example is throw from the targeted distribution. It is not the same task. How D will handle an example far from fake or real ones ? Why will D answer negatively (or positively) on this example ? \n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1514918628537,"tcdate":1509055702579,"number":197,"cdate":1509739431069,"id":"SJky6Ry0W","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SJky6Ry0W","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Independent Causal Mechanisms","abstract":"Independent causal mechanisms are a central concept in the study of causality\nwith implications for machine learning tasks. In this work we develop\nan algorithm to recover a set of (inverse) independent mechanisms relating\na distribution transformed by the mechanisms to a reference distribution.\nThe approach is fully unsupervised and based on a set of experts that compete\nfor data to specialize and extract the mechanisms. We test and analyze\nthe proposed method on a series of experiments based on image transformations.\nEach expert successfully maps a subset of the transformed data\nto the original domain, and the learned mechanisms generalize to other\ndomains. We discuss implications for domain transfer and links to recent\ntrends in generative modeling.","pdf":"/pdf/6a8a2ce728fc2f60f3f165fb54dc0e3bfce9802e.pdf","paperhash":"anonymous|learning_independent_causal_mechanisms","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Independent Causal Mechanisms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJky6Ry0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper197/Authors"],"keywords":[]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}