{"notes":[{"tddate":null,"ddate":null,"tmdate":1512880478699,"tcdate":1512880314865,"number":3,"cdate":1512880314865,"id":"rJXa_V5Zz","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Comment","forum":"SyGT_6yCZ","replyto":"rJUMQfpeM","signatures":["ICLR.cc/2018/Conference/Paper180/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper180/Authors"],"content":{"title":"Comment answers","comment":"Dear Reviewer,\n\nIn the following lines, we try to clarify your doubts.\n\nYou wrote: \"I don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance.\"\n\nTransfer learning and domain adaptation are essential in machine learning. Indeed, in some situation, we have a small image dataset which is not able to be used to train a Convolutional Neural Network (CNN) thoroughly. In such cases, we can either use a hand-designed feature or extract features from a CNN pretrained in a large dataset.  \n\nDespite being a standard approach today, extracting features from a CNN to performing transfer learning or domain adaptation has a significant drawback when compared with using hand-designed features: the training time required. Indeed, hand-designed features do not need to be trained and since they are immediately available. Hence, despite usually provide higher quality features (when a large dataset is available), extracting features from a CNN takes much more time than using directly available engineered features. \n\nTherefore, this work aims to show that we can significantly mitigate this drawback by showing that it is possible to dramatically reduce the training time required to pretrain a CNN without significantly affect the quality of the generated features.\n\nHence, we propose a method that is very efficient in considerably reducing the training time need to extract features from a CNN with minor impact on the quality of the generated features. \n\nTrading a significant training time reduction by a small decrease in features quality reduces the above mention drawback of using CNN feature extraction rather than hand-designed ones. \n\nThe proposed approach, despite simple, innovates in showing that a learning schedule that is aware of the available training can maximize its use with minor performance hurting. In other words, we propose a simple way to produces high-quality features given a time constraint requirement.\n\nYou wrote: \"And for (2), it is a relatively standard approach in utilizing CNN features. Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use). I fail to see how this would lead to superior performance compared to conventional CNNs.\"\n\nI believe the previous explanation clarifies this point. The objective is not to produce a better performance than it would be possible if more time were available. The aim is to show that the proposed method can provide almost the best possible feature quality in a small fraction of the time it would require to thoroughly train the CNN in order to get the utterly best possible feature quality."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1512876703475,"tcdate":1512874941746,"number":2,"cdate":1512874941746,"id":"r1L6779WM","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Comment","forum":"SyGT_6yCZ","replyto":"ByZqDFKWG","signatures":["ICLR.cc/2018/Conference/Paper180/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper180/Authors"],"content":{"title":"Comment answers","comment":"Dear anonymous,\n\nPlease, be more specific instead of saying that \"we had to make numerous assumptions since the paper lacks certain information about the setup of the SFC and more\".\n\nFor example, you said that \"Although not entirely clear which layout is used where, we assumed that LeNet-5 was used to represent SFC for MNIST dataset and VGG19 for CIFAR datasets\". However, the paper is very clear in saying that \"For MNIST dataset, we are using as baseline model the LeNet5 (LeCun et al., 1998)\". Moreover: \"The CIFAR-10 and CIFAR-100 dataset were trained with an adapted Visual Geometry Group (Simonyan & Zisserman, 2014) type model\".\n\nRegarding preprocessing, for either MNIST and CIFAR10/100, standard mean-std was used. Moreover, regarding CIFAR10/100, we also performed a random horizontal flip with probability 0.5. We will update to paper regarding this information.\n\nWe saw in code and it appears that you are not using batch normalization for LeNet5, but we used it in our experiments. In the paper, we wrote: \"For MNIST dataset, we are using as baseline model the LeNet5 (LeCun et al., 1998). Our modifications to the original model were changing the activation function to ReLU and adding the batch\nnormalization to the convolutional layers.\" \n\nRegarding VGG19, you appear to use dropout (p=0.5), despite we write in the paper that \"We designed the system with nineteen layers and batch normalization but without dropout (VGG19)\". Besides, you are using the original VGG19 variant used for ImageNet which has three fully connected layers instead of the VGG19 variation regularly used with CIFAR10/100 which has just one fully connected layer. Please, for example, visit https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py\n\nFinally, you need to pay attention to this line of the paper: \" In both cases, to extract for each image a 256 linear feature vector, the last layer before the full connected classifier was changed to present 256 nodes\" as your code does not appear to follow this instruction.\n\nRegarding the comment \"some hyperparameters were not mentioned in the paper (such as number of iterations per epoch for VGG19)\", we would like to clarify that the number of interactions per epoch is deterministically determined by the size of the training set and the batch size. Both pieces of information are in the paper for either MNIST and CIFAR10/100. Therefore, we should correct your code and use 60000/128=469 for MNIST and 50000/128=391 for CIFAR10/100.\n\nWe are using an NVidia 980i TI which has 6GB of RAM. If we are using a card with less memory or cores, this is probably the reason why your experiments are slower than ours.\n\nAgain, we asked you to be more specific instead of writing \"Overall the paper does not provide us with enough information on the setup and architectures to reliably reproduce the results observed by the authors\"."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1512834953036,"tcdate":1512834953036,"number":2,"cdate":1512834953036,"id":"ByZqDFKWG","invitation":"ICLR.cc/2018/Conference/-/Paper180/Public_Comment","forum":"SyGT_6yCZ","replyto":"SyGT_6yCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Reproducibility of MNIST and CIFAR-10 results","comment":"The paper under review investigates the extraction of features from images for recognition and classification purposes. The authors of the paper propose a method to simplify and increase the speed of feature extraction using convolutional models while pointing out that the drawback to this is the time required to train a CNN. Therefore, they also propose a scheduling technique in order to accelerate the training process, while maintaining the performance level.\n\nIn order to reproduce their results, we had to make numerous assumptions since the paper lacks certain information about the setup of the SFC and more. Although not entirely clear which layout is used where, we assumed that LeNet-5 was used to represent SFC for MNIST dataset and VGG19 for CIFAR datasets. For the datasets, we assumed no preprocessing was done and that the default train / test splits were used.\n\nWe were able to reproduce most of the results for the two datasets that we tried to verify (i.e. MNIST and CIFAR-10), however, we could not confirm some outcomes that were obtained by the authors. Most notably, it seems that the SFC scheduling does not work very well with LeNet-5 CNN since we experienced a sudden drop in accuracy at around epoch 50 and therefore the final accuracy for SFC100 and CNN0.1 was only 10%. We ran this test 10 times and this behavior was exhibited in each one of the rounds. Regarding the training times claimed by the authors, our experiments took roughly twice as much time for the MNIST dataset, which could be explained by less computational power at hand, however, the CIFAR-10 training times we saw were almost 5 times slower. Since we did not have access to the original code that the authors have used and some hyperparameters were not mentioned in the paper (such as number of iterations per epoch for VGG19), this could serve as an explanation for the prolonged training times and irreproducibility of the MNIST experiments.\n\nOverall the paper does not provide us with enough information on the setup and architectures to reliably reproduce the results observed by the authors. For more details on the code that we have used, visit https://github.com/lgatting/AML2017-Assignment-4."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1515642404962,"tcdate":1512018701575,"number":3,"cdate":1512018701575,"id":"rJUMQfpeM","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Review","forum":"SyGT_6yCZ","replyto":"SyGT_6yCZ","signatures":["ICLR.cc/2018/Conference/Paper180/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A simple combination of known approaches?","rating":"2: Strong rejection","review":"I am not sure how to interpret this paper. The paper seems to be very thin technically, unless I missed some important details. Two proposals in the paper are:\n\n(1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and \n(2) Extract the penultimate layer output as features to train a conventional classifier such as SVM.\n\nI don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance. And for (2), it is a relatively standard approach in utilizing CNN features. Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use). I fail to see how this would lead to superior performance compared to conventional CNNs.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1511993434517,"tcdate":1511993269092,"number":1,"cdate":1511993269092,"id":"HkTny32gM","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Comment","forum":"SyGT_6yCZ","replyto":"Bkou3Wjez","signatures":["ICLR.cc/2018/Conference/Paper180/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper180/Authors"],"content":{"title":"Comment answers","comment":"First of all, thank you for your interest in our work. \n\nRegarding your questions, we have used the default split for the MNIST dataset. Referring to SVM, we have used the multiclass variant. \n\nDespite being clear in the paper, we confirm that we have used ReLU in our adapted LeNet5 model. The libraries and frameworks which we have used were Numpy, Scikit-learn, Pandas, and PyTorch. \n \nBest regards.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1511885938730,"tcdate":1511885938730,"number":1,"cdate":1511885938730,"id":"Bkou3Wjez","invitation":"ICLR.cc/2018/Conference/-/Paper180/Public_Comment","forum":"SyGT_6yCZ","replyto":"SyGT_6yCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Clarification questions","comment":"We’re trying to reproduce your work and we found certain ambiguities which we’d like to have clarified.\n\nYou have mentioned that for the MNIST dataset, you used the 60k – 10k split, however, it is not clear whether you have used the default split or you created your own (e.g. merged all data, shuffled them and split them).\n\nWe are also not sure how you used SVM for classifying samples that belong to 10 different classes – did you use one-vs-all approach or multiclass classification?\n\nRegarding the underlying structure of SFC, we assume that LeNet5 with ReLu activation units is used since it is the only one mentioned in the paper that is not used for the baseline classifiers – is this assumption correct?\n\nCould you also provide us with some additional information regarding which (if any) libraries or frameworks have been used for constructing the learning algorithms? Alternatively, if you happen to have the code publicly available, it would be helpful if you could direct us to it.\n\nThank you for the answers in advance.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1515642405000,"tcdate":1511722085964,"number":2,"cdate":1511722085964,"id":"rk0P3FdeM","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Review","forum":"SyGT_6yCZ","replyto":"SyGT_6yCZ","signatures":["ICLR.cc/2018/Conference/Paper180/AnonReviewer2"],"readers":["everyone"],"content":{"title":"No contribution","rating":"3: Clear rejection","review":"This paper proposes a fast way to learn convolutional features that later can be used with any classifier. The acceleration of the training comes from a reduced number of training epocs and a specific schedule decay of the learning rate. \nIn the evaluation the features are used with support vector machines (SVN) and extreme learning machines on MNIST and CIFAR10/100 datasets.\n\nPros:\nThe paper compares different classifiers on three datasets.\n\nCons:\n- Considering an adaptive schedule of the learning decay is common practice in modern machine learning. Showing that by varying the learning rate the authors can reduce the number of training epocs and still obtain good performance is not a contribution and it is actually implemented in most of the recent deep learning libraries, like Keras or Pytorch.\n- It is not clear why, once a CNN has been trained, one should want to change the last layer and use a SVN or other classifiers.\n- There are many spelling errors\n- Comparing CNN based methods with hand-crafted features as in Fig. 1 and Tab.3 is not interesting anymore. It is well known that CNN features are much better if enough data is available.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1515642405042,"tcdate":1511612297515,"number":1,"cdate":1511612297515,"id":"SyWq1JvlM","invitation":"ICLR.cc/2018/Conference/-/Paper180/Official_Review","forum":"SyGT_6yCZ","replyto":"SyGT_6yCZ","signatures":["ICLR.cc/2018/Conference/Paper180/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Lack of significant results","rating":"3: Clear rejection","review":"This paper deals with early stopping but the contributions are limited. This work would fit better a workshop as a preliminary result, furthermore it is too short. Following a short review section per section.\n\nIntro: The name SFC is misleading as the method consists in stopping early the training with an optimized learning schedule scheme. Furthermore, the work is not compared to the appropriate baselines.\n\nProposal: The first motivation is not clear. The training time of the feature extractor has never been a problem for transfer learning tasks for example: once it is trained, you can reuse the architecture in a wide range of tasks. Besides, the training time of a CNN on CIFAR10 or even ImageNet is now quite small(for reasonable architectures), which allows fast benchmarking.\nThe second motivation, w.r.t. IB seems interesting but this should be empirically motivated(e.g. figures) in the subsection 2.1, and this is not done.\n\nThe section 3 is quite long and could be compressed to improve the relevance of this experimental section. All the accuracies(unsup dict, unsup, etc) on CIFAR10/CIFAR100 are reported from the paper (Oyallon & Mallat, 2015), ignoring 2-3 years of research that leads to new numerical results. Furthermore, this supervised technique is only compared to unsupervised or predefined methods, which is is not fair and the training time of the Scattering Transform is not reported, for example. \n\nFinally, extracting features is mainly useful on ImageNet (for realistic images) and this is not reported here.\n\nI believe re-thinking new learning rate schedules is interesting, however I recommend the rejection of this paper.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]}},{"tddate":null,"ddate":null,"tmdate":1509739441874,"tcdate":1509050553902,"number":180,"cdate":1509739439215,"id":"SyGT_6yCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SyGT_6yCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Simple Fast Convolutional Feature Learning","abstract":"The quality of the features used in visual recognition is of fundamental importance for the overall system. For a long time, low-level hand-designed feature algorithms as SIFT and HOG have obtained the best results on image recognition. Visual features have recently been extracted from trained convolutional neural networks. Despite the high-quality results, one of the main drawbacks of this approach, when compared with hand-designed features, is the training time required during the learning process. In this paper, we propose a simple and fast way to train supervised convolutional models to feature extraction while still maintaining its high-quality. This methodology is evaluated on different datasets and compared with state-of-the-art approaches.","pdf":"/pdf/9136bbd285842a07b9f55d97b7b035f3e0862c65.pdf","TL;DR":"A simple fast method for extracting visual features from convolutional neural networks","paperhash":"anonymous|simple_fast_convolutional_feature_learning","_bibtex":"@article{\n  anonymous2018simple,\n  title={Simple Fast Convolutional Feature Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyGT_6yCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper180/Authors"],"keywords":["Feature Learning","Convolutional Neural Networks","Visual Recognition"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}