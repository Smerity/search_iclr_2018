{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222594888,"tcdate":1511816246860,"number":3,"cdate":1511816246860,"id":"SJJrhg5lf","invitation":"ICLR.cc/2018/Conference/-/Paper245/Official_Review","forum":"B1Yy1BxCZ","replyto":"B1Yy1BxCZ","signatures":["ICLR.cc/2018/Conference/Paper245/AnonReviewer2"],"readers":["everyone"],"content":{"title":"reasonable empirical evidence for a not-too-surprising claim / could improve with more diverse set of tasks, wallclock metrics","rating":"6: Marginally above acceptance threshold","review":"## Review Summary\n\nOverall, the paper's paper core claim, that increasing batch sizes at a linear\nrate during training is as effective as decaying learning rates, is\ninteresting but doesn't seem to be too surprising given other recent work in\nthis space. The most useful part of the paper is the empirical evidence to\nbackup this claim, which I can't easily find in previous literature. I wish\nthe paper had explored a wider variety of dataset tasks and models to better\nshow how well this claim generalizes, better situated the practical benefits\nof the approach (how much wallclock time is actually saved? how well can it be\nintegrated into a distributed workflow?), and included some comparisons with\nother recent recommended ways to increase batch size over time.\n\n\n## Pros / Strengths\n\n+ effort to assess momentum / Adam / other modern methods\n\n+ effort to compare to previous experimental setups\n\n\n## Cons / Limitations\n\n- lack of wallclock measurements in experiments\n\n- only ~2 models / datasets examined, so difficult to assess generalization\n\n- lack of discussion about distributed/asynchronous SGD\n\n\n## Significance\n\nMany recent previous efforts have looked at the importance of batch sizes\nduring training, so topic is relevant to the community. Smith and Le (2017)\npresent a differential equation model for the scale of gradients in SGD,\nfinding a linear scaling rule proportional to eps N/B, where eps = learning\nrate, N = training set size, and B = batch size. Goyal et al (2017) show how\nto train deep models on ImageNet effectively with large (but fixed) batch\nsizes by using a linear scaling rule.\n\nA few recent works have directly tested increasing batch sizes during\ntraining. De et al (AISTATS 2017) have a method for gradually increasing batch\nsizes, as do Friedlander and Schmidt (2012). Thus, it is already reasonable to\npractitioners that the proposed linear scaling of batch sizes during training\nwould be effective.\n\nWhile increasing batch size at the proposed linear scale is simple and seems\nto be effective, a careful reader will be curious how much more could be\ngained from the backtracking line search method proposed in De et al.\n\n\n## Quality\n\nOverall, only single training runs from a random initialization are used. It\nwould be better to take the best of many runs or to somehow show error bars,\nto avoid the reader wondering whether gains are due to changes in algorithm or\nto poor exploration due to bad initialization. This happens a lot in Sec. 5.2.\n\nSome of the experimental setting seem a bit haphazard and not very systematic.\nIn Sec. 5.2, only two learning rate scales are tested (0.1 and 0.5). Why not\nexamine a more thorough range of values?\n\nWhy not report actual wallclock times? Of course having reduced number of\nparameter updates is useful, but it's difficult to tell how big of a win this\ncould be.\n\nWhat about distributed SGD or asyncronous SGD (hogwild)? Small batch sizes\nsometimes make it easier for many machines to be working simultaneously. If we\nscale up to batch sizes of ~ N/10, we can only get 10x speedups in\nparallelization (in terms of number of parameter updates). I think there is\nsome subtle but important discussion needed on how this framework fits into\nmodern distributed systems for SGD.\n\n\n## Clarity\n\nOverall the paper reads reasonably well.\n\nOffering a related work \"feature matrix\" that helps readers keep track of how\nprevious efforts scale learning rates or minibatch sizes for specific\nexperiments could be valueable. Right now, lots of this information is just\nprovided in text, so it's not easy to make head-to-head comparisons.\n\nSeveral figure captions should be updated to clarify which model and dataset\nare studied. For example, when skimming Fig. 3's caption there is no such\ninformation.\n\n## Paper Summary\n\nThe paper examines the influence of batch size on the behavior of stochastic\ngradient descent to minimize cost functions. The central thesis is that\ninstead of the \"conventional wisdom\" to fix the batch size during training and\ndecay the learning rate, it is equally effective (in terms of training/test\nerror reached) to gradually increase batch size during training while fixing\nthe learning rate. These two strategies are thus \"equivalent\". Furthermore,\nusing larger batches means fewer parameter updates per epoch, so training is\npotentially much faster.\n\nSection 2 motivates the suggested linear scaling using previous SGD analysis\nfrom Smith and Le (2017). Section 3 makes connections to previous work on\nfinding optimal batch sizes to close the generaization gap. Section 4 extends\nanalysis to include SGD methods with momentum.\n\nIn Section 5.1, experiments training a 16-4 ResNet on CIFAR-10 compare three\npossible SGD schedules: * increasing batch size * decaying learning rate *\nhybrid (increasing batch size and decaying learning rate) Fig. 2, 3 and 4 show\nthat across a range of SGD variants (+/- momentum, etc) these three schedules\nhave similar error vs. epoch curves. This is the core claimed contribution:\nempirical evidence that these strategies are \"equivalent\".\n\nIn Section 5.3, experiments look at Inception-ResNet-V2 on ImageNet, showing\nthe proposed approach can reach comparable accuracies to previous work at even\nfewer parameter updates (2500 here, vs. âˆ¼14000 for Goyal et al 2007)\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]}},{"tddate":null,"ddate":null,"tmdate":1512222597518,"tcdate":1511814883075,"number":2,"cdate":1511814883075,"id":"B1i1vxqgz","invitation":"ICLR.cc/2018/Conference/-/Paper245/Official_Review","forum":"B1Yy1BxCZ","replyto":"B1Yy1BxCZ","signatures":["ICLR.cc/2018/Conference/Paper245/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Useful empirical validation.","rating":"7: Good paper, accept","review":"The paper represents an empirical validation of the well-known idea (it was published several times before) \nto increase the batch size over time. Inspired by recent works on large-batch studies, the paper suggests to adapt the learning rate as a function of the batch size.\n\nI am interested in the following experiment to see how useful it is to increase the batch size compared to fixed batch size settings. \n\n1) The total budget / number of training samples is fixed. \n2) Batch size is scheduled to change between B_min and B_max\n3) Different setting of B_min and B_max>=B_min are considered, e.g., among [64, 128, 256, 512, ...] or [64, 256, 1024, ...] if it is too expensive.\n4) Drops of the learning rates are scheduled to happen at certain times represented in terms of the number of training samples passed so far (not parameter updates).\n5) Learning rates and their drops should be rescaled taking into account the schedule of the batch size and the rules to adapt learning rates in large-scale settings as by Goyal. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]}},{"tddate":null,"ddate":null,"tmdate":1512222597560,"tcdate":1511748652982,"number":1,"cdate":1511748652982,"id":"r1SNNxFlf","invitation":"ICLR.cc/2018/Conference/-/Paper245/Official_Review","forum":"B1Yy1BxCZ","replyto":"B1Yy1BxCZ","signatures":["ICLR.cc/2018/Conference/Paper245/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A simple, relevant observation as computing resources are becoming increasingly available for rent","rating":"6: Marginally above acceptance threshold","review":"The paper analyzes the the effect of increasing the batch size in stochastic gradient descent as an alternative to reducing the learning rate, while keeping the number of training epochs constant. This has the advantage that the training process can be better parallelized, allowing for faster training if hundreds of GPUs are available for a short time. The theory part of the paper briefly reviews the relationship between learning rate, batch size, momentum coefficient, and the noise scale in stochastic gradient descent. In the experimental part, it is shown that the loss function and test accuracy depend only on the schedule of the decaying noise scale over training time, and are independent of whether this decaying noise schedule is achieved by a decaying learning rate or an increasing batch size. It is shown that simultaneously increasing the momentum parameter and the batch size also allows for fewer parameters, albeit at the price of some loss in performance.\n\nCOMMENTS:\n\nThe paper presents a simple observation that seems very relevant especially as computing resources are becoming increasingly available for rent on short time scales. The observation is explained well and substantiated by clear experimental evidence. The main issue I have is with the part about momentum. The paragraph below Eq. 7 provides a possible explanation for the performance drop when $m$ is increased. It is stated that at the beginning of the training, or after increasing the batch size, the magnitude of parameter updates is suppressed because $A$ has to accumulate gradient signals over a time scale $B/(N(1-m))$. The conclusion in the paper is that training at high momentum requires additional training epochs before $A$ reaches its equilibrium value. This effect is well known, but it can easily be remedied. For example, the update equations in Adam were specifically designed to correct for this effect. The mechanism is called \"bias-corrected moment estimate\" in the Adam paper, arXiv:1412.6980. The correction requires only two extra multiplications per model parameter and update step. Couldn't the same or a very similar trick be used to correctly rescale $A$ every time one increases the batch size? It would be great to see the equivalent of Figure 7 with correctly rescaled $A$.\n\nMinor issues:\n* The last paragraph of Section 5 refers to a figure 8, which appears to be missing.\n* In Eqs. 4 & 5, the momentum parameter $m$ is not yet defined (it will be defined in Eqs. 6 & 7 below).\n* It appears that a minus sign is missing in Eq. 7. The update steps describe gradient ascent.\n* Figure 3 suggests that most of the time between the first and second change of the noise scale (approx. epochs 60 to 120) are spent on overfitting. This suggests that the number of updates in this segment was chosen unnecessarily large to begin with. It is therefore not surprising that reducing the number of updates does not deteriorate the test set accuracy.\n* It would be interesting to see a version of figure 5 where the horizontal axis is the number of epochs. While reducing the number of updates allows for faster training if a large number of parallel hardware instances are available, the total cost of training is still governed by the number of training epochs.\n* It appears like the beginning of the second paragraph in Section 5.2 describes figure 1. Is this correct?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]}},{"tddate":null,"ddate":null,"tmdate":1511404913098,"tcdate":1511404913098,"number":1,"cdate":1511404913098,"id":"BJtuH2Qlf","invitation":"ICLR.cc/2018/Conference/-/Paper245/Official_Comment","forum":"B1Yy1BxCZ","replyto":"rJIErsI1M","signatures":["ICLR.cc/2018/Conference/Paper245/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper245/Authors"],"content":{"title":"Extra results in appendix after review","comment":"Thank you for your interest in our work!\n\nWe would like to emphasize that the method of increasing the batch size during training instead of decaying the learning rate is not an alternative to large batch training, it is complimentary. Large batch training is achieved by increasing the initial learning rate and linearly scaling the batch size, thus holding the SGD noise scale constant. Meanwhile we propose increasing the batch size during training at constant learning rate, in order to maintain the same noise scale progression obtained by a decaying learning rate. \n\nWe showed in figure 5 that we could simultaneously increase the initial learning rate and batch size by a factor of 5, and also replace a decaying learning rate with an increasing batch size schedule. This did not cause any reduction in test performance, achieving final test accuracy of 94.5%. In response to your question, we attempted to instead increase the initial learning rate and batch size by a factor of 25 with a constant batch size and decaying learning rate schedule. The test set accuracy drops to 93.2%. We will add these results to the appendix after the review process. \n\nBest wishes,"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]}},{"tddate":null,"ddate":null,"tmdate":1510548782165,"tcdate":1510548782165,"number":1,"cdate":1510548782165,"id":"rJIErsI1M","invitation":"ICLR.cc/2018/Conference/-/Paper245/Public_Comment","forum":"B1Yy1BxCZ","replyto":"B1Yy1BxCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"A Suggestion for Evaluation Setting","comment":"The authors claimed that one can achieve equivalent test accuracies by increasing the batch size proportionally instead of decaying the learning rate. They also claimed that one benefit of increasing batch size is it has fewer parameter updates. However, to make the latter claim more convincing, it is strongly suggested adding a comparison with a fixed-size large batch method (say, much larger than the initial batch size of the \"Increasing batch size\" method) in the evaluation setting, since large batch method may have even fewer updates than the \"Increasing batch size\" method. If the large batch method cannot reach same test accuracies after the same number of training epochs despite fewer updates, then the claim that \"Increasing batch size\" method can achieve equivalent test accuracies with fewer updates than fixed batch size method can be solidly confirmed.\n\nI am quite interested in work on changing batch sizes and found one paper introducing ways to dynamically adapt batch size as learning proceeds, called \"On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size\" (also submitted to ICLR 2018). They've done similar work but in a self-adaptive way. Specifically, it proposed a method to dynamically select the batch size for each update so that it may achieve lower training loss after scanning the same amount of training data. However, its batch adaptive method requires more computation costs to decide a proper batch size. Check it out if you are interested.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]}},{"tddate":null,"ddate":null,"tmdate":1509739409067,"tcdate":1509080801411,"number":245,"cdate":1509739406405,"id":"B1Yy1BxCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1Yy1BxCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Don't Decay the Learning Rate, Increase the Batch Size","abstract":"It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum, and Adam. It reaches equivalent test accuracies after the same number of training epochs, but with fewer parameter updates, leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate $\\epsilon$ and scaling the batch size $B \\propto \\epsilon$. Finally, one can increase the momentum coefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly reduce the test accuracy. Crucially, our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train Inception-ResNet-V2 on ImageNet to $77\\%$ validation accuracy in under 2500 parameter updates, efficiently utilizing training batches of 65536 images.","pdf":"/pdf/714c1a4332f89412e1fbe02bd61f7be2e55bd4f1.pdf","TL;DR":"We train Inception-ResNet-V2 on ImageNet to 77% test accuracy in under 2500 parameter updates, using batches of 65536 images.","paperhash":"anonymous|dont_decay_the_learning_rate_increase_the_batch_size","_bibtex":"@article{\n  anonymous2018don't,\n  title={Don't Decay the Learning Rate, Increase the Batch Size},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Yy1BxCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper245/Authors"],"keywords":["batch size","learning rate","simulated annealing","large batch training","scaling rules","stochastic gradient descent","sgd","imagenet","optimization"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}