{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222718893,"tcdate":1512052000521,"number":3,"cdate":1512052000521,"id":"rkd7rq6gf","invitation":"ICLR.cc/2018/Conference/-/Paper68/Official_Review","forum":"ryF-cQ6T-","replyto":"ryF-cQ6T-","signatures":["ICLR.cc/2018/Conference/Paper68/AnonReviewer2"],"readers":["everyone"],"content":{"title":"It is unclear how suitable the proposed physics-inspired architecture is, for solving complex machine learning problems.","rating":"3: Clear rejection","review":"The paper studies the mapping of a mathematical object representing quantum entanglement to a neural network architecture that can be trained to predict data, e.g. images. A contribution of the paper is to propose a 2D tensor network model for that purpose, which has higher representation power than simple tensor networks used in previous works.\n\nThere are several issues with the paper: \n\nFirst, it is hard to relate the presented model to its machine learning counterpart. e.g. it is not stated clearly what is the underlying function class (are they essentially linear classifiers built on some feature space representation?).\n\nThe benchmark study doesn’t bring much evidence about the modeling advantages brought by the proposed method. Separating pairs of CIFAR-10 classes is relatively easy and can be done with reasonable accuracy without much nonlinearity. Similarly, an error rate of 5% on MNIST is already achievable by basic machine learning classifiers.\n\nThe concept of bond and bond dimensions, which are central in this paper due to their relation to model complexity, could be better explained.","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures","abstract":"The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a request of high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods.","pdf":"/pdf/a721df895a9f6d76c312414796d9760342a806b7.pdf","TL;DR":"This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.","paperhash":"anonymous|machine_learning_by_twodimensional_hierarchical_tensor_networks_a_quantum_information_theoretic_perspective_on_deep_architectures","_bibtex":"@article{\n  anonymous2018machine,\n  title={Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryF-cQ6T-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper68/Authors"],"keywords":["quantum machine learning","tensor network","quantum information"]}},{"tddate":null,"ddate":null,"tmdate":1512222718930,"tcdate":1511795899165,"number":2,"cdate":1511795899165,"id":"S17TnsFez","invitation":"ICLR.cc/2018/Conference/-/Paper68/Official_Review","forum":"ryF-cQ6T-","replyto":"ryF-cQ6T-","signatures":["ICLR.cc/2018/Conference/Paper68/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Novel application of tensor networks","rating":"4: Ok but not good enough - rejection","review":"Full disclosure: the authors' submission is not anonymous. They included a github link at the bottom of page 6 and I am aware of the name of the author and coauthors (and have previously read their work and am a fan of it). Thus, this review is not double blind. I notified the area chair last week and we agreed that I submit this review. \n\n---\n\nThis is an interesting application of tensor networks to machine learning. The work proposes using a tree tensor network for image classification. Each image is first mapped into a higher-dimensional space. Then the input features are contracted with the tensors of the tensor network. The maximum value of the final layer of the network gives the predicted class. The training algorithm is inspired by the multipartite entanglement renormalization ansatz: it corresponds to updating each tensor in the network by performing a singular value decomposition of the environment tensor (everything in the cost function after removing the current tensor to be updated).\n\nOverall, I think this is an interesting, novel contribution, but it is not accessible to non-physicists right now. The paper could be rewritten to be accessible to non-physicists and would be a highly-valuable interdisciplinary contribution.\n\n* Consider redoing the experiments with a different cost function: least squares is an unnatural cost function to use for classification. Cross entropy would be better.\n\n* discuss the scalability: why did you downsample MNIST from 28x28 pixels to 16x16 pixels? Why is training accuracy not reported on the 10-class model in Table 1? If it is because of a slow implementation, that's fine. But if it is because of the scalability of the method, it would be good to report that. In either case it wouldn't hurt the paper, it is just important to know. \n\n* In section 5, you say \"input vectors are still initially arranged ... according to their spatial locations in the image\". But don't you change the spatial locations of the image to follow equation (10)? It would be good to add a sentence clarifying this. \n\n---\n\nIn its current form, reading the paper requires a physics background. \n\nThere are a few things that would make it easier to read for a general machine learning audience:\n\n* connect your method to matrix factorization and tensor decomposition approaches\n\n* include an algorithm box for Strategy-I and Strategy-II\n\n* include an appendix, with a brief review of upward and downward indices which is crucial for understanding your method (few people in machine learning are familiar with Einstein notation)\n\n* relate your interesting ideas about quantum states to existing work in information theory. I am skeptical of the label 'quantum': how do quantum mechanical tools apply to images? What is a 'quantum' many-body state here? There is no intrinsic uncertainty principle at play in image classification. I would guess that the ideas you propose are equivalent to existing work in information theory. That would make it less confusing.\n\n* in general, maybe mention the inspiration of your work from MERA, but avoid using physics language when there are no clear physical systems. This will make your work more understandable and easier to follow. A high-level motivation for MERA from a physics perspective suffices; the rest can be phrased in terms of tensor decompositions.  \n\n---\n\nMinor nits:\n\n* replace \\citet with \\citep everywhere - all citations are malformed\n\n* figure 1 could be clarified - say that see-through gray dots are dimensions, blue squares are tensors, edges are contractions\n\n* all figure x and y labels and legends are too small\n\n* some typos: \"which classify an input image by choosing\"; \"we apply different feature map to each\"; small grammar issues in many places\n\n* Figure 4: \"up-down\" and \"left-right\" not defined anywhere","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures","abstract":"The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a request of high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods.","pdf":"/pdf/a721df895a9f6d76c312414796d9760342a806b7.pdf","TL;DR":"This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.","paperhash":"anonymous|machine_learning_by_twodimensional_hierarchical_tensor_networks_a_quantum_information_theoretic_perspective_on_deep_architectures","_bibtex":"@article{\n  anonymous2018machine,\n  title={Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryF-cQ6T-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper68/Authors"],"keywords":["quantum machine learning","tensor network","quantum information"]}},{"tddate":null,"ddate":null,"tmdate":1512222718969,"tcdate":1511150850442,"number":1,"cdate":1511150850442,"id":"rycZrCJef","invitation":"ICLR.cc/2018/Conference/-/Paper68/Official_Review","forum":"ryF-cQ6T-","replyto":"ryF-cQ6T-","signatures":["ICLR.cc/2018/Conference/Paper68/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Authors of this paper derived an efficient quantum-inspired learning algorithm based on a hierarchical representation that is known as tree tensor network, which is inspired by the multipartite entanglement renormalization ansatz approach where the tensors in the TN are kept to be unitary during training. ","rating":"6: Marginally above acceptance threshold","review":"Authors of this paper derived an efficient quantum-inspired learning algorithm based on a hierarchical representation that is known as tree tensor network, which is inspired by the multipartite entanglement renormalization ansatz approach where the tensors in the TN are kept to be unitary during training. Some observations are: The limitation of learnability of TTN strongly depends on the physical indexes and the geometrical indexes determine how well the TTNs approximate the limit; TTNs exhibit same increase level of abstractions as CNN or DBN; Fidelity and entanglement entropy can be considered as some measurements of the network.\n\nAuthors introduced the two-dimensional hierarchical tensor networks for solving image recognition problems, which suits more the 2-D nature of images. In section 2, authors stated that the choice of feature function is arbitrary, and a specific feature map was introduced in Section 4. However, it is not straightforward to connect (10) to (1) or (2). It is better to clarify this connection because some important parameters such as the virtual bond and input bond are related to the complexity of the proposed algorithm as well as the limitation of learnability. For example, the scaling of the complexity O(dN_T(b_v^5 + b_i^4)) is not easy to understand. Is it related to specific feature map? How about the complexity of eigen-decomposition for one tensor at each iterates. And also, whether the tricks used to accelerate the computations will affect the convergence of the algorithm? More details on these problems are required for readers’ better understanding.\n\nFrom Fig 2, it is difficult to see the relationship between learnability and parameters such input bond and virtual bond because it seems there are no clear trends in the Fig 2(a) and (b) to make any conclusion. It is better to clarify these relationships with either clear explanation or better examples.\n\nFrom Fig 3, authors claimed that TN obtained the same levels of abstractions as in deep learning. However, from Fig 3 only, it is hard to make this conclusion. First, there are not too many differences from Fig 3(a) to Fig 3(e).  Second, there is no visualization result reported from deep learning on the same data for comparison. Hence, it is not convincing to draw this conclusion only from Fig 3. \n\nIn Section 4.2, what strategy is used to obtain these parameters in Table 1?\n\nIn Section 5, it is interesting to see more experiments in terms of fidelity and entanglement entropy.\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures","abstract":"The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a request of high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods.","pdf":"/pdf/a721df895a9f6d76c312414796d9760342a806b7.pdf","TL;DR":"This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.","paperhash":"anonymous|machine_learning_by_twodimensional_hierarchical_tensor_networks_a_quantum_information_theoretic_perspective_on_deep_architectures","_bibtex":"@article{\n  anonymous2018machine,\n  title={Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryF-cQ6T-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper68/Authors"],"keywords":["quantum machine learning","tensor network","quantum information"]}},{"tddate":null,"ddate":null,"tmdate":1509739503816,"tcdate":1508878848827,"number":68,"cdate":1509739501148,"id":"ryF-cQ6T-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ryF-cQ6T-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures","abstract":"The resemblance between the methods used in studying quantum-many body physics and in machine learning has drawn considerable attention. In particular, tensor networks (TNs) and deep learning architectures bear striking similarities to the extent that TNs can be used for machine learning. Previous results used one-dimensional TNs in image recognition, showing limited scalability and a request of high bond dimension. In this work, we train two-dimensional hierarchical TNs to solve image recognition problems, using a training algorithm derived from the multipartite entanglement renormalization ansatz (MERA). This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning. While keeping the TN unitary in the training phase, TN states can be defined, which optimally encodes each class of the images into a quantum many-body state. We study the quantum features of the TN states, including quantum entanglement and fidelity. We suggest these quantities could be novel properties that characterize the image classes, as well as the machine learning tasks. Our work could be further applied to identifying possible quantum properties of certain artificial intelligence methods.","pdf":"/pdf/a721df895a9f6d76c312414796d9760342a806b7.pdf","TL;DR":"This approach overcomes scalability issues and implies novel mathematical connections among quantum many-body physics, quantum information theory, and machine learning.","paperhash":"anonymous|machine_learning_by_twodimensional_hierarchical_tensor_networks_a_quantum_information_theoretic_perspective_on_deep_architectures","_bibtex":"@article{\n  anonymous2018machine,\n  title={Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryF-cQ6T-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper68/Authors"],"keywords":["quantum machine learning","tensor network","quantum information"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}