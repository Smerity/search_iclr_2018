{"notes":[{"tddate":null,"ddate":null,"tmdate":1515179430973,"tcdate":1515179430973,"number":9,"cdate":1515179430973,"id":"Byy2THTQG","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"Bk72o4NWM","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Response to Referee (Part 1 of 3)","comment":"We thank the referee for their time in reviewing our work, we understand the significant\ntime constraints placed upon many referees during this season. While we appreciate the\ncall to a clear and defined statement of contributions and originality, we believe that\nperhaps the referee has misunderstood our work with respect to prior art. We hope to \nclarify the contributions of our work in our response, and with our modifications to\nthe final paragraph of the introduction. \n\n> The authors approach the task of labeling histology images with just a single global label, \n>with promising results on two different data sets. This is of high relevance given the difficulty \n>in obtaining expert annotated data. At the same time the key elements of the presented approach \n>remain identical to those in a previous study ... \n\nWe strongly contend this point. We assume that the referee is referring to the work of\nDurand et al. (2016) on the WELDON architecture. While we use this work as a starting \npoint for our application, the specifics of our approach in the application to \nHIA are not at all identical to Durand et al. Indeed, the application to HIA \n(and the modifications required to achieve it)\nwas not at all envisaged in the prior art, which was solely focused on object region \ndetection in natural images (e.g. Pascal VOC, COCO, etc.). Indeed, the application to \nmassive WSI datasets requires novel developments for acquiring instances during \ntraining (i.e. our proposed system of random sampling), much less the architectural and training \nchanges we propose. Even the pre-trained DCNN is different from Durand et al. (2016), \n(ResNet-50 in place of VGG16). Given that there is no path from Durand et al. (2016) \nto human-level diagnosis prediction in WSI from diagnosis labels without the \nsignificant developments we outline, we cannot agree with the referee's assessment.\n\n>the main novelty is to replace the final step of the previous architecture \n>(that averages across a vector) with a multiplayer perceptron.  As such I feel that this \n>would be interesting to present if there is interest in the overall application \n>(and results of the 2016 CVPR paper), but not necessarily as a novel contribution to \n>MIL and histology image classification.\n\nAs we detail in our general comments, we do indeed believe that there is a place at \nICLR for works presenting state-of-the-art results for impactful applications, especially\nin medicine, and oncology diagnostics in particular. We also argue, as in our \ncomments above, and in our general comments, for the novel contributions made by our\nwork to MIL as well as to machine learning in HIA by presenting a human-level\ndiagnosis prediction system for WSI trained without using disease annotation maps."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515179496353,"tcdate":1515179372979,"number":8,"cdate":1515179372979,"id":"BkH_ar6XM","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"Bk72o4NWM","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Response to Referee (Part 2 of 3)","comment":"> * The intro starts from a very high clinical level. A introduction that points out \n>specifics of the technical aspects of this application, the remaining technical challenges, \n>and the contribution of this work might be appreciated by some of your readers.\n\nSince our work is focused on the application of machine learning techniques to a \nvery significant and specific medical diagnostic, and given the very ML-focused audience\nof ICLR, we assume that the majority of readers will be unfamiliar with histopathological\nimage analysis and clinical pathology in general. For this reason, we discuss the \ncontext of the problem at length, including the pernicious data challenges present in \nthis application. Besides presenting our own contributions, we hope to introduce more\nresearchers to this fruitful and important field. As modern machine learning techniques \nare only recently being applied to histopathological image analysis, especially in the \nweak-learning setting, there is a tremendous opportunity for interested readers to \nmake a significant impact in this area. \n\nAs for the presentation of our own contributions with respect to prior work, we have \nmodified the last paragraph of the introduction to make these more clear.\n\n\n> * There is preprocessing that includes feature extraction, and part of the algorithm that \n>includes the same feature extraction. This is somewhat confusing to me and maybe you \n>want to review the structure of the sections.  You are telling us you are using the first layer \n>(P=1) of the ResNet50 in the method description, and you mention that you are using the \n>pre-final layer in the preprocessing section. I assume you are using the latter, or is P=1 \n>identical to the prefinal layer in your notation?  Tell us. \n\nIn our work, we propose the use of the ResNet-50 pre-output layer, namely, the \nvalues resulting from the convolutional stack, prior to the fully-connected output\nlayers. We interpret these values as a feature vector describing the structural and \ncolor content of each $244\\times 244$ pixel tile. In our notation, we use $P$ to refer\nto the dimensionality of this feature vector. In the case of ResNet-50, this layer has \ncontains 2048 neurons, so we note that $P = 2048$. This use of an ImageNet pre-trained \nResNet-50 architecture as a tile feature extractor remains consistent throughout the \nwork, as described in the text. It is not clear to us at which point the referee \nfound confusion between this definition of $P$ and ResNet-50 \nlayer indexing. If the referee would provide further details, we would be happy to \nclarify the text.\n\nAs for the structure of the paper, we discuss the pre-processing stages prior to the\nintroduction of both the feature-pooling techniques and CHOWDER since this pipeline \nremains consistent over all approaches. \n\n> Moreover, not having read Durand 2016, I would appreciate a few more technical details \n>or formal description here and there.  Can you detail about the ranking method in \n>Durand 2016, for example?\n\nBy ranking method, we assume that the referee means the operation of the MinMax layer\noperating on the feature embedding values, as the modified ranking loss metric proposed\nin Sec. 4 of Durand et al. (2016) is easily substituted for binary cross-entropy loss \nin our binary classification setting, as we point out in Sec. 3.1.\n\nThe instance ranking method used in Durand et al. (2016) during training, as well as in \nour approach, is simply sorting the embedding values in descending order, \nas we describe in the \"Top Instances\nand Negative Evidence\" subsection of Sec. 2.3. As for formal descriptions, we err on the\nside of brevity in light of the other necessary content in the paper. Since the \napplication to HIA is novel to many readers, explanation and interpretation is \nrequired in order to relate the significance of our contribution. We have endeavoured to\nmake details explicit when necessary to the presentation, \nsuch as tile selection and the operation of the feature embedding layer. In all other\ncases, we lean on the common expertise of the ICLR audience. If the referee would point\nus to any further ambiguities we would be happy to clarify the text.\n\nAdditionally, the work of Durand et al. (2016) is very informative and \npresents an ingenious architecture. Given the referee's strong interest in our comparison\nto Durand et al. (2016), we would strongly encourage the referee to \ntake the time to read their work in detail, as well. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515179326816,"tcdate":1515179326816,"number":7,"cdate":1515179326816,"id":"BJDr6HaXM","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"Bk72o4NWM","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Response to Referee (Part 3 of 3)","comment":"> * Would it make sense to discuss Durand 2016 in the base line methods section? \n\nConsidering the adaptations we make to the approach of Durand et al. (2016), \nwe felt it more appropriate to cite their work within Sec. 2.3  in order to show the line of\ndevelopment. In Sec. 2.3, we cite Durand et al. (2016) extensively, pointing out the notable \ncontributions of this work, and how the originally proposed approach must be adapted\nin order to provide an effective architecture for the setting of WSI classification\nwithout local annotations. \n\nIn Sec. 2.2, when we introduce baseline techniques, we truly mean baseline. Aggregation\nvia feature pooling is one of the most direct ways one can attempt to approach the \ntask of WSI classification sans annotations. Indeed, this approach is very attractive,\nas compared to MIL approaches, when tackling large-scale datasets from a purely \ncomputational standpoint. For this reason, we denote these approaches as our \"baseline,\"\nwhereby we demonstrate that either technique (WELDON or CHOWDER) can provide \nimprovements in both detection and localization which are significant enough, \nas compared to feature pooling, to justify their complexity.\nBy not including Durand et al. (2016) within Sec 2.2, we do not imply that we should not \ncompare (we do), rather we simply make a semantic distinction between feature \npooling and MIL.\n\n> * To some degree this paper evaluates WELDON (Durand 2016) on new data, and\n>compares it against and an extended WELDON algorithm called CHOWDER that features \n>the final MLP step. Results in table 1 suggest that this leads to some 2-5% performance \n>increase which is a nice result.  I would assume that experimental conditions (training data, \n>preprocessing, optimization, size of ensemble) are kept constant in between those two \n>comparisons? Or is there anything of relevance that also changed (like size of the ensemble, \n>size of training data) \n\nWe do, in fact, evaluate the WELDON architecture of Durand et al. on new data,\nas reported in Table 1. We also compare WELDON against our proposed modifications. \nIn all cases, experimental settings remain consistent between all tested methods. In the \ncase of WELDON and CHOWDER, we have ensured that the ensemble size remains consistent \nbetween the two ($E = 10$ as described in Sec. 3.1). For both WELDON and CHOWDER, \nwe use best-case hyper-parameter settings.\n\nAdditionally, the improvement in AUC demonstrated by the CHOWDER architecture is more\nsignificant than the referee reports. In Table 1, we report a percent change in AUC\nof 12.15% and 8.53% over the WELDON architecture for the competition and \ncross-validation splits, respectively. This corresponds to a 12.59% and 23.66% percent\nchange in AUC as compared to the best-performing baseline methods for the same splits.\nIn the case of TCGA-Lung, we demonstrate a 1.32% percent change in AUC, but we point this\nout specifically in the text. This dataset is well suited to feature pooling due to \nthe balanced instance classes present in the TCGA-Lung dataset. \nThe diseased regions in these\nslides are much more diffuse over the entire tissue sample, as opposed to the \nhighly-localized metastases present in Camelyon-16. Therefore, the excellent \nperformance of the baseline feature-pooling methods is expected for this dataset, \nas the disease signal is not lost in the pooled representation.\n\n>because the WELDON results are essentially previously generated results? \n>Please comment in case there are differences. \n\nIt is not clear to us what is meant by previously generated results. In the case of\nWELDON, in Durand et al. (2016), the method was proposed only for object region \ndetection in natural images. To the best of our knowledge, there has been no other \napplication of a WELDON-inspired architecture to HIA, or to the TCGA-Lung and \nCamelyon-16 datasets in particular. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515178813574,"tcdate":1515178813574,"number":4,"cdate":1515178813574,"id":"BJ8riS6Qf","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"S1O8uhkxf","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Response to Referee","comment":"We thank the referee for their time and effort in assessing our work. We hope that the\ndiscussion we provide in our general comments provides further justification \nfor our work's presence at ICLR. Specifically, we note the significance of our \narchitectural contributions, as well as our modifications to the training regime. We\nalso detail how our system provides human-pathologist-level performance without being\nguided by detailed expert instruction on what structures lead to disease diagnoses. \nWe believe that this significant advance in machine learning as applied to medical \nimaging, and to this gold standard oncology diagnostic in particular, will be of \ngreat interest to the general ICLR audience.\n\n>Previous publications have used MIL training on tiles with only top-level labels [1,2] \n>and this is essentially an incremental improvement on the MIL approach by using \n>several instances (both min-negative and max-positive) instead of a single instance\n>for backprop, as described in [3]. So, the main contribution here, is to adapt min-max \n>MIL to the histology domain. Although the result are good and the method interesting, \n>I think that the technical contribution is a bit thin for a ML conference and this paper \n>may be a better fit for a medical imaging conference.\n\nWe thank the referee for their positive view of our method and results. We agree that \nthe work we present is, as Reviewer1 noted, a \"down-to-earth practical application,\"\nhowever we do make novel architectural, process, and implementation contributions. While\nwe do not provide a theory of MIL in the context of HIA, we note that many successful\nadvances in our field have been made from an empirical, rather than theoretical, \nperspective. While there is no newly proposed loss, neuron non-linearity, or adaptive \nmomentum scheme in our work, we do demonstrate the steps necessary to provide \nstate-of-the-art performance for diagnosis prediction and disease localization without\nexpert assistance beyond diagnosis labels. While these results would indeed be\nincredibly pertinent at a more medically focused venue, it is our strong belief that the audience \nof ICLR would greatly benefit both from our demonstration, as well as their introduction\nto a budding application area in great need of their technical expertise.\n\n>The paper is well written and easy to understand. \n\nWe thank the referee for their comments and positive feedback on our presentation of our\nwork. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515178710851,"tcdate":1515178710851,"number":3,"cdate":1515178710851,"id":"Hy1koS67M","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"SkWQLvebf","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Response to Referee","comment":">The study seems sound from a technical viewpoint to me and its contribution is incremental,\n>as it builds on existing research, which is correctly identified.\n>Results are not always too impressive, but authors seem intent on making them useful for\n> pathogists in practice (an intention that is always worth the effort).\n>I think the paper would benefit from a more explicit statement of its original contributions \n>(against contextual published research)\n\nWe thank the referee for their comments and their effort in assessing our work. \nWith respect to our specific contributions, we have added further clarifications to\n the text (as noted in the paper modifications) to identify our contribution with \nrespect to prior art.  Additionally, with respect to the significance of the results we \npresent, we note that the performance reported in Table 1 represents the \nstate-of-the-art for HIA classification using only WSI-wide labels. For further\njustifications on the significance of our work, we refer to our general comments \non this subject.\n\n>Minor issues:\n>Revise typos (e.g. title of section 2)\n\nThank you for pointing out this (rather embarrassing) typo! We have corrected this\nmistake along with others throughout the text. \n\n>Please revise list of references (right now a mess in terms of format, typos, incompleteness\n\nAs noted in the general comments, we have revised the references to fit a common standard\nand have attempted to include all relevant citation details. We thank you for your \nattentiveness. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515178538810,"tcdate":1515178538810,"number":2,"cdate":1515178538810,"id":"rkmE5raXf","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"Paper Modifications","comment":"We would like to point out the changes made to the text of our \nsubmission to address the comments of the referees, as well as some of our own \ncorrections and clarifications.\n\n1. We have updated the explanation for our choice of a univariate feature embedding ($J=1$) \nversus a multivariate embedding ($J>1$) in light of more extensive \nexperimentation. Specifically, increasing the embedding dimensionality $J$ *can* \nimprove training loss. However, it diminishes generalization, providing \nworse scores on held-out validation data. Even though our tested\ndatasets (Camelyon-16, TCGA-Lung) rival ImageNet in overall size after tiling, \nthe number of *unique* slide images remains very limited. In the weak-learning setting,\nthe training method may attempt to find any number of possible unique features that \ncould contribute to the overall WSI (\"bag\") class. \nFor binary WSI classification, restricting the model to\n$J=1$ makes sense, as the positive/negative assignment of the embedding maps directly \nto the binary classes (e.g. \"contains cancer\", \"does not contain cancer\"). When\nsetting $J>1$, this correspondence is lost, and it becomes much more difficult to both\nregularize, as well as interpret, the model.\n\n2. We have revised the references to a consistent format.\n\n3. We have revised the metastasis detection figures (Figs. 4--6) with a more \nlegible/interpretable color map (*blue-white-red* from the previous *green-yellow-red*).\n\n4. We have updated the last paragraph of the introduction to describe our\nspecific contributions with respect to prior work (Durand et al. 2016, in particular).\n\n5. We have revised grammar, spelling, & usage in the text.\n\n6. In the results section we have added references to the recently published work of \n Bejnordi et al. (2017), which reports human pathologist AUC performance on the \n Camelyon-16 dataset."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515178500665,"tcdate":1515178425217,"number":1,"cdate":1515178425217,"id":"r1WptBaXz","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Comment","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["ICLR.cc/2018/Conference/Paper670/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper670/Authors"],"content":{"title":"General Comments to Referees","comment":"We thank the referees for their time and effort in reviewing our\nwork, especially in light of the many heavy review loads assigned this year. \n\nWe would like to address the general comments from the referees on the \nsignificance of our work to the ICLR community. Specifically, whether or not the \nCHOWDER architecture we propose for MIL in the context of histopathological image \nanalysis (HIA) represents both a reasonable contribution to the ever-growing body of MIL \nresearch, as well as the suitability of such an application-specific paper to the \nICLR community at large.\n\nIn response to the first point, we make affirmative arguments for both our contribution\nto the architecture of the proposed network, as well as for the procedural contribution,\ndemonstrating how to effectively regularize and train a network in the extreme \nsetting of weak learning at very small sample-to-feature ratios. In the case of \nthe proposed architecture, we believe that the additional multi-layer perceptron (MLP)\nat the classification layer does represent a meaningful contribution to MIL research. \nSpecifically, the MLP allows a more context-aware bag classification from the \ntop- and bottom-ranked embedded instance representations. \nIn the case of Durand et al. (2016), a simple sum of these $2R$ values is used. \nAs reported in Durand et al. (2016), even this summation is itself an\nincremental generalization of their \"min+max\" output reported in their MANTRA work \n(Durand et al., 2015). \n\nIn the case of HIA, as evidenced by the results we report in Table 1, using the context\nafforded by the distribution of embedded values *within* the top and bottom rankings\nleads to significant improvements in AUC (a 12.15% and 8.53% percent change for the \ncompetition and CV splits, respectively). This is especially critical for disease \ndetection in WSI, as diseased tissue is noted by its discrepancy from healthy tissue,\nrather than an absolute description of a fixed feature set common to *all* diseased \ntissue. Additionally, as in the case of metastasis detection in Camelyon-16, the \ndetection of highly localized regions (i.e. extreme instance class imbalance) requires\na more sensitive approach, such as that afforded by the use of an MLP, than the \nembedding sum used in Durand et al. (2016). Therefore, we believe that \nthe results and method we report will be useful for readers seeking to train deep\nnets in similar extreme MIL settings, especially those where class imbalance is a \nnoted concern. \n\nFurther, we note that the best-case AUC performance of an expert human pathologist for \nCamelyon-16 was reported as 0.884 in Bejnordi et al. (2017), with the mean pathologist AUC \nreported as 0.810. When using a large ensemble size, $E=50$, we report an AUC of 0.8706, \nthus demonstrating diagnosis prediction performance better than the average human\n pathologist, but *without* making any use of expert assistance during training (e.g. disease \nsegmentation maps). This demonstrates that our proposed methodology is as effective as \nan expert pathologist, while also allowing for machine ingenuity, as the model can adapt to \nnovel diseases and structures outside of the confines of human-produced segmentation maps.\n\nIn response to the second point, on the suitability of this work within ICLR, \nwe refer to the 2018 Call For Papers (CFP):\n\n> We take a broad view of the field and include topics such as feature learning, \n> [...] and issues regarding large scale learning...\n\n> A non-exhaustive list of relevant topics:\n>\n> [...]\n> * implementation issues, parallelization, software platforms, hardware\n> * applications in vision, audio, speech, natural language processing, robotics, \n>    neuroscience, or any other field...\n\nGiven that this work represents an application of machine learning techniques to \na very large-scale problem requiring novel contributions to an existing architecture, \nand that we detail the many implementation issues required for the successful\nutilization of our proposed approach, and that we provide state-of-the-art results \nwithin a very relevant and socially impactful field, namely histopathological\nimage analysis as an oncology diagnostic, we believe that our work is in fact very \nwell suited and topical to ICLR."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515642489647,"tcdate":1512487850795,"number":3,"cdate":1512487850795,"id":"Bk72o4NWM","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Review","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["ICLR.cc/2018/Conference/Paper670/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting application and results with incremental innovation on exististing work","rating":"5: Marginally below acceptance threshold","review":"The authors approach the task of labeling histology images with just a single global label, with promising results on two different data sets. This is of high relevance given the difficulty in obtaining expert annotated data. At the same time the key elements of the presented approach remain identical to those in a previous study, the main novelty is to replace the final step of the previous architecture (that averages across a vector) with a multiplayer perceptron.  As such I feel that this would be interesting to present if there is interest in the overall application (and results of the 2016 CVPR paper), but not necessarily as a novel contribution to MIL and histology image classification.\n\nComments to the authors:\n\n* The intro starts from a very high clinical level. A introduction that points out specifics of the technical aspects of this application, the remaining technical challenges, and the contribution of this work might be appreciated by some of your readers.\n* There is preprocessing that includes feature extraction, and part of the algorithm that includes the same feature extraction. This is somewhat confusing to me and maybe you want to review the structure of the sections.  You are telling us you are using the first layer (P=1) of the ResNet50 in the method description, and you mention that you are using the pre-final layer in the preprocessing section. I assume you are using the latter, or is P=1 identical to the prefinal layer in your notation?  Tell us. Moreover, not having read Durand 2016, I would appreciate a few more technical details or formal description here and there.  Can you detail about the ranking method in Durand 2016, for example?\n* Would it make sense to discuss Durand 2016 in the base line methods section? \n* To some degree this paper evaluates WELDON (Durand 2016) on new data, and compares it against and an extended WELDON algorithm called CHOWDER that features the final MLP step. Results in table 1 suggest that this leads to some 2-5% performance increase which is a nice result.  I would assume that experimental conditions (training data, preprocessing, optimization, size of ensemble) are kept constant in between those two comparisons? Or is there anything of relevance that also changed (like size of the ensemble, size of training data) because the WELDON results are essentially previously generated results? Please comment in case there are differences. ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515642489685,"tcdate":1512236569311,"number":2,"cdate":1512236569311,"id":"SkWQLvebf","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Review","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["ICLR.cc/2018/Conference/Paper670/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Down-to-earth practical application of DL in a medico-clinical context","rating":"6: Marginally above acceptance threshold","review":"This paper proposes a deep learning (DL) approach (pre-trained CNNs) to the analysis of histopathological images for disease localization.\nIt correctly identifies the problem that DL usually requires large image databases to provide competitive results, while annotated histopathological data repositories are costly to produce and not on that size scale.\nIt also correctly identifies that this is a daunting task for human medical experts and therefore one that could surely benefit from the use of automated methods like the ones proposed.\n\nThe study seems sound from a technical viewpoint to me and its contribution is incremental, as it builds on existing research, which is correctly identified.\nResults are not always too impressive, but authors seem intent on making them useful for pathogists in practice (an intention that is always worth the effort).\nI think the paper would benefit from a more explicit statement of its original contributions (against contextual published research)\n\nMinor issues:\nRevise typos (e.g. title of section 2)\nPlease revise list of references (right now a mess in terms of format, typos, incompleteness","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1511819090912,"tcdate":1511819090912,"number":1,"cdate":1511819090912,"id":"rkjIwbqxM","invitation":"ICLR.cc/2018/Conference/-/Paper670/Public_Comment","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Paper reproducibility","comment":"Greetings to the authors of this paper,\n\nYour paper is very interesting and insightful. As part of a reproducibility challenge, our team of students would like to attempt at reproducing the results of your paper. We are not affiliated with the official reviewers.\n\nIf it would be possible, it would be incredibly helpful if you are interested in providing parts of the code used in your implementations.\n\nIf you are interested, please comment below, and we can arrange to contact each other in private.\n\nThank you\n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515642489724,"tcdate":1511143504077,"number":1,"cdate":1511143504077,"id":"S1O8uhkxf","invitation":"ICLR.cc/2018/Conference/-/Paper670/Official_Review","forum":"ryserbZR-","replyto":"ryserbZR-","signatures":["ICLR.cc/2018/Conference/Paper670/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting MIL approach, lacks technical depth for this conference","rating":"5: Marginally below acceptance threshold","review":"This paper describes a semi-supervised method to classify and segment WSI histological images that are only labeled at the whole image level. Images are tiled and tiles are sampled and encoded into a feature vector via a ResNET-50 pretrained on ImageNET. A 1D convolutional layer followed by a min-max layer and 2 fully connected layer compose the network. The conv layer produces a single value per tile. The min-max layer selects the R min and max values, which then enter the FC layers. A multi-instance (MIL) approach is used to train the model by backpropagating only instances that generate min and max values at the min-max layer. Experiments are run on 2 public datasets achieving potentially top performance. Potentially, because all other methods supposedly make use of segmentation labels of tumor, while this method only uses the whole image label.\n\nPrevious publications have used MIL training on tiles with only top-level labels [1,2] and this is essentially an incremental improvement on the MIL approach by using several instances (both min-negative and max-positive) instead of a single instance for backprop, as described in [3]. So, the main contribution here, is to adapt min-max MIL to the histology domain. Although the result are good and the method interesting, I think that the technical contribution is a bit thin for a ML conference and this paper may be a better fit for a medical imaging conference.\n\nThe paper is well written and easy to understand. \n\n\n\n[1] Hou, L., Samaras, D., Kurc, T. M., Gao, Y., Davis, J. E., & Saltz, J. H. (2016). Patch-based convolutional neural network for whole slide tissue image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2424-2433).\n[2]  Cosatto, E., Laquerre, P. F., Malon, C., Graf, H. P., Saito, A., Kiyuna, T., ... (2013). Automated gastric cancer diagnosis on H&E-stained sections; training a classifier on a large scale with multiple instance machine learning. Medical Imaging, 2. 2013.\n[3] Durand, T., Thome, N., & Cord, M. (2016). Weldon: Weakly supervised learning of deep convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 4743-4752).","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]}},{"tddate":null,"ddate":null,"tmdate":1515178024178,"tcdate":1509131506796,"number":670,"cdate":1509739167144,"id":"ryserbZR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ryserbZR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach","abstract":"Analysis of histopathology slides is a critical step for many diagnoses, and in particular in oncology where it defines the gold standard. In the case of digital histopathological analysis, highly trained pathologists must review vast whole-slide-images of extreme digital resolution (100,000^2 pixels) across multiple zoom levels in order to locate abnormal regions of cells, or in some cases single cells, out of millions. The application of deep learning to this problem is hampered not only by small sample sizes, as typical datasets contain only a few hundred samples, but also by the generation of ground-truth localized annotations for training interpretable classification and segmentation models. We propose a method for disease available during training. Even without pixel-level annotations, we are able to demonstrate performance comparable with models trained with strong annotations on the Camelyon-16 lymph node metastases detection challenge. We accomplish this through the use of pre-trained deep convolutional networks, feature embedding, as well as learning via top instances and negative evidence, a multiple instance learning technique fromatp the field of semantic segmentation and object detection.","pdf":"/pdf/012fa6e5f65cad627fe2f27021148514eea04636.pdf","TL;DR":"We propose a weakly supervised learning method for the classification and localization of cancers in extremely high resolution histopathology whole slide images using only image-wide labels.","paperhash":"anonymous|classification_and_disease_localization_in_histopathology_using_only_global_labels_a_weaklysupervised_approach","_bibtex":"@article{\n  anonymous2018classification,\n  title={Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ryserbZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper670/Authors"],"keywords":["Weakly Supervised Learning","Medical Imaging","Histopathology","Deep Feature Extraction"]},"nonreaders":[],"replyCount":11,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}