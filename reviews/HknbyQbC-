{"notes":[{"tddate":null,"ddate":null,"tmdate":1512345828247,"tcdate":1512345828247,"number":7,"cdate":1512345828247,"id":"Sy3y-GGbf","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"HknbyQbC-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Targeted attacks in the current framework","comment":"In the architectures described in Fig 1 and Appendix B there seems to be no provision for conditioning the adversarial examples generated on the target label. I don't quite understand how you could generate targeted adversarial examples for a test image without providing the target label as an input to the generator. Thanks in advance for your answer."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1512222548528,"tcdate":1512012871714,"number":3,"cdate":1512012871714,"id":"S1gL2gTlf","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Review","forum":"HknbyQbC-","replyto":"HknbyQbC-","signatures":["ICLR.cc/2018/Conference/Paper1078/AnonReviewer3"],"readers":["everyone"],"content":{"title":"adversarial adversial example generation, wins MadryLab's mnist challenge","rating":"7: Good paper, accept","review":"The paper proposes a way of generating adversarial examples that fool classification systems.\nThey formulate it for a blackbox and a semi-blackbox setting (semi being, needed for training their own network, but not to generate new samples).\n\nThe model is a residual gan formulation, where the generator generates an image mask M, and (Input + M) is the adversarial example.\nThe paper is generally easy to understand and clear in their results.\nI am not awfully familiar with the literature on adversarial examples to know if other GAN variants exist. From this paper's literature survey, they dont exist. \nSo this paper is innovative in two parts:\n- it applies GANs to adversarial example generation\n- the method is a simple feed-forward network, so it is very fast to compute\n\nThe experiments are pretty robust, and they show that their method is better than the proposed baselines.\nI am not sure if these are complete baselines or if the baselines need to cover other methods (again, not fully familiar with all literature here).\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511944556669,"tcdate":1511944310824,"number":6,"cdate":1511944310824,"id":"rkkYlehxz","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"HJZ_Lhjgf","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Evaluation Against Appropriate Defense Missing","comment":"You did evaluate your attack against different defense methods. But, the question is what would be the *appropriate* defense against your attack? And have you tested your attack against that?"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511929449160,"tcdate":1511929449160,"number":4,"cdate":1511929449160,"id":"HJZ_Lhjgf","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Comment","forum":"HknbyQbC-","replyto":"BkGQbf9lz","signatures":["ICLR.cc/2018/Conference/Paper1078/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1078/Authors"],"content":{"title":"reply to \"Easier to Defend Against Adversarial Example Generator\"","comment":"We do think about defense when proposing an attack. In this paper, we tested our attack on defended models in the evaluation section. In our opinion, the results show that our attack is challenging to defend against because it successfully attacks different kinds of defenses.\n\nTo the above commenter, your enthusiasm is appreciated, but we don’t see a ‘straightforward’ way to defend against this attack. It would be helpful if you can provide a proposed defense algorithm for it. We also plan to open source our attack code. Again, our attack was ranked number 1 on the MNIST challenge by Madry’s group, which is a state-of-the-art defense. In our opinion, this suggests that it is not *straightforward* to defend against.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1512222548571,"tcdate":1511915923451,"number":2,"cdate":1511915923451,"id":"BJjc-tsef","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Review","forum":"HknbyQbC-","replyto":"HknbyQbC-","signatures":["ICLR.cc/2018/Conference/Paper1078/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review","rating":"6: Marginally above acceptance threshold","review":"This paper describes AdvGAN, a conditional GAN plus adversarial loss. AdvGAN is able to generate adversarial samples by running a forward pass on generator. The authors evaluate AdvGAN on semi-white box and black box setting.\n\nAdvGAN is a simple and neat solution to for generating adversary samples. The author also reports state-of-art results.\n\nComment:\n\n1. For MNIST samples, we can easily find the generated sample is a mixture of two digitals. Eg, for digital 7 there is a light gray 3 overlap. I am wondering this method is trying to mixture several samples into one to generate adversary samples. For real color samples, it is harder to figure out the mixture.\n2. Based on mixture assumption, I suggest the author add one more comparison to other method, which is relative change from original image, to see whether AdvGAN is the most efficient model to generate the adversary sample (makes minimal change to original image).\n\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511854643206,"tcdate":1511821593744,"number":5,"cdate":1511821593744,"id":"BkGQbf9lz","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"B1IfJszxM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Easier to Defend Against Adversarial Example Generator","comment":"When proposing an attack, we need to think about the right defense. I think we agree that a fixed adversarial example generator can be defended by training a discriminator. Your point that that discriminator cannot defend against other attacks is irrelevant, because here we are talking about defending against your attack, not others'.  \n\nTo summarize, while defending against your attacks seems straightforward, this is not the case for other attacks. \n\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511383560301,"tcdate":1511383560301,"number":4,"cdate":1511383560301,"id":"BylMzPmxM","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"BknKcXbxz","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Question about the \"easier defended\" ","comment":"Trying to follow this discussion. What was it that makes adversarial examples generated by GAN easier defended compared to other attacks? "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511333707906,"tcdate":1511333646054,"number":3,"cdate":1511333646054,"id":"B1IfJszxM","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Comment","forum":"HknbyQbC-","replyto":"BknKcXbxz","signatures":["ICLR.cc/2018/Conference/Paper1078/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1078/Authors"],"content":{"title":"reply to \"GAN-based Adversarial Examples Not Effective\"","comment":" I think the meaning of the question has continued to change subtly, with this latest comment bringing up the use of “the same GAN” for doing the defense. What defense method are you thinking of? (Keep in mind that the discriminator in the GAN cannot distinguish the real and generated images by definition of successfully training a GAN.)\nThat aside, the claim that adversarial examples generated by GAN can be easier defended is not the take-away here. Many fixed attacks can easily be mitigated; this would not be unique to AdvGAN. See Carlini & Wagner’s paper [https://arxiv.org/abs/1705.07263] for many such mitigations and simple workarounds that show that they are ultimately ineffective as defenses. We actually show in the paper (table 3,4,5) many cases where adversarial examples generated by AdvGAN are more successful against defenses than other strong attacks. Moreover,  we apply AdvGAN on the MNIST challenge (https://github.com/MadryLab/mnist_challenge) and achieve 88.93% accuracy on the published robust model in the semi-whitebox setting, and 92.76% in the black-box setting, which wins the top position in the challenge. This shows that adversarial examples generated by GAN are actually harder to defend compared with other attacks."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511238275627,"tcdate":1511238275627,"number":3,"cdate":1511238275627,"id":"BknKcXbxz","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"HJgQmzbgM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"GAN-based Adversarial Examples Not Effective","comment":"So, I guess this means that adversarial examples generated by GAN can be easier defended compared to other attacks. Essentially, the same GAN that does the attack can do the defense."},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511232279609,"tcdate":1511232279609,"number":2,"cdate":1511232279609,"id":"HJgQmzbgM","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Comment","forum":"HknbyQbC-","replyto":"HJpmU2JeG","signatures":["ICLR.cc/2018/Conference/Paper1078/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1078/Authors"],"content":{"title":"Reply to \"GANs for Detecting GAN-Based Adversarial Examples\"","comment":"The answer a very limited yes, where it would appear to work, but may not be a good idea, since this problem is not perfectly symmetric.  It is sufficient to be used as an attack for GAN to generate a few different adversarial examples. However, an efficient defense with GAN has to consider the much broader and more complex space of all adversarial examples.\n\nFor a fixed AdvGAN instance, you should be able to train a discriminator to differentiate the outputs of that specific AdvGAN from benign data. Lee et al. have proposed a related method of using GAN for adversarial training [https://arxiv.org/abs/1705.03387].\nHowever, the resulting discriminator is not very useful as a general defense, because it does not detect other attacks, possibly even another instance of AdvGAN. \n\nIn a similar setting, Carlini & Wagner have shown that the C&W attack can bypass a classifier that’s been trained to detect C&W attacks [https://arxiv.org/abs/1705.07263].\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1511142949433,"tcdate":1511142949433,"number":2,"cdate":1511142949433,"id":"HJpmU2JeG","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"HkZgMFp1z","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"GANs for Detecting GAN-Based Adversarial Examples","comment":"My question was: can a GAN defend against adversarial examples generated by your method (using GAN)?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1510998505363,"tcdate":1510998505363,"number":1,"cdate":1510998505363,"id":"HkZgMFp1z","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Comment","forum":"HknbyQbC-","replyto":"HJ2cJmgJf","signatures":["ICLR.cc/2018/Conference/Paper1078/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1078/Authors"],"content":{"title":"Reply to \"GANs for Detecting Adversarial Examples\"","comment":"It doesn’t follow so easily. We’ve shown that a GAN can generate attacks and that it can generate a variety of adversarial examples, but there’s no evidence that the range of outputs covers the entire space of adversarial examples. Furthermore, GANs only learn to approximate a true distribution based on limited training data--just like a classifier in this respect--so they may be susceptible to adversarial examples in the same way."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1512222548610,"tcdate":1510961143839,"number":1,"cdate":1510961143839,"id":"SJgWlg6yM","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Official_Review","forum":"HknbyQbC-","replyto":"HknbyQbC-","signatures":["ICLR.cc/2018/Conference/Paper1078/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review for 'Generating Adversarial Examples with Adversarial Networks'","rating":"3: Clear rejection","review":"\nThe authors present an interesting new method for generating adversarial examples. Namely, the author train a generative adversarial network (GAN) to adversarial examples for a target network. The authors demonstrate that the network works well in the semi-white box and black box settings.\n\nThe authors wrote a clear paper with great references and clear descriptions.\n\nMy primary concern is that this work has limited practical benefit in a realistic setting. Addressing each and every concern is quite important:\n\n1) Speed. The authors suggest that training a GAN provides a speed benefit with respect to other attack techniques. The FGSM method (Goodfellow et al, 2015) is basically 1 inference operation and 1 backward operation. The GAN is 1 forward operation. Granted this results in a small difference in timing 0.06s versus 0.01s, however it would seem that avoiding a backward pass is a somewhat small speed gain.\n \nFurthermore, I would want to question the practical usage of having an 'even faster' method for generating adversarial examples. What is the reason that we need to run adversarial attacks 'even faster'? I am not aware of any use-cases, but if there are some, the authors should describe the rationales at length in their paper.\n\n2) High spatial resolution images. Previous methods, e.g. FGSM, may work on arbitrarily sized images. At best, GANs generate reasonable images that are lower resolutions (e.g. < 128x128). Building GAN's that operate above-and-beyond moderate spatial resolution is an open research topic. The best GAN models for generating high resolution images are  difficult to train and it is not clear if they would work in this setting. Furthermore, images with even higher resolutions, e.g. 512x512, which is quite common in ImageNet, are difficult to synthesizes using current techniques.\n\n3) Controlling the amount of distortion. A feature of previous optimization based methods is that a user may specify the amount of perturbation (epsilon). This is a key feature if not requirement in an adversarial perturbation because a user might want to examine the performance of a given model as a function of epsilon. Performing such an analysis with this model is challenging (i.e. retraining a GAN) and it is not clear if a given image generated by a GAN will always achieve a given epsilon perturbation/\n\nOn a more minor note, the authors suggest that generating a *diversity* of adversarial images is of practical import. I do not see the utility of being able to generate a diversity of adversarial images. The authors need to provide more justification for this motivation.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"tddate":null,"ddate":null,"tmdate":1510121364116,"tcdate":1510121364116,"number":1,"cdate":1510121364116,"id":"HJ2cJmgJf","invitation":"ICLR.cc/2018/Conference/-/Paper1078/Public_Comment","forum":"HknbyQbC-","replyto":"HknbyQbC-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"GANs for Detecting Adversarial Examples","comment":"If a GAN can learn to attack, can't another GAN learn the adversarial perturbations and defend against it?\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]}},{"ddate":null,"tddate":1509200803342,"tmdate":1510092381125,"tcdate":1509138182843,"number":1078,"cdate":1510092360170,"id":"HknbyQbC-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HknbyQbC-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Generating Adversarial Examples with Adversarial Networks","abstract":"Recently deep neural networks (DNNs) have been found to be vulnerable against adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them more efficiently and guarantee the diversity of adversarial perturbations requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and preserve the distribution of original instances. For AdvGAN, once the generator is trained, it can generate an adversarial perturbation efficiently for any instance, and the generated adversarial examples have large variety depending on the underlying distribution, so as to accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In the black-box attack, we dynamically train a distilled model for the black-box and optimize the generator accordingly. Extensive experimental results show that black-box attacks based on AdvGAN can achieve comparable attack success rate with that of semi-whitebox settings. Adversarial examples generated by AdvGAN on different models have high attack success rate under state-of-the-art defenses compared with other attacks. We have achieved 92.76% accuracy on the MNIST black-box challenge and been ranked at the top position.","pdf":"/pdf/e074cf9e1b09af73e658886fd664e257da48c396.pdf","TL;DR":"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings.","paperhash":"anonymous|generating_adversarial_examples_with_adversarial_networks","_bibtex":"@article{\n  anonymous2018generating,\n  title={Generating Adversarial Examples with Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HknbyQbC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1078/Authors"],"keywords":["adversarial examples","generative adversarial network","black-box attack"]},"nonreaders":[],"replyCount":14,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}