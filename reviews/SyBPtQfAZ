{"notes":[{"tddate":null,"ddate":null,"tmdate":1515642394995,"tcdate":1511836820041,"number":3,"cdate":1511836820041,"id":"Hk2qhr5gf","invitation":"ICLR.cc/2018/Conference/-/Paper1175/Official_Review","forum":"SyBPtQfAZ","replyto":"SyBPtQfAZ","signatures":["ICLR.cc/2018/Conference/Paper1175/AnonReviewer1"],"readers":["everyone"],"content":{"title":"A variety of ideas but non-standard experimental methodology makes it difficult to draw conclusions","rating":"3: Clear rejection","review":"The paper proposes a variety of modifications to improve GAN training and evaluates them using a variant of the Generative Adversarial Metric.\n\nThe first proposed approach, Static Reusable Noise, proposes sampling a fixed set of latent noise vectors instead of producing them via online sampling. It is motivated by the observation that the generator encounters different noise samples at each iteration of training while for real data the discriminator sees only a fixed number of samples. This does not seem to be a particularly convincing argument. One could argue likewise that this makes the discriminator's job easier as it only has to track the finite amount of samples the generator can produce instead of the full distribution. Experimentally it does not appear to consistently help.\n\nThe second approach, Image based noise generation, replaces noise sampled from a simple distribution such as gaussian or uniform noise with a downsampled and grayscaled version of training images. This does not seem particularly well motivated. Usually the latent space of a generative model is assumed to represent high level disentangled/compositional factors of the data - not a low-level course grained representation of the image. In the case of conditional GANs, this is explicitly the case. The paper's experimental section suggests this failed to improve upon a baseline in all cases. This approach has an additional drawback of no longer having a tractable process to draw new samples from the model as it is dependent on samples from the data distribution.\n\nThe third variant, audition based noise selection (ABNS), proposes selecting a subset of generator samples in a given batch to train on. Two variants are considered, selecting only the best performing (according to the generator) or a mix of the best, worst, and random. This approach most directly addresses the proposed problem of generator discriminator imbalance and seems to be the most well-motivated. With the experimental methodology of the paper it also appears to be the one that potentially helps the most.\n\nThe proposed changes are motivated by the intuition that they better balance the difficulty of the tasks of the generator and discriminator. To potentially validate this, the authors could check whether the training loss terms of the generator and discriminator are better balanced on average. Could the authors comment on whether they observed this to be the case?\n\nFor comparisons, the number of epochs of training appears to be chosen arbitrarily per experiment. Throughout the paper comparisons are reported at epoch 8, 14, 16, 18, 20, 22, 25, 40, and 50. The graphs visualizing the reported metric over training show large oscillations between epochs. This makes it difficult to draw strong conclusions from the results. The authors could improve the strength of their results by comparing/evaluating with a more widely used metric, such as the Inception Score from (Salimans et al. 2016) which has seen wide adoption yet is missing from the evaluation metrics discussed in section 4.3.\n\nOverall, the paper presents a variety of proposed changes to GAN training. Several of the proposed approaches seem ad-hoc and not particularly well motivated. One of the proposed approaches, ABNS, is potentially promising but the experimental methodology appears to have significant issues which makes evaluating and drawing strong conclusions from the results difficult. The reader is left with an unclear picture of the value of the proposed approaches.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Discriminator-Generator Balance in Generative Adversarial Networks","abstract":"Training Artificial Neural Networks to generate better images is a hard problem\nto solve with supervised techniques. Generative Adversarial Networks (GAN) is\nan unsupervised approach that utilizes two ANNs in one system. The first neural\nnetwork is called the Discriminator and evaluates the quality of images generated\nby the other network, the Generator. However, image generation has no fixed\nsolution, making evaluation difficult. This can be addressed through comparing\ntwo GAN models by letting them evaluate each other; the paper proposes a custom\nimplementation of this evaluation method that allows for comparison between two\nGAN models both overall and throughout the learning process.\nGANs have a reputation for being hard to train. One concrete problem is main-\ntaining the balance between the Generator and Discriminator. As for humans, it\nis easier to rate the quality of images then it is to actually create them. A good\nevaluator is necessary, but it must not out-power the generative model. The paper\nexplores two main approaches to achieve a better balanced GAN model. The first\nmethod makes guided alterations to the usually random input of the Generator.\nThe second method adds an additional Discriminator to the model. Techniques\nbased on both of these methods were shown to effectively guide the training pro-\ncess and creating strong models that outperformed regular GANs when compared\nusing the previously mentioned evaluation method.","pdf":"/pdf/b9ca5077f6a0c9481b172ad051d0bff48f2949c2.pdf","paperhash":"anonymous|improving_discriminatorgenerator_balance_in_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Discriminator-Generator Balance in Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyBPtQfAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1175/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1515642395036,"tcdate":1511774747994,"number":2,"cdate":1511774747994,"id":"HJ47cIKxG","invitation":"ICLR.cc/2018/Conference/-/Paper1175/Official_Review","forum":"SyBPtQfAZ","replyto":"SyBPtQfAZ","signatures":["ICLR.cc/2018/Conference/Paper1175/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review from AnonReviewer2","rating":"3: Clear rejection","review":"[Overview]\n\nThis paper proposed four different ways to balance the discriminator and generator during the training of GAN. Specifically, the authors proposed to use static reusable noise, image-based noise generation, audition based noise selection and generative multi-adversarial network with historic discriminator. Based on GAM (Im et al, 2016), the authors compared the modified GAN models with DCGAN to show the performance of different balancing methods, on three different datasets, CelebA, CIFAR-10 and IKEA.\n\n[Strengths] \n\nThis paper tried multiple ways to balance the generator and discriminator. Through the experiments on three different datasets, the authors showed ABNS and GMAN achieved better performance than DCGAN based on the GAM evaluation method. The paper also showed the accuracy curves in different epochs of training.\n\n[Weaknesses]\n\n1. This paper is poorly written. it is hard to follow the storyline in this paper. Also, the content in the paper, especially the experiment part is very redundant, like the figures showing the accuracy with epoch. It would be better to show some qualitative results instead.\n\n2. Many papers proposed the evaluation metric, which the authors mentioned as well. However, the authors did not give any persuasive reason why they choose GAM as the evaluation metric in this paper. Recently, the metrics like Inception Score is more commonly used in many related works. The authors should report Inception Score as well in the experiments.\n\n3. The intuitions behind the proposed different ways of balancing discriminator and generator are not clear. The authors should explain the motivation behind the proposed methods.\n\n4. The paper presents no mathematical explanation for the proposed methods, which make it extremely hard to get precise senses of the proposed methods.\n\n5. The organization of the paper is weird. The proposed methods reside in the experimental setup section. The discussion section should be used for summarizing the phenomenon emerged in the experiments, and hence should be short and compact.\n\n[Summary]\n\nBased on the above comments, I think this paper is in poor condition in both paper writing, methods and experiments. I suggest the authors first re-organize the paper and make more justification for the proposed methods on both theoretically and empirically before submitting.\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Discriminator-Generator Balance in Generative Adversarial Networks","abstract":"Training Artificial Neural Networks to generate better images is a hard problem\nto solve with supervised techniques. Generative Adversarial Networks (GAN) is\nan unsupervised approach that utilizes two ANNs in one system. The first neural\nnetwork is called the Discriminator and evaluates the quality of images generated\nby the other network, the Generator. However, image generation has no fixed\nsolution, making evaluation difficult. This can be addressed through comparing\ntwo GAN models by letting them evaluate each other; the paper proposes a custom\nimplementation of this evaluation method that allows for comparison between two\nGAN models both overall and throughout the learning process.\nGANs have a reputation for being hard to train. One concrete problem is main-\ntaining the balance between the Generator and Discriminator. As for humans, it\nis easier to rate the quality of images then it is to actually create them. A good\nevaluator is necessary, but it must not out-power the generative model. The paper\nexplores two main approaches to achieve a better balanced GAN model. The first\nmethod makes guided alterations to the usually random input of the Generator.\nThe second method adds an additional Discriminator to the model. Techniques\nbased on both of these methods were shown to effectively guide the training pro-\ncess and creating strong models that outperformed regular GANs when compared\nusing the previously mentioned evaluation method.","pdf":"/pdf/b9ca5077f6a0c9481b172ad051d0bff48f2949c2.pdf","paperhash":"anonymous|improving_discriminatorgenerator_balance_in_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Discriminator-Generator Balance in Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyBPtQfAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1175/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1515642395074,"tcdate":1511029162637,"number":1,"cdate":1511029162637,"id":"S1XnKlRJz","invitation":"ICLR.cc/2018/Conference/-/Paper1175/Official_Review","forum":"SyBPtQfAZ","replyto":"SyBPtQfAZ","signatures":["ICLR.cc/2018/Conference/Paper1175/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Missing baselines, metrics, samples and connection to theory","rating":"3: Clear rejection","review":"Impossible to compare to prior work:\n   * No samples for CelebA and cifar are provided\n   * No accepted metrics in the literature are reported.\n  * Comparing DCGAN against IBNG is not a fair comparison: IBNG has information of the data distribution, DCGAN does not\n\nMetrics:\n  * there is a lot of criticism of already used metrics (which are valid), but then the authors do not report any of the standard metrics, and do not display samples.\n  * the proposed metric does not assess: sample quality, overfitting. it compares two models, but if both models are not able to capture the data distribution the metric is meaningless. From the paper: \". In other words, the two Discriminators must perform about equal on the test dataset for GAM to elect the better GAN\". This is a very big assumption.\n\nMissing connection to theory on discriminator versus generator power:\n   * no mention of Wasserstein GAN, where the discriminator can be made more powerful than the generator\n   * no mention of gradient penalties (DRAGAN), a powerful regularizer which could help with this issue\n\nProblems with suggested approaches:\n  * Static reusable noise: No mention of overfitting, or whether the ability to generalize of the generator is impacted by this. The birthday paradox test (https://arxiv.org/pdf/1706.08224.pdf) could have been employed to check the effect on the support of the distribution, together with a metric which assess sample quality.\n  * IBNG: makes use of data information, so it is not comparable to unconditional GAN methods. \n  * Audition based noise selection: interesting idea, but a heuristic which introduces two more hyperparameters: the selection size and the selection strategy, without any theoretical justification.\n\nOverall comments:\n  * there is no strong contribution in the paper. \n  * the manuscript needs polishing, there is a lot of repetition and typos in the current text\n  * there is a lot of detail of existing methods, not sufficient details regarding the methods employed. \n  * paper not reproducible, learning rates and other training details missing. \n  * will the IKEA dataset be made available?\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Discriminator-Generator Balance in Generative Adversarial Networks","abstract":"Training Artificial Neural Networks to generate better images is a hard problem\nto solve with supervised techniques. Generative Adversarial Networks (GAN) is\nan unsupervised approach that utilizes two ANNs in one system. The first neural\nnetwork is called the Discriminator and evaluates the quality of images generated\nby the other network, the Generator. However, image generation has no fixed\nsolution, making evaluation difficult. This can be addressed through comparing\ntwo GAN models by letting them evaluate each other; the paper proposes a custom\nimplementation of this evaluation method that allows for comparison between two\nGAN models both overall and throughout the learning process.\nGANs have a reputation for being hard to train. One concrete problem is main-\ntaining the balance between the Generator and Discriminator. As for humans, it\nis easier to rate the quality of images then it is to actually create them. A good\nevaluator is necessary, but it must not out-power the generative model. The paper\nexplores two main approaches to achieve a better balanced GAN model. The first\nmethod makes guided alterations to the usually random input of the Generator.\nThe second method adds an additional Discriminator to the model. Techniques\nbased on both of these methods were shown to effectively guide the training pro-\ncess and creating strong models that outperformed regular GANs when compared\nusing the previously mentioned evaluation method.","pdf":"/pdf/b9ca5077f6a0c9481b172ad051d0bff48f2949c2.pdf","paperhash":"anonymous|improving_discriminatorgenerator_balance_in_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Discriminator-Generator Balance in Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyBPtQfAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1175/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510750034977,"tcdate":1510750034977,"number":1,"cdate":1510750034977,"id":"r1oUD3FkM","invitation":"ICLR.cc/2018/Conference/-/Paper1175/Public_Comment","forum":"SyBPtQfAZ","replyto":"SyBPtQfAZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Related work","comment":"This work references just one work from 2017, this could lead to the impression that recent related work was not considered sufficiently.  E.g. \n\n[1] stated that it is crucial to maintain a balance between the generator and discriminator and proposed the Boundary Equilibrium GAN (BEGAN).\n\n[2] introduced the Fréchet Inception Distance (FID) for evaluating GANs.\n\nThe authors claim that GAM is the best suited evaluation metric for this work. The authors should clarify more precisely why this is the case.\n\n[1] https://arxiv.org/abs/1703.10717\n[2] https://arxiv.org/abs/1706.08500"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Discriminator-Generator Balance in Generative Adversarial Networks","abstract":"Training Artificial Neural Networks to generate better images is a hard problem\nto solve with supervised techniques. Generative Adversarial Networks (GAN) is\nan unsupervised approach that utilizes two ANNs in one system. The first neural\nnetwork is called the Discriminator and evaluates the quality of images generated\nby the other network, the Generator. However, image generation has no fixed\nsolution, making evaluation difficult. This can be addressed through comparing\ntwo GAN models by letting them evaluate each other; the paper proposes a custom\nimplementation of this evaluation method that allows for comparison between two\nGAN models both overall and throughout the learning process.\nGANs have a reputation for being hard to train. One concrete problem is main-\ntaining the balance between the Generator and Discriminator. As for humans, it\nis easier to rate the quality of images then it is to actually create them. A good\nevaluator is necessary, but it must not out-power the generative model. The paper\nexplores two main approaches to achieve a better balanced GAN model. The first\nmethod makes guided alterations to the usually random input of the Generator.\nThe second method adds an additional Discriminator to the model. Techniques\nbased on both of these methods were shown to effectively guide the training pro-\ncess and creating strong models that outperformed regular GANs when compared\nusing the previously mentioned evaluation method.","pdf":"/pdf/b9ca5077f6a0c9481b172ad051d0bff48f2949c2.pdf","paperhash":"anonymous|improving_discriminatorgenerator_balance_in_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Discriminator-Generator Balance in Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyBPtQfAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1175/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510092378010,"tcdate":1509206365511,"number":1175,"cdate":1510092358954,"id":"SyBPtQfAZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SyBPtQfAZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Improving Discriminator-Generator Balance in Generative Adversarial Networks","abstract":"Training Artificial Neural Networks to generate better images is a hard problem\nto solve with supervised techniques. Generative Adversarial Networks (GAN) is\nan unsupervised approach that utilizes two ANNs in one system. The first neural\nnetwork is called the Discriminator and evaluates the quality of images generated\nby the other network, the Generator. However, image generation has no fixed\nsolution, making evaluation difficult. This can be addressed through comparing\ntwo GAN models by letting them evaluate each other; the paper proposes a custom\nimplementation of this evaluation method that allows for comparison between two\nGAN models both overall and throughout the learning process.\nGANs have a reputation for being hard to train. One concrete problem is main-\ntaining the balance between the Generator and Discriminator. As for humans, it\nis easier to rate the quality of images then it is to actually create them. A good\nevaluator is necessary, but it must not out-power the generative model. The paper\nexplores two main approaches to achieve a better balanced GAN model. The first\nmethod makes guided alterations to the usually random input of the Generator.\nThe second method adds an additional Discriminator to the model. Techniques\nbased on both of these methods were shown to effectively guide the training pro-\ncess and creating strong models that outperformed regular GANs when compared\nusing the previously mentioned evaluation method.","pdf":"/pdf/b9ca5077f6a0c9481b172ad051d0bff48f2949c2.pdf","paperhash":"anonymous|improving_discriminatorgenerator_balance_in_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Discriminator-Generator Balance in Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyBPtQfAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1175/Authors"],"keywords":[]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}