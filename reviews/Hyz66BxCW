{"notes":[{"tddate":null,"ddate":null,"tmdate":1515642422087,"tcdate":1511831939212,"number":3,"cdate":1511831939212,"id":"SJoKY49xz","invitation":"ICLR.cc/2018/Conference/-/Paper265/Official_Review","forum":"Hyz66BxCW","replyto":"Hyz66BxCW","signatures":["ICLR.cc/2018/Conference/Paper265/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Some good experiments and explanations of them, but writing is poor and literature review significantly lacking","rating":"4: Ok but not good enough - rejection","review":"The quality and clarity of this manuscript are somewhat low. While an empirical exploration of capacity and generalization on text could provide novel insights, the experiments are performed only on one task; a medium-small sentiment analysis dataset, and there are no novel conclusions reached.\n\nPros:\n - experimental results are clearly presented\n - most details of experiments are explained\n - the basic outline of the paper explores an interesting question\n\nCons\n - many sentences do not have a clear point, and there are many spelling and grammar errors\n - Despite claims to the contrary, the experiments are far from extensive; they explore two models, with variations in context for embeddings, with 3 optimizers, on just one task. To be an extensive discussion of \"text\", I would expect to see language-modeling and seq-to-seq tasks as well\n - the majority of the manuscript is taken up by overly long explanations of background concepts (e.g. half a page on risk minimization, half a page on \"different kinds of neural networks\" with vague and occasionally misleading descriptions of RNN vs CNN, containing zero citations)\n - the related work is significantly lacking, and it appears that the authors are unaware of results and published work which would be directly relevant to theirs (e.g. Arpit et al. A closer look at memorization in deep networks ; Advani and Saxe Generalization error dynamics in high dimensions)\n - in the introduction, generalization is not clearly explained, which seems kind of like an important thing to do...\n - VC is a measure/set, not a norm?\n - the section \"Linked to the mode selection of distribution\" is unclear. I don't see the justification for assuming that a decrease in test accuracy indicates mode selection, and don't understand figure 4b (it's just two bumps labelled mode 1 and mode 2 with an arrow between them. What are the axes of this plot?? Is this real data, or just a vague illustration of mode selection?)\n - Did you tune the learning rate for the adagrad and gradient descent methods? I find it very surprising that they would fail to converge.\n - experiments are not described in sufficient detail to be reproduced. What are the other hyperparameters for the various experiments? Only test set results are plotted; what about training/validation curves?\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text","abstract":"Recently, deep neural network models have shown promising opportunities for many natural language processing (NLP) tasks. In practice, the number of parameters of deep neural models is often significantly larger than the size of the training set, and its generalization behavior cannot be explained by the classic generalization theory. In this paper, with extensive experiments, we empirically investigate the model capacity and generalization of neural models for text. The experiments show that deep neural models can find patterns better than brute-force memorization. Therefore, a large-capacity model with early-stopping stochastic gradient descent (SGD) as implicit regularizer seems to be the best choice, as it has better generalization ability and higher convergence speed.","pdf":"/pdf/c25bc54d3f3e94c3080b74e7725966d0c46d7dd4.pdf","paperhash":"anonymous|empirical_investigation_on_model_capacity_and_generalization_of_neural_networks_for_text","_bibtex":"@article{\n  anonymous2018empirical,\n  title={Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hyz66BxCW}\n}","withdrawal":"Confirmed","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper265/Authors"],"keywords":["Text","Empirical Investigation","Model Capacity","Generalization Ability","Neural Networks","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1515642422124,"tcdate":1511819678423,"number":2,"cdate":1511819678423,"id":"B18jF-qxf","invitation":"ICLR.cc/2018/Conference/-/Paper265/Official_Review","forum":"Hyz66BxCW","replyto":"Hyz66BxCW","signatures":["ICLR.cc/2018/Conference/Paper265/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Unsurprising experimental results, no theoretical contribution.","rating":"3: Clear rejection","review":"Summary: As indicated by the paper's title, this paper provides an \"empirical investigation on model capacity and generalization of neural networks for text\". It defines the capacity of a model to be the maximal number of random training points which a model can memorize (up to x% accuracy, for different values of x). It studies CNN, LSTM, and CBOW models, showing that larger models have larger capacity (the relationship between number of parameters $p$, and the capacity $c$ of the model, appears to be $c = O(log(p))$), and also generalize better. It also studies how the optimization method affects model capacity, showing that Adam is much more effective for memorizing random data than \"vanilla SGD\" or AdaGrad.\n\nReview:\nQuality: Experiments appear to be correct and of high quality.\n\nClarity: The paper is relatively clear, though there are many grammatical mistakes.  Also, the description of the output layer in section 3.3 didn't make it clear to me that a single hidden layer neural network was used (I figured this out based on the number of parameters in the models) --- it made it seem that the output of the processing layer is directly connected to the softmax.\n\nOriginality: The work is not very original, and the results are not surprising.  Neyshabur et al (2014,2017) have already shown that larger networks generalize better than smaller networks, and Zhang et al (2017) have already shown that neural networks are able to both memorize and generalize.\n\nSignificance: While the experiments presented in this paper are nice, I do not believe that the results are particularly significant or informative.\n\nPros\n- Extensive experiments on NLP data.\n\nCons\n- Results are not surprising\n- The questions tackled by the experiments are not original.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text","abstract":"Recently, deep neural network models have shown promising opportunities for many natural language processing (NLP) tasks. In practice, the number of parameters of deep neural models is often significantly larger than the size of the training set, and its generalization behavior cannot be explained by the classic generalization theory. In this paper, with extensive experiments, we empirically investigate the model capacity and generalization of neural models for text. The experiments show that deep neural models can find patterns better than brute-force memorization. Therefore, a large-capacity model with early-stopping stochastic gradient descent (SGD) as implicit regularizer seems to be the best choice, as it has better generalization ability and higher convergence speed.","pdf":"/pdf/c25bc54d3f3e94c3080b74e7725966d0c46d7dd4.pdf","paperhash":"anonymous|empirical_investigation_on_model_capacity_and_generalization_of_neural_networks_for_text","_bibtex":"@article{\n  anonymous2018empirical,\n  title={Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hyz66BxCW}\n}","withdrawal":"Confirmed","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper265/Authors"],"keywords":["Text","Empirical Investigation","Model Capacity","Generalization Ability","Neural Networks","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1515642422162,"tcdate":1511539261437,"number":1,"cdate":1511539261437,"id":"SkSrf6Sef","invitation":"ICLR.cc/2018/Conference/-/Paper265/Official_Review","forum":"Hyz66BxCW","replyto":"Hyz66BxCW","signatures":["ICLR.cc/2018/Conference/Paper265/AnonReviewer2"],"readers":["everyone"],"content":{"title":"review","rating":"4: Ok but not good enough - rejection","review":"This paper is a kind of follow-up on previous work such as Zhang et al (2017) trying to empirically analyze the relationship between model capacity and generalization for deep neural networks. In particular, this paper concentrates on sequence models for text classification, using LSTMs, CNNs or Bag-of-Words.  They follow similar experiments as Zhang et al (2017) which was for images and obtain similar conclusions for text models.\n\nGiven previous results on this topic, the results of this paper are not surprising: all results follow what previous papers have already shown, except that now it extends to recurrent and convolutional models for text.  Overall, this is a nice report, but there is not enough novelty.\n\nSmaller points:\n- it would have been better to use state-of-the-art models for the selected task as a baseline, and then vary some design choices accordingly (like replacing the LSTM layer by a CNN layer, or Adam by SGD, etc. The current setting feels arbitrary as it is not clear that any of the models are good (with respect to the state-of-the-art).\n- I didn't understand the argument trying to convince us that SGD performs implicit generalization; I agree it should be the case, but I didn't understand the explanation, nor understood what was the \"mode selection\" and the \"pattern of distribution\".","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text","abstract":"Recently, deep neural network models have shown promising opportunities for many natural language processing (NLP) tasks. In practice, the number of parameters of deep neural models is often significantly larger than the size of the training set, and its generalization behavior cannot be explained by the classic generalization theory. In this paper, with extensive experiments, we empirically investigate the model capacity and generalization of neural models for text. The experiments show that deep neural models can find patterns better than brute-force memorization. Therefore, a large-capacity model with early-stopping stochastic gradient descent (SGD) as implicit regularizer seems to be the best choice, as it has better generalization ability and higher convergence speed.","pdf":"/pdf/c25bc54d3f3e94c3080b74e7725966d0c46d7dd4.pdf","paperhash":"anonymous|empirical_investigation_on_model_capacity_and_generalization_of_neural_networks_for_text","_bibtex":"@article{\n  anonymous2018empirical,\n  title={Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hyz66BxCW}\n}","withdrawal":"Confirmed","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper265/Authors"],"keywords":["Text","Empirical Investigation","Model Capacity","Generalization Ability","Neural Networks","Deep Learning"]}}],"limit":2000,"offset":0}