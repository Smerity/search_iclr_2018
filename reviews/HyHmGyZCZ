{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222664159,"tcdate":1512003064978,"number":3,"cdate":1512003064978,"id":"SJWbIA3eG","invitation":"ICLR.cc/2018/Conference/-/Paper476/Official_Review","forum":"HyHmGyZCZ","replyto":"HyHmGyZCZ","signatures":["ICLR.cc/2018/Conference/Paper476/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A set of retrofitting methods for measuring lexical similarity","rating":"3: Clear rejection","review":"I hate to say that the current version of this paper is not ready, as it is poorly written. The authors present some observations of the weaknesses of the existing vector space models and list a 6-step approach for refining existing word vectors (GloVe in this work), and test the refined vectors on 80 TOEFL questions and 50 ESL questions. In addition to the incoherent presentation, the proposed method lacks proper justification. Given the small size of the datasets, it is also unclear how generalizable the approach is.\n\nPros:\n  1. Experimental study on retrofitting existing word vectors for ESL and TOEFL lexical similarity datasets\n\nCons:\u000b  1. The paper is poorly written and the proposed methods are not well justified.\n  2. Results on tiny datasets\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING","abstract":"Distributional semantics models derive word space from linguistic items in context. Meaning is obtained by deﬁning a distance measure between vectors corresponding to lexical entities. Such vectors present several problems. In this paper we provide a guideline for post process improvements to the baseline vectors. We focus on reﬁning the similarity aspect, address imperfections of the model by applying the hubness reduction method, implementing relational knowledge into the model, and providing a new ranking similarity deﬁnition that give maximum weight to the top 1 component value. This feature ranking is similar to the one used in information retrieval. All these enrichments outperform any literature results so far for joint ESL and TOEF sets comparison. Since single word embedding is a basic element of any semantic tasks one can expect a signiﬁcant improvement of results for these tasks. Moreover, our improved method of text processingcanbetranslatedtocontinuousdistributedrepresentationofbiological sequences for deep proteomics and genomics.\n","pdf":"/pdf/041a1f06d3fa94f0aec3c9e9f2d115cf2ed114dd.pdf","TL;DR":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING THAT GIVES STATE-OF-THE-ART RESULTS","paperhash":"anonymous|novel_ranking_based_lexical_similarity_measure_for_word_embedding","_bibtex":"@article{\n  anonymous2018novel,\n  title={NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyHmGyZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper476/Authors"],"keywords":["language models","vector spaces","word embedding","similarity"]}},{"tddate":null,"ddate":null,"tmdate":1512222664358,"tcdate":1511830395975,"number":2,"cdate":1511830395975,"id":"HJmKXVcgz","invitation":"ICLR.cc/2018/Conference/-/Paper476/Official_Review","forum":"HyHmGyZCZ","replyto":"HyHmGyZCZ","signatures":["ICLR.cc/2018/Conference/Paper476/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a ranking-based similarity metric for distributional semantic models. The main idea is to learn \"baseline\" word embeddings, retrofitting those and applying localized centering, to then calculate similarity using a measure called \"Ranking-based Exponential Similarity Measure\" (RESM), which is based on the recently proposed APSyn measure.\n\nI think the work has several important issues:\n\n1. The work is very light on references. There is a lot of previous work on evaluating similarity in word embeddings (e.g. Hill et al, a lot of the papers in RepEval workshops, etc.); specialization for similarity of word embeddings (e.g. Kiela et al., Mrksic et al., and many others); multi-sense embeddings (e.g. from Navigli's group); and the hubness problem (e.g. Dinu et al.). For the localized centering approach, Hara et al.'s introduced that method. None of this work is cited, which I find inexcusable. \n\n2. The evaluation is limited, in that the standard evaluations (e.g. SimLex would be a good one to add, as well as many others, please refer to the literature) are not used and there is no comparison to previous work. The results are also presented in a confusing way, with the current state of the art results separate from the main results of the paper. It is unclear what exactly helps, in which case, and why. \n\n3. There are technical issues with what is presented, with some seemingly factual errors. For example, \"In this case we could apply the inversion, however it is much more convinient [sic] to take the negative of distance. Number 1 in the equation stands for the normalizing, hence the similarity is defined as follows\" - the 1 does not stand for normalizing, that is the way to invert the cosine distance (put differently, cosine distance is 1-cosine similarity, which is a metric in Euclidean space due to the properties of the dot product). Another example, \"are obtained using the GloVe vector, not using PPMI\" - there are close relationships between what GloVe learns and PPMI, which the authors seem unaware of (see e.g. the GloVe paper and Omer Levy's work). \n\n4. Then there is the additional question, why should we care? The paper does not really motivate why it is important to score well on these tests: these kinds of tests are often used as ways to measure the quality of word embeddings, but in this case the main contribution is the similarity metric used *on top* of the word embeddings. In other words, what is supposed to be the take-away, and why should we care?\n\nAs such, I do not recommend it for acceptance - it needs significant work before it can be accepted at a conference.\n\nMinor points:\n- Typo in Eq 10\n- Typo on page 6 (/cite instead of \\cite)","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING","abstract":"Distributional semantics models derive word space from linguistic items in context. Meaning is obtained by deﬁning a distance measure between vectors corresponding to lexical entities. Such vectors present several problems. In this paper we provide a guideline for post process improvements to the baseline vectors. We focus on reﬁning the similarity aspect, address imperfections of the model by applying the hubness reduction method, implementing relational knowledge into the model, and providing a new ranking similarity deﬁnition that give maximum weight to the top 1 component value. This feature ranking is similar to the one used in information retrieval. All these enrichments outperform any literature results so far for joint ESL and TOEF sets comparison. Since single word embedding is a basic element of any semantic tasks one can expect a signiﬁcant improvement of results for these tasks. Moreover, our improved method of text processingcanbetranslatedtocontinuousdistributedrepresentationofbiological sequences for deep proteomics and genomics.\n","pdf":"/pdf/041a1f06d3fa94f0aec3c9e9f2d115cf2ed114dd.pdf","TL;DR":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING THAT GIVES STATE-OF-THE-ART RESULTS","paperhash":"anonymous|novel_ranking_based_lexical_similarity_measure_for_word_embedding","_bibtex":"@article{\n  anonymous2018novel,\n  title={NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyHmGyZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper476/Authors"],"keywords":["language models","vector spaces","word embedding","similarity"]}},{"tddate":null,"ddate":null,"tmdate":1512222664402,"tcdate":1511824888927,"number":1,"cdate":1511824888927,"id":"S1ZbRMqlM","invitation":"ICLR.cc/2018/Conference/-/Paper476/Official_Review","forum":"HyHmGyZCZ","replyto":"HyHmGyZCZ","signatures":["ICLR.cc/2018/Conference/Paper476/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Main point of paper is unclear and unproven","rating":"2: Strong rejection","review":"The paper suggests taking GloVe word vectors, adjust them, and then use a non-Euclidean similarity function between them. The idea is tested on very small data sets (80 and 50 examples, respectively). The proposed techniques are a combination of previously published steps, and the new algorithm fails to reach state-of-the-art on the tiny data sets.\n\nIt isn't clear what the authors are trying to prove, nor whether they have successfully proven what they are trying to prove. Is the point that GloVe is a bad algorithm? That these steps are general? If the latter, then the experimental results are far weaker than what I would find convincing. Why not try on multiple different word embeddings? What happens if you start with random vectors? What happens when you try a bigger data set or a more complex problem?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING","abstract":"Distributional semantics models derive word space from linguistic items in context. Meaning is obtained by deﬁning a distance measure between vectors corresponding to lexical entities. Such vectors present several problems. In this paper we provide a guideline for post process improvements to the baseline vectors. We focus on reﬁning the similarity aspect, address imperfections of the model by applying the hubness reduction method, implementing relational knowledge into the model, and providing a new ranking similarity deﬁnition that give maximum weight to the top 1 component value. This feature ranking is similar to the one used in information retrieval. All these enrichments outperform any literature results so far for joint ESL and TOEF sets comparison. Since single word embedding is a basic element of any semantic tasks one can expect a signiﬁcant improvement of results for these tasks. Moreover, our improved method of text processingcanbetranslatedtocontinuousdistributedrepresentationofbiological sequences for deep proteomics and genomics.\n","pdf":"/pdf/041a1f06d3fa94f0aec3c9e9f2d115cf2ed114dd.pdf","TL;DR":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING THAT GIVES STATE-OF-THE-ART RESULTS","paperhash":"anonymous|novel_ranking_based_lexical_similarity_measure_for_word_embedding","_bibtex":"@article{\n  anonymous2018novel,\n  title={NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyHmGyZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper476/Authors"],"keywords":["language models","vector spaces","word embedding","similarity"]}},{"tddate":null,"ddate":null,"tmdate":1509739281745,"tcdate":1509122588931,"number":476,"cdate":1509739279088,"id":"HyHmGyZCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HyHmGyZCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING","abstract":"Distributional semantics models derive word space from linguistic items in context. Meaning is obtained by deﬁning a distance measure between vectors corresponding to lexical entities. Such vectors present several problems. In this paper we provide a guideline for post process improvements to the baseline vectors. We focus on reﬁning the similarity aspect, address imperfections of the model by applying the hubness reduction method, implementing relational knowledge into the model, and providing a new ranking similarity deﬁnition that give maximum weight to the top 1 component value. This feature ranking is similar to the one used in information retrieval. All these enrichments outperform any literature results so far for joint ESL and TOEF sets comparison. Since single word embedding is a basic element of any semantic tasks one can expect a signiﬁcant improvement of results for these tasks. Moreover, our improved method of text processingcanbetranslatedtocontinuousdistributedrepresentationofbiological sequences for deep proteomics and genomics.\n","pdf":"/pdf/041a1f06d3fa94f0aec3c9e9f2d115cf2ed114dd.pdf","TL;DR":"NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING THAT GIVES STATE-OF-THE-ART RESULTS","paperhash":"anonymous|novel_ranking_based_lexical_similarity_measure_for_word_embedding","_bibtex":"@article{\n  anonymous2018novel,\n  title={NOVEL RANKING BASED LEXICAL SIMILARITY MEASURE FOR WORD EMBEDDING},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyHmGyZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper476/Authors"],"keywords":["language models","vector spaces","word embedding","similarity"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}