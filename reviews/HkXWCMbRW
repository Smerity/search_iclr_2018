{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222543682,"tcdate":1511799144437,"number":3,"cdate":1511799144437,"id":"rJx_tnFeM","invitation":"ICLR.cc/2018/Conference/-/Paper1036/Official_Review","forum":"HkXWCMbRW","replyto":"HkXWCMbRW","signatures":["ICLR.cc/2018/Conference/Paper1036/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Training for Compression, Classification and Segmentation","rating":"6: Marginally above acceptance threshold","review":"This is a well-written and quite clear work about how a previous work on image compression using deep neural networks can be extended to train representations which are also valid for semantic understanding. IN particular, the authors tackle the classic and well-known problems of image classification and segmentation.\n\nThe work evolves around defining a loss function which initially considers only a trade-off between reconstruction error and total bit-rate. The representations trained with the loss function, at three different operational points, are used as inputs for variations of ResNet (image classification) and DeepLab (segmentation). The results obtained are similar to a ResNet trained directly over the RGB images, and actually with a slight increase of performance in segmentation. The most interesting part is a joint training for both compression and image classification.\n\nPROS\nP.1 Joint training for both compression and classification. First time to the authors knowledge.\nP.2 Performance on classification and segmentation tasks are very similar when compared to the non-compressed case with state-of-the-art ResNet architectures.\nP.3 Text is very clear.\nP.4 Experimentation is exhaustive and well-reported.\n\nCONS\nC1. The authors fail into providing a better background regarding the metrics MS-SSIM and SSIM (and PSNR, as well) and their relation to the MSE used for training the network. Also, I missed an explanation about whether high or low values for them are beneficial, as actually results compared to JPEG and JPEG-2000 differ depending on the experiment.\nC2. The main problem is of the work is that, while the whole argument is that in an indexing system it would not be necessary to decompress the representation coded with a DNN, in terms of computation JPEG2000 (and probably JPEG) are much lighter that coding with DNN, even if considering both the compression and decompression. The authors already point at another work where they explore the efficient compression with GPUs, but this point is the weakest one for the adoption of the proposed scheme.\nC3. The paper exceeds the recommendation of 8 pages and expands up to 13 pages, plus references. An effort of compression would be advisable, moving some of the non-core results to the appendixes.\n\nQUESTIONS\nQ1. Do you have any explanation for the big jumps on the plots of Figure 5 ?\nQ2. Did you try a joint training for the segmentation task as well ?\nQ3. Why are the dots connected in Figure 10, but not in Figure 11.\nQ4. Actually results in Figure 10 do not seem good... or maybe I am not understanding them properly. This is related to C1.\nQ5. There is a broken reference in Section 5.3. Please fix.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Towards Image Understanding from Deep Compression Without Decoding","abstract":"Motivated by recent work on deep neural network (DNN)-based image compression methods showing potential improvements in image quality, savings in storage, and bandwidth reduction, we propose to perform image understanding tasks such as classification and segmentation directly on the compression representations produced by these compression methods. Since the encoders and decoders in DNN-based compression methods are neural networks with feature-maps as internal representations of the images, we directly integrate these with architectures for image understanding. This bypasses decoding of the compressed representation into RGB space and reduces computational cost. Our study shows that performance comparable to networks that operate on compressed RGB images can be achieved. Furthermore, we show that synergies are obtained by jointly training compression networks with classification networks on the compressed representations, improving image quality, classification accuracy, and segmentation performance. We find that inference from compressed representations is particularly advantageous compared to inference from compressed RGB images at high compression rates.","pdf":"/pdf/ab1882c18d655b75d232dd208c49aa09b3ccb4ac.pdf","paperhash":"anonymous|towards_image_understanding_from_deep_compression_without_decoding","_bibtex":"@article{\n  anonymous2018towards,\n  title={Towards Image Understanding from Deep Compression Without Decoding},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkXWCMbRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1036/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222543727,"tcdate":1511756731551,"number":2,"cdate":1511756731551,"id":"SkE6QMtlG","invitation":"ICLR.cc/2018/Conference/-/Paper1036/Official_Review","forum":"HkXWCMbRW","replyto":"HkXWCMbRW","signatures":["ICLR.cc/2018/Conference/Paper1036/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review for \"Towards Image Understanding from Deep Compression Without Decoding\"","rating":"3: Clear rejection","review":"Summary:\nThis work explores the use of learned compressed image representation for solving 2 computer vision tasks without employing a decoding step. \n\nThe paper claims to be more computationally and memory efficient compared to the use of original or the decompressed images. Results are presented on 2 datasets \"Imagenet\" and \"PASCAL VOC 2012\". They also jointly train the compression and classification together and empirically shows it can improve both classification and compression together.\n\nPros:\n+ The idea of learning from a compressed representation is a very interesting and beneficial idea for large-scale image understanding tasks. \n\nCons:\n- The paper is too long (13 pages + 2 pages of references). The suggested standard number of pages is 8 pages + 1 page of references. There are many parts that are unnecessary in the paper and can be summarized. Summarizing and rewording them makes the paper more consistent and easier to read:\n  ( 1. A very long introduction about the benefits of inferring from the compressed images and examples.\n    2. A large part of the intro and Related work can get merged.  \n    3. Experimental setup part is long but not well-explained and is not self-contained particularly for the evaluation metrics. \n    “Please briefly explain what MS-SSIM, SSIM, and PSNR stand for”. There is a reference to the Agustsson et al 2017 paper \n     “scalar quantization”, which is not well explained in the paper. It is better to remove this part if it is not an important part or just briefly but clearly explain it.\n     4. Fig. 4 is not necessary. 4.3 contains extra information and could be summarized in a more consistent way.\n     5. Hyperparameters that are applied can be summarized in a small table or just explain the difference between the \n      architectures that are used.)\n\n- There are parts of the papers which are confusing or not well-written. It is better to keep the sentences short and consistent:\nE.g: subsection 3.2, page 5: “To adapt the ResNet … where k is the number of … layers of the network” can be changed to 3 shorter sentences, which is easier to follow.\nThere are some typos: e.g: part 3.1, fever ---> fewer, \n\n- As it is mentioned in the paper, solving a Vision problem directly from a compressed image, is not a novel method (e.g: DCT coefficients were used for both vision and audio data to solve a task without any decompression). However, applying a deep representation for the compression and then directly solving a vision task (classification and segmentation) can be considered as a novel idea.\n\n- In the last part of the paper, both compression and classification parts are jointly trained, and it is empirically presented that both results improved by jointly training them. However, to me, it is not clear if the trained compression model on this specific dataset and for the task of classification can work well for other datasets or other tasks.  \nThe experimental setup and the figures are not well explained and well written. \n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Towards Image Understanding from Deep Compression Without Decoding","abstract":"Motivated by recent work on deep neural network (DNN)-based image compression methods showing potential improvements in image quality, savings in storage, and bandwidth reduction, we propose to perform image understanding tasks such as classification and segmentation directly on the compression representations produced by these compression methods. Since the encoders and decoders in DNN-based compression methods are neural networks with feature-maps as internal representations of the images, we directly integrate these with architectures for image understanding. This bypasses decoding of the compressed representation into RGB space and reduces computational cost. Our study shows that performance comparable to networks that operate on compressed RGB images can be achieved. Furthermore, we show that synergies are obtained by jointly training compression networks with classification networks on the compressed representations, improving image quality, classification accuracy, and segmentation performance. We find that inference from compressed representations is particularly advantageous compared to inference from compressed RGB images at high compression rates.","pdf":"/pdf/ab1882c18d655b75d232dd208c49aa09b3ccb4ac.pdf","paperhash":"anonymous|towards_image_understanding_from_deep_compression_without_decoding","_bibtex":"@article{\n  anonymous2018towards,\n  title={Towards Image Understanding from Deep Compression Without Decoding},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkXWCMbRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1036/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222543768,"tcdate":1511646101577,"number":1,"cdate":1511646101577,"id":"r1A9XDwgG","invitation":"ICLR.cc/2018/Conference/-/Paper1036/Official_Review","forum":"HkXWCMbRW","replyto":"HkXWCMbRW","signatures":["ICLR.cc/2018/Conference/Paper1036/AnonReviewer2"],"readers":["everyone"],"content":{"title":"obvious but welcomed application for neural-net based image compression","rating":"9: Top 15% of accepted papers, strong accept","review":"Neural-net based image compression is a field which is about to get hot, and this paper asks the obvious question: can we design a neural-net based image compression algorithm such that the features it produces are useful for classification & segmentation?\n\nThe fact that it's an obvious question does not mean that it's a question that's worthless. In fact, I am glad someone asked this question and tried to answer it. \n\nPros:\n- Clear presentation, easy to follow.\n- Very interesting, but obvious, question is explored. \n- The paper is very clear, and uses building blocks which have been analyzed before, which leaves the authors free to explore their interactions rather than each individual building block's property.\n- Results are shown on two tasks (classification / segmentation) rather than just one (the obvious one would have been to only discuss results on classification), and relatively intuitive results are shown (i.e., more bits = better performance). What is perhaps not obvious is how much impact does doubling the bandwidth have (i.e., initially it means more, then later on it plateaus, but much earlier than expected).\n- Joint training of compression + other tasks. As far as I know this is the first paper to talk about this particular scenario.\n- I like the fact that classical codecs were not completely discarded (there's a comparison with JPEG 2K).\n- The discussion section is of particular interest, discussing openly the pros/cons of the method (I wish more papers would be as straightforward as this one).\n\nCons:\n- I would have liked to have a discussion on the effect of the encoder network. Only one architecture/variant was used.\n- For PSNR, SSIM and MS-SSIM I would like a bit more clarity whether these were done channel-wise, or on the grayscale channel.\n- While runtime is given as pro, it would be nice for those not familiar with the methods to provide some runtime numbers (i.e., breakdown how much time does it take to encode and how much time does it take to classify or segment, but in seconds, not flops). For example, Figure 6 could be augmented with actual runtime in seconds.\n- I wish the authors did a ctrl+F for \"??\" and fixed all the occurrences.\n- One of the things that would be cool to add later on but I wished to have beeyn covered is whether it's possible to learn not only to compress, but also downscale. In particular, the input to ResNet et al for classification is fixed sized, so the question is -- would it be possible to produced a compact representation to be used for classification given arbitrary image resolutions, and if yes, would it have any benefit?\n\nGeneral comments:\n- The classification bits are all open source, which is very good. However, there are very few neural net compression methods which are open sourced. Would you be inclined to open source the code for your implementation? It would be a great service to the community if yes (and I realize that it could already be open sourced -- feel free to not answer if it may lead to break anonymity, but please take this into consideration).\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Towards Image Understanding from Deep Compression Without Decoding","abstract":"Motivated by recent work on deep neural network (DNN)-based image compression methods showing potential improvements in image quality, savings in storage, and bandwidth reduction, we propose to perform image understanding tasks such as classification and segmentation directly on the compression representations produced by these compression methods. Since the encoders and decoders in DNN-based compression methods are neural networks with feature-maps as internal representations of the images, we directly integrate these with architectures for image understanding. This bypasses decoding of the compressed representation into RGB space and reduces computational cost. Our study shows that performance comparable to networks that operate on compressed RGB images can be achieved. Furthermore, we show that synergies are obtained by jointly training compression networks with classification networks on the compressed representations, improving image quality, classification accuracy, and segmentation performance. We find that inference from compressed representations is particularly advantageous compared to inference from compressed RGB images at high compression rates.","pdf":"/pdf/ab1882c18d655b75d232dd208c49aa09b3ccb4ac.pdf","paperhash":"anonymous|towards_image_understanding_from_deep_compression_without_decoding","_bibtex":"@article{\n  anonymous2018towards,\n  title={Towards Image Understanding from Deep Compression Without Decoding},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkXWCMbRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1036/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510092381952,"tcdate":1509137918368,"number":1036,"cdate":1510092360514,"id":"HkXWCMbRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkXWCMbRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Towards Image Understanding from Deep Compression Without Decoding","abstract":"Motivated by recent work on deep neural network (DNN)-based image compression methods showing potential improvements in image quality, savings in storage, and bandwidth reduction, we propose to perform image understanding tasks such as classification and segmentation directly on the compression representations produced by these compression methods. Since the encoders and decoders in DNN-based compression methods are neural networks with feature-maps as internal representations of the images, we directly integrate these with architectures for image understanding. This bypasses decoding of the compressed representation into RGB space and reduces computational cost. Our study shows that performance comparable to networks that operate on compressed RGB images can be achieved. Furthermore, we show that synergies are obtained by jointly training compression networks with classification networks on the compressed representations, improving image quality, classification accuracy, and segmentation performance. We find that inference from compressed representations is particularly advantageous compared to inference from compressed RGB images at high compression rates.","pdf":"/pdf/ab1882c18d655b75d232dd208c49aa09b3ccb4ac.pdf","paperhash":"anonymous|towards_image_understanding_from_deep_compression_without_decoding","_bibtex":"@article{\n  anonymous2018towards,\n  title={Towards Image Understanding from Deep Compression Without Decoding},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkXWCMbRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1036/Authors"],"keywords":[]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}