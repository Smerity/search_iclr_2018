{"notes":[{"tddate":null,"ddate":null,"tmdate":1515479405458,"tcdate":1515479405458,"number":6,"cdate":1515479405458,"id":"BJBuWyf4z","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"r1IP74-Ez","signatures":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer1"],"content":{"title":"Reviewer response","comment":"Ah, thank you.  The figure caption is a bit confusing since you describe it as a \"preference\" rather than saying that you compare to a reference accent (as you do in the first par. of Section 5.2), but I think you have answered the question."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515434917504,"tcdate":1515434845736,"number":5,"cdate":1515434845736,"id":"r1IP74-Ez","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"B1LlRgbVM","signatures":["ICLR.cc/2018/Conference/Paper1095/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/Authors"],"content":{"title":"Human ratings of accent preference","comment":"Thanks for getting back to us. If you would look at Figure 4, the presented graph is the weighted preference (plotted to show the difference between models explicitly). We describe what exactly has been plotted in  the graph in section 5.2 (the last paragraph being most relevant). We decided not to report the actual values for space considerations, and hoped the representation would help us to get the point across better. We apologise for the confusion this might have caused. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515422810304,"tcdate":1515421166140,"number":4,"cdate":1515421166140,"id":"B1LlRgbVM","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"SkuDwwaQf","signatures":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer1"],"content":{"title":"Human ratings of closeness of accent","comment":"Thanks for responding to the review.  I did spot in the original paper \"they were also asked to mark on a numeric scale which of the two samples they thought was closer to the accent in the reference samples,\" but I could not find these result in the original paper nor in the revised version. Again, apologies if I am just missing these."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515186015746,"tcdate":1515186015746,"number":3,"cdate":1515186015746,"id":"SkuDwwaQf","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"rJfNnSxez","signatures":["ICLR.cc/2018/Conference/Paper1095/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/Authors"],"content":{"title":"Human evaluation and Critic based evaluation is used keeping in mind the uniqueness of the problem being tackled","comment":"We thank the reviewer for all the valuable inputs. \n\nMotivation: The reviewer’s point about motivating the problem of generated accented speech further is well received and we thank the reviewer for pointing us to some relevant references. The revised version now contains a more detailed motivation.\n\nAccent-invariant representations for recognition: Our proposed approach could indeed be used to generate representations that can be incorporated within speech recognition systems for accented speech. This is a direction we intend to explore as future work and we consider this to be outside the scope of the current work.\n\nHuman judgment of whether the generated audio matched the desired accent: We did actually conduct such a study. Section 4.2.2 describes the setup of our human evaluation study where we asked participants to listen to reference samples corresponding to a specific accent and then rate on a numeric scale how close a generated sample was to the accent in the reference sample. \n\nEffect of not adding structure to the latent representation: This is discussed in Table 2 which shows Wasserstein distances from an independent critic on different ablations of AccentGAN. PolicyGAN is identical to AccentGAN except there is no conditioning of the latent variables. We observe that PolicyGAN performs poorly in comparison to AccentGAN.\n\nThe remaining comments on improving clarity will be addressed in the revised version.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515186215870,"tcdate":1515185915280,"number":2,"cdate":1515185915280,"id":"H1m-DPpmf","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"rkKtPpFxz","signatures":["ICLR.cc/2018/Conference/Paper1095/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/Authors"],"content":{"title":"Independent Wasserstein Critics measure the distance between distributions well","comment":"The reviewer has made several objections. We agree to the extent that the exposition could have been improved. We would like to answer the other concerns below.\n\nNeed for policy gradients: As we detailed in an answer to the first reviewer, simple back-propagation as the reviewer suggests demonstrably fails. Using policy gradients overcame the drawbacks of directly using back-propagation, without introducing significant computational overheads. While we had carried out extensive experimentation on this aspect, we omitted it entirely in our submission. We shall incorporate this in the revised version.\n\nUse of an independent Wasserstein critic to compare across models: We do not agree with the reviewer’s contention that using an independent Wasserstein critic to compare across models is unjustified. Not only is it a natural approach, but also one of the main uses detailed in  Danihelka et al. To quote from the paper: “If we use the independent critic, we can compare generators trained by other GAN methods or by different approaches.”\n\nTable 2 Comparisons:  The GAN models from the literature we compare with did not provide a means to incorporate accent information during training. Nevertheless, they were trained on data from a mix of accents identical to that in the validation/test data. So the additional data that our models were given corresponds to less than 5 bits per utterance, and this was essential for a harder task (of being able to generate speech in given accents) that is not captured in Table 2.\n\nWe have tried to improve the presentation by removing some mysterious sounding phrasings (that resulted from using the vocabulary from our internal discussions). We apologize for any confusion they may have caused.\n\nWe urge the reviewer to kindly reconsider their impression of the paper in light of our response.\n\nThe remaining comments on improving clarity have been addressed in the revised version.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515186254698,"tcdate":1515185792211,"number":1,"cdate":1515185792211,"id":"HJdYIP6Qz","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Comment","forum":"rJ6iJmWCW","replyto":"SkxuGmyZG","signatures":["ICLR.cc/2018/Conference/Paper1095/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper1095/Authors"],"content":{"title":"Policy Gradients are efficient and robust during training, in comparison to standard backprop","comment":"We thank the reviewer for the valuable suggestions. \n\nUsefulness of policy gradients for continuous variables: \n\nWe thank the reviewer for raising this question, as we should have included a discussion regarding this in the paper. (Indeed, given this question from two reviewers, a contribution of our work could be seen as showcasing the relevance of policy gradients even when the variables involved are continuous.)\n\nIn the early stages of our project, we did experiment with plain back-propagation, as the reviewer suggested. But we observed that the resulting generated samples were of very poor quality. (We have uploaded a few samples from such a model at http://ec2-13-126-31-173.ap-south-1.compute.amazonaws.com:5000/ alongside samples generated by our proposed approach.) Hence we clearly needed techniques beyond plain back-propagation. Policy gradients appealed to us as we could readily adopt it to our setting, and immediately it gave us improvements over the original approach (with high quality utterances up to 12s long). Further, it did not add any significant computational overhead.\n\nWe have added this discussion in the revised version.\n\nWe do not deny the possibility that other recent approaches developed for similar purposes could also be adopted to our task, but the goal of this work has been to report the very significant improvements we achieved by adopting policy gradients. \n\n\nComments on clarity: These have all been addressed in the revised version.\n\nComments on evaluation: Conditioning on text and synthesizing accented speech is indeed part of our future work. Given the additional technical challenges involved, we have considered this to be outside the scope of the current work. \n\nThe remaining comments on improving clarity have been addressed in the revised version."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515642382890,"tcdate":1512153704055,"number":3,"cdate":1512153704055,"id":"SkxuGmyZG","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Review","forum":"rJ6iJmWCW","replyto":"rJ6iJmWCW","signatures":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Policy gradients are not needed for continuous latent variables","rating":"4: Ok but not good enough - rejection","review":"The paper considers speech generation conditioned on an accent class.\nLeast Squares GAN and a reconstruction loss is used to train the network.\n\nThe network is using continuous latent variables. These variables are trained by policy gradients.\nI do not see a reason for the policy gradients. It would be possible to use the cleaner gradient from the discriminator.\nThe decoder is already trained with gradient from the discriminator.\nIf you are worried about truncated backpropagation through time,\nyou can bias it by \"Unbiasing Truncated Backpropagation Through Time\" by Corentin Tallec and Yann Ollivier.\n\n\nComments on clarity:\n- It would be helpful to add x, z, y, o labels to the Figure 1.\nI understood the meaning of `o` only from Algorithm 1.\n- It was not clear from the text what is called the \"embedding variable\". Is it `z`?\n- It is not clear how the skip connections connect the encoder and the decoder.\nAre the skip connections not used when generating?\n- In Algorithm 1, \\hat{y}_k is based on z_k, instead of \\hat{z}_k. That seems to be a typo.\n\nComments on evaluation:\n- It is hard to evaluate speech conditioned just on the accent class.\nOverfitting may be unnoticed.\nYou should do an evaluation on a validation set.\nFor example, you can condition on a text and generate samples\nfor text sentences from a validation set.\nPeople can then judge the quality of the speech synthesis.\nA good speech synthesis would be very useful.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515642382927,"tcdate":1511802753080,"number":2,"cdate":1511802753080,"id":"rkKtPpFxz","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Review","forum":"rJ6iJmWCW","replyto":"rJ6iJmWCW","signatures":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The paper lacks any novel technical insight, contributions are not explained well, exposition is poor, and the evaluations are invalid.","rating":"3: Clear rejection","review":"The contributions made by this paper is unclear. As one of the listed contributions, the authors propose using policy gradient. However, in this setting, the reward is a known differentiable function, and the action is continuous, and thus one could simply backpropagate through to get the gradients on the encoder. Also, it seems the reward is not a function of the future actions, which further questions the need for a reinforcement learning formulation.\n\nThe paper is written poorly. For instance, I don't understand what this sentence means: \"We condition the latent variables to come from rich distributions\". Observed accent labels are referred to as latent (hidden) variables.\n\nWhile the independent Wasserstein critic is useful to study whether models are overfitting (by comparing train/heldout numbers), their use for comparing across different model types is not justified. Moreover, since GAN-based methods optimize the Wasserstein distance directly, it cannot serve as a metric to compare GAN-based models with other models.\n\nAll of the models compared against do not use accent information during training (table 2), so this is not a fair comparison.\n\nOverall, the paper lacks any novel technical insight, contributions are not explained well, exposition is poor, and the evaluations are invalid.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515642382964,"tcdate":1511181353947,"number":1,"cdate":1511181353947,"id":"rJfNnSxez","invitation":"ICLR.cc/2018/Conference/-/Paper1095/Official_Review","forum":"rJ6iJmWCW","replyto":"rJ6iJmWCW","signatures":["ICLR.cc/2018/Conference/Paper1095/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Relevant work, but not executed or presented well","rating":"5: Marginally below acceptance threshold","review":"This paper presents a method for generating speech audio in a particular accent. The proposed approach relies on a generative adversarial network (GAN), combined with a policy approach for joining together generated speech segments. The latter is used to deal with the problem of generating very long sequences (which is generally difficult with GANs).\n\nThe problem of generating accented speech is very relevant since accent plays a large role in human communication and speech technology. Unfortunately, this paper is hard to follow. Some of the approach details are unclear and the research is not motivated well. The evaluation does not completely support the claims of the paper, e.g., there is no human judgment of whether the generated audio actually matches the desired accent.\n\nDetailed comments, suggestions, and questions:\n- It would be very useful to situate the research within work from the speech community. Why is accented modelling important? How is this done at the moment in speech synthesis systems? The paper gives some references, but without context. The paper from Ikeno and Hansen below might be useful.\n- Accents are also a big problem in speech recognition (references below). Could your approach give accent-invariant representations for recognition?\n- Figure 1: Add $x$, $y$, and the other variables you mention in Section 3 to the figure.\n- What is $o$ in eq. (1)?\n- Could you add a citation for eq. (2)? This would also help justifying that \"it has a smoother curve and hence allows for more meaningful gradients\".\n- With respect to the critic $C_\\nu$, I can see that it might be helpful to add structure to the hidden representation. In the evaluation, could you show the effect of having/not having this critic (sorry if I missed it)? The statement about \"more efficient layers\" is not clear.\n- Section 3.4: If I understand correctly, this is a nice idea for ensuring that generated segments are combined sensibly. It would be helpful defining with \"segments\" refer to, and stepping through the audio generation process.\n- Section 4.1: \"using which we can\" - typo.\n- Section 5.1: \"Figure 1 shows how the Wasserstein distance ...\" I think you refer to the figure with Table 1?\n- Figure 4: Add (a), (b) and (c) to the relevant parts in the figure.\n\nReferences that might be useful:\n- Ikeno, Ayako, and John HL Hansen. \"The effect of listener accent background on accent perception and comprehension.\" EURASIP Journal on Audio, Speech, and Music Processing 2007, no. 3 (2007): 4.\n- Van Compernolle, Dirk. \"Recognizing speech of goats, wolves, sheep and… non-natives.\" Speech Communication 35, no. 1 (2001): 71-79.\n- Benzeghiba, Mohamed, Renato De Mori, Olivier Deroo, Stephane Dupont, Teodora Erbes, Denis Jouvet, Luciano Fissore et al. \"Automatic speech recognition and speech variability: A review.\" Speech communication 49, no. 10 (2007): 763-786.\n- Wester, Mirjam, Cassia Valentini-Botinhao, and Gustav Eje Henter. \"Are We Using Enough Listeners? No!—An Empirically-Supported Critique of Interspeech 2014 TTS Evaluations.\" In Sixteenth Annual Conference of the International Speech Communication Association. 2015.\n\nThe paper tries to address an important problem, and there are good ideas in the approach (I suspect Sections 3.3 and 3.4 are sensible). Unfortunately, the work is not presented or evaluated well, and I therefore give a week reject.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]}},{"tddate":null,"ddate":null,"tmdate":1515186394332,"tcdate":1509138342946,"number":1095,"cdate":1510092360083,"id":"rJ6iJmWCW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rJ6iJmWCW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION","abstract":"In this paper, we propose the generation of accented speech using generative adversarial\nnetworks. Through this work we make two main contributions a) The\nability to condition latent representations while generating realistic speech samples\nb) The ability to efficiently generate long speech samples by using a novel\nlatent variable transformation module that is trained using policy gradients. Previous\nmethods are limited in being able to generate only relatively short samples\nor are not very efficient at generating long samples. The generated speech samples\nare validated through a number of various evaluation measures viz, a WGAN\ncritic loss and through subjective scores on user evaluations against competitive\nspeech synthesis baselines and detailed ablation analysis of the proposed model.\nThe evaluations demonstrate that the model generates realistic long speech samples\nconditioned on accent efficiently.","pdf":"/pdf/42b2803ce78dc167a45e73cbb6d1a1e2fd7384e1.pdf","paperhash":"anonymous|policy_driven_generative_adversarial_networks_for_accented_speech_generation","_bibtex":"@article{\n  anonymous2018policy,\n  title={POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJ6iJmWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1095/Authors"],"keywords":["speech","generation","accent","gan","adversarial","reinforcement","memory","lstm","policy","gradients","human"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}