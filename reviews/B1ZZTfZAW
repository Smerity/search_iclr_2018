{"notes":[{"tddate":null,"ddate":null,"tmdate":1512398788711,"tcdate":1512398788711,"number":3,"cdate":1512398788711,"id":"Hk6aJkmWM","invitation":"ICLR.cc/2018/Conference/-/Paper991/Official_Review","forum":"B1ZZTfZAW","replyto":"B1ZZTfZAW","signatures":["ICLR.cc/2018/Conference/Paper991/AnonReviewer3"],"readers":["everyone"],"content":{"title":"an interesting approach and generates time series sequences, however the medical use case needs work.","rating":"5: Marginally below acceptance threshold","review":"This paper proposes to use RGANs and RCGANS to generate synthetic sequences of actual data. They demonstrate the quality of the sequences on sine waves, MNIST, and ICU telemetry data.\n\nThe authors demonstrate novel approaches for generating real-valued sequences using adversarial training, a train on synthetic, test of real and vice versa method for evaluating GANS, generating synthetic medical time series data, and an empirical privacy analysis. \n\nMajor\n- the medical use case is not motivating. de-identifying the 4 telemetry measures is extremely easy and there is little evidence to show that it is even possible to reidentify individuals using these 4 measures. our institutional review board would certainly allow self-certification of the data (i.e. removing the patient identifiers and publishing the first 4 hours of sequences).\n- the labels selected by the authors for the icu example are to forecast the next 15 minutes and whether a critical value is reached. Please add information about how this critical value was generated. Also it would be very useful to say that a physician was consulted and that the critical values were \"clinically\" useful.\n- the changes in performance of TSTR are large enough that I would have difficulty trusting any experiments using the synthetic data. If I optimized a method using this synthetic data, I would still need to assess the result on real data.\n- In addition it is unclear whether this synthetic process would actually generate results that are clinically useful. The authors certainly make a convincing statement about the internal validity of the method. An externally valid measure would strengthen the results. I'm not quite sure how the authors could externally validate the synthetic data as this would also require generating synthetic outcome measures. I think it would be possible for the synthetic sequence to also generate an outcome measure (i.e. death) based on the first 4 hours of stay.\n\nMinor\n- write in the description for table 1 what task the accuracies correspond.\n\nSummary\nThe authors present methods for generating synthetic sequences. The MNIST example is compelling. However the ICU example has some pitfalls which need to be addressed.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs","abstract":"Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.","pdf":"/pdf/a6406e34205961f2f85966b096fada789313aa89.pdf","TL;DR":"Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.","paperhash":"anonymous|realvalued_medical_time_series_generation_with_recurrent_conditional_gans","_bibtex":"@article{\n  anonymous2018real-valued,\n  title={Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1ZZTfZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper991/Authors"],"keywords":["GAN","medical","records","time","series","generation","privacy"]}},{"tddate":null,"ddate":null,"tmdate":1512222834889,"tcdate":1511757460377,"number":2,"cdate":1511757460377,"id":"SyhqIGYxG","invitation":"ICLR.cc/2018/Conference/-/Paper991/Official_Review","forum":"B1ZZTfZAW","replyto":"B1ZZTfZAW","signatures":["ICLR.cc/2018/Conference/Paper991/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This paper is a good extension of GANs and generative RNNs to the continuous domain time series setting","rating":"6: Marginally above acceptance threshold","review":"In this paper, the authors propose a recurrent GAN architecture that generates continuous domain sequences. To accomplish this, they use a generator LSTM that takes in a sequence of random noise as well as a sequence of conditonal information and outputs a sequence. The discriminator LSTM takes a sequence (and conditional information) as input and classifies each element of the sequence as real or synthetic -- the entire sequence is then classified by vote. The authors evaluate on several synthetic tasks, as well as an ICU timeseries data task.\n\nOverall, I thought the paper was clearly written and extremely easy to follow. To the best of my knowledge, the method proposed by the authors is novel, and differs from traditional sentence generation (as an example) models because it is intended to produce continuous domain outputs. Furthermore, the story of generating medical training data for public release is an interesting use case for a model like this, particularly since training on synthetic data appears to achieve not competitive but quite reasonable accuracy, even when the model is trained in a differentially private fashion.\n\nMy most important piece of feedback is that I think it would be useful to include a few examples of the eICU time series data, both real and synthetic. This might give a better sense of: (1) how difficult the task is, (2) how much variation there is in the real data from patient to patient, and (3) how much variation we see in the synthetic time series. Are the synthetic time series clearly multimodal, or do they display some of the mode collapse behavior occasionally seen in GANs?\n\nI would additionally like to see a few examples of the time series data at both the 5 minute granularity and the 15 minute granularity. You claim that downsampling the data to 15 minute time steps still captures the relevant dynamics of the data -- is it obvious from the data that variations in the measured variables are not significant over a 5 minute interval? As it stands, this is somewhat an unknown, and should be easy enough to demonstrate.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs","abstract":"Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.","pdf":"/pdf/a6406e34205961f2f85966b096fada789313aa89.pdf","TL;DR":"Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.","paperhash":"anonymous|realvalued_medical_time_series_generation_with_recurrent_conditional_gans","_bibtex":"@article{\n  anonymous2018real-valued,\n  title={Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1ZZTfZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper991/Authors"],"keywords":["GAN","medical","records","time","series","generation","privacy"]}},{"tddate":null,"ddate":null,"tmdate":1512222834933,"tcdate":1511735730547,"number":1,"cdate":1511735730547,"id":"H1q2baOxM","invitation":"ICLR.cc/2018/Conference/-/Paper991/Official_Review","forum":"B1ZZTfZAW","replyto":"B1ZZTfZAW","signatures":["ICLR.cc/2018/Conference/Paper991/AnonReviewer1"],"readers":["everyone"],"content":{"title":"interesting application but no clear takeaways","rating":"4: Ok but not good enough - rejection","review":"The authors propose to use synthetic data generated by GANs as a replacement for personally identifiable data in training ML models for privacy-sensitive applications such as medicine. In particular it demonstrates adversarial training of a recurrent generator for an ICU monitoring multidimensional time series, proposes to evaluate such models by the performance (on real data) of supervised classifiers trained on the synthetic data (\"TSTR\"), and empirically analyzes the privacy implications of training and using such a model. \n\nThis paper touches on many interesting issues -- deep/recurrent models of time series, privacy-respecting ML, adaptation from simulated to real-world domains. But it is somewhat unfocused and does not seem make a clear contribution to any of these. \n\nThe recurrent GAN architecture does not appear particularly novel --- the authors note that similar architectures have been used for discrete tasks such language modeling (and fail to note work that uses convolutional or recurrent generators for video prediction, a more relevant continuous task, see e.g.  http://carlvondrick.com/tinyvideo/, or autoregressive approaches to deep models of time series, e.g. WaveNet https://arxiv.org/abs/1609.03499) and there is no obvious new architectural innovation. \n\nI also find it difficult to assess whether the proposed model is actually generating reasonable time series. It may be true that \"one plot showing synthetic ICU data would not provide enough information to evaluate its actual similarity to the real data\" because it could not rule out that case that the model has captured the marginal distribution in each dimension but not joint structure. However producing marginal distributions that look reasonable is at least a *necessary* condition and without seeing those plots it is hard to rule out that the model may be producing highly unrealistic samples. \n\nThe basic privacy paradigm proposed seems to be:\n1. train a GAN using private data\n2. generate new synthetic data, assume this data does not leak private information\n3. train a supervised classifier on the private data\nso that the GAN training-sampling loop basically functions as an anonymization procedure. For this to pan out, we'd need to see that the GAN samples are a) useful for a range of supervised tasks, and b) do not leak private information. But the results  in Table 2 show that the TSTR results are quite a lot worse than real data in most cases, and it's not obvious that the small set of tasks evaluated are representative of all tasks people might care about. The attempts to demonstrate empirically that the GAN does not memorize training data aren't particularly convincing; this is an adversarial setting so the fact that a *particular* test doesn't reveal private data doesn't imply that a determined attacker wouldn't succeed. In this vein, the experiments with DP-\u000fSGD are more interesting, although a more direct comparison would be helpful (it is frustrating to flip back and forth between Tables 2 and 3 in an attempt to tease out relative performance) and and it is not clear how the settings (ε \u000f\u000f\u000f= 0.5 and δ ≤ 9.8 × 10−3) were selected or whether they provide a useful level of privacy. That said I agree this is an interesting avenue for future work.\n\nFinally it's worth noting that discarding patients with missing data is unlikely to be innocuous for ICU applications; data are quite often not missing at random (e.g., a patient going into a seizure may dislocate a sensor). It appears that the analysis in this paper threw out more than 90% of the patients in their original dataset, which would present serious concerns in using the resulting synthetic data to represent the population at large. One could imagine coding missing data in various ways (e.g. asking the generator to produce a missingness pattern as well as a time series and allowing the discriminator to access only the masked time series, or explicitly building a latent variable model) and some sort of principled approach to missing data seems crucial for meaningful results on this application. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs","abstract":"Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.","pdf":"/pdf/a6406e34205961f2f85966b096fada789313aa89.pdf","TL;DR":"Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.","paperhash":"anonymous|realvalued_medical_time_series_generation_with_recurrent_conditional_gans","_bibtex":"@article{\n  anonymous2018real-valued,\n  title={Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1ZZTfZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper991/Authors"],"keywords":["GAN","medical","records","time","series","generation","privacy"]}},{"tddate":null,"ddate":null,"tmdate":1510092382843,"tcdate":1509137663527,"number":991,"cdate":1510092360872,"id":"B1ZZTfZAW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1ZZTfZAW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs","abstract":"Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.","pdf":"/pdf/a6406e34205961f2f85966b096fada789313aa89.pdf","TL;DR":"Conditional recurrent GANs for real-valued medical sequences generation, showing novel evaluation approaches and an empirical privacy analysis.","paperhash":"anonymous|realvalued_medical_time_series_generation_with_recurrent_conditional_gans","_bibtex":"@article{\n  anonymous2018real-valued,\n  title={Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1ZZTfZAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper991/Authors"],"keywords":["GAN","medical","records","time","series","generation","privacy"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}