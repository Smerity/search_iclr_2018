{"notes":[{"tddate":null,"ddate":null,"tmdate":1512453811594,"tcdate":1512453569176,"number":3,"cdate":1512453569176,"id":"rJtar37Zf","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Comment","forum":"BJIgi_eCZ","replyto":"S1UrbZQ-f","signatures":["ICLR.cc/2018/Conference/Paper317/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper317/Authors"],"content":{"title":"Review Rebuttal for Reviewer2","comment":"Thank you for your review!\n\n1. We understand that from our Table 2, it seems FusionNet only improve the best-published model (R-net) by EM 0.3 (single model). We apologize for not writing this part clear. If you look into the ACL2017 paper of R-net [1] or the recent technical report (http://aka.ms/rnet), you will find that the best-published version of R-net only achieves EM: 72.3, F1: 80.6, while FusionNet has EM: 76.0, F1: 83.9. The improvement is near 4% in EM. It is because the authors of R-net has been designing new models without publishing it while using the same model name (R-net) on SQuAD leaderboard. At the time of ICLR2018 submission, the best-published model is Reinforced Mnemonic Reader [2] (https://arxiv.org/pdf/1705.02798.pdf), which achieved EM: 73.2, F1: 81.8, 1% higher than published version of R-net. Reinforced Mnemonic Reader proposed feature-rich encoder, semantic fusion unit, iterative interactive-aligning self-aligning, multihop memory-based answer pointer, and a reinforcement learning technique to achieve their high performance. On the other hand, utilizing our simple \"HoW\" attention mechanism, FusionNet obtained a decent performance (EM: 76.0, F1: 83.9) on original SQuAD with a relatively simplistic model. For example, in Table 6, by changing S(h_i^C, h_j^Q) to S(HoW_i^C, HoW_j^Q) in a vanilla model (encoder + single-level attention), we observed +8% improvement and achieved EM: 73.3, F1: 81.4 on the dev set.\n\n2. In our paper, we only compare with the official results on adversarial dataset shown in this year EMNLP paper [3]. But there is an additional Codalab worksheet maintained by the author (Robin Jia) to test more recent higher performing models.\nhttps://worksheets.codalab.org/worksheets/0x77ca15a1fc684303b6a8292ed2167fa9/\nIn this worksheet, Robin Jia has compared with another state-of-the-art model DCN+, which is also submitted to ICLR2018. On the AddSent dataset, DCN+ achieved F1: 44.5, and on the AddOneSent dataset, DCN+ achieved F1: 54.3. The results are comparable to the previous state-of-the-art on the adversarial datasets. But FusionNet is +6% higher than DCN+ on both datasets. We attribute this significant gain to the proposed HoW attention, which can very easily incorporate into other models. We are excited to share this simple idea with the community to improve machines in better understanding texts.\n\n3. SQuAD is a very competitive dataset, so it is unlikely that the significant gain we have (+3% over best-documented models, +5% in adversarial datasets) comes from giving the model more parameters. Furthermore, existing models can always incorporate more parameters if it helps. For example, in the high-performing Reinforced Mnemonic Reader, they can increase the number of iterations in iterative aligning or increase the hidden size in LSTM. Additionally, in our Table 6, we have compared FA All-level and FA Multi-level. FA All-level uses the same attention weight for different levels and fuses all level of representation (including input vector). FA All-level has more parameters than FA Multi-level but performs 2% worse. Based on Reviewer3's comment, we will also include visualization to show that multi-level attention will learn to attend to \"different regions for different levels.\"\n\nReferences:\n[1] Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou. \"Gated self-matching networks for reading comprehension and question answering.\" ACL (2017).\n[2] Minghao Hu, Yuxing Peng, and Xipeng Qiu. \"Reinforced Mnemonic Reader for Machine Comprehension.\" arXiv preprint arXiv:1705.02798 (2017).\n[3] Robin Jia, and Percy Liang. \"Adversarial examples for evaluating reading comprehension systems.\" EMNLP (2017)."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512414782609,"tcdate":1512411617859,"number":4,"cdate":1512411617859,"id":"rkqkzzm-G","invitation":"ICLR.cc/2018/Conference/-/Paper317/Public_Comment","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Ablation without CoVE? SotA through better word embeddings? ","comment":"Hi, most models this paper compares to are trained with GloVe embeddings but you only show results with CoVe (if I am not mistaken). I feel like this model is only able to achieve SotA because it uses CoVe and not because of the additional extensions.  Is this correct? Do you have an ablation for that?"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512408444109,"tcdate":1512407358455,"number":3,"cdate":1512407358455,"id":"S1UrbZQ-f","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Review","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["ICLR.cc/2018/Conference/Paper317/AnonReviewer2"],"readers":["everyone"],"content":{"title":"An Ok paper, but needs more contribution","rating":"4: Ok but not good enough - rejection","review":"The authors present an enhancement to the attention mechanism called \"multi-level fusion\" that they then incorporate into a reading comprehension system. It basically takes into account a richer context of the word at different levels in the neural net to compute various attention scores.\n\ni.e. the authors form a vector \"HoW\" (called history of the word), that is defined as a concatenation of several vectors:\n\nHoW_i = [g_i, c_i, h_i^l, h_i^h]\n\nwhere g_i = glove embeddings, c_i = COVE embeddings (McCann et al. 2017), and h_i^l and h_i^h are different LSTM states for that word.\n\nThe attention score is then a function of these concatenated vectors i.e. \\alpha_{ij} = \\exp(S(HoW_i^C, HoW_j^Q))\n\nResults on SQuAD show a small gain in accuracy (75.7->76.0 Exact Match). The gains on the adversarial set are larger but that is because some of the higher performing, more recent baselines don't seem to have adversarial numbers.\n\nThe authors also compare various attention functions (Table 5) showing a particularone (Symmetric + ReLU) works the best. \n\nComments:\n\n-I feel overall the contribution is not very novel.  The general neural architecture that the authors propose in Section 3 is generally quite similar to the large number of neural architectures developed for this dataset (e.g. some combination of attention between question/context and LSTMs over question/context). The only novelty is these \"HoW\" inputs to the extra attention mechanism that takes a richer word representation into account.\n\n-I feel the model is seems overly complicated for the small gain (i.e. 75.7->76.0 Exact Match), especially on a relatively exhausted dataset (SQuAD) that is known to have lots of pecularities (see anonymous comment below). It is possible the gains just come from having more parameters.\n\n-The authors (on page 6) claim that that by running attention multiple times with different parameters but different inputs (i.e. \\alpha_{ij}^l, \\alpha_{ij}^h, \\alpha_{ij}^u) it will learn to attend to \"different regions for different level\". However, there is nothing enforcing this and the gains just probably come from having more parameters/complexity.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512341250548,"tcdate":1512336119759,"number":3,"cdate":1512336119759,"id":"HkeZo1MZG","invitation":"ICLR.cc/2018/Conference/-/Paper317/Public_Comment","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Only SQuAD Evaluation!?","comment":"I noticed that you only evaluate against SQuAD which is known to be a bad dataset for evaluating machine comprehension. It has only short documents and most of the answers are easily extractable. This is a bit troubling especially given that there are plenty of good and much more complex datasets out there, e.g., TriviaQA, NewsQA, just to mention a few. It feels like we are totally overfitting on a simple dataset. Would it be possible to also provide results on one of those, otherwise it is really hard to judge whether there is indeed any significant improvement. I think this is a big issue."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222619459,"tcdate":1512195144006,"number":2,"cdate":1512195144006,"id":"SJxIVpkZM","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Review","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["ICLR.cc/2018/Conference/Paper317/AnonReviewer1"],"readers":["everyone"],"content":{"title":"state of the art on SQuAD with FusionNet","rating":"8: Top 50% of accepted papers, clear accept","review":"The primary intellectual point the authors make is that previous networks for machine comprehension are not fully attentive. That is, they do not provide attention on all possible layers on abstraction such as the word-level and the phrase-level. The network proposed here, FusionHet, fixes problem. Importantly, the model achieves state-of-the-art performance of the SQuAD dataset.\n\nThe paper is very well-written and easy to follow. I found the architecture very intuitively laid out, even though this is not my area of expertise. Moreover, I found the figures very helpful -- the authors clearly took a lot of time into clearly depicting their work! What most impressed me, however, was the literature review. Perhaps this is facilitated by the SQuAD leaderboard, which makes it simple to list related work. Nevertheless, I am not used to seeing comparison to as many recent systems as are presented in Table 2. \n\nAll in all, it is difficult not to highly recommend an architecture that achieves state-of-the-art results on such a popular dataset.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222619503,"tcdate":1511651270095,"number":1,"cdate":1511651270095,"id":"r1ApvdPxG","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Review","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["ICLR.cc/2018/Conference/Paper317/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Nice analysis of literature, interesting model and good results, but a little lack of substance","rating":"7: Good paper, accept","review":"The paper first analyzes recent works in machine reading comprehension (largely centered around SQuAD), and mentions their common trait that the attention is not \"fully-aware\" of all levels of abstraction, e.g. word-level, phrase-level, etc. In turn, the paper proposes a model that performs attention at all levels of abstraction, which achieves the state of the art in SQuAD. They also propose an attention mechanism that works better than others (Symmetric + ReLU).\n\nStrengths:\n- The paper is well-written and clear.\n- I really liked Table 1 and Figure 2; it nicely summarizes recent work in the field.\n- The multi-level attention is novel and indeed seems to work, with convincing ablations.\n- Nice engineering achievement, reaching the top of the leaderboard (in early October).\n\n\nWeaknesses:\n- The paper is long (10 pages) but relatively lacks substances. Ideally, I would want to see the visualization of the attention at each level (i.e. how they differ across the levels) and also possibly this model tested on another dataset (e.g. TriviaQA).\n- The authors claim that the symmetric + ReLU is novel, but  I think this is basically equivalent to bilinear attention [1] after fully connected layer with activation, which seems quite standard. Still useful to know that this works better, so would recommend to tone down a bit regarding the paper's contribution.\n\n\nMinor:\n- Probably figure 4 can be drawn better. Not easy to understand nor concrete.\n- Section 3.2 GRU citation should be Cho et al. [2].\n\n\nQuestions:\n- Contextualized embedding seems to give a lot of improvement in other works too. Could you perform ablation without contextualized embedding (CoVe)?\n\n\nReference:\n[1] Luong et al. Effective Approaches to Attention-based Neural Machine Translation. EMNLP 2015.\n[2] Cho et al. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. EMNLP 2014.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1511023037342,"tcdate":1511023037342,"number":2,"cdate":1511023037342,"id":"rJBpWyR1z","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Comment","forum":"BJIgi_eCZ","replyto":"Sy1MCpzJf","signatures":["ICLR.cc/2018/Conference/Paper317/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper317/Authors"],"content":{"title":"Re: Nice.","comment":"Thank you for your compliment!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1511022994760,"tcdate":1511022994760,"number":1,"cdate":1511022994760,"id":"H1sqbJ01G","invitation":"ICLR.cc/2018/Conference/-/Paper317/Official_Comment","forum":"BJIgi_eCZ","replyto":"SJftaCpyM","signatures":["ICLR.cc/2018/Conference/Paper317/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper317/Authors"],"content":{"title":"Training Parameters","comment":"Thank you for being interested in reproducing our work!\n\n- Which components are used without dropout?\nDropout is applied before every linear transform, including the input for each layer of LSTM and Attention. For fast implementation, we do not use hidden state dropout in LSTM. Also, an additional dropout is applied after the GloVe and CoVe embedding layer.\nThe dropout is shared across time step (i.e., variational dropout). And different linear layers use different dropout masks.\n\n- Attention dimensions for the various fusions present.\nFor all the fully-aware attention S(HoW_i, HoW_j), we used an attention dimension k = 250 (the same as the output size of BiLSTM)."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1511022581125,"tcdate":1511021946392,"number":2,"cdate":1511021946392,"id":"SJftaCpyM","invitation":"ICLR.cc/2018/Conference/-/Paper317/Public_Comment","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Reproductive Study - Training Parameters","comment":"I set up a reproduction experiment for which I need a little clarification on the following.\n\n- Which components are used/set up without dropout?\n- Attention dimensions for the various fusions present."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1510297094879,"tcdate":1510297094879,"number":1,"cdate":1510297094879,"id":"Sy1MCpzJf","invitation":"ICLR.cc/2018/Conference/-/Paper317/Public_Comment","forum":"BJIgi_eCZ","replyto":"BJIgi_eCZ","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Nice.","comment":"Nice simple model."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739367437,"tcdate":1509096173704,"number":317,"cdate":1509739364781,"id":"BJIgi_eCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJIgi_eCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension","abstract":"This paper introduces a new neural structure called FusionNet, which extends existing attention approaches from three perspectives. First, it puts forward a novel concept of \"History of Word\" to characterize attention information from the lowest word-level embedding up to the highest semantic-level representation. Second, it introduces an improved attention scoring function that better utilizes the \"History of Word\" concept. Third, it proposes a fully-aware multi-level attention mechanism to capture the complete information in one text (such as a question) and exploit it in its counterpart (such as context or passage) layer by layer. We apply FusionNet to the Stanford Question Answering Dataset (SQuAD) and it achieves the first position for both single and ensemble model on the official SQuAD leaderboard at the time of writing (Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two adversarial SQuAD datasets and it sets up the new state-of-the-art on both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.","pdf":"/pdf/51bdc52c4b39149b4104832f675837dac6fa81b5.pdf","TL;DR":"We propose a light-weight enhancement for attention and a neural architecture, FusionNet, to achieve STOA on SQuAD and adversarial SQuAD.","paperhash":"anonymous|fusionnet_fusing_via_fullyaware_attention_with_application_to_machine_comprehension","_bibtex":"@article{\n  anonymous2018fusionnet:,\n  title={FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJIgi_eCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper317/Authors"],"keywords":["Attention Mechanism","Machine Comprehension","Natural Language Processing","Deep Learning"]},"nonreaders":[],"replyCount":10,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}