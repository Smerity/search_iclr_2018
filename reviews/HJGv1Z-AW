{"notes":[{"tddate":null,"ddate":null,"tmdate":1515084890923,"tcdate":1515084890923,"number":8,"cdate":1515084890923,"id":"S1XPn0jXG","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"HJGv1Z-AW","signatures":["ICLR.cc/2018/Conference/Paper639/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/Authors"],"content":{"title":"Revised manuscript","comment":"We would like to thank all the reviewers for their thoughtful and detailed feedback. We particularly thank them for recognizing that this is an interesting piece of work.\n\nWe have now revised our manuscript to address the concerns raised by the reviewers, hopefully producing a stronger and clearer submission. The most significant changes are:\n\n\t(as asked by AnonReviewer3)\n* We have added statistical tests (permutation test) to support claims regarding the results of the topographic similarity\n* We have added 2 sentences in the abstract and conclusion to make clear our contributions on extending work in the language evolution literature to contemporary DL materials.\n\n\t(as asked by AnonReviewer2)\n* We have added in the Appendix C a new experiment on  communicative success  on the raw pixel data with models operating  on gold attribute classifiers\n* We have added a comment about instability of REINFORCE affecting nature of protocols in same of the experimental setups of Section 4\n\n\t(as asked by AnonReviewer1)\n* We made all the requested clarifications (thanks again for the detailed review)\n* Added Figure 2 to visually illustrate the claims in Section 3.2\n* Added topographic similarity measurements for Section 4 (Table 3) which strengthen the findings of the qualitative analysis of game A producing structurally consistent messages.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515056490686,"tcdate":1515056490686,"number":7,"cdate":1515056490686,"id":"r1QdpPjXf","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"SJWDw1iXG","signatures":["ICLR.cc/2018/Conference/Paper639/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/AnonReviewer1"],"content":{"title":"Thanks for the clarifications","comment":"Thanks for the clarifications, and looking forward to the revised paper."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515022168612,"tcdate":1515022168612,"number":6,"cdate":1515022168612,"id":"SJWDw1iXG","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"H15X_V8yM","signatures":["ICLR.cc/2018/Conference/Paper639/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/Authors"],"content":{"title":"Response to AnonReviewer1","comment":"We would like to thank the reviewer for their review. We found their comments extremely helpful and we are in the process of updating the manuscript accordingly. We will upload the revised paper tomorrow. In the meantime, we respond here to the major comments.\n\n\n<review>\n* CLARITY OF EXPOSITION\n</review>\nWe will introduce the terminology together with the description of the game.\n\n<review>\n* RELATION BETWEEN VOCABULARY SIZE AND PROTOCOL SIZE\n</review>\nWithout any explicit penalty on the length of the messages (Section 2), agents are not motivated to produce shorter messages (despite the fact that as the reviewer points, agents can decide to do so) since this constrains the space of messages (and thus the possibility of the speaker and listener agreeing on a successful naming convention), opting thus to always make use of the maximum possible length. When we introduced a penalty on the length of the message (Section 3), agents produced shorter messages for the ambiguous messages since this strategy maximizes the total expected reward.\n\n\n<review>\n* RELATION BETWEEN CONCEPT-PROPERTY AND RAW-PIXEL STUDIES\n</review>\nThanks for the suggestion. Correlating CNN-based representations with message similarities would not yield any new insight since these representations are the input to the message generation process. However, we ran the analysis on the symbolic representations of the images (location cluster, color, shape, floor color cluster) and the messages and found that the topographic similarities of the games are ordered as follows (in parentheses we report the topographic $\\rho$): game A (0.13) > game C (0.07) > game D (0.06) > game B (0.006).\nThis ordering is in line with our qualitative analysis of the protocols presented in Section 4.1.\n\n<review>\nFigures/Tables for \"Note that the distractor\"paragraph and degenerate strategy.\n</review>\nWe will include in the manuscript the training curves that this paragraph refers to.\nThe degenerate strategy is that of picking a target at random from the topically relevant set of distractors, thus reducing the effective size of distractors.\n\n<review>\n\"random\" setup...\n</review>\nDespite the fact that the weights of the networks are random, since the message generation is a parametric process, similar inputs will tend to generate similar outputs, thus producing messages that retain (at least to some small degree) the structure of the input data, despite the fact that there is no learning at all.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1514849459302,"tcdate":1514849459302,"number":5,"cdate":1514849459302,"id":"ryjhESdQG","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"HJ3-u2Ogf","signatures":["ICLR.cc/2018/Conference/Paper639/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/Authors"],"content":{"title":"Response to AnonReviewer2 (part 2)","comment":"\n<review>\nrandom chance of probe classifiers.\n</review>\nWhen generating the dataset, we sample locations and floor colors from a continuous scale. For the probe classifiers, we quantize location by clustering each coordinate in 5 clusters (and thus accuracy is reported by averaging the performance of the x and y probe classifiers with chance being at 20% for each co-ordinate) and floor colors in 3 clusters (with chance being at 33%). We will include the chance levels in Table 4.\n\n<review>\nWhy not use cross-entropy loss for listener?\n</review>\nWe decided to train both agents via REINFORCE for symmetry. Given the nature of the listener’s choice, we don’t anticipate full supervision to have an effect other than speeding up learning.\n\n\n<review>\nWhat about message length?\n</review>\nWithout any explicit penalty on the length of the messages (Section 2), agents are not motivated to produce shorter messages (despite the fact that as the reviewer points, agents can decide to do so) since this constrains the space of messages (and thus the possibility of the speaker and listener agreeing on a successful naming convention). When we introduced a penalty on the length of the message (Section 3), agents produced shorter messages for the ambiguous messages (since this strategy maximizes the total expected reward).\n\n<review>\nWhy use reinforcement learning over some sort of differentiable sampler?\n</review>\nWhile a differentiable communication channel would make learning faster, it goes against the basic and fundamental principles of human communication (and also against how this phenomenon is studied in language evolution).  Simply put, having a differentiable channel would mean in practice that speakers can back-propagate through listeners’ brains (which unfortunately is not the case in real life :)) We wanted to stay as close as possible to this communication paradigm, thus using a discrete communication channel."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1514849433689,"tcdate":1514849433689,"number":4,"cdate":1514849433689,"id":"S1GjVrOmz","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"HJ3-u2Ogf","signatures":["ICLR.cc/2018/Conference/Paper639/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/Authors"],"content":{"title":"Response to AnonReviewer2 (part 1)","comment":"We thank the reviewer for their thorough review. We respond to the comments raised while we are in the process of making the necessary changes in the manuscript.\n\n<review>\nHow stable are results?\n</review>\nOverall, results with REINFORCE in these non-stationary multi-agent environments (where speakers and listeners are learning at the same time) show instability, and -- as expected -- some of the experimental runs did not converge. However, we believe that the stability of the nature of the protocol (rather than its existence) is mostly influenced by the configuration of the game itself, i.e., how constrained the message space is. As an example, games C & D impose constraints on the nature of the protocol since location encoding location on the messages is not an acceptable solution -- on runs that we had convergence, the protocols would always communicate about color. The same holds for game A (position is a very good strategy since it uniquely identifies objects combined with the environmental pressure of many distractors). However, game B is more unconstrained in nature and the converged protocols were more varied. We will include a discussion of these observations in the updated manuscript.\n\n<review>\nInference time procedure\n</review>\nThe reviewer is correct. At training time we sample, at test time we argmax. We will clarify this.\n\n<review>\nProtocol size vs lexicon\n</review>\nThank you for pointing this out. We will clarify the terminology.\nProtocol size (or lexicon -- we will remove this term and use protocol size only) is the number of invented messages (sequences of symbols).\nIn Table 1, we report the protocol size obtained with argmax on training data.\nIn Table 2, we report the number of novel messages, i.e., messages that were not generated for the training data, on 100 novel objects.\n\n<review>\nGeneralization on raw pixel data -- training and test accuracy are close\n</review>\nThis observation is correct. By randomly creating train and test splits, chances are that the test data contain objects of seen color and shape combination but unseen location. Neural networks (and any other parametric model) do better in these type of “smooth” generalizations caused by a continuous property like location.\n\n<review>\nHowever, taking Game A as an example, the probe classifiers are relatively poor at these attributes -- indicating the speaker's representation is not capturing these attributes well. \nThen how do the agents effectively differentiate so well between 20 images leveraging primarily color and shape?\n</review>\nIn Game A, agents differentiate 20 objects leveraging primarily object position rather than color and shape.\nIn Game A, the listener needs to differentiate between 20 objects, and so, communicating about color and shape is not a good strategy as there are chances that there will be some other red cube, for example, on the distractor list. The probe classifiers are performing relatively poorly on these attributes (especially on the object color) whereas they perform very well on position (which is in fact a good strategy), which as we find by our analysis is what the protocol describes. We note that location is a continuous variable (which we discretize only for performing the probe analysis in Section 4.2) and so it is very unlikely that two objects have the same location, thus uniquely identifying objects among distractors. This is not the case for games C & D since the listener sees a variation of the speaker’s target.\nMoreover, we note, that object location is encoded across all games.\n\n<review>\nUpper-bound analysis based on ground truth attributes.\n</review>\nWe agree with the reviewer that an upper-bound analysis relying on gold information of objects will facilitate the exposition of results. Note that since location is a continuous variable, ground truth of location is not relevant.\n\t\tcolor \tshape  color & shape\nA\t\t0.37\t         0.24\t0.80\nB & C \t0.93\t         0.90\t0.98\nD\t\t0.89\t         0.89\t0.98\n\nWe could perform the same analysis by discretizing the location in the same way we performed the probe analysis in Section 4.2, however, the upper-bound results depend on the number of discrete locations we derive.\n\t\tlocation\t    color & location\tshape & location\nA\t\t0.69\t\t         0.95\t\t\t0.92\nB \t\t0.97\t\t         0.99\t\t\t0.99\n(for C and D results for location are not applicable)\n\n\n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1513611495076,"tcdate":1513611495076,"number":3,"cdate":1513611495076,"id":"rJylbvSzG","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Comment","forum":"HJGv1Z-AW","replyto":"BytyNwclz","signatures":["ICLR.cc/2018/Conference/Paper639/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper639/Authors"],"content":{"title":"Response to AnonReviewer3","comment":"We thank the reviewer for their comments.\nFor replying, we copy-paste the relevant part and comment on it.\n\n<review> 1. One of the key question ...  Carr et al. (2016): http://www.research.ed.ac.uk/portal/files/25091325/Carr_et_al_2016_Cognitive_Science.pdf\" \n</review>\n\nWe agree with the reviewer that there are good existing measures. Our point was only that there is no mathematical definition and hence no definitive measure. In fact, we do include such a measure found in the literature on language evolution. Our topographic similarity measure (which is introduced by Brighton & Kirby (2006)) is in line with the measure introduced in 2.2.3 in Carr et al.. In Carr et al, the authors correlate Levenshtein message distances and triangle dissimilarities (as obtained from humans). In our study, we correlate Levenshtein message distances and object dissimilarities as obtained by measuring cosine distance of the object feature norms (which are produced by humans). We will make sure to make this connection to previous literature explicit in our description of the measure.\n\n<review>\n2. In general the results occurred be more quantitative....statistics that are reported.\n</review>\n\nWe agree with the reviewer that statistical tests are important, and we politely point out that our claims on 3.3.2 are in fact based on the reported numbers in Table 1 “topographic ρ” column.  However, we will evaluate the statistical significance of the “topographic ρ” measure by calculating the null distribution via a repeated shuffling of the Levenshtein distances (or an additional test if the reviewer has an alternative suggestion).\n\n<review>\n3. As noted above the main novelty of this work is the use of contemporary network models\n</review>\n\nWe believe the novelty of this work is to take the well-defined and interesting questions that the language evolution literature has posed and try to scale them up to contemporary deep learning models and materials, i.e., realistic stimuli in terms of objects and their properties (see Section 3), raw pixel stimuli (see Section 4) and neural network architectures (see Section 2). This kind of interdisciplinary work can not only inform current models on their strengths and weaknesses (as we note in Section 4 we find that neural networks starting from raw pixels cannot out-of-the-box process easily stimuli in a compositional way), but also open up new possibilities for language evolution research in terms of more realistic model simulations. We believe that this might not have been clear from the manuscript and will update the abstract and conclusion to reflect the premises of the work.\n\n<review>\nOne of the advantages of this is that it makes it possible to work with more complex data stimuli, such as images. However, unfortunately the image example that is used is still very artificial being based on a small set of synthetically generated images.\n</review>\n\nMore complex image stimuli and realistic simulations is where we are heading. However, we (as a community) first need to understand how these models behave with raw pixels before scaling them up to complex stimuli. The nature of this work was to lay the groundwork on this question and investigate the properties of protocols in controlled (yet realistic in terms of nature) environments where we can tease apart clearly the behaviour of the model given the small number of variations of the pixel stimuli (object color/shape/position and floor color). Performing the type of careful analysis we did for complex scenes is substantially harder due to the very large number of factors we would have to control (diverse objects of multiple colors, shapes, sizes, diverse backgrounds etc) so it puts into question to what degree we could have achieved a similar degree of introspection by immediately using more complex datasets in the current study.\n\n<review>\nOverall, I see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution, but I think the results require more careful analysis and the novelty is relatively limited, at least in the way that the results are presented here.\n</review>\n\nWe will upload an updated version of our paper by the end of this week containing \n1) the statistical test of the null distribution  \n2) clarifications regarding the topographic measure and \n3) we will clarify the main contributions of this work and better relate it to the existing literature in language evolution\n\nMoreover, we would be really happy to conduct further analyses and clarify the exposition of results. If the reviewer has specific suggestions on this, we would like to hear them in order to improve the quality of the manuscript and strengthen our submission. \n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515642483863,"tcdate":1511842785323,"number":3,"cdate":1511842785323,"id":"BytyNwclz","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Review","forum":"HJGv1Z-AW","replyto":"HJGv1Z-AW","signatures":["ICLR.cc/2018/Conference/Paper639/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Explores interesting issues,  but needs more quantitative analysis and has limited novelty","rating":"5: Marginally below acceptance threshold","review":"This paper presents an analysis of the communication systems that arose when neural network based agents played simple referential games. The set up is that a speaker and a listener engage in a game where both can see a set of possible referents (either represented symbolically in terms of features, or represented as simple images) and the speaker produces a message consisting of a sequence of numbers while the listener has to make the choice of which referent the speaker intends. This is a set up that has been used in a large amount of previous work, and the authors summarize some of this work. The main novelty in this paper is the choice of models to be used by speaker and listener, which are based on LSTMs and convolutional neural networks. The results show that the agents generate effective communication systems, and some analysis is given of the extent to which these communications systems develop compositional properties – a question that is currently being explored in the literature on language creation.\n\nThis is an interesting question, and it is nice to see worker playing modern neural network models to his question and exploring the properties of the solutions of the phone. However, there are also a number of issues with the work.\n\n1. One of the key question is the extent to which the constructed communication systems demonstrate compositionality. The authors note that there is not a good quantitative measure of this. However, this is been the topic of much research of the literature and language evolution. This work has resulted in some measures that could be applied here, see for example Carr et al. (2016): http://www.research.ed.ac.uk/portal/files/25091325/Carr_et_al_2016_Cognitive_Science.pdf\n\n2. In general the results occurred be more quantitative. In section 3.3.2 it would be nice to see statistical tests used to evaluate the claims. Minimally I think it is necessary to calculate a null distribution for the statistics that are reported.\n\n3. As noted above the main novelty of this work is the use of contemporary network models. One of the advantages of this is that it makes it possible to work with more complex data stimuli, such as images. However, unfortunately the image example that is used is still very artificial being based on a small set of synthetically generated images.\n\nOverall, I see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution, but I think the results require more careful analysis and the novelty is relatively limited, at least in the way that the results are presented here.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515698154654,"tcdate":1511733252502,"number":2,"cdate":1511733252502,"id":"HJ3-u2Ogf","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Review","forum":"HJGv1Z-AW","replyto":"HJGv1Z-AW","signatures":["ICLR.cc/2018/Conference/Paper639/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review","rating":"7: Good paper, accept","review":"--------------\nSummary:\n--------------\nThis paper presents a series of experiments on language emergence through referential games between two agents. They ground these experiments in both fully-specified symbolic worlds and through raw, entangled, visual observations of simple synthetic scenes. They provide rich analysis of the emergent languages the agents produce under different experimental conditions. This analysis (especially on raw pixel images) make up the primary contribution of this work.\n\n\n--------------\nEvaluation:\n--------------\nOverall I think the paper makes some interesting contributions with respect to the line of recent 'language emergence' papers. The authors provide novel analysis of the learned languages and perceptual system across a number of environmental settings, coming to the (perhaps uncontroversial) finding that varying the environment and restrictions on language result in variations in the learned communication protocols. \n\nIn the context of existing literature, the novelty of this work is somewhat limited -- consisting primarily of the extension of multi-agent reference games to raw-pixel inputs. While this is a non-trivial extension, other works have demonstrated language learning in similar referring-expression contexts (essentially modeling only the listener model [Hermann et.al 2017]). \n\nI have a number of requests for clarification in the weaknesses section which I think would improve my understanding of this work and result in a stronger submission if included by the authors.  \n\n--------------\nStrengths:\n--------------\n- Clear writing and document structure. \n\n\n- Extensive experimental setting tweaks which ablate the information and regularity available to the agents. The discussion of the resulting languages is appropriate and provides some interesting insights.\n\n\n- A number of novel analyses are presented to evaluate the learned languages and perceptual systems. \n\n\n--------------\nWeaknesses:\n--------------\n- How stable are the reported trends / languages across multiple runs within the same experimental setting? The variance of REINFORCE policy gradients (especially without a baseline) plus the general stochasticity of SGD on randomly initialized networks leads me to believe that multiple training runs of these agents might result is significantly different codes / performance. I am interested in hearing the author's experiences in this regard and if multiple runs present similar quantitative and qualitative results. I admit that expecting identical codes is unrealistic, but the form of the codes (i.e. primarily encoding position) might be consistent even if the individual mappings are not).\n\n\n- I don't recall seeing descriptions of the inference-time procedure used to evaluate training / test accuracy. I will assume argmax decoding for both speaker and listener. Please clarify or let me know if I missed something.\n\n\n- There is ambiguity in how the \"protocol size\" metric is computed. In Table 1, it is defined as 'the effective number of unique message used'. This comes back to my question about decoding I suppose, but does this count the 'inference-time' messages or those produced during training? \nFurthermore, Table 2 redefines \"protocol size\" as the percentage of novel message. I assume this is an editing error given the values presented and take these columns as counts. It also seems \"protocol size\" is replaced with the term \"lexicon\" from 4.1 onward.\n\n- I'm surprised by how well the agents generalize in the raw pixel data experiments. In fact, it seems that across all games the test accuracy remains very close to the train accuracy. \n\nGiven the dataset is created by taking all combinations of color / shape and then sampling 100 location / floor color variations, it is unlikely that a shape / color combo has not been seen in training. Such that the only novel variations are likely location and floor color. However, taking Game A as an example, the probe classifiers are relatively poor at these attributes -- indicating the speaker's representation is not capturing these attributes well. Then how do the agents effectively differentiate so well between 20 images leveraging primarily color and shape?\n\nI think some additional analysis of this setting might shed some light on this issue. One thought is to compute upper-bounds based on ground truth attributes. Consider a model which knows shape perfectly, but cannot predict other attributes beyond chance. To compute the performance of such a model, you could take the candidate set, remove any instances not matching the ground truth shape, and then pick randomly from the remaining instances. Something similar could be repeated for all attributes independently as well as their combinations -- obviously culminating in 100% accuracy given all 4. It could be that by dataset construction, object location and shape are sufficient to achieve high accuracy because the odds of seeing the same shape at the same location (but different color) is very low. \n\nGiven these are operations on annotations and don't require time-consuming model training, I hope to see this analysis in the rebuttal to put the results into appropriate context.\n\n\n- What is random chance for the position and floor color probe classifiers? I don't think it is mentioned how many locations / floor colors are used in generation.  \n\n\n- Relatively minor complaint: Both agents are trained via the REINFORCE policy gradient update rule; however, the listener agent makes a fairly standard classification decision and could be trained with a standard cross-entropy loss. That is to say, the listener policy need not make intermediate discrete policy decisions. This decision to withhold available supervision is not discussed in the paper (as far as I noticed), could the authors speak to this point?\n\n\n\n--------------\nCuriosities:\n--------------\n- I got the impression from the results (specifically the lack of discussion about message length) that in these experiments agents always issued full length messages even though they did not need to do so. If true, could the authors give some intuition as to why? If untrue, what sort of distribution of lengths do you observe?\n\n- There is no long term planning involved in this problem, so why use reinforcement learning over some sort of differentiable sampler? With some re-parameterization (i.e. Gumbel-Softmax), this model could be end-to-end differentiable.\n\n\n--------------\nMinor errors:\n--------------\n[2.2 paragraph 1] LSTM citation should not be in inline form.\n[3 paragraph 1] 'Note that these representations do care some' -> carry\n[3.3.1 last paragraph] 'still able comprehend' --> to\n\n\n-------\nEdit\n-------\nUpdating rating from 6 to 7.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515642483937,"tcdate":1510520866128,"number":1,"cdate":1510520866128,"id":"H15X_V8yM","invitation":"ICLR.cc/2018/Conference/-/Paper639/Official_Review","forum":"HJGv1Z-AW","replyto":"HJGv1Z-AW","signatures":["ICLR.cc/2018/Conference/Paper639/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Very interesting paper, writeup could be clearer","rating":"9: Top 15% of accepted papers, strong accept","review":"This paper presents a set of studies on emergent communication protocols in referential games that use either symbolic object representations or pixel-level representations of generated images as input. The work is extremely creative and packed with interesting experiments.\n\nI have three main comments.\n\n* CLARITY OF EXPOSITION\n\nThe paper was rather hard to read. I'll provide some suggestions for improvement in the minor-comments section below, but one thing that could help a lot is to establish terminology at the beginning, and be consistent with it throughout the paper: what is a word, a message, a protocol, a vocabulary, a lexicon? etc.\n\n* RELATION BETWEEN VOCABULARY SIZE AND PROTOCOL SIZE\n\nIn the compositional setup considered by the authors, agents can choose how many basic symbols to use and the length of the \"words\" they will form with these symbols. There is virtually no discussion of this interesting interplay in the paper. Also, there is no information about the length distribution of words (in basic symbols), and no discussion of whether the latter was meaningful in any way.\n\n* RELATION BETWEEN CONCEPT-PROPERTY AND RAW-PIXEL STUDIES\n\nThe two studies rely on different analyses, and it is difficult to compare them. I realize that it would be impossible to report perfectly comparable analyses, but the authors could at least apply the \"topographic\" analysis of compositionality in the raw-pixel study as well, either by correlating the CNN-based representational similarities of the Speaker with its message similarities, or computing similarity of the inputs in discretized, symbolic terms (or both?).\n\n* MINOR/DETAILED COMMENTS\n\nSection 1\n\nHow do you think emergent communication experiments can shed light on language acquisition?\n\nSection 2\n\nIn figure 1, the two agents point at nothing.\n\n\\mathbf{v} is a set, but it's denoted as a vector. Right below that, h^S is probably h^L?\n\nall candidates c \\in C: or rather their representations \\mathbf{v}?\n\nGive intuition for the reward function.\n\nSection 3\n\nWe use the dataset of Visual Attributes...: drop \"dataset\"\n\nI think the pre-linguistic objects are not represented by 1-hot, but binary vectors.\n\ndo care some inherent structure: carry\n\nNote that symbols in V have no pre-defined semantics...: This is repeated multiple times.\n\nSection 3\n\nI couldn't find simulation details: how many training elements, and how is training accuracy computed? Also, \"training data\", \"training accuracy\" are probably misleading terms, as I suppose you measured performance on new combinations of objects.\n\nI find \"Protocol Size\" to be a rather counterintuitive term: maybe call Vocabulary Size \"Alphabet Size\", and Protocol Size \"Lexicon Size\"?\n\nState in Table 1 caption that the topographic measure will be explained in a later section. Also, the -1 is confusing: you can briefly mention when you introduce the measure that since you correlate a distance with a similarity you expect an inverse relation? Also, you mention in the caption that all Spearman rhos are significant, but where are they presented again?\n\nSection 3.2\n\nDoes the paragraph starting with \"Note that the distractor\" refer to a figure or table that is not there? If not, it should be there, since it's not clear what are the data that support your claims there. Also, you should explain what the degenerate strategy the agents find is.\n\nNext paragraph:\n\n- I find the usage of \"obtaining\" to refer to the relation between messages and objects strange.\n\n- in which space are the reported pairwise similarities computed?\n\n- make clear that in the non-uniform case confusability is less influenced by similarity since the agents must learn to distinguish between similar objects that naturally co-occur (sheep and goats)\n\n- what is the expected effect on the naturalness of the emerged language?\n\nSection 3.3\n\nadhere to, the ability to: \"such as\" missing?\n\nIs the unigram chimera distribution inferred from the statistics over the distribution of properties across all concepts or what? (please clarify.)\n\nIn Tables 2 and 3, why is vocabulary size missing?\n\nIn Table 2, say that the protocol size columns report novel message percentage **for the \"test\" conditions***\n\nFigure 2: spelling of Levensthein\n\nSection 3.3.2\n\nwhile for languages (c,d)... something missing.\n\nwith a randomly initialized...: no a\n\nMore importantly, I don't understand this \"random\" setup: if architecture was fixed and randomly initialized, how could something be learned about the structure of the data?\n\nSection 4\n\nRefer to the images the agents must communicate about as \"scenes\", since objects are just a component of them.\n\nWhat are the absolute sizes of train and test splits?\n\nSection 4.1\n\nwe do not address this issue: the issue\n\nSection 4.2\n\nat least in the game C&D: games\n\nWhy is Appendix A containing information that logically follows that in Appendix B?\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]}},{"tddate":null,"ddate":null,"tmdate":1515085067024,"tcdate":1509130073955,"number":639,"cdate":1509739184293,"id":"HJGv1Z-AW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJGv1Z-AW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input","abstract":"The ability of algorithms to evolve or learn (compositional) communication protocols has been traditionally measured in the language evolution literature by emergent communication tasks. In this work, we scale up this research by using contemporary deep learning materials and train reinforcement learning neural-network agents on referential communication games. We extend previous work in this direction in which agents learn from symbolic environments to those learning from using raw pixel input data, a more challenging and realistic input representation. We find that the degree of structure found in the input data affects the nature of the emerged protocols, and thereby corroborate the hypothesis that structured compositional language is most likely to emerge when agents perceive the world as being structured.  ","pdf":"/pdf/03978df8e51cdd7d42821961e9cd5580a4596408.pdf","TL;DR":"A controlled study of the role of environments with respect to properties in emergent communication protocols.","paperhash":"anonymous|emergence_of_linguistic_communication_from_referential_games_with_symbolic_and_pixel_input","_bibtex":"@article{\n  anonymous2018emergence,\n  title={Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJGv1Z-AW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper639/Authors"],"keywords":["disentanglement","communication","emergent language","compositionality","multi-agent"]},"nonreaders":[],"replyCount":9,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}