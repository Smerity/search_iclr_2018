{"notes":[{"tddate":null,"ddate":null,"tmdate":1514149459065,"tcdate":1514149459065,"number":4,"cdate":1514149459065,"id":"BJoLLcTMM","invitation":"ICLR.cc/2018/Conference/-/Paper568/Public_Comment","forum":"H1uP7ebAW","replyto":"S1KuIB5gz","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Author Rebuttal","comment":"\"The only issue with this paper is, that their proposed method, in practice is not tractable for inference on estimating probability of a single output, a task which would be critical in medical domain. Considering that their paper is titled as a work to use \"dependencies\" among labels, not being able to evaluate their network's, and lack of interpretable evaluation results on this model in the experiment section is a major limitation.\"\n\nThe reviewer is correct that estimating the marginal probability of a given abnormality using the proposed model would be computationally expensive. We do not consider this a major limitation because the motivation for our research was to model events (i.e. the abnormalities) that occur together. By definition, the marginal probability describes each event in isolation. Section 1 of the paper provides a few specific examples of abnormalities that domain experts know to be dependent. The proposed model attempts to capture such dependencies by describing the joint distribution abnormalities. The medical use case that we intended to support is for the model to predict all abnormalities that are present in the image and the joint probability quantifies the confidence of the prediction as a whole. That being said, other metrics such as sensitivities and specificities remain accessible (Section 4.2) for individual abnormalities.\n\n\"On the other hand, there are many alternative models where one could simply use multi-task learning and shared parameter, to predict multiple outcomes extremely efficiently. To be able to claim that this paper improved the prediction by better modeling of 'dependencies' among labels, I would need to see how the (much simpler) multi-task setting works as well.\"\n\nThe baseline model (model_{a}) described in our paper represents the standard multi-task learning approach in which the encoder parameters are shared across classes and decoder uses class-specific output layers. The alternative models (model_{b1} and model_{b2}) employ a comparable encoder architecture but a recurrent decoder. Our claim that modeling dependencies improved the predictions is based entirely on the a comparison you have suggested."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1514149221226,"tcdate":1514149221226,"number":3,"cdate":1514149221226,"id":"BkpwSqpMG","invitation":"ICLR.cc/2018/Conference/-/Paper568/Public_Comment","forum":"H1uP7ebAW","replyto":"BkE5LPlZG","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Author Rebuttal","comment":"Thank you for taking time reviewing our manuscript. Much effort has been devoted into making this paper digestible for both machine learning researchers and medical practitioners. We are surprised that you have found none of them useful. For instance, the rationale behind our modelling choices is carefully phrased from the medical point of view in length in Section 1 (especially paragraph 2), Section 3.1, Section 3.3.1, Section 4.2 and Section 5. In fact, wherever relevant, we have made an effort to motivate and justify the modeling decisions with the medical application in question, although there might still be places where the narrative could be improved to draw a deeper connection. Regarding your point of the dataset, Wang et al. (2017) (the paper introducing the dataset to the community) has thorough descriptions of its curation, context, label distribution. That being said, we agree with you that this is not strictly speaking a medicine-oriented publication that is meant to guide the clinical practice, as rigorous work in that category would require conducting a randomized clinical trial in the hospital environment to systematically measure its clinical outcome."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1514149612922,"tcdate":1514148885910,"number":2,"cdate":1514148885910,"id":"SyAfEqafG","invitation":"ICLR.cc/2018/Conference/-/Paper568/Public_Comment","forum":"H1uP7ebAW","replyto":"HJZ2MKRbM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Author Rebuttal","comment":"\"The paper does not introduce strong technical novelties -- mostly, it seems to apply previous techniques to the medical domain.\"\n\nThe NADE-LSTM hybrid model has not previously been explored. Leveraging the label dependency has been ignored in previous work on medical diagnosis. We carefully designed such models to address it while taking into account application-specific constraints (e.g.  Section 1 (especially paragraph 2), Section 3.1, Section 3.3.1 and Section 5). In addition, clinical-relevant metrics are proposed, analyzed (see Section 4.2) and measured (see Section 4.4) as opposed to conventional machine learning metrics that are hard to interpret clinically by medical practitioners. We believe all of the above contributions are novel.\n\n\"It could have been interesting to know if there are more insights / lessons learned in this process. This could be of interest for a broader audience. For instance, what are the implications of using higher-resolution images as input to DenseNet / decreasing the number of layers? How do the features learned at different layers compare to the ones of the original network trained for image classification? How do features of networks pre-trained on ImageNet, and then fine-tuned for the medical domain, compare to features learned from medical images from scratch?\"\n\nThank you for the suggestions. The central idea is to exploit the label dependencies, for which we have focus on extensively. For other non-central design choices (such as architectural choice of DenseNets, the use of fine-tuning), the reasoning has been stated while leaving quantitative evaluation for the future study. Regarding your point of pre-trained models: Table 2 shows the diminishing benefits of using pretrained out-of-domain models once a large amount of in-domain training pairs are available, as the previous SOTA relies a pretrained model from ImageNet. For both pretraining and fine-tuning, lower resolution (224*224, as opposed to 512*512 in our work) and out-of-domain bias (from ImageNet, very much different from medical images) could possibly account for the difference. As you mentioned, fine-tuning might be a reasonable middle-ground. However, as has been recently observed, fine-tuning has its inherent issue of “catastrophic forgetting” and needs to be dealt with care.\n\n\"The impact of the proposed approach on medical diagnostics is unclear. The authors could better discuss how the approach could be adopted in practice. Also, it could be interesting also to discuss how the results in Table 2 and 3 compare to human classification capabilities, and if that performance would be already enough for building a computer-aided diagnosis system.\"\n\nThe medical use case that motivated our research was the automated prediction of all (modeled) abnormalities that are present in a chest x-ray image. While the performance of the proposed model represented an improvement over the previous state of the art, the accuracy certainly falls short of human performance. In practice, however, the predictions are probably good enough to find utility in triage applications or as a second-read diagnostic aid. Measurement of the clinical impact, as well as a comparison to human performance, will have to wait for future studies designed to collect and analyze the required data in a standard randomized clinical trial. \n\n\"Finally -- is it expected that the ordering of the factorization in Eq. 3 does not count much (results in Table 3)? As a non-expert in the field, I'd expect that ordering between pathologic patterns matters more.\"\n\nJust to be clear, this is an empirical question. In theory, all orderings are equivalent but in practice they might differ because factors are parameterized by models. Based on our experiments, however, the ordering of the factorization does not significantly impact the results. This phenomenon has been consistently observed in other publications that use NADEs (e.g. Iterative Neural Autoregressive Distribution Estimator, NIPS 2014). In practice, one could average models trained with different orderings. Model averaging is not the central point of this work.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1515783587150,"tcdate":1513161384984,"number":3,"cdate":1513161384984,"id":"HJZ2MKRbM","invitation":"ICLR.cc/2018/Conference/-/Paper568/Official_Review","forum":"H1uP7ebAW","replyto":"H1uP7ebAW","signatures":["ICLR.cc/2018/Conference/Paper568/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting application of DenseNet/LSTM to the medical field","rating":"6: Marginally above acceptance threshold","review":"The paper proposes to combine the recently proposed DenseNet architecture with LSTMs to tackle the problem of predicting different pathologic patterns from chest x-rays. In particular, the use of LSTMs helps take into account interdependencies between pattern labels. \n\nStrengths:\n- The paper is very well written. Contextualization with respect to previous work is adequate. Explanations are clear. Novelties are clearly identified by the authors.\n- Quantitative improvement with respect to the state the art. \n\nWeaknesses:\n- The paper does not introduce strong technical novelties -- mostly, it seems to apply previous techniques to the medical domain. It could have been interesting to know if there are more insights / lessons learned in this process. This could be of interest for a broader audience. For instance, what are the implications of using higher-resolution images as input to DenseNet / decreasing the number of layers? How do the features learned at different layers compare to the ones of the original network trained for image classification? How do features of networks pre-trained on ImageNet, and then fine-tuned for the medical domain, compare to features learned from medical images from scratch? \n- The impact of the proposed approach on medical diagnostics is unclear. The authors could better discuss how the approach could be adopted in practice. Also, it could be interesting also to discuss how the results in Table 2 and 3 compare to human classification capabilities, and if that performance would be already enough for building a computer-aided diagnosis system.\n\nFinally -- is it expected that the ordering of the factorization in Eq. 3 does not count much (results in Table 3)? As a non-expert in the field, I'd expect that ordering between pathologic patterns matters more.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1515642471169,"tcdate":1512236684020,"number":2,"cdate":1512236684020,"id":"BkE5LPlZG","invitation":"ICLR.cc/2018/Conference/-/Paper568/Official_Review","forum":"H1uP7ebAW","replyto":"H1uP7ebAW","signatures":["ICLR.cc/2018/Conference/Paper568/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting but flawed in terms of applicability","rating":"6: Marginally above acceptance threshold","review":"Well written and appropriately structured. Well within the remit of the conference.\nNot much technical novelty to be found, but the original contributions are adequately identified and they are interesting on their own.\n\nMy main concern (and complaint) is not technical, but application-based. This study is (unfortunately) typical in that it focuses on and provides detail of the technical modeling issues, but ignores the medical applicability of the model and results. This is exemplified by the fact that the data set is hardly described at all and the 14 abnormalities/pathologies, the rationale behind their choice and the possible interrelations and dependencies are never described from a medical viewpoint. If I were a medical expert, I would not have a clue about how these results and models could be applied in practice, or about what medical insight I could achieve.\n\nThe bottom line seems to be: \"my model and approach works better than the other guys' model and approach\", but one is left with the impression that these experiments could have been made with other data, other problems, other fields of application and they would not have not changed much ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1515642471213,"tcdate":1511835248955,"number":1,"cdate":1511835248955,"id":"S1KuIB5gz","invitation":"ICLR.cc/2018/Conference/-/Paper568/Official_Review","forum":"H1uP7ebAW","replyto":"H1uP7ebAW","signatures":["ICLR.cc/2018/Conference/Paper568/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","rating":"6: Marginally above acceptance threshold","review":"This paper presents an impressive set of results on predicting lung pathologies from chest x-ray images. \nAuthors present two architectures: one based on denseNet, and one based on denseNet + LSTM on output dimensions (i.e. similar to NADE model), and compare it to state of the art on the chest x-ray classification. Experiments are clearly described and results are significantly better compared to state of the art.\n\nThe only issue with this paper is, that their proposed method, in practice is not tractable for inference on estimating probability of a single output, a task which would be critical in medical domain. Considering that their paper is titled as a work to use \"dependencies\" among labels, not being able to evaluate their network's, and lack of interpretable evaluation results on this model in the experiment section is a major limitation. \n\nOn the other hand, there are many alternative models where one could simply use multi-task learning and shared parameter, to predict multiple outcomes extremely efficiently. To be able to claim that this paper improved the prediction by better modeling of 'dependencies' among labels, I would need to see how the (much simpler) multi-task setting works as well. \n\nThat said, the paper has several positive aspects in all areas:\n\nOriginality - the paper presents first combination of DenseNets with LSTM-based output factorization,\nWriting clarity - the paper is very well written and clear.\nQuality - (apart from the missing multi-task baseline), the results are significantly better than state of the art, and experiments are well done,\nSignificance - Apart from the issue of intractable inference which is arguably a large limitation of this work, the application in medical field is significant. \n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]}},{"tddate":null,"ddate":null,"tmdate":1509739231217,"tcdate":1509127008232,"number":568,"cdate":1509739228557,"id":"H1uP7ebAW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1uP7ebAW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning to diagnose from scratch by exploiting dependencies among labels","abstract":"The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.","pdf":"/pdf/0e8a878df9119ec211564b0277837670e8459f72.pdf","TL;DR":"we present the state-of-the-art results of using neural networks to diagnose chest x-rays","paperhash":"anonymous|learning_to_diagnose_from_scratch_by_exploiting_dependencies_among_labels","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning to diagnose from scratch by exploiting dependencies among labels},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1uP7ebAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper568/Authors"],"keywords":["medical diagnosis","medical imaging","multi-label classification"]},"nonreaders":[],"replyCount":6,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}