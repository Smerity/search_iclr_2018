{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222627675,"tcdate":1512045876046,"number":2,"cdate":1512045876046,"id":"H1n46uTxf","invitation":"ICLR.cc/2018/Conference/-/Paper376/Official_Review","forum":"SkAK2jg0b","replyto":"SkAK2jg0b","signatures":["ICLR.cc/2018/Conference/Paper376/AnonReviewer1"],"readers":["everyone"],"content":{"title":"has novelty issue, results are not impressive","rating":"4: Ok but not good enough - rejection","review":"The paper addresses the scenario when using a pretrained deep network as learnt feature representation for another (small) task where retraining is not an option or not desired. In this situation it proposes to use all layers of the network to extract feature from, instead of only one layer. \nThen it proposes to standardize different dimensions of the features based on their response on the original task. Finally, it discretize each dimension into {-1, 0, 1} to compress the final concatenated feature representation. \nDoing this, it shows improvements over using a single layer for 9 target image classification datasets including object, scene, texture, material, and animals.\n\nThe reviewer does not find the paper suitable for publication at ICLR due to the following reasons:\n- The paper is incremental with limited novelty.\n- the results are not encouraging\n- the pipeline of standardization, discretization is relatively costly, the final feature vector still large. \n- combining different layers, as the only contribution of the paper, has been done in the literature before,  for instance:\n“The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling\nfor Image Classification” CVPR 2016\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"An Out-of-the-box Full-network Embedding for Convolutional Neural Networks","abstract":"Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.","pdf":"/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf","TL;DR":"We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.","paperhash":"anonymous|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkAK2jg0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper376/Authors"],"keywords":["Embedding spaces","feature extraction","transfer learning."]}},{"tddate":null,"ddate":null,"tmdate":1512222627720,"tcdate":1511838444208,"number":1,"cdate":1511838444208,"id":"BkNxXL5ef","invitation":"ICLR.cc/2018/Conference/-/Paper376/Official_Review","forum":"SkAK2jg0b","replyto":"SkAK2jg0b","signatures":["ICLR.cc/2018/Conference/Paper376/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Lack of novelty","rating":"3: Clear rejection","review":"This paper proposes an out-of-the-box embedding for image classification task. Instead of taking one single layer output from pre-trained network as the feature vector for new dataset, the method first extracts the activations from all the layers, then runs spatial average pooling on all convolutional layers, then normalizes the feature and uses two predefined thresholds to discretize the features to {-1, 0, 1}. Final prediction is learned through a SVM model using those embeddings. Experimental results on nine different datasets show that this embedding outperforms baseline of using one single layer. I think in general this paper lacks novelty and it shouldn't be surprising that activations from all layers should be more representative than one single layer representation. Moreover, in Table 4, it shows that discretization actually hurts the performance. It is also very heuristic to choose the two thresholds.  \n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"An Out-of-the-box Full-network Embedding for Convolutional Neural Networks","abstract":"Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.","pdf":"/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf","TL;DR":"We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.","paperhash":"anonymous|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkAK2jg0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper376/Authors"],"keywords":["Embedding spaces","feature extraction","transfer learning."]}},{"tddate":null,"ddate":null,"tmdate":1509739336793,"tcdate":1509108870435,"number":376,"cdate":1509739334142,"id":"SkAK2jg0b","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SkAK2jg0b","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"An Out-of-the-box Full-network Embedding for Convolutional Neural Networks","abstract":"Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.","pdf":"/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf","TL;DR":"We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.","paperhash":"anonymous|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkAK2jg0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper376/Authors"],"keywords":["Embedding spaces","feature extraction","transfer learning."]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}