{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222611267,"tcdate":1511819934940,"number":3,"cdate":1511819934940,"id":"r1vicbqeG","invitation":"ICLR.cc/2018/Conference/-/Paper279/Official_Review","forum":"B1Gi6LeRZ","replyto":"B1Gi6LeRZ","signatures":["ICLR.cc/2018/Conference/Paper279/AnonReviewer2"],"readers":["everyone"],"content":{"title":" Learning from Between-class Examples increases the Fisher’s criterion. BC learning regularizes the positional relationship of the classes in the feature space, by training the model not to misclassify the mixed sound as different classes. The presentation and discussion on the proposed method is good (even if the organisation of the paper could be improved). Some simplifications can be conducted (in the mixture). The main idea is good and novel, and relevant for ICLR.","rating":"8: Top 50% of accepted papers, clear accept","review":"The propose data augmentation and BC learning is relevant, much robust than frequency jitter or simple data augmentation. \n\nIn equation 2, please check the measure of the mixture. Why not simply use a dB criteria ?\n\nThe comments about applying a CNN to local features or novel approach to increase sound recognition could be completed with some ICLR 2017 work towards injected priors using Chirplet Transform.\n\nThe authors might discuss more how to extend their model to image recognition, or at least of other modalities as suggested.\n\nSection 3.2.2 shall be placed later on, and clarified.\n\nDiscussion on mixing more than two sounds leads could be completed by associative properties, we think... ?\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning from Between-class Examples for Deep Sound Recognition","abstract":"Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: learning from between-class examples (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher’s criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (DSRNet) and train it with BC learning. As a result, the performance of DSRNet surpasses the human level.","pdf":"/pdf/7bab33c6626002460fb18794622578dc097a4347.pdf","TL;DR":"We propose an novel learning method for deep sound recognition named BC learning.","paperhash":"anonymous|learning_from_betweenclass_examples_for_deep_sound_recognition","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning from Between-class Examples for Deep Sound Recognition},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Gi6LeRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper279/Authors"],"keywords":["sound recognition","deep learning","feature learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222611308,"tcdate":1511803598272,"number":2,"cdate":1511803598272,"id":"HJ80q6KlG","invitation":"ICLR.cc/2018/Conference/-/Paper279/Official_Review","forum":"B1Gi6LeRZ","replyto":"B1Gi6LeRZ","signatures":["ICLR.cc/2018/Conference/Paper279/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting data augmentation technique, but lacks of deep insights on how and why does it work.","rating":"4: Ok but not good enough - rejection","review":"This manuscript proposes a method to improve the performance of a generic learning method by generating \"in between class\" (BC) training samples. The manuscript motivates the necessity of such technique and presents the basic intuition. The authors show how the so-called BC learning helps training different deep architectures for the sound recognition task.\n\nMy first remark regards the presentation of the technique. The authors argue that it is not a data augmentation technique, but rather a learning method. I strongly disagree with this statement, not only because the technique deals exactly with augmenting data, but also because it can be used in combination to any learning method (including non-deep learning methodologies). Naturally, the literature review deals with data augmentation technique, which supports my point of view.\n\nIn this regard, I would have expected comparison with other state-of-the-art data augmentation techniques. The usefulness of the BC technique is proven to a certain extent (see paragraph below) but there is not comparison with state-of-the-art. In other words, the authors do not compare the proposed method with other methods doing data augmentation. This is crucial to understand the advantages of the BC technique.\n\nThere is a more fundamental question for which I was not able to find an explicit answer in the manuscript. Intuitively, the diagram shown in Figure 4 works well for 3 classes in dimension 2. If we add another class, no matter how do we define the borders, there will be one pair of classes for which the transition from one to another will pass through the region of a third class. The situation worsens with more classes. However, this can be solved by adding one dimension, 4 classes and 3 dimensions seems something feasible. One can easily understand that if there is one more class than the number of dimensions, the assumption should be feasible, but beyond it starts to get problematic. This discussion does not appear at all in the manuscript and it would be an important limitation of the method, specially when dealing with large-scale data sets.\n\nOverall I believe the paper is not mature enough for publication.\n\nSome minor comments:\n- 2.1: We introduce --> We discussion\n- Pieczak 2015a did not propose the extraction of MFCC.\n- the x_i and t_i of section 3.2.2 should not be denoted with the same letters as in 3.2.1.\n- The correspondence with a semantic feature space is too pretentious, specially since no experiment in this direction is shown.\n- I understand that there is no mixing in the test phase, perhaps it would be useful to recall it.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning from Between-class Examples for Deep Sound Recognition","abstract":"Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: learning from between-class examples (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher’s criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (DSRNet) and train it with BC learning. As a result, the performance of DSRNet surpasses the human level.","pdf":"/pdf/7bab33c6626002460fb18794622578dc097a4347.pdf","TL;DR":"We propose an novel learning method for deep sound recognition named BC learning.","paperhash":"anonymous|learning_from_betweenclass_examples_for_deep_sound_recognition","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning from Between-class Examples for Deep Sound Recognition},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Gi6LeRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper279/Authors"],"keywords":["sound recognition","deep learning","feature learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222611383,"tcdate":1511576699170,"number":1,"cdate":1511576699170,"id":"HJmtVULeG","invitation":"ICLR.cc/2018/Conference/-/Paper279/Official_Review","forum":"B1Gi6LeRZ","replyto":"B1Gi6LeRZ","signatures":["ICLR.cc/2018/Conference/Paper279/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Novel Approach to Using Limited Training Data By Changing Task for Better Class Discrimination","rating":"9: Top 15% of accepted papers, strong accept","review":"Overall: Authors defined a new learning task that requires a DNN to predict mixing ratio between sounds from two different classes. Previous approaches to training data mixing are (1) from random classes, or (2) from the same class. The presented approach mixes sounds from specific pairs of classes to increase discriminative power of the final learned network. Results look like significant improvements over standard learning setups.\n\nDetailed Evaluation: The approach presented is simple, clearly presented, and looks effective on benchmarks. In terms of originality, it is different from warping training example for the same task and it is a good extension of previously suggested example mixing procedures with a targeted benefit for improved discriminative power. The authors have also provided extensive analysis from the point of views (1) network architecture, (2) mixing method, (3) number of labels / classes in mix, (4) mixing layers -- really well done due-diligence across different model and task parameters.\n\nMinor Asks:\n(1) Clarification on how the error rates are defined. Especially since the standard learning task could be 0-1 loss and this new BC learning task could be based on distribution divergence (if we're not using argmax as class label).\n(2) #class_pairs targets as analysis - The number of epochs needed is naturally going to be higher since the BC-DNN has to train to predict mixing ratios between pairs of classes. Since pairs of classes could be huge if the total number of classes is large, it'll be nice to see how this scales. I.e. are we talking about a space of 10 total classes or 10000 total classes? How does num required epochs get impacted as we increase this class space?\n(3) Clarify how G_1/20 and G_2/20 is important / derived - I assume it's unit conversion from decibels.\n(4) Please explain why it is important to use the smoothed average of 10 softmax predictions in evaluation... what happens if you just randomly pick one of the 10 crops for prediction?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning from Between-class Examples for Deep Sound Recognition","abstract":"Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: learning from between-class examples (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher’s criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (DSRNet) and train it with BC learning. As a result, the performance of DSRNet surpasses the human level.","pdf":"/pdf/7bab33c6626002460fb18794622578dc097a4347.pdf","TL;DR":"We propose an novel learning method for deep sound recognition named BC learning.","paperhash":"anonymous|learning_from_betweenclass_examples_for_deep_sound_recognition","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning from Between-class Examples for Deep Sound Recognition},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Gi6LeRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper279/Authors"],"keywords":["sound recognition","deep learning","feature learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739388883,"tcdate":1509088666388,"number":279,"cdate":1509739386225,"id":"B1Gi6LeRZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1Gi6LeRZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning from Between-class Examples for Deep Sound Recognition","abstract":"Deep learning methods have achieved high performance in sound recognition tasks. Deciding how to feed the training data is important for further performance improvement. We propose a novel learning method for deep sound recognition: learning from between-class examples (BC learning). Our strategy is to learn a discriminative feature space by recognizing the between-class sounds as between-class sounds. We generate between-class sounds by mixing two sounds belonging to different classes with a random ratio. We then input the mixed sound to the model and train the model to output the mixing ratio. The advantages of BC learning are not limited only to the increase in variation of the training data; BC learning leads to an enlargement of Fisher’s criterion in the feature space and a regularization of the positional relationship among the feature distributions of the classes. The experimental results show that BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes, in which BC learning proves to be always beneficial. Furthermore, we construct a new deep sound recognition network (DSRNet) and train it with BC learning. As a result, the performance of DSRNet surpasses the human level.","pdf":"/pdf/7bab33c6626002460fb18794622578dc097a4347.pdf","TL;DR":"We propose an novel learning method for deep sound recognition named BC learning.","paperhash":"anonymous|learning_from_betweenclass_examples_for_deep_sound_recognition","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning from Between-class Examples for Deep Sound Recognition},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1Gi6LeRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper279/Authors"],"keywords":["sound recognition","deep learning","feature learning"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}