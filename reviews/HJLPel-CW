{"notes":[{"tddate":null,"ddate":null,"tmdate":1516609174517,"tcdate":1516609174517,"number":5,"cdate":1516609174517,"id":"H1CqCzXrz","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Comment","forum":"HJLPel-CW","replyto":"HkCHMJvVG","signatures":["ICLR.cc/2018/Conference/Paper550/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper550/Authors"],"content":{"title":"Thank you for your suggestions","comment":">>> if we could just have a binary classifier to discriminate y1 and y* and train it end-to-end. \n\nRecall that the source domain in our problem may contain various styles. It is thus possible that some sentences in the source domain have the same style as/or very similar to the target style. Therefore, we think training such a classifier may be problematic. \n\n>>> the experiment without the style discrepancy loss.\n\nWe conducted an experiment without the style discrepancy loss on Yelp. \nFollowing the settings of the first experiment (Table 1) in our paper, we run our model without the style discrepancy loss when the source domain contains not only negative sentences but also 50k, 100k, 150k positive sentences. \n\nWhen the models converge, the cycle consistency loss is about 15 for our full model, but it is about 20 for the model without the style discrepancy loss. Also, we find that most generated sentences deviate very far from their original content, which indicates that the style and content representations are not well learned. Thus we argue that the style discrepancy is inseparable under our problem setting.\n\nFollowing are some transferred sentences by the model without the style discrepancy loss. The original sentences are same as that in Table 18 in the Appendix (Section 6.3).\n\n-> 1st sample\nOriginal: it is rather bad .     \nOurs: it is really good .                          \nOurs without style disc: i love this place .\n-> 2nd sample \nOriginali have tried to go to them twice silly me .\nOurs: i have tried the place and it was great . \nOurs without style disc: good the , , and and service .\n-> 3rd sample\nOriginal: i wish i could give zero stars .             \nOurs: i recommend this place to anyone .      \nOurs without style disc: the service is and and service .\n-> 4th sample\nOriginal: and just not very good .        \nOurs: and i love it .                \nOurs without style disc: the will is great .\n\n>>> it might be a little bit misleading to use an indicator function to represent E_y.\n\nWe will use separate representations for the target style and the styles of the source domain.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515807302545,"tcdate":1515807302545,"number":4,"cdate":1515807302545,"id":"HkCHMJvVG","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Comment","forum":"HJLPel-CW","replyto":"BJkfcx67z","signatures":["ICLR.cc/2018/Conference/Paper550/AnonReviewer2"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper550/AnonReviewer2"],"content":{"title":"Thank you for responding to my comments","comment":">>> additive contribution\n\nI agree that this paper deals with a new and more challenging problem setting. I just say that it extends an existing standard approach to address a more challenging problem. I regard the extension is valuable to the community. Thus, I rated it as \"7: Good paper, accept\". I just changed \"additive\" to \"valuable\" in my review.\n\n>>> If it (the pre-trained classifier D_s) can be integrated into the training end-to-end.\n>>>include results without style discrepancy loss. \n\nI wonder if we could just have a binary classifier to discriminate y1 and y* and train it end-to-end. \n\nI think that the experiment without the style discrepancy loss is important to show that it is inseparable. I think it is possible that the combination of L_rec and L_adv has some power to force the network to represent contents by z and styles by y even though it does not model the relationship between y1 and y* explicitly as you point out in Section 3.2. \n\n>>> how y^* is chosen in Section 3.3. \n\nIt might be OK, but it might be a little bit misleading to use an indicator function to represent E_y. If you just look at Fig. 1, probably,  you think that y* is computed by an encoder."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515158167656,"tcdate":1515158167656,"number":3,"cdate":1515158167656,"id":"HJeocx6Xf","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Comment","forum":"HJLPel-CW","replyto":"rJ8FQQYxf","signatures":["ICLR.cc/2018/Conference/Paper550/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper550/Authors"],"content":{"title":"Response to AnonReviewer3","comment":"Thanks for your comments. We are very sorry for the late reply.\n\n>>> Why use CNN for the style representation layer?\n\nThere are two main reasons why we use CNN for style representation: (1) CNN is widely used in sentence classification tasks. Taking Yelp dataset as an example, we use the CNN model to distinguish positive sentences from non-positive sentences.  As shown in our pre-trained classifier or the evaluation classifier, CNN model achieves a high classification accuracy above 95%. Thus, we consider that the output layer of CNN is able to encode meaningful representations for these different sentiment styles. (2) Sentences in our datasets such as Yelp is short. As is shown in Yin et al. (2017), when sentences are not that long and sentiment is mostly determined by local features rather than the whole sentence, CNN is more efficient for sentiment classification, and thus it is better at text style representation. \n\n\n>>> Are long-range correlations irrelevant to the text style?\n\nLong-range correlations can contribute to text style representation. But for our datasets such as Yelp, all the sentences have no more than 15 words. And it has only three classes of sentiments which are easy to determine by local key-phrases. Thus we consider the long-range correlations are not very important in our experiments. In addition, we vary the filter size in the CNN model from 2 * 200 to 5 * 200, where 200 is the size of word embeddings, and the maximum filter size 5 * 200 should be capable of capturing some long-range correlations. Also, in our experiments, we want to keep the same setting as in Shen et al. (2017) which is our baseline, and make the results reported in Shen et al. (2017) and ours directly comparable. Thus we have not put much focus on investigating the usefulness of long-range correlations for the text styles. But this may be a possible way to improve our current performance and we will try it later.\n\n\n>>> If y* is simply fixed somewhere in the model.\n\nWe apologize for our mistake about y^*.\nFor the source domain with various unknown styles, we use a style encoder to obtain each of their representations; for the target domain, we assume they have only one style representation y^* directly, which is not obtained from the encoder function. But both y^* and the parameters of encoder functions are learned jointly together with other parts of parameters in our model.\nThus, our model will not suffer from the mode collapse problem or make different sentences with different styles have very similar representations.\nWe have fixed this mistake and make that part more clearly in Section 3.2.\n\n\n>>> Limited vocabulary...learnt to overfit the sentiment classifier...the transferred sentences may lack variations.\n\nWe are sorry that we happen to select some similar input sentences (all are about customer services) which lead to this confusion. Our primary goal of showing these examples is to discuss in what cases the models perform well or suffer some mistakes. Please find some additional examples in Table 18 in the Appendix (Section 6.3). They show that our model can generate outputs with rich vocabulary. \n\n\n>>> lacks practical use.\n\nAs is shown in the selected examples in Table 2, we did find the current methods suffer from some mistakes. But we disagree our work lacks practical use.\nFirst, we propose a style transfer model under a more practical setting for use. The previous literatures on language style transfer all aim to transfer sentences from one style to the other. However, in many real applications such as multi-rounded chatbot (more detailed descriptions can be found in our introduction), we may need to transfer sentences with various unknown styles into one target style, which is exactly the problem setting we study here.\nSecond, experimental results show that our model performs better than the current state-of-the-art style transfer model under our problem setting. Especially, we report results on a real dialogue dataset to demonstrate the usefulness of our method. Hence, we are making a step forward towards applying the language style transfer techniques in real applications.\n\n\n>>> It would be convincing if the authors could transfer an English paragraph into the style of a certain author\n\nNote that our model targets for the style transfer problem at the sentence level. Here, we add an experiment on revising modern text in the language of Shakespeare at the sentence-level as in Mueller et al. (2017). We present the experiment and analysis in the Appendix (Section 6.4).\n\n\nReferences: \n1. Yin, Wenpeng, et al. \"Comparative Study of CNN and RNN for Natural Language Processing.\" arXiv preprint arXiv:1702.01923 (2017).\n2. Shen, Tianxiao, et al. \"Style Transfer from Non-Parallel Text by Cross-Alignment.\" arXiv preprint arXiv:1705.09655 (2017).\n3. Mueller, Jonas, et al. \"Sequence to better sequence: continuous revision of combinatorial structures.\" ICML. 2017."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515158022923,"tcdate":1515158022923,"number":2,"cdate":1515158022923,"id":"BJkfcx67z","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Comment","forum":"HJLPel-CW","replyto":"S10nr1cgf","signatures":["ICLR.cc/2018/Conference/Paper550/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper550/Authors"],"content":{"title":"Response to AnonReviewer2","comment":"Thanks for your comments and suggestions. We are very sorry for the late reply.\n\n>>> additive contribution; does not bring completely new perspectives for the task.\n\nIn this paper, we propose a new style transfer model under a new and more challenging problem setting. The previous literatures on language style transfer all aim to transfer sentences from one style to the other. However, in many real applications such as multi-rounded chatbot (more detailed descriptions can be found in our introduction), we may need to transfer sentences with various unknown styles into one target style. To address this new problem setting, we propose a new style transfer model which relies on the use of two proposed loss functions. Thus, our work should not be considered as an additive contribution. \n\n\n>>> If it (the pre-trained classifier D_s) can be integrated into the training end-to-end.\n\nD_s may be jointly trained. However, if we integrate it into the end-to-end training, we may start with a D_s with a low accuracy, and then our model is easy to optimize a wrong style-discrepancy loss for many epochs and get stuck into a poor local optimum. A possibly better way is to first pre-train D_s and then fine-tune it jointly during training. We will try it later to see if any further improvement can be made.\n\n>>>include results without style discrepancy loss. \n\nIn our problem, each sentence in the source domain is assumed to have its own text style. Recall that our model aims to transfer sentences in the source domain with various text styles to a target style. We rely on the style discrepancy loss to regulate the style encoder so that it can characterize the differences among these text styles. Thus, the style discrepancy loss is an inseparable part of our model, and we did not include experimental results without this loss.\n\n\n>>> how y^* is chosen in Section 3.3. \n\nWe apologize for our mistake about y^*. We have corrected this part in Section 3.2.\nFor sentences in the source domain with various unknown styles, we use a style encoder to obtain each of their representations; for those in the target domain, we assume they have only one style representation y^*, which is not obtained from the encoder function. But both y^* and the parameters of encoder functions are learned jointly. \n\n\n>>> why STB is better than the proposed method with 100k positive samples.\n\nFor each setting, we run three times and report the mean and variance of classification accuracies. In this setting, STB and our model have a similar mean accuracy (0.927:0.922), but the variance of STB (0.024) is much larger than ours (0.008). Thus STB should not be considered better than our model.\n\n\n>>> The algorithm of STB should be briefly explained in Section 4.2.\n\nWe have added the explanation of the algorithm of STB in Section 4.2."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515136642753,"tcdate":1515136642753,"number":1,"cdate":1515136642753,"id":"SJjtUsnmM","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Comment","forum":"HJLPel-CW","replyto":"Sks9k6olz","signatures":["ICLR.cc/2018/Conference/Paper550/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper550/Authors"],"content":{"title":"Response to AnonReviewer1","comment":"Thanks for your comments. We are very sorry for the late reply.\n\n>>>It does not measure how well the content is preserved.\n\nWe rigorously followed the experimental setup and performed the same model-based evaluation as in Shen et al. (2017) so that the results reported in Shen et al. (2017) and ours can be directly compared. However, we agree that this evaluation metric may be inadequate in estimating style transfer models. Thus, we randomly select 200 test samples from Yelp and perform human evaluations on four aspects of the results: content, sentiment, fluency, and overall. Detailed annotation rules are presented in the Appendix (Section 6.2).\n\nThe final evaluation results are presented in Table 16 and Table 17 in the Appendix (Section 6.2). Table 16 shows results on Yelp when source domain contains not only negative sentences but also 150k positive sentences (Table 1 row 3), and Table 17 shows results on Yelp when target domain contains only 100k positive sentences (Table 4 row 1). As can be seen, our model is better in terms of sentiment accuracy and overall quality, which is consistent with the automatic evaluation results. We are still collecting more human annotation results for all settings reported in our paper and will try to include these results in our final version.\n\n\n>>> from the qualitative examples of Yelp, I do not think that the contents are well preserved.\n\nThe examples are not dedicated to showing good results of our models only. They are used to discuss in what cases the models perform well or make some mistakes. We will revise that part more clearly in our final version. \nIn table 18 in the Appendix (Section 6.3), we provide more examples showing that our model can preserve the contents well. \n\n\n>>> not clear how good the classifier is.\n\nThe testing accuracy of the evaluation classifier is 95.36% for Yelp and 87.05% for Chat, which is stated in Section 4.3. \n\n\n>>> It seems there are only two styles in Yelp dataset, and it's not clear how many styles are there in the \"On Chat\" dataset.\n\nThe Yelp dataset has three sentiments (styles): positive, neutral, and negative. \nIn the Chat dataset, the source domain contains sentences from a real Chinese dialog dataset, which consists of responses from different people and in different contexts. Thus it is hard to determine how many styles the source domain has. The target domain contains romantic sentences collected from online novel websites and filtered by human annotators, thus all the sentences in the target domain are assumed to have a romantic style. Note that our model can transfer sentences with various unknown styles to a target style and is not restricted by the number of text styles. Thus we can directly apply the Chat dataset to validate the performance of our method.\n\n\n>>> The discriminator D_s.\n\n(1) how it is obtained\nWe divided each dataset into three parts: one for training the style transfer model, one for training D_S, and one for training the evaluation classifier. D_S and the evaluation classifier have the same CNN network structure but are trained on non-overlapping data. Statistics of data for the evaluation classifiers are presented in Table 10 and Table 12 in the Appendix. The configuration of D_s is introduced in Section 4.2.\n\n(2) how the GT labels are obtained\nFor Yelp, all the sentences in a review are assumed to share the same sentiment. Following Shen et al. (2017), reviews rated more than three stars are considered positive, those rated three stars are considered neutral, and those rated less than three stars are considered negative. The source domain contains neutral or negative sentences and the sentences are assigned a non-positive label, and we assume the target domain contains only positive sentences and assign them a positive label.\nFor Chat, a general label is assigned to sentences in the source domain because it has various language styles. Sentences in the target domain are assigned a romantic label because nearly all of them have a romantic style. Details are described in Section 4.1.\n\n(3) whether trained jointly\nD_S is pre-trained and fixed during training the style transfer model. D_s may be jointly trained. However, if we integrate it into the end-to-end training, we may start with a D_s with a low accuracy, and then our model is easy to optimize a wrong style-discrepancy loss for many epochs and get stuck into a poor local optimum. A possibly better way is to first pre-train D_s and then fine-tune it jointly during training. We will try it later to see if any further improvement can be made.\n\n(4) is it the same as the evaluation classifier\nAs replied in (1), we only use the same network structure to train D_S and the evaluation classifier, but they are trained on non-overlapping data. Thus, they are different and no testing information is revealed during training."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515642467224,"tcdate":1511931795050,"number":3,"cdate":1511931795050,"id":"Sks9k6olz","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Review","forum":"HJLPel-CW","replyto":"HJLPel-CW","signatures":["ICLR.cc/2018/Conference/Paper550/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Language style transfer using cycle-consistency loss","rating":"5: Marginally below acceptance threshold","review":"This paper is an extension of the recent language style transfer method without parallel training pairs (Shen et al. 2017). The author extend the  original algorithm from two-folds:\n\n1. A style discrepancy loss that pushes the style vector of the sentences away from target style\n2. A cycle consistency loss that makes sure the content vector of transferred sentences and style vector of the original sentence should be able to reconstruct the original sentences. \n\nBoth extensions are reasonable to me. The experiments further verify the performance gain compared against the baseline. \n\n\nI have several concerns:\n\nMetrics are not very reasonable to me: \n- It does not measure how well the content is preserved. Style transfer has two key components, the first is how well it is transferred to the target style; second is how well it preserves the original contents. However, the metric that using a pre-trained style classification network has issues in terms of evaluating how well the original content is preserved. In fact, from the qualitative examples of Yelp, I do not think that the contents are well preserved. Also it is not clear how good the classifier is. \n- It seems there are only two styles in Yelp dataset, and it's not clear how many styles are there in the \"On Chat\" dataset. \n\nThe paper does not clearly describe how D_s is obtained. Also in the formulation D_S is not optimised. I am wondering how D_S is trained, how the GT labels are obtained and whether it is trained jointly. Moreover, is this D_S same as the style classifier used in the metric? These are the crucial questions related with fair comparisons, which I would like to know specific answers to make my final decisions. \n\nMy final decision is dependent on the author's response to my questions. ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515803663227,"tcdate":1511810486192,"number":2,"cdate":1511810486192,"id":"S10nr1cgf","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Review","forum":"HJLPel-CW","replyto":"HJLPel-CW","signatures":["ICLR.cc/2018/Conference/Paper550/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Well written, valuable contribution, and good results.","rating":"7: Good paper, accept","review":"This paper introduces two new loss functions which can be used along with the existing reconstruction and adversarial losses for language style transfer. The first one is a style discrepancy loss to enforce that the discrepancy between the learnt style representation for a source sentence and the target style representation is consistent with a pre-trained discriminator. The second one is a cycle consistency loss to make sure that the the original sentence can be recovered from the content of the transferred sentence and the style of the original sentence. The proposed method does not assume that the source sentences have only one style and allows them to have unknown styles.\n\nGenerally speaking, this paper is well written and easy to follow. The ideas are straightforward and make sense given the current trends in the field. This paper does not bring completely new perspectives for the task, but the contribution is valuable to the community. \n\nThe experimental results show the effectiveness of the approach. It can be trained with source sentences having various styles and it can produce sentences in a different style without changing the content much. These are pros of the approach.\n\nThe cons of the approach may be the fact that it needs a pre-trained classifier for the style discrepancy loss. If it can be integrated into the training end-to-end, it might be better.\n\nThe experimental results show the results without the cyclic loss. The experimental results could also include results without style discrepancy loss. \n\nIt looks that this paper denotes the style of the target domain as y^* and assume that it is shared by all samples in X_2. However, y^* is also estimated by the encoder as shown in Eq. (2) and it varies depending on the input to the encoder. It is not very clear to me how y^* is chosen in Section 3.3. Please make that part clear.\n\nPlease explain the reason why STB is better than the proposed method with 100k positive samples.\n\nThe difference between STB and the proposed method is not clear without reading the reference. The algoroithm of STB should be briefly explained in Section 4.2.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515642467298,"tcdate":1511760766556,"number":1,"cdate":1511760766556,"id":"rJ8FQQYxf","invitation":"ICLR.cc/2018/Conference/-/Paper550/Official_Review","forum":"HJLPel-CW","replyto":"HJLPel-CW","signatures":["ICLR.cc/2018/Conference/Paper550/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A borderline paper","rating":"5: Marginally below acceptance threshold","review":"In this paper, the authors proposed a method to transfer the text style to a specific target style. To this end, the authors combined a text reconstruction loss, an adversarial decoding loss, a cyclic consistency loss and a style discrepancy loss. The method seems solid, and the writing is pretty good. But there are a few key issues that are not clearly addressed and the experimental results are not convincing.\n\nPros:\nThis method combines the contributions of a few previous works, and obtains a stronger and more general model. Especially it borrows the cyclic loss from the image style transfer, which provides a reasonable regularization to the text style transfer model. \n\nCons:\nThere are a few key technical issues that are not clearly addressed. Hence I'm not fully convinced that this model indeed works as claimed.\n1. Why use CNN for the style representation layer? CNN is known to be usually unable to capture long-range correlations in natural language (unless enhanced with attentions). Are long-range correlations irrelevant to the text style?\n2. The authors made an essential assumption that all target samples have the same style embedding y*. But seems none of the 4 loss functions incorporates this constraint. If y* is simply fixed somewhere in the model, then I'm worried that it may cause mode collapse (i.e. the encoder always output similar values), and one possible bad consequence is that y1_i of different sentences in the source domain may have very similar values. \n3. The experiments are toyish and not convincing. The given examples seem to exhibit certain kind of mode collapse, i.e. different examples have similar wording from a very limited vocabulary. It is possible that the generator just learned to overfit the sentiment classifier, so that the classifier thought the transferred sentences have the desired sentiment, but the transferred sentences may lack variations and hence lacks practical use. It would be convincing if the authors could transfer an English paragraph into the style of a certain author, such as Shakespeare, which can be easily evaluated by a human instead of a trained classifier.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]}},{"tddate":null,"ddate":null,"tmdate":1515158391241,"tcdate":1509126237976,"number":550,"cdate":1509739238611,"id":"HJLPel-CW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJLPel-CW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Language Style Transfer from Non-Parallel Text with Arbitrary Styles","abstract":"Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.","pdf":"/pdf/eecf5986cd71cab5e8d68e8c29b3cddca23cfadc.pdf","TL;DR":"We present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles.","paperhash":"anonymous|language_style_transfer_from_nonparallel_text_with_arbitrary_styles","_bibtex":"@article{\n  anonymous2018language,\n  title={Language Style Transfer from Non-Parallel Text with Arbitrary Styles},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJLPel-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper550/Authors"],"keywords":["style transfer","text generation","non-parallel data"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}