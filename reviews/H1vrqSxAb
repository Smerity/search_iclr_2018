{"notes":[{"tddate":null,"ddate":null,"tmdate":1515185232175,"tcdate":1515185209627,"number":5,"cdate":1515185209627,"id":"SJfBED6QG","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Comment","forum":"H1vrqSxAb","replyto":"BJ1p0Adxz","signatures":["ICLR.cc/2018/Conference/Paper260/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper260/Authors"],"content":{"title":"Responses to Reviewer #3 (1/3)","comment":"We thank the reviewer for the insightful comments. In what follows, we provide the responses. \n\n1- On data augmentation and domain adaptation literature:\n\nIn related work section, we mentioned the connection of our work to both domain adaptation and data augmentation literature. To the best of our knowledge, our experiments are not explored in either of these fields. While our focus is on analyzing generalization capability of CNNs, the results can have applications in developing better domain adaptation and data augmentation methods. \n\n2- On comparison of MLPs and CNNs:\n\nThe focus of the paper is to study the behavior of convolutional networks. However, we also provided the results for 1- and 2-layer MLPs on MNIST dataset. The reason is since the accuracies of MLP and CNN models are comparable on MNIST, the performance on negative images can give insight on the effect of the network structure on generalization capability.\n\n----------------------------------------------------------------------------------------------------------\n\nHere, we summarize the experimental results of Sections 4 and 5 on MNIST. Both the MLP and CNN models are trained using the same optimizer and without any regularization.\n\na) Training only with regular images:\n\nNetwork architecture | accuracy on regular test images | accuracy on negative test images\nMLP: 98.5%, 8%\nCNN: 99.5%, 12%\n\nb) Training with regular images and 9 classes of negative images. Test on images of excluded class.\n\nNetwork architecture | accuracy on images of excluded class\nMLP: 0% \nCNN: 0%\n\nAs can be seen, the convolutional network does not show any major difference compared to the MLP model, although one might have expected that the CNN model would perform much better, considering that it takes into account the spatial structure of images. \n\nNow, let’s repeat the experiments with batch normalization used. The results are as follows:\n\na) Training only with regular images:\n\nNetwork architecture | accuracy on regular test images | accuracy on negative test images\nMLP: 98.5%, 8%\nCNN: 99.5%, 28%\n\nb) Training with regular images and 9 classes of negative images. Test on images of excluded class.\n\nNetwork architecture | accuracy on images of excluded class\nMLP: 0% \nCNN: 98%\n\nIn these experiments, the convolutional network performs qualitatively differently compared to the MLP model. The results of first experiment imply that, when batch normalization is used, a CNN model that is only trained on regular images, partially learns to classify images based on their shape. Batch normalization, however, does not improve the performance of the MLP model. \nThe second experiment shows that when batch normalization and proper data augmentation is used, unlike MLP, the CNN model fully displays the shape bias.\n\nBased on these and other results of the paper, we concluded that CNNs do not display strong shape bias per se. They learn to classify objects based on their shapes, only when training data possesses strong color diversity and also batch normalization is used.\n\n----------------------------------------------------------------------------------------------------------\n\nOn comparing VGG and ResNet:\n\nWe did experiments on different deep networks and also on VGG with different number of layers. We observed that, in general, deeper models perform better, although not significantly. Also, the results of different networks were not significantly different."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515185249549,"tcdate":1515185143782,"number":4,"cdate":1515185143782,"id":"Hyx-EwamG","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Comment","forum":"H1vrqSxAb","replyto":"BJ1p0Adxz","signatures":["ICLR.cc/2018/Conference/Paper260/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper260/Authors"],"content":{"title":"Responses to Reviewer #3 (2/3)","comment":"3- On experiments in Figure 2:\n\nThe conclusion of experiments 1-3 of Figure 2 is that, using a specific CNN architecture does not automatically guarantee certain property, such as shape bias. Indeed, different data augmentation can fundamentally change the convergence point, while preserving the performance on the target distribution (distribution of regular images). If CNN models were to inherently display shape bias, they wouldn’t have been able to classify regular and negative images differently, both with high accuracy (experiment 3). \n\nSpecifically, we showed that, by augmenting training data differently, we can force the network to put different degree of emphasis on different features and, importantly, the network would still be able to generalize well to regular images.\n\nAs mentioned in Section 4, the results also have a security implication. Assume that a client uploads their training data to a server and obtains the trained model. The client then evaluates the model by computing the accuracy on the hold-out data. In most real-world settings, the training methods and parameters are not known to the client. Therefore, the server can maliciously train the model not only with the client data, but also with some external data or transformations of client dataset. Our results show that the server can train the model in such a way that it yields high accuracy on client dataset, while recognizing also the server-desired data. This can be used to inject backdoors in machine learning models. Further studying this problem is left for future work.\n\n4- On augmenting training data with negative images of fewer classes:\n\nFollowing reviewer’s suggestion, we did detailed experiments to examine the effect of the number of negative images in training data on the model generalization to negative images of unseen classes. The results are provided in Appendix A. \n\nTo summarize, we found that increasing the number of negative images from the same set of classes improves the accuracy on negative images of unseen classes. Also, increasing the number of classes while keeping number of negative images the same improves the generalization performance. Essentially, more number of classes enhances the diversity of negative images, and hence helps the model to better recognize negative images of unseen classes.\n\n5 and 7- On paper organization:\n\nFollowing the reviewer’s suggestions, we moved subsection 6-1 to Section 5, and combined sections 6-2 and 6-4. \n\n6- On analysis of Batch Normalization (BN):\n\nThanks for suggesting the two papers. We added them to references.\n\nIt is known that BN reduces the internal covariate shift of deep networks, and hence can help domain adaptation, as the reviewer pointed out. Current approaches of using BN for domain adaptation, including the two papers mentioned by reviewer, are focused on normalizing the middle layers to the distribution of the new domain, which improves the accuracy on the new domain.\n\nIn contrast, we used the raw BN without updating the model with respect to the distribution of negative images. As mentioned in comment 2, we observed that BN drastically improves the generalization performance of CNNs. Specifically, it improves the model accuracy on negative images from 0% to 98% for MNIST and from 16% to 76% for CIFAR10. This behavior was consistent across all of our experiments that involved training and testing on different distributions. Hence, the generalization capability of convolutional networks is fundamentally different with and without BN.\n\n8- On fine-tuning experiment:\n\nFor fine-tuning the model, we fully retrain all layers with the new dataset, i.e., we did not freeze any of the network layers. \n\nFollowing reviewer’s suggestion, we added a discussion about the difference between training with all data at the same time or with fine-tuning in two different steps. Our results show that doing data augmentation yields better results compared to fine-tuning, as the model seems to fully retain the features of the first dataset. Specifically, with fine-tuning and data augmentation, we obtained 95% and 99.8% accuracy on negative images, respectively. The proposed approach of data augmentation can also mitigate the catastrophic forgetting in neural networks [3], a phenomenon in which machine learning models “forget” features of the first task, when retrained on a second task.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515185284131,"tcdate":1515185060217,"number":3,"cdate":1515185060217,"id":"HknjQw6mf","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Comment","forum":"H1vrqSxAb","replyto":"BJ1p0Adxz","signatures":["ICLR.cc/2018/Conference/Paper260/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper260/Authors"],"content":{"title":"Responses to Reviewer #3 (3/3)","comment":"On conclusions of paper:\n\nOur focus in paper is on analyzing the generalization capability of CNNs. In [1], authors showed that CNNs display “shape bias,” i.e., they classify objects mostly based on their shape, rather than color. Also, [2] showed that deep networks learn simple patterns in training data first, before memorizing. Similar to us, they demonstrated the results by analyzing neural networks on MNIST and CIFAR10 datasets.\n\nOur paper is in line with these recent works on analyzing how CNNs generalize. In our paper, we designed controlled experiments to systematically investigate how CNNs learn the structures and generalize shapes. Experiments are designed to specifically analyze the role of various factors, such as initialization, regularization, training dataset and data augmentation. \n\nWe presented the following results:\n1-\tCNNs do not classify objects based on their shapes per se. Specifically, CNNs display shape bias only when training data possesses strong color diversity and also batch normalization is used. \n2-\tA network, trained to have shape bias on one dataset, displays shape bias on another dataset as well. \n3-\tThe shape bias property of a network does not fade away after fine-tuning with another dataset. \n4-\tAugmenting the training data with images of an unrelated dataset helps the generalization. \n5-\tCNNs do not learn shape bias property from a dataset that lacks any structure, e.g., a dataset with random images. Also, a network with shape bias does not generalize this property to random images.\n\n\nReferences:\n[1] Samuel Ritter, David GT Barrett, Adam Santoro, and Matt M Botvinick. “Cognitive psychology for deep neural networks: A shape bias case study.” arXiv preprint arXiv:1706.08606, 2017.\n[2] Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. “A closer look at memorization in deep networks.” In International Conference on Machine Learning, pp. 233–242, 2017.\n[3] Ian Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. “An empirical investigation of catastrophic forgetting in gradient-based neural networks.” arXiv preprint arXiv:1312.6211 (2013)."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515183803670,"tcdate":1515183803670,"number":2,"cdate":1515183803670,"id":"H14pR8TQf","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Comment","forum":"H1vrqSxAb","replyto":"SkdQ4Z5xz","signatures":["ICLR.cc/2018/Conference/Paper260/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper260/Authors"],"content":{"title":"Responses to Reviewer #2","comment":"We thank the reviewer for the comments. In what follows, we provide the responses. \n\n1- On paper title: we revised the title to “Assessing Capability of Convolutional Neural Networks in Generalizing Shapes”.\n\n2- On paper conclusion:\n\nCNN models are designed to take into account the spatial structure of image data. In fact, [1] showed that CNNs display “shape bias,” i.e., they classify objects mostly based on their shape, rather than color. Also, [2] argued that deep networks learn simple patterns in training data first, before memorizing. \n\nIn our paper, we showed that convolutional networks do not intrinsically tend to classify objects based on their structures. In fact, in Sections 4 and 5, we showed that a CNN model trained without batch normalization, performs similarly to an MLP model, on the MNIST dataset. Our results show that CNNs display shape bias only when certain data augmentation and regularization techniques are used. \n\nOn Figure 6:\nFigure 6 is indeed one of the main results of our paper. It shows that if data augmentation is not done properly, it can have adverse effect on the network generalization.\n\nSpecifically, we found that after training with few negative images, the model converges to the simpler hypothesis, which is classifying images based on their pixel-wise similarity to training images. As the number of negative images is increased, the model learns to classify objects based on their structure and shape. We have done this experiment with different datasets and consistently obtained similar results. \n\n3- On using negative images:\n\nFor examining the shape bias, [2] assembled a dataset consisting of 90 images (30 triples) of objects collected using Google Image Search. Images were arranged in triples consisting of a probe, a shape-match and a color-match. This approach of collecting data is limited and does not scale. In contrast, negative images are interesting in a sense that they are easy to obtain and can effectively quantify the shape generalization capability of image classifiers. Please note that we used negative images just as a tool to study the behavior of CNNs in different settings. \n\nOn using color/gray-scale images:\nWe did the experiments with negative images, because image complementing discards much of the color information and hence the model needs to rely on object structure and shape to correctly classify it. In contrast, the accuracy of a model that is trained with color images does not drop much when it is tested on gray-scale images (~5% in our experiments with CIFAR10). The reason is that, unlike negative images, the pixel values of gray-scale images is not significantly different from the color images. \n\nOn using ImageNet:\nAs stated in Section 3, we did the experiments on MNIST, CIFAR and notMNIST datasets, since the classes are very distinct and image complementing is unlikely to change the ground-truth label. Therefore, we expect the model to classify negative images into the same class as their corresponding original images. In datasets with very high number of closely related classes, such as ImageNet or CIFAR100, image complementing may change the ground-truth label of the image. Hence, the model accuracy on negative images cannot be considered as a metric for evaluating the shape bias property.\n\n4- On using transferability of features in Section 6 for domain adaptation. \n\nIn section 6, we showed that proper initialization and data augmentation by an unrelated dataset can qualitatively improve the model generalization. The results can certainly help domain adaptation. Specifically, for improving domain adaptation, we can do one of the following: 1) initializing the network with an unrelated dataset and then fine-tuning with the first target dataset, 2) augmenting the target dataset with an unrelated dataset. Our results imply that both approaches can help the domain adaptation; however, we observed that, despite the common practice in transfer learning, data augmentation approach yields better results. We added a discussion about comparing data augmentation and fine-tuning at the end of Section 6.\n\nPlease note that augmenting training data with an unrelated dataset is especially interesting, since the classes of the two datasets do not need to be related. Hence, it is easy to obtain new data and include them into the training data. Essentially, any image dataset with the desired properties would help the model generalization.\n\n\nReferences:\n[1] Samuel Ritter, David GT Barrett, Adam Santoro, and Matt M Botvinick. “Cognitive psychology for deep neural networks: A shape bias case study.” International Conference on Machine Learning, 2017.\n[2] Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. “A closer look at memorization in deep networks.” International Conference on Machine Learning, 2017."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515188409962,"tcdate":1515183342475,"number":1,"cdate":1515183342475,"id":"HyUeTUaQf","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Comment","forum":"H1vrqSxAb","replyto":"rJlJd93ef","signatures":["ICLR.cc/2018/Conference/Paper260/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper260/Authors"],"content":{"title":"Responses to Reviewer #1","comment":"We thank the reviewer for the comments. In what follows, we provide the responses.\n\nOur focus in paper is on experimentally analyzing the generalization capability of CNNs. CNN models are designed to take into account the spatial structure of image data. In fact, [2] showed that CNNs display “shape bias,” i.e., they classify objects mostly based on their shape, rather than color. Also, [3] argued that deep networks learn simple patterns in training data first, before memorizing. \n\nOur paper is in line with these recent works on analyzing the generalization capability of CNNs. We designed controlled experiments to systematically investigate how CNNs learn the structures and generalize shapes, and to examine the role of various factors, such as initialization, regularization, training dataset and data augmentation. \n\nWe presented the following results:\n1-\tCNNs do not classify objects based on their shapes per se. Specifically, CNNs display shape bias only when training data possesses strong color diversity and also batch normalization is used. \n2-\tA network, trained to have shape bias on one dataset, displays shape bias on another dataset as well. \n3-\tThe shape bias property of a network does not fade away after fine-tuning with another dataset. \n4-\tAugmenting training data with images of an unrelated dataset helps the generalization. \n5-\tCNNs do not learn shape bias property from a dataset that lacks any structure, e.g., a dataset with random images. Also, a network with shape bias does not generalize this property to random images.\n\nItems 2 and 3 explain why initializing the network with a pre-trained model usually helps the generalization. On the practical side, item 4 implies that data augmentation can be done by including an unrelated dataset into the training data. This is in contrast with current methods that augment training dataset with transformations of the same data. The proposed data augmentation method is especially helpful, when the training dataset is small.\n\nIn our paper, we used negative images as a tool to design controlled experiments and analyze the performance of CNNs. By testing on negative images, we can specifically evaluate the model for how much color invariant it is. The designed experiments are novel and can help better understand how deep networks work.\n\nOn using ImageNet:\nAs stated in Section 3, we did the experiments on MNIST, CIFAR and notMNIST datasets, since the classes are very distinct and image complementing is unlikely to change the ground-truth label. Therefore, we expect the model to classify negative images into the same class as their corresponding original images. In datasets with very high number of closely related classes, such as ImageNet or CIFAR100, image complementing may change the ground-truth label of the image. Hence, the model accuracy on negative images cannot be considered as a metric for evaluating the shape bias property.\n\nCNN models trained on benchmark datasets such as MNIST and CIFAR10 are rich enough to give insight on how convolutional networks recognize objects. In fact, a recent paper [2] on analyzing generalization performance of deep networks demonstrated the results by studying neural networks on MNIST and CIFAR10 datasets.\n\nReferences:\n[1] Samuel Ritter, David GT Barrett, Adam Santoro, and Matt M Botvinick. “Cognitive psychology for deep neural networks: A shape bias case study.” International Conference on Machine Learning, 2017.\n[2] Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. “A closer look at memorization in deep networks.” International Conference on Machine Learning, 2017."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515642421524,"tcdate":1511987160052,"number":3,"cdate":1511987160052,"id":"rJlJd93ef","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review of Assessing Generalization Capability of Convolutional Neural Networks","rating":"5: Marginally below acceptance threshold","review":"The paper presents a series of empirical studies of the generalization ability of convolutional neural networks (CNNs) applied to image recognition tasks related to shape images.  The paper makes a number of observations about the learning or transfer learning of shape bias vs. color by controlling and manipulating the input of training data based on shapes, negative shapes, and random images.   A concluding observation is that CNN models learn and generalize the structure content of images.\n\nThe work is described in sufficient detail including the experimental setups, data set, neural networks, and results.  The experiments should be reproducible given the descriptions in the paper.\n\nThe overall significance of the results is not very strong since the paper focuses solely on experiments conducted on very limited data and artificially manipulated data.  It is not clear how the observations made from the experiments generalize beyond these specific learning tasks or how one may take advantage of them in practice. \n\nOne way to greatly improve the impact of the paper would be to take the observations made from the simulated data experiments (e.g., MNIST) and use them to make changes to how CNN training is done on another real task (e.g., ImageNet) and show improvements in performance.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515642421562,"tcdate":1511818272531,"number":2,"cdate":1511818272531,"id":"SkdQ4Z5xz","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This paper studies the generalization capability of CNNs on object shapes. In particular, it trains CNNs with negative images with different architectures, regularizations, etc. The approach is heuristic, and the conclusion is not very surprising.","rating":"5: Marginally below acceptance threshold","review":"Pros: \nThe paper is clearly written and studies an interesting problem. \nThe transferrability of features described in Section 6 is interesting.\n\nCons:\n\n1. The title “assessing the generalization capability of CNNs” is too broad, as the paper is only studying a narrow aspect of generalization.\n\n2. One of the conclusions of the paper is: “Although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors.” The conclusion is obvious when we train the network to make it invariant to colors and textures.  If the emphasis of this conclusion is on  the number of images needed, then it will be good to show more analysis on Figure 6: e.g. Why does the accuracy curve drops to zero before going up? Are the negative images messing up the training when the number is between 10^1 and 10^2?\n\n3. Negative images are fast to obtain, but they are oversimplified, and can be obtained via linear transform which is easy for neural networks. Therefore it is not very convincing whether the conclusion applies to other types of data, e.g. train/test on RGB&Gray image pairs, which are more commonly seen. Larger scale experiments on ImageNet is also recommended to show how general the conclusion of the paper is.\n\n4. The transferrability of features in Section 6 is an interesting problem to explore. It could provide more insights to practical problems if more experiments were done: e.g. can this technique help domain adaptation?\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515642421604,"tcdate":1511743158560,"number":1,"cdate":1511743158560,"id":"BJ1p0Adxz","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A lot of experiments, but the concusions are a bit confused","rating":"4: Ok but not good enough - rejection","review":"The paper proposes a large experimental analysis with the goal of evaluating the generalization capabilities of CNNs.\nSpecifically the analysis involves three datasets and two visual domains for each dataset: besides the original version\nof each image a new version is created by inverting its colors, i.e. simply rescaling the color channels in [0,1] and then\napplying (1-pixel_value).\n\n+ Several possible combinations between datasets and domains are considered to evaluate the network behaviour.\nThe analysis is also performed by varying the network architectures, considering data augmentation and/or fine tuning.\n\n- The text is confused in several points and the final overall conclusions are not fully clear. Some experimental settings\nare well defined to shed light on few generalization aspects of the networks. Other do not add a significant novelty\nand their contribution is not clear.\n\nDeatailed comments:\n1) at the end of page 2 \"most conventional data transformation only introduce slight variations...limited in evaluating \nthe generalization capabilities\". Conventional data transformations are introduced for data augmentation without\nsupposing the existance of a significand domain shift between training and test data. If this shift exists (as for the\ncase of negative images) it is possible to refer to the extensive deep domain adaptation literature. \n\n2) With reference to the previous point, the experiment 1 in Figure 2 provides a standard example of domain shift.\nThe fact that 1-layer softmax and 2-layers MLP perform worse than VGG is not surprising, I do not see it as an \ninteresting contribution. It would it make more sense if the comparison was between VGG and ResNet or other\ndifferent deep structures.\n\n3) Also the results of experiments 2 and 3 in figure 2 are not surprising. \nIn my understanding, in experiment 2 the network, while learning to recognize the numbers, it also learns to\nbe invariant to color thanks to a tailored data augmentation and the good final results are expected. \nIn experiment 3 instead, the defined setting is supposed to give imporance to colors, as stated at the end of page 4.\nHowever, there is no reason to automatically expect that this will decrease the importance of shape. Every category \nis defined by a specific combination of color and shape that is well recognized at test time.\n\n4) the experiments in figure 3 show that the tailored data augmentation can be done even for a subset of the\nclasses and still work well for all of them. It would be interesting to investigate the limits of this statement: what\nwould happen by augmenting only 8 or 7 or 6 or 5... categories instead of 9?\n\n5) the experiment in section 6.1, figure 5 is just slightly different from that in figure 3. I would suggest to \nput the two together since they both demonstrate that the network can learn to be invariant to a certain\ndomain aspect as far as data augmentation is used to cover that aspect for at least a part of the observed\ncategories.\n\n6) I do not see any novel contribution in the analysis of the batch normalization (end of section 5): bn has been \npreviously used for  domain adaptation\nRevisiting Batch Normalization For Practical Domain Adaptation, arXiv:1603.04779\nAutoDIAL: Automatic DomaIn Alignment Layers, ICCV 2017\n\n7) the experiment in section 6.4 should be presented as an extreme case of that of figure 7. \nSo the two can be presented together in the same section. Dividing them makes more complicated to \ndraw general conclusions from this particular data augmentation setting.\n\n8) the fine-tuning experiments do not bring significant novelty. In figure 8, my interpretation of (a) is\nthat the initial model has learned to be invariant to color and this remains true even if the fine-tuning data\ndo not contain any negative data. Given this conclusion, I would have expected a discussion about \nthe difference between learning with all data at the same time or with fine-tuning in two different \nsteps. Morever this fine-tuning experiment needs more details: is it based only on parameter initialization\nor there are some fully frozen network layers?\n\nThis work shows few interesting results but the paper is not easy to read, the presentation is sparse \nand the bit and pieces of information do not allow to derive strong final conclusions.\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1515189506506,"tcdate":1509083711429,"number":260,"cdate":1509739396029,"id":"H1vrqSxAb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Assessing Capability of Convolutional Neural Networks in Generalizing Shapes","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/31b283063a0c639ca9f043084d33aef1c22a6632.pdf","paperhash":"anonymous|assessing_capability_of_convolutional_neural_networks_in_generalizing_shapes","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}