{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222707836,"tcdate":1512156180630,"number":3,"cdate":1512156180630,"id":"Hy6M2mybG","invitation":"ICLR.cc/2018/Conference/-/Paper642/Official_Review","forum":"HJIoJWZCZ","replyto":"HJIoJWZCZ","signatures":["ICLR.cc/2018/Conference/Paper642/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Fresh idea on adversarial training for domain adaptation ","rating":"8: Top 50% of accepted papers, clear accept","review":"I think the paper was mostly well-written, the idea was simple and great. I'm still wrapping my head around it and it took me a while to feel convinced that this idea helps with domain adaptation. A better explanation of the intuition would help other readers. The experiments were extensive and show that this is a solid new method for trying out for any adaptation problem. This also shows how to better utilize task models associated with GANs and domain adversarial training, as used eg. by Bousmalis et al., CVPR 2017, or Ganin et al, ICML 2015, Ghifary et al, ECCV 2016, etc.\n\nI think important work was missing in related work for domain adaptation. I think it's particularly important to talk about pixel/image-level adaptations eg CycleGAN/DiscoGAN etc and specifically as those were used for domain adaptation such as Domain Transfer Networks, PixelDA, etc. Other works like Ghifary et al, 2016, Bousmalis et al. 2016 could also be cited in the list of matching distributions in hidden layers of a CNN.\n\nSome specific comments: \n\nSect. 3 paragraph 2 should be much clearer, it was hard to understand.\n\nIn Sect. 3.1 you mention that each node of the network is removed with some probability; this is not true. it's each node within a layer associated with dropout (unless you have dropout on every layer in the network).  It also wasn't clear to me whether C_1 and C_2 are always different. If so, is the symmetric KL divergence still valid if it's minimizing the divergence of distributions that are different in every iteration? (Nit: capitalize Kullback Leibler)\n\nEq.3 I think the minus should be a plus?\n\nFig.3 should be improved, it wasn't well presented and a few labels as to what everything is could help the reader significantly. It also seems that neuron 3 does all the work here, which was a bit confusing to me. Could you explain that?\n\nOn p.6 you discuss that you don't use a target validation set as in Saito et al. Is one really better than the other and why? In other words, how do you obtain these fixed hyperparameters that you use? \n\nOn p. 9 you claim that the unlabeled images should be distributed uniformly among the classes. Why is that? ","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial Dropout Regularization","abstract":"We present a method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by fooling a special domain critic network. However, a drawback of this approach is that the critic simply labels the generated features as in-domain or not, without considering the boundaries between classes. This can lead to ambiguous features being generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), to encourage the generator to output more discriminative features for the target domain. Our key idea is to replace the critic with one that detects non-discriminative features, using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvement over the state of the art. We also show that our approach can be used to train Generative Adversarial Networks for semi-supervised learning.","pdf":"/pdf/29e3459d5822291fc46b545b2180a636d688db7c.pdf","TL;DR":"We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.","paperhash":"anonymous|adversarial_dropout_regularization","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial Dropout Regularization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJIoJWZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper642/Authors"],"keywords":["domain adaptation","computer vision","generative models"]}},{"tddate":null,"ddate":null,"tmdate":1512222707876,"tcdate":1511845807644,"number":2,"cdate":1511845807644,"id":"rJO3y_qgz","invitation":"ICLR.cc/2018/Conference/-/Paper642/Official_Review","forum":"HJIoJWZCZ","replyto":"HJIoJWZCZ","signatures":["ICLR.cc/2018/Conference/Paper642/AnonReviewer2"],"readers":["everyone"],"content":{"title":"An interesting method for domain adaptation","rating":"7: Good paper, accept","review":"\nUnsupervised Domain adaptation is the problem of training a classifier without labels in some target domain if we have labeled data from a (hopefully) similar dataset with labels. For example, training a classifier using simulated rendered images with labels, to work on real images. \nLearning discriminative features for the target domain is a fundamental problem for unsupervised domain adaptation. The problem is challenging (and potentially ill-posed) when no labeled examples are given in the target domain. This paper proposes a new training technique called ADR, which tries to learn discriminative features for the target domain. The key idea of this technique is to move the target-domain features away from the source-domain decision boundary. ADR achieves this goal by encouraging the learned features to be robust to the dropout noise applied to the classifier.\n\nMy main concern about this paper is that the idea of \"placing the target-domain features far away from the source-domain decision boundary\" does not necessarily lead to *discriminative features* for the target domain. In fact, it is easy to come up with a counter-example: the target-domain features are far from the *source-domain* decision boundary, but they are all (both the positive and negative examples) on the same side of the boundary, which leads to poor target classification accuracy. The loss function (Equations 2-5) proposed in the paper does not prevent the occurrence of this counter-example.\n\nAnother concern comes from using the proposed idea in training a GAN (Section 4.3). Generating fake images that are far away from the boundary (as forced by the first term of Equation 9) is somewhat opposite to the objective of GAN training, which aims at aligning distributions of real and fake images. Although the second term of Equation 9 tries to make the generated and the real images similar, the paper does not explain how to properly balance the two terms of Equation 9. As a result, I am worried that the proposed method may lead to more mode-collapsing for GAN.\n\nThe experimental evaluation seems solid for domain adaptation. The semi-supervised GANs part seemed significantly less developed and might be weakening rather than strengthening the paper. \n\nOverall the performance of the proposed method is quite well done and the results are encouraging, despite the lack of theoretical foundations for this method. \n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial Dropout Regularization","abstract":"We present a method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by fooling a special domain critic network. However, a drawback of this approach is that the critic simply labels the generated features as in-domain or not, without considering the boundaries between classes. This can lead to ambiguous features being generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), to encourage the generator to output more discriminative features for the target domain. Our key idea is to replace the critic with one that detects non-discriminative features, using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvement over the state of the art. We also show that our approach can be used to train Generative Adversarial Networks for semi-supervised learning.","pdf":"/pdf/29e3459d5822291fc46b545b2180a636d688db7c.pdf","TL;DR":"We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.","paperhash":"anonymous|adversarial_dropout_regularization","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial Dropout Regularization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJIoJWZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper642/Authors"],"keywords":["domain adaptation","computer vision","generative models"]}},{"tddate":null,"ddate":null,"tmdate":1512222707912,"tcdate":1511783868193,"number":1,"cdate":1511783868193,"id":"HJ4p6dFeG","invitation":"ICLR.cc/2018/Conference/-/Paper642/Official_Review","forum":"HJIoJWZCZ","replyto":"HJIoJWZCZ","signatures":["ICLR.cc/2018/Conference/Paper642/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review","rating":"5: Marginally below acceptance threshold","review":"(Summary)\nThis paper is about learning discriminative features for the target domain in unsupervised DA problem. The key idea is to use a critic which randomly drops the activations in the logit and maximizes the sensitivity between two versions of discriminators.\n\n(Pros)\nThe approach proposed in section 3.2 uses dropout logits and the sensitivity criterion between two softmax probability distributions which seems novel.\n\n(Cons)\n1. By biggest concern is that the authors avoid comparing the method to the most recent state of the art approaches in unsupervised domain adaptation and yet claims \"achieved state of the art results on three datasets.\" in sec5. 1) Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks, Bousmalis et al. CVPR17, and 2) Learning Transferrable Representations for Unsupervised Domain Adaptation, Sener et al. NIPS16. Does the proposed method outperform these state of the art methods using the same network architectures?\n2. I suggest the authors to rewrite the method section 3.2 so that the loss function depends on the optimization variables G,C. In the current draft, it's not immediately clear how the loss functions depend on the optimization variables. For example, in eqns 2,3,5, the minimization is over G,C but G,C do not appear anywhere in the equation. \n3. For the digits experiments, appendix B states \"we used exactly the same network architecture\". Well, which architecture was it?\n4. It's not clear what exactly the \"ENT\" baseline is. The text says \"(ENT) obtained by modifying (Springenberg 2015)\". I'd encourage the authors to make this part more explicit and self-explanatory.\n\n(Assessment)\nBorderline. The method section is not very well written and the authors avoid comparing the method against the state of the art methods in unsupervised DA.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarial Dropout Regularization","abstract":"We present a method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by fooling a special domain critic network. However, a drawback of this approach is that the critic simply labels the generated features as in-domain or not, without considering the boundaries between classes. This can lead to ambiguous features being generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), to encourage the generator to output more discriminative features for the target domain. Our key idea is to replace the critic with one that detects non-discriminative features, using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvement over the state of the art. We also show that our approach can be used to train Generative Adversarial Networks for semi-supervised learning.","pdf":"/pdf/29e3459d5822291fc46b545b2180a636d688db7c.pdf","TL;DR":"We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.","paperhash":"anonymous|adversarial_dropout_regularization","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial Dropout Regularization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJIoJWZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper642/Authors"],"keywords":["domain adaptation","computer vision","generative models"]}},{"tddate":null,"ddate":null,"tmdate":1509739185287,"tcdate":1509130141889,"number":642,"cdate":1509739182628,"id":"HJIoJWZCZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJIoJWZCZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Adversarial Dropout Regularization","abstract":"We present a method for transferring neural representations from label-rich source domains to unlabeled target domains. Recent adversarial methods proposed for this task learn to align features across domains by fooling a special domain critic network. However, a drawback of this approach is that the critic simply labels the generated features as in-domain or not, without considering the boundaries between classes. This can lead to ambiguous features being generated near class boundaries, reducing target classification accuracy. We propose a novel approach, Adversarial Dropout Regularization (ADR), to encourage the generator to output more discriminative features for the target domain. Our key idea is to replace the critic with one that detects non-discriminative features, using dropout on the classifier network. The generator then learns to avoid these areas of the feature space and thus creates better features. We apply our ADR approach to the problem of unsupervised domain adaptation for image classification and semantic segmentation tasks, and demonstrate significant improvement over the state of the art. We also show that our approach can be used to train Generative Adversarial Networks for semi-supervised learning.","pdf":"/pdf/29e3459d5822291fc46b545b2180a636d688db7c.pdf","TL;DR":"We present a new adversarial method for adapting neural representations based on a critic that detects non-discriminative features.","paperhash":"anonymous|adversarial_dropout_regularization","_bibtex":"@article{\n  anonymous2018adversarial,\n  title={Adversarial Dropout Regularization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJIoJWZCZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper642/Authors"],"keywords":["domain adaptation","computer vision","generative models"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}