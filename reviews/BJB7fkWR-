{"notes":[{"tddate":null,"ddate":null,"tmdate":1515642454310,"tcdate":1511891410443,"number":3,"cdate":1511891410443,"id":"BJ5RWXilM","invitation":"ICLR.cc/2018/Conference/-/Paper477/Official_Review","forum":"BJB7fkWR-","replyto":"BJB7fkWR-","signatures":["ICLR.cc/2018/Conference/Paper477/AnonReviewer3"],"readers":["everyone"],"content":{"title":"review","rating":"4: Ok but not good enough - rejection","review":"- This paper discusses an agent architecture which uses a shared representation to train multiple tasks with different sprite level visual statistics. The key idea is that the agent learns a shared representations for tasks with different visual statistics\n\n- A lot of important references  touching on very similar ideas are missing. For e.g. \"Unsupervised Pixel-level Domain Adaptation with Generative Adversarial Networks\", \"Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping\", \"Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics\". \n\n- This paper has a lot of orthogonal details. For instance sec 2.1 reviews the history of games and AI, which is besides the key point and does not provide any literary context. \n\n- Only single runs for the results are shown in plots. How statistically valid are the results?\n\n- In the last section authors mention the intent to do future work on atari and other env. Given that this general idea has been discussed in the literature several times, it seems imperative to at least scale up the experiments before the paper is ready for publication","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games","abstract":"Many deep reinforcement learning approaches use graphical state representations,\nthis means visually distinct games that share the same underlying structure cannot\neffectively share knowledge. This paper outlines a new approach for learning\nunderlying game state embeddings irrespective of the visual rendering of the game\nstate. We utilise approaches from multi-task learning and domain adaption in\norder to place visually distinct game states on a shared embedding manifold. We\npresent our results in the context of deep reinforcement learning agents.","pdf":"/pdf/7e363a7fca433fde62ac5acc4d8fc8a55eff2a66.pdf","TL;DR":"An approach to learning a shared embedding space between visually distinct games.","paperhash":"anonymous|domain_adaptation_for_deep_reinforcement_learning_in_visually_distinct_games","_bibtex":"@article{\n  anonymous2018domain,\n  title={Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJB7fkWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper477/Authors"],"keywords":["Deep Reinforcement Learning","Domain Adaptation","Adversarial Networks"]}},{"tddate":null,"ddate":null,"tmdate":1515642454347,"tcdate":1511805928742,"number":2,"cdate":1511805928742,"id":"SyZl4CKeM","invitation":"ICLR.cc/2018/Conference/-/Paper477/Official_Review","forum":"BJB7fkWR-","replyto":"BJB7fkWR-","signatures":["ICLR.cc/2018/Conference/Paper477/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting idea maybe? Very poor experimental section.","rating":"2: Strong rejection","review":"This paper introduces a method to learn a policy on visually different but otherwise identical games. While the idea would be interesting in general, unfortunately the experiment section is very much toy example so that it is hard to know the applicability of the proposed approach to any more reasonable scenario. Any sort of remotely convincing experiment is left to 'future work'.\n\nThe experimental setup is 4x4 grid world with different basic shape or grey level rendering. I am quite convinced that any somewhat correctly setup vanilla deep RL algorithm would solve these sort of tasks/ ensemble of tasks almost instantly out of the box.\n\nFigure 5: Looks to me like the baseline is actually doing much better than the proposed methods?\n\nFigure 6: Looking at those 2D PCAs, I am not sure any of those method really abstracts the rendering away. Anyway, it would be good to have a quantified metric on this, which is not just eyeballing PCA scatter plots.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games","abstract":"Many deep reinforcement learning approaches use graphical state representations,\nthis means visually distinct games that share the same underlying structure cannot\neffectively share knowledge. This paper outlines a new approach for learning\nunderlying game state embeddings irrespective of the visual rendering of the game\nstate. We utilise approaches from multi-task learning and domain adaption in\norder to place visually distinct game states on a shared embedding manifold. We\npresent our results in the context of deep reinforcement learning agents.","pdf":"/pdf/7e363a7fca433fde62ac5acc4d8fc8a55eff2a66.pdf","TL;DR":"An approach to learning a shared embedding space between visually distinct games.","paperhash":"anonymous|domain_adaptation_for_deep_reinforcement_learning_in_visually_distinct_games","_bibtex":"@article{\n  anonymous2018domain,\n  title={Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJB7fkWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper477/Authors"],"keywords":["Deep Reinforcement Learning","Domain Adaptation","Adversarial Networks"]}},{"tddate":null,"ddate":null,"tmdate":1515642454384,"tcdate":1510305655712,"number":1,"cdate":1510305655712,"id":"H1xFygmyz","invitation":"ICLR.cc/2018/Conference/-/Paper477/Official_Review","forum":"BJB7fkWR-","replyto":"BJB7fkWR-","signatures":["ICLR.cc/2018/Conference/Paper477/AnonReviewer1"],"readers":["everyone"],"content":{"title":"This paper contains interesting ideas, but it is not ready for publication.","rating":"3: Clear rejection","review":"In this paper, the authors propose a new approach for learning underlying structure of visually distinct games.\n\nThe proposed approach combines convolutional layers for processing input images, Asynchronous Advantage Actor Critic for deep reinforcement learning task and adversarial approach to force the embedding representation to be independent of the visual representation of games. \n\nThe network architecture is suitably described and seems reasonable to learn simultaneously similar games, which are visually distinct. However, the authors do not explain how this architecture can be used to do the domain adaptation. \nIndeed, if some games have been learnt by the proposed algorithm, the authors do not precise what modules have to be retrained to learn a new game. This is a critical issue, because the experiments show that there is no gain in terms of performance to learn a shared embedding manifold (see DA-DRL versus baseline in figure 5).\nIf there is a gain to learn a shared embedding manifold, which is plausible, this gain should be evaluated between a baseline, that learns separately the games, and an algorithm, that learns incrementally the games. \nMoreover, in the experimental setting, the games are not similar but simply the same.\n\nMy opinion is that this paper is not ready for publication. The interesting issues are referred to future works.\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games","abstract":"Many deep reinforcement learning approaches use graphical state representations,\nthis means visually distinct games that share the same underlying structure cannot\neffectively share knowledge. This paper outlines a new approach for learning\nunderlying game state embeddings irrespective of the visual rendering of the game\nstate. We utilise approaches from multi-task learning and domain adaption in\norder to place visually distinct game states on a shared embedding manifold. We\npresent our results in the context of deep reinforcement learning agents.","pdf":"/pdf/7e363a7fca433fde62ac5acc4d8fc8a55eff2a66.pdf","TL;DR":"An approach to learning a shared embedding space between visually distinct games.","paperhash":"anonymous|domain_adaptation_for_deep_reinforcement_learning_in_visually_distinct_games","_bibtex":"@article{\n  anonymous2018domain,\n  title={Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJB7fkWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper477/Authors"],"keywords":["Deep Reinforcement Learning","Domain Adaptation","Adversarial Networks"]}},{"tddate":null,"ddate":null,"tmdate":1509739281217,"tcdate":1509122588988,"number":477,"cdate":1509739278557,"id":"BJB7fkWR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJB7fkWR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games","abstract":"Many deep reinforcement learning approaches use graphical state representations,\nthis means visually distinct games that share the same underlying structure cannot\neffectively share knowledge. This paper outlines a new approach for learning\nunderlying game state embeddings irrespective of the visual rendering of the game\nstate. We utilise approaches from multi-task learning and domain adaption in\norder to place visually distinct game states on a shared embedding manifold. We\npresent our results in the context of deep reinforcement learning agents.","pdf":"/pdf/7e363a7fca433fde62ac5acc4d8fc8a55eff2a66.pdf","TL;DR":"An approach to learning a shared embedding space between visually distinct games.","paperhash":"anonymous|domain_adaptation_for_deep_reinforcement_learning_in_visually_distinct_games","_bibtex":"@article{\n  anonymous2018domain,\n  title={Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJB7fkWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper477/Authors"],"keywords":["Deep Reinforcement Learning","Domain Adaptation","Adversarial Networks"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}