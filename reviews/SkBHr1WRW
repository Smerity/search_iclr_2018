{"notes":[{"tddate":null,"ddate":null,"tmdate":1515161144608,"tcdate":1513663351576,"number":6,"cdate":1513663351576,"id":"r1lYsm8Mz","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Comment","forum":"SkBHr1WRW","replyto":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference/Paper479/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper479/Authors"],"content":{"title":"Announcement for reviewers","comment":"A revision updated (latest updated on 5 Jan.)\n* Section 3\n - replace Algorithm steps of Ego-Convolution with formal definition\n - add comparison to previous work to show why they fail to detect precise structure\n - rewrite verbose sentences without changing the meaning and fix typos\n* Section 4\n - add details to visualization steps\n - add definition of scale-free"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1513664451611,"tcdate":1513663250022,"number":5,"cdate":1513663250022,"id":"Sk5zj78zz","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Comment","forum":"SkBHr1WRW","replyto":"H1FOVLn-G","signatures":["ICLR.cc/2018/Conference/Paper479/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper479/Authors"],"content":{"title":"Re: Review","comment":"Dear reviewer,\nThank you for your time and comments. Before replying your specific comments, we think it is necessary to clarify some misunderstandings first.\n\nFirst, the model of Kipf and Welling [1] is not quite related to our paper, and this may have misled you from judging the novelty.\n\nYou said:\n>> Regarding novelty: The general idea of Ego-CNN seems to be quite closely related to the model of Kipf and Welling.\n\nOur main idea is to detect the “precise” critical structure but not aiming to be a generalization of Weisfeiler-Lehman(WL).\nIn fact, as you pointed out in Appendix A.1 of Kipf and Welling [1], to be a generalization of WL, it only requires the algorithm to approximate the “hash function” in WL. And to generalize WL, convolving on the “summation” of neighbors’ node embeddings is enough.\n\nHowever, being a generalization of WL is not enough to detect the “precise” neighborhood structure. As “summing” over neighbors’ node embeddings loses the relative position of neighbors’ neighborhoods (which is also the same problem as Neural Fingerprints [2] and is discussed in Section 2 in the draft).\n\nAnd that is the reason why we design our filters to learn the “entire” neighborhood structure, but not an approximation (i.e. “summation” of neighboring node embeddings). Although the math formula may look similar, the underlying ideas are quite different. It is the goal of detecting precise structure that separates us from those previous works such as Kipf and Welling[1], and Neural Fingerprints[2].\n\nWe hope the above explanation can help you understand the fundamental difference between our work and Kipf and Welling [1].\n\nThe following answers your specific comments:\n\nQ: The paper lacks a complete formal definition of the model\nA: Thank for your comment. \nWe have  replaced the Algorithm describing Ego-Convolution with formal math definition in the revision. \nAlso, more explanation is added to section 4.1 visualization based on your suggestion.\n\nQ: >> - The discussion of scale-free regularization in Section 4.2 is very hand-wavy...\nA: Thanks, we have cited the definition of a Scale-Free network [3] and added further explanations to the paper, as extracted below:  “Scale-Free networks [3] are networks with self-similarity, which means the same patterns can be observed when zooming at different scales.” \nThe power-low distribution shown in the paper is a common indicator for scale-free networks.\nAnd, by the definition of “self-similar” property, the weight-tying (i.e.repeat the combination of neighborhood patterns at each layer) is a natural way to generate scale-free networks(, and the power-law degree distribution will surely follow).\n\nQ: why can't Neural Fingerprint detect critical structures?\nA: It is that the filters in Neural Fingerprint only learn the approximated neighborhood(i.e. summation of neighbors’ node embeddings). Neural Fingerprint is basically a hash function that maps a graph to a unique fingerprint. But you cannot do the inverse to derive precise structure from a given fingerprint in their model(due to the summation in their design) and they do not need to be able to.\nAlthough, you may argue it is possible to use a dictionary to store the mapping. But that additional dictionary is not even needed in our case. The above has been explained in Section 2.\n\nQ: Similarly, how is the k-node neighborhood constraint of Patchy-San different than the one of Ego-CNN?\nA: Sorry, we do not understand your question very well. Are you asking why the k used in Patchy-San layer and the one in Ego-Convolution can be different? (ex: k=10 in Patchy-San layer, and k=16 in Ego-Convolution)\nBecause our main idea is to “aggregate” k neighbors’ neighborhoods, the size of the neighborhoods has nothing to do with the aggregation. As long as the neighborhoods are centered at the corresponding node, our Ego-Convolution can generate enlarged neighborhoods by aggregation.\n\nIf you have further questions, please feel free to comment below. And we appreciate if you could update your rating if the above clears your doubts.\n\n\n[1] Kipf et al. \"Semi-supervised classification with graph convolutional\", ICLR 2017.\n[2] Duvenaud et al. “Convolutional networks on graphs for learning molecular fingerprints”, NIPS 2015.\n[3] LI, Lun, et al. “Towards a theory of scale-free graphs: Definition, properties, and implications. Internet Mathematics”, 2005."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1515161450288,"tcdate":1513663172838,"number":4,"cdate":1513663172838,"id":"rkp69mLfM","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Comment","forum":"SkBHr1WRW","replyto":"rk7Oq1oxG","signatures":["ICLR.cc/2018/Conference/Paper479/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper479/Authors"],"content":{"title":"Re: Interesting topic but poor/informal presentation","comment":"Dear reviewer,\nThank you for time and constructive comments. Here are our answers to your questions.\n\nQ: What exactly Patchy-San cannot do but we can?\n\nBoth of Patchy-San and ours can detect useful patterns, but ours are more efficient in terms of the size of detectable local regions.\n\nRemind that Patchy-San scans the k x k adjacency matrix of neighborhoods formed by the k nearest neighbors. However, Patchy-San (proposed in their paper) is only a “single layer” model, meaning that it can only detect local neighborhoods with at most k nodes. By contrast, the detectable size of local neighborhoods of our Ego-CNN is increased as depth increases.\n\nIn Section 2, we tried to “generalize” Patchy-San’s idea (detecting patterns in the adjacency matrix of a node) to multiple layers and showed that generalization fails.\nHowever, Patchy-San cannot be directly stacked into multiple layers because the output of Patchy-San(i.e. neighborhood embeddings) cannot be treated as the required input \"adjacency matrix\" of the next Patchy-San layer.\nA naive way to generate the required k x k adjacency matrix is to calculate the pairwise similarity of the k neighborhoods with the most similar embeddings.\nThis generalization does enlarge the receptive fields of Patchy-San as depth increases. \n\nHowever, as stated in Section 2, it would be very hard to realize in practice because of two reasons:\n(1) similar neighborhoods are selected based on the “output” of previous layer. During training, the output of previous layer is likely to change, making the composition of a neighborhood “non-static”.\n(2) similar neighborhoods may not be adjacent at a deeper layer, preventing the enlarged receptive field of a neuron from denoting a local neighborhood (i.e. connected subgraph) .\n\nThe components forming into a neighborhood at deeper layer are likely to change and may spread out to the \"entire graph\" during training. Thus, this generalization (based on adjacency matrix) does not give neighborhoods corresponding to local regions. And our egocentric design is designed to solve the above problems.\n\nBack to the sentences that are confusing to you: \n>> “The reason why the idea of Patchy-San fails to generalize into multiple layers is that its\n>> definition of neighborhood, which is based on adjacency matrix, is not static and may not\n>> corresponding to local regions in the graph. ”\n\nThank you for picking them out. We meant to briefly mention the drawbacks of the “generalized” version. In fact, the “adjacency matrix” is the one defined on the neighborhood embeddings. \nHere is an update with more details:\n“The reason why the idea of Patchy-San fails to generalize into multiple layers is that its definition of neighborhood (which is based on adjacency matrix) makes the composition of neighborhoods at deeper layer not static and may not corresponding to local regions in the graph. ”\n\nQ: >> \"Our main idea is to use the egocentric design, i.e. ...\" Unfortunately, I find it difficult to understand \n     >> what this means.\nA: Thanks for your constructive comments, we have revised Section 3 based on your suggestions. \n\nQ: What exactly is the formal definition of the method?\nA:We replace the Algorithm describing steps of Ego-Convolution with formal definition in math formula. Please refer to the Section 3.\n\nIf you have further questions, please comment below. And we appreciate if you could update your rating if the above clears your doubts."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1513662626000,"tcdate":1513662626000,"number":3,"cdate":1513662626000,"id":"S1cjuXIMf","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Comment","forum":"SkBHr1WRW","replyto":"Hk3rCW5ef","signatures":["ICLR.cc/2018/Conference/Paper479/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper479/Authors"],"content":{"title":"Re: A well designed architecture for task driven graph embedding","comment":"Dear Reviewer,\nThank you for the positive comments and useful suggestions. We have revise based on your suggestions.\n\nQ: >> “1. The two panels of Figure 1 seems redundant.”\nA: Thank you for the suggestion. Indeed, having Figure 1(b) is enough.\n\nQ: >> “2. Figure 4 does not provide useful information, especially ...”\nA: Thank you for pointing out. We have include that in Figure 4.\n\nQ: >> “3. There seems to be a mistake in Figure 5 with the top neighborhood in white”\nA: You are right. Thanks for pointing out.\n\nQ: >> “4. The connection between weight-tying and scale-free structure needs better explanation. Are the authors trying to say that fractal processes generates power-law degree distributions?”\nA: Thanks, we have cited the definition of a Scale-Free network [1] and added further explanations to the paper, as extracted below:  “Scale-Free networks [1] are networks with self-similarity, which means the same patterns can be observed when zooming at different scales.” \nThe power-low distribution shown in the paper is a common indicator for scale-free networks.\nAnd, by the definition of “self-similar” property, the weight-tying (i.e.repeat the combination of neighborhood patterns at each layer) is a natural way to generate scale-free networks(, and the power-law degree distribution will surely follow).\n\nQ: >> 5. “it might be better to look into structures in high level layers for truly global signatures ...”\nA: Thank for your suggestion. Hopefully, we would try other way to show global signatures before 5 Jan.\n\n[1] LI, Lun, et al. “Towards a theory of scale-free graphs: Definition, properties, and implications”. Internet Mathematics, 2005."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1515642454579,"tcdate":1513018481060,"number":3,"cdate":1513018481060,"id":"H1FOVLn-G","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Review","forum":"SkBHr1WRW","replyto":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference/Paper479/AnonReviewer4"],"readers":["everyone"],"content":{"title":"Review","rating":"4: Ok but not good enough - rejection","review":"The paper proposes a new method (Ego-CNN) to compute supervised embeddings of graphs based on the neighborhood structure of nodes. Using an approach similar to attention and deconvolution, the paper also aims to detect substructures in graphs that are important for a given supervised task.\n\nLearning graph representations is an important task and fits well into ICLR. The paper pursues interesting ideas and shows promising experimental results. I've also found the focus of the paper on interpretability (by detecting important substructures) interesting and promising. However, in its current form, I am concerned about both the novelty and the clarity of the paper.\n\nRegarding novelty: The general idea of Ego-CNN seems to be quite closely related to the model of Kipf and Welling [2]. Unfortunately, this connection is neither made clear in the discussion of related work, nor does the experimental evaluation include a comparison. In particular, the paper mentions that Ego-CNN is similar to the Weißfeiler-Lehman (WL) algorithm. However, the same is the case for [2] (see Appendix A in [2] for a discussion). It would therefore be important to discuss the benefits of Ego-CNN over [2] clearly, especially since [2] is arguably simpler and doesn't require a fixed-size neighborhood.\n\nRegarding clarity: In general, the paper would greatly benefit from a clearer discussion of methods and results. For instance,\n- The paper lacks a complete formal definition of the model.\n- Detecting critical substructures is an explicit focus of the paper. However, Section 4.1 provides only a very short description of the proposed approach and lacks again any formal definition. Similarly, the experimental results in Section 5.3 require a deeper analysis of the detected substructures as the presented examples are mostly anecdotal. For instance, quantitative results on synthetic graphs (where the critical substructures are known) would improve this section.\n- The discussion of scale-free regularization in Section 4.2 is very hand-wavy. It lacks again any formal proof that the proposed approach exploits scale-free structures or even a proper motivation why this regularization should improve results. Furthermore, the experimental results in Section 5.2 are only evaluated on a single dataset and it is difficult to say whether the improvement gains are due to some scale-free property of the model. For instance, the improvement could also just stem from the different architecture and/or decreased overfitting due to the decreased number of parameters from weight-tying.\n \nFurther comments:\n- The discussion of related work is sometimes unclear. For instance, precisely why can't Neural Fingerprint detect critical structures? Similarly, how is the k-node neighborhood constraint of Patchy-San different than the one of Ego-CNN?\n- In graph theory, the standard notion of neighborhood are all nodes adjacent to a given node, e.g., see [1]\n- The writing could be improved, since I found some passages difficult to read due to typos and sentence structure.\n\n[1] https://en.wikipedia.org/wiki/Neighbourhood_(graph_theory)\n[2] Kipf et al. \"Semi-supervised classification with graph convolutional\", 2017.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1515642454618,"tcdate":1511877227407,"number":2,"cdate":1511877227407,"id":"rk7Oq1oxG","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Review","forum":"SkBHr1WRW","replyto":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference/Paper479/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting topic but poor/informal presentation ","rating":"4: Ok but not good enough - rejection","review":"Dear authors,\n\nThank you for your contribution to ICLR. The problem you are addressing with your work is important. Your paper is well-motivated. Detecting and exploiting \"critical structures\" in graphs for graph classification is indeed something that is missing in previous work. \n\nAfter the introduction you discuss some related work. While I really appreciate the effort you put into this section (including the figures etc.) there are several inaccuracies in the portrayal of existing methods. Especially the comparison to Patchy-san is somewhat vague. Please make sure that you clearly state the differences between patchy-san and Ego-CNNs. What exactly is it that Patchy cannot achieve that you can. I believe I understood what the advantages of the proposed method are but it took a while to get there. Just one example to show you what I mean; you write:\n\n\"The reason why the idea of Patchy-San fails to generalize into multiple layers is that its definition of\nneighborhood, which is based on adjacency matrix, is not static and may not corresponding to local\nregions in the graph. \"\n\nIt is very difficult to understand what it is that you want to express with the above sentence. Its definition of neighborhood is based on adjacency matrix - what does that mean? A neighborhood is a set of nodes, no? Why is it that their definition of neighborhood might not correspond to local regions? In general, you should try to be more precise and concise when discussing related work. \n\nSection 3, the most important section in the paper that describes the proposed Ego-CNN approach, should also be written more clearly. For instance, it would be good if you could define the notion of an \"Ego-Convolution layer.\" You use that term without properly defining it and it is difficult to make sense of the approach without understanding it. Also, you contrast your approach with patchy and write that \"Our main idea is to use the egocentric design, i.e. the neighborhood at next\nlayer is defined on the same node.\" Unfortunately, I find it difficult to understand what this means. In general, this section is very verbose and needs a lot more work. This is at the moment also the crucial shortcoming of the paper. You should spent more time on section 3 and formally and more didactically introduce your approach. In my opinion, without a substantial improvement of this section, the paper should not be accepted. \n\nThe experiments are standard and compare to numerous existing state of the art methods. The data sets are also rather standard. The one thing I would add to the results are the standard deviations. It is common to report those. Also, in the learning for graph structured data, the variance can be quite high and providing the stddev would at least indicate how significant the improvements are. \n\nI also like the visualizations and the discussion of the critical structures found in some of the graphs.\n\nOverall, I think this is an interesting paper that has a lot of potential. The problem, however, is that the presentation of the proposed approach is verbose and partially incomprehensible. What exactly is different to existing approaches? What exactly is the formal definition of the method? All of this is not well presented and, in my opinion, requires another round of editing and reviews.\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1515642454656,"tcdate":1511820868158,"number":1,"cdate":1511820868158,"id":"Hk3rCW5ef","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Review","forum":"SkBHr1WRW","replyto":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference/Paper479/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A well desgined architechture for task driven graph embedding","rating":"7: Good paper, accept","review":"The authors proposed a convolutional framework based on merging ego-networks. It combines graph embedding layers with task driven output layers, producing interpretable results for critical structure detection. While based on existing embedding methods such as Patchy-San, the contribution of ego-centric convolution and multi-layer architechture is novel and has a lot of potential in applications. The overall presentation of the draft is also of high quality. I recommend its publication at ICLR.\n\nHere is a list of suggested changes to further improve the draft,\n\n1. The two panels of Figure 1 seems redundant.\n\n2. Figure 4 does not provide useful information, especially in terms of how overlapping neighborhoods are aggregated at deeper layers.\n\n3. There seems to be a mistake in Figure 5 with the top neighborhood in white\n\n4. The connection between weight-tying and scale-free structure needs better explanation. Are the authors trying to say that fractal processes generates power-law degree distributions?\n\n5. The visualization of critical structures are very helpful. However, it might be better to look into structures in high level layers for truly global signatures. This is especially the case for the reddit dataset, where visualizations at the node and edge level creates hairballs.\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1511249460668,"tcdate":1509268498143,"number":2,"cdate":1509268498143,"id":"rk9fnGXRZ","invitation":"ICLR.cc/2018/Conference/-/Paper479/Official_Comment","forum":"SkBHr1WRW","replyto":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference/Paper479/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper479/Authors"],"content":{"title":"Correction of Typos","comment":"\n* In the 4th paragraph of section 1., The only work ... is Spatial GCN ..., but it has the complexity O(N^2), ... should be O(N^3).\n* In section 3. Effective Receptive Field on Ambient Graph, all reference to Figure 4.2 should be Figure 6.\n* Table 4. caption should be \"Ego-CNN with ...\"\n* Figure 8(b) caption should be C_82 H_165 OH"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]}},{"tddate":null,"ddate":null,"tmdate":1515165468434,"tcdate":1509123389370,"number":479,"cdate":1509739277287,"id":"SkBHr1WRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SkBHr1WRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures","abstract":"While existing graph embedding models can generate useful embedding vectors that perform well on graph-related tasks, what valuable information can be jointly learned by a graph embedding model is less discussed. In this paper, we consider the possibility of detecting critical structures by a graph embedding model. We propose Ego-CNN to embed graph, which works in a local-to-global manner to take advantages of CNNs that gradually expanding the detectable local regions on the graph as the network depth increases. Critical structures can be detected if Ego-CNN is combined with a supervised task model. We show that Ego-CNN is (1) competitive to state-of-the-art graph embeddings models, (2) can nicely work with CNNs visualization techniques to show the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency.","pdf":"/pdf/3ed1125fb6b161177afa9693bd98b5cc305d92f2.pdf","paperhash":"anonymous|egocnn_an_ego_networkbased_representation_of_graphs_detecting_critical_structures","_bibtex":"@article{\n  anonymous2018ego-cnn:,\n  title={Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkBHr1WRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper479/Authors"],"keywords":["graph embedding","CNN"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}