{"notes":[{"tddate":null,"ddate":null,"tmdate":1515025843913,"tcdate":1515025843913,"number":3,"cdate":1515025843913,"id":"ByhnHxsXM","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Comment","forum":"HyiS6k-CW","replyto":"Hyjfce1mG","signatures":["ICLR.cc/2018/Conference/Paper527/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper527/Authors"],"content":{"title":"Clarifications on novelty and scalability","comment":"To us, the novelty in our paper comes in proposing a methodology for studying and interacting with human observers, which involves selecting the right combination of dataset, model, evaluation methods, and tractable applications.\n\nWe do not quite understand the issues with scale that were raised generally. We feel that scale works in our favor in this work, since the nature of the well-controlled portraits allows for a much smaller set of images to be used. \n\nAlthough the models trained appear to us to be capable of generating many new faces that are variations on the original dataset, we believe that the only limitation of the current dataset size is that it may not capture a large enough portion of possible human identities (e.g., Obama’s face). However, we think smaller datasets with diverse human faces are more likely to avoid this problem than large datasets with redundant identities and strong biases (i.e., attractive American celebrities), and the requirement that much more variation be captured by the corresponding models (i.e., perspective). We should also note that Humanae is constantly growing, currently at 3,545 images since the current draft of our paper.\n\nPlease refer to our other responses that address the issue of missing technical details. Like other models used in the paper, our enlargement procedure comes from the author’s official implementation and no changes beyond altering the data source and setting the input and output size parameters were necessary to obtain the reported results. We will make a note of this and report these defaults in the final version of our paper, along with links to the original repositories, our forked versions, and the fully preprocessed data."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1515025771180,"tcdate":1515025771180,"number":2,"cdate":1515025771180,"id":"HJ7uSesXf","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Comment","forum":"HyiS6k-CW","replyto":"rJSDZVNlf","signatures":["ICLR.cc/2018/Conference/Paper527/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper527/Authors"],"content":{"title":"Clarifications and technical details","comment":"To us, the novelty in our paper comes in proposing a methodology for studying and interacting with human observers, which involves selecting the right combination of dataset, model, evaluation methods, and tractable applications.\n\nIn terms of technical details, we should make clear that all of the models used, with the exception of DFC-VAE, were the original implementations from those models’ authors, and all three implementations are freely available and require no modifications besides altering the data source to obtain the reported results. We originally searched hyperparameters broadly, but found no real advantage as opposed to searching model architectures instead, which we do in our paper. We will make this process clear in our final paper and include links to all implementations. Upon acceptance of our paper, we will also release our forked versions of the code and our preprocessed portrait sets. If the reviewer would like to obtain a trained model, or the training code and datasets, we are happy to oblige.\n\nWe also found it surprising that some models performed so well with so little data, but it is important to note that all faces are aligned, forward-facing, and of similar scale. Part of the novelty of our paper is to strategically exploit the highly controlled variation that the artist labored to produce to solve just the problem set before us. We discuss this in our outline and sections 2, 2.1, and 6. We feel that obtaining “impressive” results through simple means (innovative dataset selection) should be regarded as a strong positive, as opposed to say proposing a complicated method with scant improvements.\n\nAs for the reference in section 2.1, it was an error and should be a citation to Kazemi & Sullivan’s 2014 CVPR paper. The error is fixed in the updated manuscript. Thanks for pointing this out."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1515025780065,"tcdate":1515025674579,"number":1,"cdate":1515025674579,"id":"Hy7GSlsQf","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Comment","forum":"HyiS6k-CW","replyto":"rkIoAWDlf","signatures":["ICLR.cc/2018/Conference/Paper527/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper527/Authors"],"content":{"title":"Clarifications on novelty and scope of the paper","comment":"To us, the novelty in our paper comes in proposing a methodology for studying and interacting with human observers, which involves selecting the right combination of dataset, model, evaluation methods, and tractable applications.\n\nThe claim that the dataset used is unique is based on the reported objective of the artist, the result of which is a set of portraits that specifically aims to capture the gamut of skin tones while controlling other factors. In fact, each individual observation in the dataset is meant to capture a different perceived skin color. Rather than competing with datasets meant to make facial recognition in the wild more robust, we find this dataset uniquely suited to studying aspects of human face representation, since it is well-controlled enough to be captured by current models in the field, and captures a fascinating subset of variation in facial appearance. We agree that including basic statistics about other datasets would make this clearer, and will include more details in the final paper. \n\nNote that a comparison to StackGAN does not apply, since our dataset does not contain textual descriptions, and our aim was to learn a space and select an algorithm that would allow a human to efficiently search that space with arbitrary criteria in mind, not just those included in a caption dataset.\n\nFor a demo of a method for navigating the face space, please see the final section of our paper. Indeed, we found subjects were able to navigate the high-dimensional space in a small number of trials, arriving at plausible mental pictures for the textual cues in question.\n\nAnswers to questions: The line between “fine detail” and “new identity” is a fascinating question that we aim to eventually answer using these models and additional human experiments. We believe this paper lays the groundwork for allowing such questions to be answered. Thank you for bringing the unexplained notation to our attention; we will include descriptions in our final paper.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1515642462442,"tcdate":1514240530837,"number":3,"cdate":1514240530837,"id":"Hyjfce1mG","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Review","forum":"HyiS6k-CW","replyto":"HyiS6k-CW","signatures":["ICLR.cc/2018/Conference/Paper527/AnonReviewer5"],"readers":["everyone"],"content":{"title":"Impressive results but lacking details and novelty","rating":"4: Ok but not good enough - rejection","review":"This paper investigates identity space learning with well-controlled variations using an artistic portraits dataset. Especially, the authors propose a visual Turing test to evaluate the synthesize quality of three generative models: WGAN-GP, DFC-VAE, and Pixel VAE.\n\nThe submission has following PROS:\n\n+ The proposed visual Turing test provides a novel solution to evaluate the generation quality. The test not only distinguishes real from synthesized faces but also evaluates the observer ability by determining whether the observer is a human. This is a merit compared with existing protocols used in generation evaluation. \n\n+ The generated face images are very impressive, especially the improved 512x512-pixel outputs.\n\n+ The paper presents a promising application in police composite sketching, which can significantly improve human-in-the-loop search in face modeling. \n\nHowever, the submission also suffers from multiple CONS:\n\n- The novelty of this paper is limited. The only novelty I can pinpoint is the proposed visual Turing test. The dataset, as well as all investigated models/approaches, are existing work. The visual Turing test is interesting but not concrete enough to support an ICLR publication.\n\n- A very small dataset (3,300 subjects and 3,353 images) is used in the whole investigation. It is doubtful that the conclusion or results obtained in this small dataset could be scaled up to real-world applications or datasets (millions of subjects and images). It would be favorable to empirically prove this by designing additional experiments.\n\n- Missing details. \n(a)In section 4, how to use formal method (Ledig et al., 2016) to enlarge the portrait from 64x64 to 512x512 is unclear.\n(b) Lacking details of the model setups and training strategies. The generation models are usually highly sensitive to details settings. The readers can hardly reproduce the results or evaluate possible performance by reading the paper. \n(c) If the paper length is limited, a supplementary material about those details would be preferred.\n\n- Typos.\n(a) Page 7, \"Figure 8 shows the seeds and example images for 10 rounds...\" \n----> Figure 8 should be Figure 10\n(b) Page 4, \"yet is is unclear how many pixels are required...\"\n----> yet is is","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1515642462481,"tcdate":1511624350025,"number":2,"cdate":1511624350025,"id":"rkIoAWDlf","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Review","forum":"HyiS6k-CW","replyto":"HyiS6k-CW","signatures":["ICLR.cc/2018/Conference/Paper527/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Pleasing results but uses existing methodologies ","rating":"5: Marginally below acceptance threshold","review":"This paper proposes a new space for reasoning about human identity. It proposes a new dataset based on an artist's work, and compares existing methods in terms of the realism of the synthetic faces they can create. \n\nPros:\n+ The results are very pleasing visually.\n+ The authors show that one of the existing methods can fairly successfully fool humans to believe its synthetic results are actual human faces.\n\nCons:\n- There is no new methodology proposed.\n- If the main contribution is the dataset, perhaps the claim that it is \"uniquely diverse\" could be justified with some quantitative arguments / statistics, comparing to other datasets. \n- Since there are existing methods to generate images from a textual description (e.g. Zhang ICCV 2017, \"StackGAN\"), Fig. 10 merits a comparison to those.\n- It would have been convincing to see an experiment showing actual use of the proposed method for navigating the face space, e.g. for finding criminals based on a description.\n\nQuestions:\n- \"Inventing plausible fine details while preserving identity\" -- since identity is created and there is no ground truth, where does the line between \"fine detail\" and \"new identity\" lie?\n- Some notation is not defined in the equation on the last page.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1515642462520,"tcdate":1511436637549,"number":1,"cdate":1511436637549,"id":"rJSDZVNlf","invitation":"ICLR.cc/2018/Conference/-/Paper527/Official_Review","forum":"HyiS6k-CW","replyto":"HyiS6k-CW","signatures":["ICLR.cc/2018/Conference/Paper527/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The authors present results from several state-of-the-art generative models trained on a facial dataset for learning a general facial identity space. ","rating":"3: Clear rejection","review":"OVERVIEW: The authors present results from several state-of-the-art generative models trained on a facial dataset for learning a general facial identity space. \n\nSTRENGTHS: The paper in general is well written and easy to ready. I appreciate the idea of the Turing test and qualitative results presented are quite impressive. Also, the use of  diverse state-of-the-art generative models is also a strong point.  \n\nWEAKNESSES: While the strengths mentioned above are obvious I had the impression through the whole paper that a whole part is missing. My list of concerns are the following: \n\n    The authors state as their first contribution the presentation of a novel dataset. This is nice but I see the data is actually already available as the photographic work of an artist. So what's the authors' contribution? As I understand from the paper it is just compiling this already available data.\n    The major problem of this paper in my opinion is the total lack of technical details. In this sense the results cannot by any means by reproduced. While the authors use a set of very novel generative models there is absolutely no detail on how do they train them. We are just shown some very impressive qualitative results which are indeed admirable but without further details I cannot judge them as true or not. I strongly recommend to the authors, to provide technical details of topologies used, hyper parameters and any other important detail that would help a third party research to reproduce these results. \n    Also it is really hard to understand how could they obtain such impressive result by doing an unsupervised training on a dataset containing 3353 samples taking into account the high capacity of the models they are using. \n    In section 2.1 the authors mention that facial landmarks have been detected using a 'pre-trained ensemble-of-regresion-trees detector (Gerbrands, 1981)'. I know very well the facial alignment literature and I do not understand this reference. This I do not think is a reference to a facial alignment method bu t rather a set of general purpose linear algebra methods. \n\nTaking into account this major weaknesses I cannot accept this paper and I do not think it is worth discussing results and applications in Sections 3,4,5 before authors detail, explain and clarify how exactly they have obtained these results. ","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]}},{"tddate":null,"ddate":null,"tmdate":1509739254006,"tcdate":1509125443131,"number":527,"cdate":1509739251341,"id":"HyiS6k-CW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HyiS6k-CW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning a face space for experiments on human identity","abstract":"Generative models of human identity and appearance have broad applicability to behavioral science and technology, but the exquisite sensitivity of human face perception means that their utility hinges on alignment of the latent representation to human psychological representations and the photorealism of the generated images. Meeting these requirements is an exacting task, and existing models of human identity and appearance are often unworkably abstract, artificial, uncanny, or heavily biased. Here, we use a variational autoencoder with an autoregressive decoder to learn a latent face space from a uniquely diverse dataset of portraits that control much of the variation irrelevant to human identity and appearance. Our method generates photorealistic portraits of fictive identities with a smooth, navigable latent space. We validate our model's alignment with human sensitivities by introducing a psychophysical Turing test for images, which humans mostly fail, a rare occurrence with any interesting generative image model. Lastly, we demonstrate an initial application of our model to the problem of fast search in mental space to obtain detailed police sketches in a small number of trials.","pdf":"/pdf/8338680582860322884e2d86319674906ab06dbd.pdf","TL;DR":"Learning generative models for faces with realistic sample quality, useful for human experiments","paperhash":"anonymous|learning_a_face_space_for_experiments_on_human_identity","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a face space for experiments on human identity},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyiS6k-CW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper527/Authors"],"keywords":["face perception","generative models","psychology"]},"nonreaders":[],"replyCount":6,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}