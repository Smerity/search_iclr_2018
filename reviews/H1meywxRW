{"notes":[{"tddate":null,"ddate":null,"tmdate":1512439394467,"tcdate":1512413533823,"number":3,"cdate":1512413533823,"id":"S1UPKfXbM","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Comment","forum":"H1meywxRW","replyto":"BJfdokG-M","signatures":["ICLR.cc/2018/Conference/Paper282/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper282/Authors"],"content":{"title":"RE: SQuAD evaluation","comment":"Hi,\n\nYou are correct in that we only evaluate on the SQuAD dataset. In short, we agree with your sentiment that it would be interesting to evaluate on other datasets, however we respectfully disagree that SQuAD is known to be a bad dataset. In fact, we feel that it is one of the best datasets for reading comprehension. There seems to be agreement within the community about this in that\n\n1. SQuAD received the best resource paper award at EMNLP\n2. It is highly competitive, drawing significant participation from not only the authors' institution but other well-regarded academic and industry institutions (e.g. AI2, MSR (A), FAIR, CMU, Google, Stanford, Montreal, NYU ...).\n3. It has shown very useful downstream applications and impact (e.g. http://nlp.cs.washington.edu/zeroshot/)\n\nGiven these points, we feel that the performance gains afforded by our proposal (~3% F1) is significant, given that the top models on the leaderboard are within ~1% F1 of each other. We think these techniques are beneficial to the community at large.\n\nOf course, the fact that the other datasets do not (yet) have the above distinctions does not make them less interesting. We think that each dataset has its pros and cons. For example, TriviaQA is labeled via distant supervision. NewsQA  frankly has not been very popular (2 leaderboard submissions in ~1 year), and there seems to be concerns regarding its evaluation (see https://openreview.net/forum?id=ry3iBFqgl), though the authors seems to have made some enhancements since then. Given the higher popularity and competitiveness of SQuAD, we felt that it is a better choice on which to compare our proposal with the best models developed by the community.\n\nNevertheless, the two datasets you mentioned are either larger and longer (TriviaQA) or at least longer (NewsQA) than SQuAD. We will attempt to evaluate on one of these two datasets, however given the time constraints we are unlikely to be able to fine tune the model. I will update here with results once we obtain them."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512412169193,"tcdate":1512411694461,"number":2,"cdate":1512411694461,"id":"H1UVzfmZf","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Comment","forum":"H1meywxRW","replyto":"SJtORWmZM","signatures":["ICLR.cc/2018/Conference/Paper282/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper282/Authors"],"content":{"title":"RE: Ablation without CoVe","comment":"Hi,\n\nYou are correct in that CoVe does provide a significant performance gain, as demonstrated by McCann et al. (https://arxiv.org/abs/1708.00107). However, CoVe itself, when combined with the original DCN, does not obtain state of the art performance whereas this work does (please see Table 1 of our paper). In addition, we feel that the performance gain provided by deep residual coattention and mixed objective are significant (3.2% dev F1) given the competitive nature of the task. For reference on how significant a 3% F1 gain is, the top 5 state of the art models on the leaderboard are within ~1% dev F1 of each other.\n\nIn addition, CoVe is focused on the encoder of the model, whereas our work focuses on the coattention and the mixed objective. Our additions are applicable to other types of encoders as well.\n\nWe decided to perform ablation studies with respect to DCN with CoVe because it seemed like a natural foundation to build upon, but I agree with your sentiment that we should also evaluate our proposed additions without CoVe. We can try to perform this experiment and update here with the results.\n\nThanks!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512410827222,"tcdate":1512410737085,"number":2,"cdate":1512410737085,"id":"SJtORWmZM","invitation":"ICLR.cc/2018/Conference/-/Paper282/Public_Comment","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Ablation without CoVe? Only SoTA by using newer embeddings?","comment":"Hi, most models this paper compares to are trained with GloVe embeddings but you only show results with CoVe (if I am not mistaken). Given the large boost of CoVe to the original model, it looks like this model is only able to achieve SotA because it uses CoVe and not because of the additional extensions. The mentioned 3% boost to the original model without CoVe would result in a much lower score which would probably **not be SoTA**. \n\nIs this correct?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512341286240,"tcdate":1512336233724,"number":1,"cdate":1512336233724,"id":"BJfdokG-M","invitation":"ICLR.cc/2018/Conference/-/Paper282/Public_Comment","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Only SQuAD Evaluation!?","comment":"I noticed that you only evaluate against SQuAD which is known to be a bad dataset for evaluating machine comprehension. It has only short documents and most of the answers are easily extractable. This is a bit troubling especially given that there are plenty of good and much more complex datasets out there, e.g., TriviaQA, NewsQA, just to mention a few. It feels like we are totally overfitting on a simple dataset. Would it be possible to also provide results on one of those, otherwise it is really hard to judge whether there is indeed any significant improvement. I think this is a big issue."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222611789,"tcdate":1512007506468,"number":3,"cdate":1512007506468,"id":"rJ9UPyaeG","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Review","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["ICLR.cc/2018/Conference/Paper282/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Significant improvement of DCN answer selection models using mixed objectives and 2 stacked levels of coattention","rating":"8: Top 50% of accepted papers, clear accept","review":"The authors of this paper propose some extensions to the Dynamic Coattention Networks models presented last year at ICLR. First they modify the architecture of the answer selection model by adding an extra coattention layer to improve the capture of dependencies between question and answer descriptions. The other main modification is to train their DCN+ model using both cross entropy loss and F1 score (using RL supervision) in order to  reward the system for making partial matching predictions. Empirical evaluations conducted on the SQuAD dataset indicates that this architecture achieves an improvement of at least 3%, both on F1 and exact match accuracy, over other comparable systems. An ablation study clearly shows the contribution of the deep coattention mechanism and mixed objective training on the model performance. \n\nThe paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. It seems to me that this paper is a significant contribution to the field of question answering systems. \n","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222611830,"tcdate":1511841274323,"number":2,"cdate":1511841274323,"id":"rkf-R8qlz","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Review","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["ICLR.cc/2018/Conference/Paper282/AnonReviewer3"],"readers":["everyone"],"content":{"title":"An improvement of DCN model","rating":"6: Marginally above acceptance threshold","review":"This paper proposed an improved version of dynamic coattention networks, which is used for question answering tasks. Specifically, there are 2 aspects to improve DCN: one is to use a mixed objective that combines cross entropy with self-critical policy learning, the other one is to imporve DCN with deep residual coattention encoder. The proposed model achieved STOA performance on Stanford Question Asnwering Dataset and several ablation experiments show the effectiveness of these two improvements. Although DCN+ is an improvement of DCN, I think the improvement is not incremental. \n\nOne question is that since the model is compicated, will the authors release the source code to repeat all the experimental results?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222611874,"tcdate":1511653944197,"number":1,"cdate":1511653944197,"id":"HyeSGKwgf","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Review","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["ICLR.cc/2018/Conference/Paper282/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review","rating":"7: Good paper, accept","review":"Summary:\nThis paper proposed an extension of the dynamic coattention network (DCN) with deeper residual layers and self-attention. It also introduced a mixed objective with self-critical policy learning to encourage predictions with high word overlap with the gold answer span. The resulting DCN+ model achieved significant improvement over DCN.\n\nStrengths:\nThe model and the mixed objective is well-motivated and clearly explained.\nNear state-of-the-art performance on SQuAD dataset (according to the SQuAD leaderboard).\n\nOther questions and comments:\nThe ablation shows 0.7 improvement on EM with mixed objective. It is interesting that the mixed objective (which targets F1) also brings improvement on EM. \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1510340061023,"tcdate":1510340032421,"number":1,"cdate":1510340032421,"id":"rJdarOXyG","invitation":"ICLR.cc/2018/Conference/-/Paper282/Official_Comment","forum":"H1meywxRW","replyto":"H1meywxRW","signatures":["ICLR.cc/2018/Conference/Paper282/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper282/Authors"],"content":{"title":"Errata","comment":"In Equation 17 (page 5), we made a typo in that we did not include the regularization terms $$\\log \\sigma_{ce}^2 + \\log \\sigma_{rl}^2$$."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739387259,"tcdate":1509089003345,"number":282,"cdate":1509739384606,"id":"H1meywxRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1meywxRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"DCN+: Mixed Objective And Deep Residual Coattention for Question Answering","abstract":"Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning, using rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we introduce a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state of the art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1.","pdf":"/pdf/b7c199be8412c1e46db225723ee4e5125c699a2c.pdf","TL;DR":"We introduce the DCN+ with deep residual coattention and mixed-objective RL, which achieves state of the art performance on the Stanford Question Answering Dataset.","paperhash":"anonymous|dcn_mixed_objective_and_deep_residual_coattention_for_question_answering","_bibtex":"@article{\n  anonymous2018dcn+:,\n  title={DCN+: Mixed Objective And Deep Residual Coattention for Question Answering},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1meywxRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper282/Authors"],"keywords":["question answering","deep learning","natural language processing","reinforcement learning"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}