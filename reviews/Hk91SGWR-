{"notes":[{"tddate":null,"ddate":null,"tmdate":1516327979176,"tcdate":1516327979176,"number":11,"cdate":1516327979176,"id":"B1mN4AC4M","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Comment","forum":"Hk91SGWR-","replyto":"B1LEVNTXG","signatures":["ICLR.cc/2018/Conference/Paper830/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper830/Authors"],"content":{"title":"Response to updated review rating","comment":"Thank you for upgrading the rating of our paper. We addressed the concerns raised in your review and reported all experiments you asked for.  It would be great and helpful if you could provide details about your current concerns. Thanks a lot for your time!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515174863402,"tcdate":1515173142902,"number":4,"cdate":1515173142902,"id":"Syy7rN67M","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Comment","forum":"Hk91SGWR-","replyto":"S1sHPAWgz","signatures":["ICLR.cc/2018/Conference/Paper830/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper830/Authors"],"content":{"title":"Response to review","comment":"We thank the reviewer for the detailed and very useful feedback. We have addressed all of your concerns below.\n\nIssue 0\n“..there are only 30 participants per condition and so it’s hard to tell whether the large differences in conditions are due to noise and what a stable ranking of conditions actually looks like …”  \nA: Good point! As per your suggestion, we have increased the sample size substantially by recruiting a total of 120 subjects per condition. The results and conclusions remain unchanged. \n\n“... the error bars in figure 1 represent, are they standard deviations of the mean?... ”\nA: Sorry for the confusion. The error bars in Figure 1 represent standard error of the mean (we have added that clarification in the revision).\n\n“Did you collect any extra data about participants? One potentially helpful example is asking how familiar participants are with platformer video games …”\nA: Yes! For all of the games, we found only a moderate correlation (around 0.3) between familiarity with video games and average time taken to solve the game. This relatively moderate correlation indicates that familiarity with video games only results in slight improvement in performance of human players. \n\nIssue 1\n“What do you mean by “objects”?”\nA: Thank you for asking this question. We have clarified the definition of objects in the revised version of the manuscript. In the video game setting, objects are simply entities that are visibly distinct from their surroundings. The hypothesis is that humans use these visually distinct entities as subgoals, which results in more efficient exploration than random search. Performance of humans in game manipulation shown in Figure 2(c), demonstrates that when players cannot distinguish entities from the background, their performance drops significantly. We believe that mechanisms to bias exploration towards salient entities would be an interesting step towards improving the efficiency of RL agents.\n \nIssue 2.\n“There are two ways to interpret the authors’ main claim: the strong version would maintain that semantic priors aren’t important at all..”\nA: We are sorry for the confusion. Our claim is that while prior knowledge about semantics and affordances is important for human players, more general priors about objects (i.e. existence of visually salient entities that are subgoals; entities that look similar have the same semantics)  are more critical to performance. In essence, we agree with the reviewer and we do not claim that semantic priors aren't important (just that general prior about objects are more critical). We have revised the manuscript to clarify this. As per your suggestion, we have also included an additional experiment (refer to section A in Appendix) and indeed find that reversing the semantics leads to worse performance than that of simply masking the semantics. \n\n“..Here without semantic priors I would hypothesize that human performance would fall quite far (whereas with semantics people would be able to figure it out quite well).”\nA: We completely agree. However, at the same time, we believe that the prior of treating visually distinct entities as sub-goals for exploration will be more important than the prior about semantics alone. \n\n“..It’s also important to take into account how much work general priors about video game playing (games have goals, up jumps, there is basic physics) are doing here..”\nA: Great point. Humans bring in various priors about general video game playing such as moving up or right in games is generally correlated with progress, games have goals etc. Quantifying the importance of such priors is an interesting direction of research and we will include this discussion in the next revision of the paper.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515173225393,"tcdate":1515172909895,"number":3,"cdate":1515172909895,"id":"B1LEVNTXG","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Comment","forum":"Hk91SGWR-","replyto":"ry07SzQgG","signatures":["ICLR.cc/2018/Conference/Paper830/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper830/Authors"],"content":{"title":"Reviewer might have misunderstood our experimental setup and methodology","comment":"\nThe reviewer says “..Formally, we cannot conclude that one minute is lesser than 4 million of steps..”\n\nA: In Figure 1 of the revised manuscript,  we have now reported the number of steps taken by both the RL agents and human players for direct comparison. Human players take three orders of magnitude fewer steps to solve the game. Further, please note that the main point of our work was not to compare absolute performance of humans against RL agents, but to show that the performance of human players changes significantly with re-rendering of the game which makes it hard for humans to use their prior knowledge, whereas the performance of RL agent is almost unchanged.\n\nThe reviewer says “..So it cannot be concluded that the change of performances is due to human priors. In these cases, I think that the change of performances is due to the increased difficulty of the game.”  \n\nA: We are afraid that the reviewer might have misunderstood our experimental setup and methodology.  First, note that all games are *exactly the same* in their reward and goal structure - the only difference between the different versions of the game is in the rendering of the game entities. Because there is no other difference between the original and the manipulated versions of the game, it can be inferred that drop in performance is due to the inability of humans to employ their prior knowledge and beliefs in those manipulated games. \n\nThe reviewer says, “...The authors have to include RL agent in all their experiments to be able to dissociate what is due to human priors and what is due to the noise introduced in the game”\n\nA: We do not agree with the reviewer’s comment because the performance of the RL agents on different manipulations of the game has no effect on the conclusions of the human study. At the same time, we do believe that studying the performance of RL agents on all game manipulations is an interesting question; one that is independent of the study of priors employed by humans. We have included the performance of RL agents for various game manipulations in Section C, Appendix. The RL agent’s performance is unaffected in all game manipulations except for the version in which visual similarity is removed. The results provide direct evidence that reviewer’s claim that “masking where objects are ...should also deteriorate the performance of a RL agent.” is simply not true.\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515174770010,"tcdate":1515172682440,"number":2,"cdate":1515172682440,"id":"SJML7NamG","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Comment","forum":"Hk91SGWR-","replyto":"BJZ52L6lf","signatures":["ICLR.cc/2018/Conference/Paper830/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper830/Authors"],"content":{"title":"Response to review","comment":"We thank the reviewer for the positive and useful feedback. Our response to your concerns below:\n\nQ: “there is something of an apples-to-oranges comparison when considering how quickly humans can complete the task (order of minutes) and how quickly the SOTA RL agents can complete the task (number of frames).”\nA:  Good point! In Figure 1 of the revised manuscript, we have now reported number of actions taken by both human players and RL agents to solve the games.\n\nQ: “... it would be further instructive if the RL agents were also run on the different game manipulations…” \nA: Thank you for this useful suggestion! We have included additional experiments that quantify the performance of  RL agent on the different game manipulations (Section C, Appendix). The RL agent’s performance is unaffected in all game manipulations except for the version in which visual similarity is removed. \n\nResponse to additional comments:\nQ: “ .. graphs shown in Figure 3, are the meaning of the 'State' variable is not clear -- is it the number of *unique* states visited? ..”\nA: In graph 3, the 'State' variable indeed refers to the unique states visited which serves as a measure of how much players explore a game manipulation. We have clarified this in the revised manuscript.\n\nWe have made revisions to the text addressing other minor corrections pointed by you. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515173328669,"tcdate":1515172442162,"number":1,"cdate":1515172442162,"id":"SkMvz4TQM","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Comment","forum":"Hk91SGWR-","replyto":"Hk91SGWR-","signatures":["ICLR.cc/2018/Conference/Paper830/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper830/Authors"],"content":{"title":"Main Response to Reviewers","comment":"We thank the reviewers for their encouraging comments. We are glad that the reviewers found the questions addressed in the paper to be super important (R3) and the narrative to be coherent (R1). R1 says, “Given recent advances in RL ... it is a well-timed reminder that being able to transfer know-how from human behaviour to artificially-intelligent ones”.  The reviewers also had a number of great suggestions that we have incorporated in the revised manuscript.  The major changes are as follows:\n\na) We have rewritten the introduction to clarify the main claims of our paper. \n\nb) We increased the sample size significantly for all the human experiments to ensure robustness.\n\nc) We evaluated the performance of RL agent on various game manipulations to shed further light as to how RL agents differ from humans in terms of prior knowledge (Section C, Appendix).\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515642517982,"tcdate":1512037513013,"number":3,"cdate":1512037513013,"id":"BJZ52L6lf","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Review","forum":"Hk91SGWR-","replyto":"Hk91SGWR-","signatures":["ICLR.cc/2018/Conference/Paper830/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Review - Accept","rating":"7: Good paper, accept","review":"The authors present a study of priors employed by humans in playing video\ngames -- with a view to providing some direction for RL agents to be more\nhuman-like in their behaviour.\n\nThey conduct a series of experiments that systematically elides visual\ncues that humans can use in order to reason about actions and goals in a\nplatformer game that they have a high degree of control over.\n\nThe results of the experiments, conducted using AMT participants, demonstrates\nthe existence of a taxonomy of features that affect the ability to complete\ntasks in the game to varying degrees.\n\nThe paper is clearly written, and the experiments follow a clean and coherent\nnarrative. Both the premises assumed and the conclusions drawn are quite\nreasonable given the experimental paradigm and domain in which they are\nconducted.\n\nThere were a couple of concerns I did have however:\n\n1. Right at the beginning, and through the manuscript, there is something of an\n   apples-to-oranges comparison when considering how quickly humans can\n   complete the task (order of minutes) and how quickly the SOTA RL agents can\n   complete the task (number of frames).\n\n   While the general spirit of the argument is somewhat understandable despite\n   this, it would help strengthen any inference drawn from human   performance\n   to be applied to RL agents, if the comparison between the two were to be\n   made more rigorous -- say by estimating a rough bijection between human and\n   RL measures.\n\n2. And in a related note to the idea of establishing a comparison, it would be\n   further instructive if the RL agents were also run on the different game\n   manipulations to see what (if any) sense could be made out of their\n   performance.\n\n   I understand that at least one such experiment is shown in Figure 1 which\n   involves consistent semantics, but it would be quite interesting to see how\n   RL agents perform when this consistency is taken away.\n\nOther questions and comments:\n\n1. In the graphs shown in Figure 3, are the meaning of the 'State' variable is\n   not clear -- is it the number of *unique* states visited? If not, is it the\n   total number of states/frames seen? In that case, how is it different from\n   'Time'?\n\n2. The text immediately below Figure 3's caption seems to have an incorrect\n   reference (referring to Figure 2(a) instead of Figure 3(a)).\n\nGiven recent advances in RL and ML that eschew all manner of structured\nrepresentations, I believe this is a well-timed reminder that being able to\ntransfer know-how from human behaviour to artificially-intelligent ones.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1516267579966,"tcdate":1511363878043,"number":2,"cdate":1511363878043,"id":"ry07SzQgG","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Review","forum":"Hk91SGWR-","replyto":"Hk91SGWR-","signatures":["ICLR.cc/2018/Conference/Paper830/AnonReviewer2"],"readers":["everyone"],"content":{"title":"I have concerns about the method and the conclusions","rating":"4: Ok but not good enough - rejection","review":"This paper investigates human priors for playing video games.\n\nConsidering a simple video game, where an agent receives a reward when she completes a game board, this paper starts by stating that:\n-\tFirstly, the humans perform better than an RL agent to complete the game board.\n-\tSecondly, with a simple modification of textures the performances of human players collapse, while those of a RL agent stay the same.\n\nIf I have no doubts about these results, I have a concern about the method. \nIn the case of human players the time needed to complete the game is plotted, and in the case of a RL agent the number of steps needed to complete the game is plotted (fig 1). Formally, we cannot conclude that one minute is lesser than 4 million of steps.\n\nThis issue could be easily fixed. Unfortunately, I have other concerns about the method and the conclusions.\n\nFor instance, masking where objects are or suppressing visual similarity between similar objects should also deteriorate the performance of a RL agent. So it cannot be concluded that the change of performances is due to human priors. In these cases, I think that the change of performances is due to the increased difficulty of the game.\n\nThe authors have to include RL agent in all their experiments to be able to dissociate what is due to human priors and what is due to the noise introduced in the game. \n\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515642518062,"tcdate":1511282499443,"number":1,"cdate":1511282499443,"id":"S1sHPAWgz","invitation":"ICLR.cc/2018/Conference/-/Paper830/Official_Review","forum":"Hk91SGWR-","replyto":"Hk91SGWR-","signatures":["ICLR.cc/2018/Conference/Paper830/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Investigating Human Priors review","rating":"5: Marginally below acceptance threshold","review":"Overall:\nI really enjoyed reading this paper and think the question is super important. I have some reservations about the execution of the experiments as well as some of the conclusions drawn. For this reason I am currently a weak reject (weak because I believe the question is very interesting). However, I believe that many of my criticisms can be assuaged during the rebuttal period.\n\nPaper Summary:\nFor RL to play video games, it has to play many many many many times. In fact, many more times than a human where prior knowledge lets us learn quite fast in new (but related) environments. The authors study, using experiments, what aspects of human priors are the important parts. \n\nThe authors’ Main Claim appears to be: “While common wisdom might suggest that prior knowledge about game semantics such as ladders are to be climbed, jumping on spikes is dangerous or the agent must fetch the key before reaching the door are crucial to human performance, we find that instead more general and high-level priors such as the world is composed of objects, object like entities are used as subgoals for exploration, and things that look the same, act the same are more critical.”\n\nOverall, I find this interesting. However, I am not completely convinced by some of the experimental demonstrations. \n\nIssue 0: The experiments seem underpowered / not that well analyzed. \nThere are only 30 participants per condition and so it’s hard to tell whether the large differences in conditions are due to noise and what a stable ranking of conditions actually looks like. I would recommend that the authors triple the sample size and be more clear about reporting the outcomes in each of the conditions. \n\nIt’s not clear what the error bars in figure 1 represent, are they standard deviations of the mean? Are they standard deviations of the data? Are they confidence intervals for the mean effect? \n\nDid you collect any extra data about participants? One potentially helpful example is asking how familiar participants are with platformer video games. This would give at least some proxy to study the importance of priors about “how video games are generally constructed” rather than priors like “objects are special”.\n\nIssue 1: What do you mean by “objects”?\nThe authors interpret the fact that performance falls so much between conditions b and c to mean that human priors about “objects are special” are very important. However, an alternative explanation is that people explore things which look “different” (ie. Orange when everything else is black). \n\nThe problem here comes from an unclear definition of what the authors mean by an “object” so in revision I would like authors to clarify what precisely they mean by a prior about “the world is composed of objects” and how this particular experiment differentiates “object” from a more general prior about “video games have clearly defined goals, there are 4 clearly defined boxes here, let me try touching them.”\n\nThis is important because a clear definition will give us an idea for how to actually build this prior into AI systems.\n\nIssue 2: Are the results here really about “high level” priors?\nThere are two ways to interpret the authors’ main claim: the strong version would maintain that semantic priors aren’t important at all.\n\nThere is no real evidence here for the strong version of the claim. A real test would be to reverse some of the expected game semantics and see if people perform just as well as in the “masked semantics” condition.\n\nFor example, suppose we had exactly the same game and N different types of objects in various places of the game where N-1 of them caused death but 1 of them opened the door (but it wasn’t the object that looked like a key). My hypothesis would be that performance would fall drastically as semantic priors would quickly lead people in that direction. \n\nThus, we could consider a weaker version of the claim: semantic priors are important but even in the absence of explicit semantic cues (note, this is different from having the wrong semantic cues as above) people can do a good job on the game. This is much more supported by the data, but still I think very particular to this situation. Imagine a slight twist on the game:\n\nThere is a sword (with a lock on it), a key, a slime and the door (and maybe some spikes). The player must do things in exactly this order: first the player must get the key, then they must touch the sword, then they must kill the slime, then they go to the door. Here without semantic priors I would hypothesize that human performance would fall quite far (whereas with semantics people would be able to figure it out quite well).\n\nThus, I think the authors’ claim needs to be qualified quite a bit. It’s also important to take into account how much work general priors about video game playing (games have goals, up jumps, there is basic physics) are doing here (the authors do this when they discuss versions of the game with different physics).","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]}},{"tddate":null,"ddate":null,"tmdate":1515222584104,"tcdate":1509135586488,"number":830,"cdate":1509739075711,"id":"Hk91SGWR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Hk91SGWR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Investigating Human Priors for Playing Video Games","abstract":"Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate human-like representations in their systems.","pdf":"/pdf/8ae4d0019b3907769e5beb7d5d44aa61e858e99a.pdf","TL;DR":"We investigate the various kinds of prior knowledge that help human learning and find that general priors about objects play the most critical role in guiding human gameplay.","paperhash":"anonymous|investigating_human_priors_for_playing_video_games","_bibtex":"@article{\n  anonymous2018investigating,\n  title={Investigating Human Priors for Playing Video Games},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk91SGWR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper830/Authors"],"keywords":["Prior knowledge","Reinforcement learning","Cognitive Science"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}