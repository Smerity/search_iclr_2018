{"notes":[{"tddate":null,"ddate":null,"tmdate":1516115754045,"tcdate":1516115754045,"number":5,"cdate":1516115754045,"id":"r1MVPcoNM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Comment","forum":"r1YqWz-R-","replyto":"HyRbL5YxM","signatures":["ICLR.cc/2018/Conference/Paper780/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper780/Authors"],"content":{"title":"Response to Reviewer 1 - Updated Comments","comment":"Thank you very much for reading the responses and updating the comments.\n\n- I read the revision. The writing has improved, and the new experiments are good. That said, it is my opinion that the paper is still not quite ready for publication, mostly because the story behind the model doesn't lead to the conclusions being made from the experiments in a clean and consistent way. It's a bit like patchwork at this point. The authors I think will need to put some time into a rewrite, but the content itself is worth pushing forward.\nSome notes: \"StepGAN a general version of SeqGAN, and can simulate the process of Monte-Carlo search with low extra computational cost:\" This really is a strong claim that's not proven in any way in the paper.\n\nAns: It is widely known that stepwise evaluation is critical for sequence generation by GAN, and Monte-Carlo search and REGS are previous attempt that we know. REGS does not perform as good as Monte-Carlo search in its original paper, but Monte-Carlo search has additional computational cost. We find that StepGAN behaves more like Monte-Carlo search without additional cost. We have observed that the variation of stepwise scores given by discriminator dominates the learning process of generator, which directly affects the final training results. We plot the variation (Figure 3), and can observe that StepGAN approximates Monte-Carlo search (MC-SeqGAN in Figure 3) better than REGS. Therefore, we claim that StepGAN can approximate Monte-Carlo. It is intuitive that StepGAN does not add any complexity to the original GAN. \nThank you for your encouragement. We will further improve the paper to make it better if we further have chance to modify the paper.\n\n- \"In typical reinforcement learning, the agent obtains a reward...\": in typical RL settings, it's just as likely to find single or episodal rewards and this setting isn't limited to those where you have an extrinsic reward at each step.\n\nAns: We think in an MDP, the reward is given when transition happens from any state s to another state s’. This definition does not exclude situations when receiving single or episodal rewards. These cases can be considered as the extrinsic rewards at every intermediate steps are zero and only the terminal step get a non-zero reward.\n\n\n- Why do you still have WGAN-GP when there are no accompanying numbers?\n\nAns: The synthetic experiments (in Table 2) do include the results of WGAN-GP because WGAN-GP is a notable method, and we want to show that we have tested it. However, we have observed that WGAN-GP cannot improve the baseline under our settings. We therefore marked the numbers as dash (-), which you could interpret as worse than MLE. I will put the number of WGAN-GP in Table 2 if we have chance to modify the paper in the future.\n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515182161115,"tcdate":1515182086720,"number":4,"cdate":1515182086720,"id":"rJkf_Upmz","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Comment","forum":"r1YqWz-R-","replyto":"HkTXuSulM","signatures":["ICLR.cc/2018/Conference/Paper780/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper780/Authors"],"content":{"title":"Response to Reviewer3","comment":"Quality: The paper proposes a direct improvement over SeqGAN by Yu. et. al. (2017). My assessment is partially determined by comparing this paper to Yu et. al (2017). In my opinion, this paper is lacking in quality in comparison to Yu et. al (2017). In particular, Yu et. al. (2017) provides detailed derivation of the policy gradient accompanied by a pseudo-code (algorithm) on how one can implement SeqGAN. On the contrary, this paper does not provide such details. Perhaps, all of the details of SeqGAN follows immediately, but the paper should not assume that all readers will be familiar with SeqGAN. \n\n\nAns: Thanks for your advice. We have add pseudo-code in Appendix A.\n\nClarity: \n\n1. The paper provides a review of related methods on conditional sequence generation in Section 3. However, it is very brief and as a non-expert in this field, I needed to refer to the original papers anyways. Perhaps, the review of the related methods can go to the Appendix and this space can be better utilized to expand on the original contributions made by the paper. \nAns: Thanks for your suggestion. We have rewrote Section 3 for better explaination.\n\n2. MCMC (Markov chain Monte Carlo) is mentioned in 4.1 but it is not explained. \nAns: We have added the explaination in Section 3.3.1: SeqGAN.\n\n3. Figure 1 is not sufficiently explained; neither in text nor in the figure caption. It would help greatly to describe the details of the network architecture shown in this figure.\nAns: We have rewrote Section 4. Hope that is more clear.\n\nOriginality: The paper proposes a generalization of SeqGAN; however, in my opinion, the methodological contribution appears to be only incremental on SeqGAN. \n\nAns: We think the main contribution and originality of this paper are proposing a method to approximate Monte Carlo search with little computational cost.\n\nSignificance: The paper's significance may be evaluated in terms of its impact on applications as it proposes an improvement over the previous work of SeqGAN. However, the extent to which the evaluation is carried out is somewhat unsatisfactory with only one real application. Also, the applications considered in the experiments are primarily on dialogue generation. My initial impression is that the methodology lacks generality and may perhaps cater better to domain specific publication venues. \n\nAns: Thanks for your indication. While we do not have much time to conduct many different real-world tasks, we think approximating Monte Carlo search might be another significance. There are some other points we want to clarify. First, we think that this paper serves more as an evaluation on conditional sequence generation rather than the original work of SeqGAN, which is sequence generation without condition. Second, we mainly apply to dialogue generation because it’s one of the typical 1-to-many conditional sequence generation task and one of our most important baseline “REGS” is proposed on this. \n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515182030332,"tcdate":1515182030332,"number":3,"cdate":1515182030332,"id":"rkLRDUTXz","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Comment","forum":"r1YqWz-R-","replyto":"HyRbL5YxM","signatures":["ICLR.cc/2018/Conference/Paper780/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper780/Authors"],"content":{"title":"Response to Reviewer1 - part 2","comment":"\nP5\nWhy is this a generalized version of SeqGAN? The claim the discriminator value D(x_1..t | y) is the same as what you would get from a full-sequence generator using MCMC seems like a stretch.\n\nAns: Thanks for your indication. We can understand our previous description is not appropriate, therefore we have rewrote the paragraph. StepGAN-Seq (the new name for the old ESGAN) is a generalized version of basic-SeqGAN, which uses 1-sample estimation instead of MCMC, because we can directly derive from the formulation. As you mentioned, we cannot directly say that StepGAN is a generalized version of SeqGAN using MCMC, and what we wanted to say is that StepGAN aims to approximate MCMC and to replace it.\n\nDid you not use a baseline?\n\nAns: Yes, we do use baseline. In synthetic experiments, we estimated the baseline using the average of batch. In dialogue generation, we trained another value network to estimate the baseline.\n\nYou might want to build in a little more motivation for these different update rules. I think I understand that (10) is meant to accumulate credit across the rest of the sequence, while (11) does not, but it would be good to have this clearly stated. Why do you think one would work better than the other?\n\nAns: Thanks for your suggestion. We try to clarify this point in our updated version as (8) (the old (10)) viewing discriminator’s scores as rewards and (9) (the old (11)) viewing discriminator’s scores as expected returns (or Q value for state-action pair). We are not sure which one is better, but in our synthetic experiments, (9) has apparently higher accuracy than (10) in  “Counting”, while they do not show large difference in the other two tasks. Therefore we choose to use (9) in dialogue generation.\n\nP6\n“The generator G, in the mean time, struggle to maximize the likelihood of discriminator D” I don’t understand what this means.\n\nAns: Thanks, we have rewrote that.\n\nWhat was the motivation for using the same model here? Is the energy in this formulation related in any ways to EBGAN? Could you do something similar with separate parameters? Why would be or why would this not be a good idea?\n\nAns: Due to the performance of EBStepGAN (the new name of the old EBESGAN) does not show apparently difference with StepGAN and we have reached the page limitation, we have moved EBStepGAN to Appendix C and rewrote the description.\nThe motivation of EBStepGAN is that we can use the same pretrained model for both generator and discriminator with only a variation of objective function. We indeed think that even though the generator and discriminator do similar things, it can still work.\nThe spirit of EBGAN is viewing discriminator as an energy function, and we use a cross-entropy as the enery function here.\n\nI do like these synthetic tasks. I think that more analyses would be helpful in understanding what the model (and what competing models) are doing.\n\nAns: Thanks ! We have add more analyses based on the real-world task: dialogue generation.\n\nP7:\nWhat is VLGAN in the table?\nPerhaps it would be worth exploring changing alpha through optimization?\n\nAns: Yes, thanks for your realization. We have corrected the “VLGAN” -> “StepGAN” and “VLGAN-VRL” -> “StepGAN-Seq”. The table listed our exploring of alpha^G and the detail is described in Section 5.1.\n\nP8:\nIt seems like many of the improvements in the table are marginal (with some exceptions): is it possible that ESGAN was optimized better?\n“auxiliary tricks” I would avoid this wording.\n\nAns: Sorry for that we don’t have many time to conduct more experiments. Since we have done grid search over most hyper parameters, we thinks the most possible optimization way are changing the pretrained discriminator and adding value network for synthetic tasks.\n\nOther comments on experiments:\nIt seems like the actual NLP part of this paper is quite sparse. Why was MaliGAN left out of the real experiments?\n\nAns: Thanks for your advice. We have added MaliGAN in our new human evaluation experiments, which is listed in Table 3."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515181998097,"tcdate":1515181998097,"number":2,"cdate":1515181998097,"id":"HkIhDI6XG","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Comment","forum":"r1YqWz-R-","replyto":"HyRbL5YxM","signatures":["ICLR.cc/2018/Conference/Paper780/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper780/Authors"],"content":{"title":"Response to Reviewer1 - part 1","comment":"The approach is interesting, but as a contribution the paper has a long way to go. The ideas are there and everything seems correct, but there’s little motivation / insight on the model and why it might be better than competing methods for NLP tasks.\nIt would be good to see some sort of concrete analysis as far as what the model is doing (for instance how the discriminator scores change), and a comparison of how the reward signal given here might differ from other methods (SeqGAN, MaliGAN), and why this might be better. All we get is some scores, but it’s never clear why these scores indicate good (conditional) language generation. Can we not also look at BLEU scores for language generation or some other metric?\n\nAns: Thanks for your suggestion. We propose to use the variation throughout the training process of discriminator to check which part is the most crucial one for the method (SeqGAN, Monte Carlo search, REGS, StepGAN). The reason we didn’t choose MaliGAN because its objective function is different from SeqGAN, from which REGS and StepGAN derived. We found that StepGAN can better approximate the crucial part as Monte Carlo search than REGS, and the estimated crucial parts are also correspondent to human knowledge. The details are described in Section 5.2.\n\nFinally, the writing need to be improved: it starts out OK, but it progressively gets worse and worse.\n\nAns: Because none of the authors are English native speakers, we hire an English speaker with computer science Ph.D to polish the English writing. \n\nDetailed notes:\nP2\nIt might be good to mention beam search and scheduled sampling as other common methods to address the exposure bias.\n\nAns: We will cite the related paper.\n\n“objective function irrelevant to backpropagation”: what does this mean?\nMaliGAN actually also uses a “policy gradient”, which corresponds to an estimate of the likelihood ratio, to address the discrete problem.\nThough distinct from this work, Gulrajani used a CNN.\n\nAns: Thanks for your indication. I thought MaliGAN directly derived the gradient estimator, which has the same form as policy gradient, instead of evaluated a reward for policy gradient. This might be my uncarefulness in explanation.\n\nP3\nUse \\log for logarithm\n\nAns: Thanks for your suggestion. We have revised this.\n\n“Moreover, the likelihood is only estimated at word-level”: is this true? It seems to me that likelihood of the sequence is estimated as well.\n\nAns: This is my interpretation. The likelihood is estimated over the whole sequence, however, the minimization is conducted on word-level when training. This is like the description of training stage in “exposure bias”."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515181210316,"tcdate":1515181210316,"number":1,"cdate":1515181210316,"id":"B1zoNLpmz","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Comment","forum":"r1YqWz-R-","replyto":"HJygOiYxM","signatures":["ICLR.cc/2018/Conference/Paper780/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper780/Authors"],"content":{"title":"Response to Reviewer2","comment":"In the proposed approach, a more flexible discrimination score is obtained by treating independently each sub-sequence of the input. Technically speaking, the authors' contribution is to add a set of free parameters in the sub-sequence discriminator sum of equation 8. From a more general point of view, what is the key output of the paper, except to confirm that curriculum learning can help in dialog generation?  \n\nAns: The proposed approach aims to approximate the expected return obtained from Monte Carlo search with a apparently lower computational cost. We have described it more clearly in Section 1: Introduction.\n\nThe experiments do not seem to show that a net performance improvement can be associated with the introduced free weights and what is a good strategy to tune them in an optimal way. In general, as the authors report also in the abstract, the performance of the proposed algorithm is 'comparable' with the state of the art but never outperforms other existing methods in a consistent way. \n\nAns: We think the most inconsistent experiment is “sequence” artificial grammar. The reason is very possible to be a very strong pretrained generator (accuracy~97%) for pre-trained discriminator. The discriminator is easily not pre-trained well with a very plausible generator. Therefore, the adversarial training cannot get advantages here. We have added this reason in Section 5.1.\n\nIn fact, the performance of the algorithms depends strongly on the specific grammar used to generate the dataset and on the specific evaluation score. The human evaluation experiment is interesting but the proposed method is only compared with one other algorithm (seqGAN) and only two examples of the output are given explicitly.\n\nAns: Thanks for your advice. We add MaliGAN, REGS, beam search, and MMI for comparison. Therefore we conduct a new human evaluation process and renew the table. For more examples, we have put them in Appendix D.\n\nThe increase in computational cost due to the weighted sub-sequence evaluation is also poorly discussed.   \n\nAns: We add one sentence in Section 4 for StepGAN (the new name for the old ESGAN) and one sentence in Section 3.3.1 for Monte Carlo search. We hope you can find it useful.\n\nFew more questions:\n-through the experiments section, the authors focus on evaluating the set of possible good answers (softmax and coverage score) instead of the best answer (argmax). Why is this important for dialog generation? In the generation of a real conversation, shouldn t one always choose the argmax option? What would be a practical use of the second and third-best options?\n\nAns: We think the practical use of options other than the argmax one is that we can further transfer the style of the generation. Because learning the set of possible good answers means the model learns the underlying distribution, this enable the model to generate assigned style from the set of possible answers.\n\n-why softmax is always lower than argmax in the synthetic experiment and always higher than argmax in the human evaluation experiment?\n\nAns: In synthetic experiments, the accuracy only considers whether the response is correct. Therefore, if the argmax has learned pretty good, the softmax would only has lower accuracy because it diverse from the correct answer.\nHowever, in dialogue generation, the human score was evaluated over whether the response was good, which included both coherence and the information provided by the response. Since the softmax results were much diverse and resulted in more interesting response, we thought this diversity would also be considered by human critics.\nBesides, due to the high variety of softmax and the high costs of inviting human critics, we do not use softmax in our new human evaluation experiment. Also, to better analyze where’s the improvement, we separate the coherence and the information provided into two scores for human evaluation.\n\n-why MLE, which is used as initialization, does better than all optimized models in the first simulation? Why is the GAN approach expected to increase the coverage compared to MLE? And why, in general, this is not always the case?\n\nAns: We have added explanation in Section 5.1. MLE in the first simulation has a very high accuracy, which then reduces the performance of pre-trained discriminator. The GAN-based algorithms then cannot get advantages based on this poor pre-trained discriminator. This is why we thought the first simulation is different from others.\n\n-would it be possible to compare the output of the proposed methods with the output of a non-GAN conditional sequence generator (if any) on human-scored dialog?  \n\nAns: Thanks for your suggestion. We add beam search and MMI in our new human-scored dialog experiments. The result is listed in Table 3."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515642510149,"tcdate":1511794663506,"number":3,"cdate":1511794663506,"id":"HJygOiYxM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A well written paper with somehow weak experimental results","rating":"5: Marginally below acceptance threshold","review":"The authors present a new scheme for applying adversarial networks to dialog generation. The idea of why using adversarial networks is important in dialog generation is really well motivated in the paper and related works are discussed in details. \n\nIn the proposed approach, a more flexible discrimination score is obtained by treating independently each sub-sequence of the input. Technically speaking, the authors' contribution is to add a set of free parameters in the sub-sequence discriminator sum of equation 8. From a more general point of view, what is the key output of the paper, except to confirm that curriculum learning can help in dialog generation?  \n\nThe experiments do not seem to show that a net performance improvement can be associated with the introduced free weights and what is a good strategy to tune them in an optimal way. In general, as the authors report also in the abstract, the performance of the proposed algorithm is 'comparable' with the state of the art but never outperforms other existing methods in a consistent way. \n\nIn fact, the performance of the algorithms depends strongly on the specific grammar used to generate the dataset and on the specific evaluation score. The human evaluation experiment is interesting but the proposed method is only compared with one other algorithm (seqGAN) and only two examples of the output are given explicitly.\n\nThe increase in computational cost due to the weighted sub-sequence evaluation is also poorly discussed.   \n\nFew more questions:\n-through the experiments section, the authors focus on evaluating the set of possible good answers (softmax and coverage score) instead of the best answer (argmax). Why is this important for dialog generation? In the generation of a real conversation, shouldn t one always choose the argmax option? What would be a practical use of the second and third-best options?\n-why softmax is always lower than argmax in the synthetic experiment and always higher than argmax in the human evaluation experiment?\n-why MLE, which is used as initialization, does better than all optimized models in the first simulation? Why is the GAN approach expected to increase the coverage compared to MLE? And why, in general, this is not always the case?\n-would it be possible to compare the output of the proposed methods with the output of a non-GAN conditional sequence generator (if any) on human-scored dialog?  ","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515702705830,"tcdate":1511790086039,"number":2,"cdate":1511790086039,"id":"HyRbL5YxM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting and potentially powerful approach to language generation, but incomplete and lacking insight / more thorough evaluation","rating":"5: Marginally below acceptance threshold","review":"UPDATE, 1/11/18:\nI read the revision. The writing has improved, and the new experiments are good. That said, it is my opinion that the paper is still not quite ready for publication, mostly because the story behind the model doesn't lead to the conclusions being made from the experiments in a clean and consistent way. It's a bit like patchwork at this point. The authors I think will need to put some time into a rewrite, but the content itself is worth pushing forward.\n\nSome notes:\n\"StepGAN a general version of SeqGAN, and can simulate the process of Monte-Carlo search with low extra computational cost:\" This really is a strong claim that's not proven in any way in the paper.\n\"In typical reinforcement learning, the agent obtains a reward...\": in typical RL settings, it's just as likely to find single or episodal rewards and this setting isn't limited to those where you have an extrinsic reward at each step.\nWhy do you still have WGAN-GP when there are no accompanying numbers?\n\n/begin old review\nThe approach is interesting, but as a contribution the paper has a long way to go. The ideas are there and everything seems correct, but there’s little motivation / insight on the model and why it might be better than competing methods for NLP tasks.\n\nIt would be good to see some sort of concrete analysis as far as what the model is doing (for instance how the discriminator scores change), and a comparison of how the reward signal given here might differ from other methods (SeqGAN, MaliGAN), and why this might be better. All we get is some scores, but it’s never clear why these scores indicate good (conditional) language generation. Can we not also look at BLEU scores for language generation or some other metric?\n\nFinally, the writing need to be improved: it starts out OK, but it progressively gets worse and worse.\n\nDetailed notes:\nP2\nIt might be good to mention beam search and scheduled sampling as other common methods to address the exposure bias.\n“objective function irrelevant to backpropagation”: what does this mean?\nMaliGAN actually also uses a “policy gradient”, which corresponds to an estimate of the likelihood ratio, to address the discrete problem.\nThough distinct from this work, Gulrajani used a CNN.\n\nP3\nUse \\log for logarithm\n“Moreover, the likelihood is only estimated at word-level”: is this true? It seems to me that likelihood of the sequence is estimated as well.\n\nP5\nWhy is this a generalized version of SeqGAN? The claim the discriminator value D(x_1..t | y) is the same as what you would get from a full-sequence generator using MCMC seems like a stretch.\nDid you not use a baseline?\nYou might want to build in a little more motivation for these different update rules. I think I understand that (10) is meant to accumulate credit across the rest of the sequence, while (11) does not, but it would be good to have this clearly stated. Why do you think one would work better than the other?\n\nP6\n“The generator G, in the mean time, struggle to maximize the likelihood of discriminator D” I don’t understand what this means.\nWhat was the motivation for using the same model here? Is the energy in this formulation related in any ways to EBGAN? Could you do something similar with separate parameters? Why would be or why would this not be a good idea?\nI do like these synthetic tasks. I think that more analyses would be helpful in understanding what the model (and what competing models) are doing.\n\nP7:\nWhat is VLGAN in the table?\nPerhaps it would be worth exploring changing alpha through optimization?\n\nP8:\nIt seems like many of the improvements in the table are marginal (with some exceptions): is it possible that ESGAN was optimized better?\n“auxiliary tricks” I would avoid this wording.\n\nOther comments on experiments:\nIt seems like the actual NLP part of this paper is quite sparse. Why was MaliGAN left out of the real experiments?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515642510227,"tcdate":1511704613231,"number":1,"cdate":1511704613231,"id":"HkTXuSulM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The paper is concerned with improving the sequence generation problem, in particular, for dialogue generation problem. The main contribution is in proposing to compute the cumulative reward for each step in the sequence generation procedure. The paper demonstrates that this leads to better performance in artificially generated grammar and for dialogue generation.","rating":"4: Ok but not good enough - rejection","review":"Quality: The paper proposes a direct improvement over SeqGAN by Yu. et. al. (2017). My assessment is partially determined by comparing this paper to Yu et. al (2017). In my opinion, this paper is lacking in quality in comparison to Yu et. al (2017). In particular, Yu et. al. (2017) provides detailed derivation of the policy gradient accompanied by a pseudo-code (algorithm) on how one can implement SeqGAN. On the contrary, this paper does not provide such details. Perhaps, all of the details of SeqGAN follows immediately, but the paper should not assume that all readers will be familiar with SeqGAN. \n\nClarity: \n\n1. The paper provides a review of related methods on conditional sequence generation in Section 3. However, it is very brief and as a non-expert in this field, I needed to refer to the original papers anyways. Perhaps, the review of the related methods can go to the Appendix and this space can be better utilized to expand on the original contributions made by the paper. \n2. MCMC (Markov chain Monte Carlo) is mentioned in 4.1 but it is not explained. \n3. Figure 1 is not sufficiently explained; neither in text nor in the figure caption. It would help greatly to describe the details of the network architecture shown in this figure.\n\nOriginality: The paper proposes a generalization of SeqGAN; however, in my opinion, the methodological contribution appears to be only incremental on SeqGAN. \n\nSignificance: The paper's significance may be evaluated in terms of its impact on applications as it proposes an improvement over the previous work of SeqGAN. However, the extent to which the evaluation is carried out is somewhat unsatisfactory with only one real application. Also, the applications considered in the experiments are primarily on dialogue generation. My initial impression is that the methodology lacks generality and may perhaps cater better to domain specific publication venues. \n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1515182513978,"tcdate":1509134736900,"number":780,"cdate":1509739104442,"id":"r1YqWz-R-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is composed of input-output pairs with the one-to-many property. Given the recent success of generative adversarial networks (GANs), GANs have been used for sequence generation. However, there is still limited work of its application on conditional sequence generation. We investigate the influence of GAN on conditional sequence generation with three artificial grammars and  dialogue generation. Moreover, we propose stepwise GAN (StepGAN) for conditional sequence generation, which predicts the reward at each time-step. StepGAN can be seen as the general version of SeqGAN. It estimates the expected returns predicted by Monte-Carlo Search in SeqGAN, but it has a lower computational cost than Monte-Carlo Search. Experimental results show that stepwise GAN can outperform other state-of-the-art algorithms in most tasks.","pdf":"/pdf/9e0fd3e0061af145dfc2b0edb311923f69f3dc83.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_stepwise_evaluation","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]},"nonreaders":[],"replyCount":8,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}