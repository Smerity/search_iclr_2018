{"notes":[{"tddate":null,"ddate":null,"tmdate":1515189450355,"tcdate":1515189450355,"number":4,"cdate":1515189450355,"id":"BkGC4OpQM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Comment","forum":"B1X4DWWRb","replyto":"ByozI_rlG","signatures":["ICLR.cc/2018/Conference/Paper685/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper685/Authors"],"content":{"title":"We thank Reviewer 1 for their comments.","comment":"We thank Reviewer 1 for their comments."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515189116890,"tcdate":1515189116890,"number":3,"cdate":1515189116890,"id":"r1HF7_pQM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Comment","forum":"B1X4DWWRb","replyto":"H1HywYblM","signatures":["ICLR.cc/2018/Conference/Paper685/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper685/Authors"],"content":{"title":"We respond to the specific concerns of Reviewer 3, both here and in our updated draft.","comment":"Q: The manuscript is written in a very compact style and I wish some passages would have been explained in more depth and detail. Especially the second half of page 5 is at times very hard to understand as it is so dense. \n\nA: We have improved clarity throughout the paper. For page 5 (Theory) specifically, we have adding headings and explanatory comments to provide additional context. \n\nQ: The implications of the assumptions in Theorem 1 are not easy to understand, especially relating to the quantities B_\\Phi, C^\\mathcal{F}_{n,\\delta} and D^{\\Phi,\\mathcal{H}}_\\delta. Why would we expect these quantities to be small or bounded? How does that compare to the assumptions needed for standard inverse probability weighting? \n\nA: We have added comments about the implications of Theorem 1. B_\\Phi is determined by the determinant of the Jacobian of the inverse representation \\Psi. For smooth invertible representations and an appropriate IPM, we can expect B to be bounded, but it could well be large. As long as we have sufficient overlap, there exists a weighting function to make the IPM term zero, (regardless of the scale of B). C and D are defined explicitly in the appendix and are standard sample complexity terms. Depending on application, Rademacher complexity, VC dimension, or covering numbers could be used for C. This has been clarified. For inverse probability weighting, our bound reduces to that of Cortes et al (2010) as the IPM term vanishes. For other weightings, the added assumption is that the loss lies in the family of functions determining the IPM. A larger family increases the changes of this being true, but loosens the bound in general.\n\nQ: I appreciate that it is difficult to find good test datasets for evaluating causal estimator. The experiment on the semi-synthetic IHDP dataset is ok, even though there is very little information about its structure in the manuscript (even basic information like number of instances or dimensions seems missing?). The example does not provide much insight into the main ideas and when we would expect the procedure to work more generally.\n\nA: The description of IHDP has been improved. We have also added a more targeted synthetic experiment (see above), that confirms our expectation that the usefulness of our method is largest when sample sizes are small. When sample sizes are large, more complex models can be fit and model misspecification can be reduced, thus reducing the usefulness of weighting methods in general. We have added a synthetic experiment in Section 6.1 to demonstrate this further.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515189416659,"tcdate":1515189013093,"number":2,"cdate":1515189013093,"id":"r1pGQ_aQM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Comment","forum":"B1X4DWWRb","replyto":"ryOA0TKgG","signatures":["ICLR.cc/2018/Conference/Paper685/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper685/Authors"],"content":{"title":"We respond to the specific concerns of Reviewer 2, both here and in our updated draft.","comment":"Q: In order to make sure the second  equality in Equation 2 holds, p_mu (y|x,t) = p_pi (y|x,t) should hold as well. Is this a standard assumption in the literature?\n\nA: This is a version of the standard, so-called covariate shift assumption (see e.g. Shimodaira, 2000) often made in e.g. domain adaptation. This was referred to only as outcomes being \"stationary\" in Section 2, but this has been clarified.\n\nQ: Two drawbacks of previous methods motivate this work, including the bias of representation learning and the high variance of re-weighting. According to Lemma 1, the proposed method is unbiased for the optimal weights in the large data limit. However, is there any theoretical guarantee or empirical evidence to show the proposed method does not suffer from the drawback of high variance?\n\nA: The variance of our estimator due to the weighting is accounted for theoretically in our bound by the factor V_\\mu and controlled in practice by a penalty on the norm of the weights, see Section 5. A more uniform set of weights yield lower variance but increased bias due to design shift (measured by the IPM term). We have also added a synthetic experiment investigating this, see Section 6.1. \n\nQ: Experiments on synthetic datasets, where both the shift in policy and the shift in domain are simulated and therefore can be controlled, would better demonstrate how the performance of the proposed approach (and those baseline \n methods) changes as the degree of design shift varies. \n\nA: We have added a small synthetic experiment to highlight the behavior of our model under varying sample sizes, comparing to methods using importance sampling weights. This is complementary to varying design shift.\n\nQ: Besides IHDP, did the authors run experiments on other real-world datasets, such as Jobs, Twins, etc?\n\nA: The Twins experiment, as used by Louizos et al. 2017, was primarily created to evaluate methods for dealing with hidden confounding. This is not the focus of our method as we assume ignorability. We found that in the setting of weak hidden confounding (small proxy noise), the imbalance between “treatment groups” was relatively small, and additional balancing neither hurt nor helped. We did not run experiments on Jobs.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515188830747,"tcdate":1515188830747,"number":1,"cdate":1515188830747,"id":"Skwvf_pmM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Comment","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper685/Authors"],"content":{"title":"We have taken the comments of the reviewers into account and updated our paper.","comment":"We thank all of the reviewers for their helpful comments and suggestions. Addressing these issues has increased the length of the manuscript, but we are confident that this is justified by the improved quality of the paper. We have responded to the concerns of the reviewers individually below.  "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515642491898,"tcdate":1511804624315,"number":3,"cdate":1511804624315,"id":"ryOA0TKgG","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Good theoretical results, more empirical evaluations can improve the paper","rating":"7: Good paper, accept","review":"Summary:\nThis paper proposes a new approach to tackle the problem of prediction under\nthe shift in design, which consists of the shift in policy (conditional\ndistribution of treatment given features) and the shift in domain (marginal \ndistribution of features).\n\nGiven labeled samples from a source domain and unlabeled samples from a target\ndomain, this paper proposes to minimize the risk on the target domain by \njointly learning the shift-invariant representation and the re-weighting \nfunction for the induced representations. According to Lemma 1 and its finite\nsample version in Theorem 1, the risk on the target domain can be upper bounded\nby the combination of 1) the re-weighted empirical risk on the source domain; \nand 2) the distributional discrepancy between the re-weighted source domain and\nthe target domain. These theoretical results justify the objective function\nshown in Equation 8. \n\nExperiments on the IHDP dataset demonstrates the advantage of the proposed\napproach compared to its competing alternatives.\n\nComments:\n1) This paper is well motivated. For the task of prediction under the shift in\ndesign, shift-invariant representation learning (Shalit 2017) is biased even in\nthe inifite data limit. On the other hand, although re-weighting methods are\nunbiased, they suffer from the drawbacks of high variance and unknown optimal\nweights. The proposed approach aims to overcome these drawbacks.\n\n2) The theoretical results justify the optimization procedures presented in\nsection 5. Experimental results on the IHDP dataset confirm the advantage of\nthe proposed approach.\n\n3) I have some questions on the details. In order to make sure the second \nequality in Equation 2 holds, p_mu (y|x,t) = p_pi (y|x,t) should hold as well.\nIs this a standard assumption in the literature?\n\n4) Two drawbacks of previous methods motivate this work, including the bias of\nrepresentation learning and the high variance of re-weighting. According to\nLemma 1, the proposed method is unbiased for the optimal weights in the large\ndata limit. However, is there any theoretical guarantee or empirical evidence\nto show the proposed method does not suffer from the drawback of high variance?\n\n5) Experiments on synthetic datasets, where both the shift in policy and the\nshift in domain are simulated and therefore can be controlled, would better \ndemonstrate how the performance of the proposed approach (and thsoe baseline \nmethods) changes as the degree of design shift varies. \n\n6) Besides IHDP, did the authors run experiments on other real-world datasets, \nsuch as Jobs, Twins, etc?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515642491936,"tcdate":1511519763052,"number":2,"cdate":1511519763052,"id":"ByozI_rlG","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Deep architecture for shift invariance in predictive modeling","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper proposes a deep learning architecture for joint learning of feature representation, a target-task mapping function, and a sample re-weighting function. Specifically, the method tries to discover feature representations, which are invariance in different domains, by minimizing the re-weighted empirical risk and distributional shift between designs.\nOverall, the paper is well written and organized with good description on the related work, research background, and theoretic proofs. \n\nThe main contribution can be the idea of learning a sample re-weighting function, which is highly important in domain shift. However, as stated in the paper, since the causal effect of an intervention T on Y conditioned on X is one of main interests, it is expected to add the related analysis in the experiment section.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515642491972,"tcdate":1511261917342,"number":1,"cdate":1511261917342,"id":"H1HywYblM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Reweighting for causal inference in absence of confounding","rating":"5: Marginally below acceptance threshold","review":"The paper proposes a novel way of causal inference in situations where in causal SEM notation the outcome Y = f(T,X) is a function of a treatment T and covariates X. The goal is to infer the treatment effect E(Y|T=1,X=x) - E(Y|T=0,X=x) for binary treatments at every location x. If the treatment effect can be learned, then forecasts of Y under new policies that assign treatment conditional on X will still \"work\" and the distribution of X can also change without affecting the accuracy of the predictions. \n\nWhat is proposed seems to be twofold:\n- instead of using a standard inverse probability weighting, the authors construct a bound for the prediction performance under new distributions of X and new policies and learn the weights by optimizing this bound. The goal is to avoid issues that arise if the ratio between source and target densities become very large or small and the weights in a standard approach would become very sparse, thus leading to a small effective sample size.\n- as an additional ingredient the authors also propose \"representation learning\" by mapping x to some representation Phi(x). \nThe goal is to learn the mapping Phi (and its inverse) and the weighting function simultaneously by optimizing the derived bound on the prediction performance. \n\nPros: \n- The problem is relevant and also appears in similar form in domain adaptation and transfer learning. \n- The derived bounds and procedures are interesting and nontrivial, even if there is some overlap with earlier work of Shalit et al. \n\nCons:\n- I am not sure if ICLR is the optimal venue for this manuscript but will leave this decision to others. \n- The manuscript is written in a very compact style and I wish some passages would have been explained in more depth and detail. Especially the second half of page 5 is at times very hard to understand as it is so dense. \n- The implications of the assumptions in Theorem 1 are not easy to understand, especially relating to the quantities B_\\Phi, C^\\mathcal{F}_{n,\\delta} and D^{\\Phi,\\mathcal{H}}_\\delta. Why would we expect these quantities to be small or bounded? How does that compare to the assumptions needed for standard inverse probability weighting? \n- I appreciate that it is difficult to find good test datasets for evaluating causal estimator.  The experiment on the semi-synthetic IHDP dataset is ok, even though there is very little information about its structure in the manuscript (even basic information like number of instances or dimensions seems missing?). The example does not provide much insight into the main ideas and when we would expect the procedure to work more generally.\n\n\n\n\n\n\n\n\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1515189334327,"tcdate":1509132074617,"number":685,"cdate":1509739157817,"id":"B1X4DWWRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a bound on the generalization error under design shift, based on integral probability metrics and sample re-weighting. We combine this idea with representation learning, generalizing and tightening existing results in this space. Finally, we propose an algorithmic framework inspired by our bound and verify is effectiveness in causal effect estimation.","pdf":"/pdf/4f50fa235bd67edc0f4fe1575d4ca3aea418f368.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]},"nonreaders":[],"replyCount":7,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}