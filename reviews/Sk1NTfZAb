{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222835141,"tcdate":1511844886817,"number":2,"cdate":1511844886817,"id":"SJyQ2wqlf","invitation":"ICLR.cc/2018/Conference/-/Paper997/Official_Review","forum":"Sk1NTfZAb","replyto":"Sk1NTfZAb","signatures":["ICLR.cc/2018/Conference/Paper997/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting idea to mitigate the GAN attack","rating":"5: Marginally below acceptance threshold","review":"Collaborative learning has been proposed as a way to learn over federated data while preserving privacy. However collaborative learning has been shown to be suscepti\nble to active attacks in which one of the participants uses a GAN to reveal information about another participant.\n\nThis paper proposes a collaborative learning framework (CLF) that mitigates the GAN attack. The framework involves using the neural net to learn a mapping of the inp\nut to a high-dimensional vector and computing the inner product of this vector to a random class-specific key (the final class prediction is the argmax of this inner product). The class-specific key can be chosen randomly by each participant. By choosing sufficiently long random keys, the probability of an attacker guessing the key can be reduced. Experiments on two datasets show that this scheme successfully avoids the GAN attack.\n \n1. Some of the details of key sharing are not clear and would appear to be important for the scheme to work. For example, if participants have instances associated with the same class, then they would need to share the key. This would require a central key distribution scheme which would then allow the attacker to also get access to the key.\n\n2. I would have  liked to see how the method works with an increasing fraction of adversarial participants (I could only see experiments with one adversary). Similarly, I would have liked to see experiments with and without the fixed dense layer to see its contribution to effective learning. ","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Key Protected Classification for GAN Attack Resilient Collaborative Learning","abstract":"Large-scale publicly available datasets accelerate deep learning studies. However they are not always available for all domains, especially for the ones in which sensitive information of subjects must be kept private. Collaborative learning techniques provide a privacy-preserving solution for the data owners who do not want to directly share their datasets with each other due to privacy concerns. Existing collaborative learning techniques (with the integration of the differential privacy concept) are shown to be resilient against a passive adversary which tries to infer the training data only from the resulting model parameters. However, recently, it has been shown that the existing collaborative learning techniques are vulnerable to an active adversary that runs a GAN attack during the learning phase. In this work, we propose a novel key-based collaborative leaning technique that is resilient against the GAN attack. We propose a collaborative learning technique in which class scores of each participant are protected by class-specific keys. We also introduce fixed neural network components into the proposed model in order to use high dimensional keys (for higher robustness) without increasing the model complexity. Via experiments using two popular datasets MNIST and AT\\&T Olivetti Faces, we show the robustness of the proposed technique against the GAN attack. To the best of our knowledge, the proposed technique is the first collaborative leaning technique that is resilient against an active adversary. ","pdf":"/pdf/bafff473e16c4115d8fcd80cb0d5047f430aa851.pdf","paperhash":"anonymous|key_protected_classification_for_gan_attack_resilient_collaborative_learning","_bibtex":"@article{\n  anonymous2018key,\n  title={Key Protected Classification for GAN Attack Resilient Collaborative Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk1NTfZAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper997/Authors"],"keywords":["privacy preserving deep learning","collaborative learning","adversarial attack"]}},{"tddate":null,"ddate":null,"tmdate":1512222835183,"tcdate":1511763970510,"number":1,"cdate":1511763970510,"id":"r1qWlNtlM","invitation":"ICLR.cc/2018/Conference/-/Paper997/Official_Review","forum":"Sk1NTfZAb","replyto":"Sk1NTfZAb","signatures":["ICLR.cc/2018/Conference/Paper997/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The weak assumption on the adversary undermines the usefulness of the protection scheme","rating":"4: Ok but not good enough - rejection","review":"This paper is a follow-up work to the CCS'2017 paper on the GAN-based attack on collaborative learning system where multiple users contribute their private and sensitive data to joint learning tasks. In order to avoid the potential risk of adversary's mimic based on information flow among distributed users, the authors propose to embed the class label into a multi-dimensional space, such that the joint learning is conducted over the embedding space without knowing the accurate representation of the classes. Under the assumption that the adversary can only generate fake and random class representations, they show their scheme is capable of hiding information from individual samples, especially over image data.\n\nThe paper is clearly written and easy to understand. The experiments show interesting results, which are particularly impressive with the face data. However, the reviewer feels the assumption on the adversary is generally too weak, such that slightly smarter adversary could circumvent the protection scheme and remain effective on sample recovery.\n\nBasically, instead of randomly guessing the representations of the classes from other innocent users, the adversary could apply GAN to learn the representation based on the feedback from these users. This can be easily done by including the representations in the embedding space in the parameters in GAN for learning.\n\nThis paper could be an interesting work, if the authors address such enhanced attacks from the adversary and present protection results over their existing experimental settings.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Key Protected Classification for GAN Attack Resilient Collaborative Learning","abstract":"Large-scale publicly available datasets accelerate deep learning studies. However they are not always available for all domains, especially for the ones in which sensitive information of subjects must be kept private. Collaborative learning techniques provide a privacy-preserving solution for the data owners who do not want to directly share their datasets with each other due to privacy concerns. Existing collaborative learning techniques (with the integration of the differential privacy concept) are shown to be resilient against a passive adversary which tries to infer the training data only from the resulting model parameters. However, recently, it has been shown that the existing collaborative learning techniques are vulnerable to an active adversary that runs a GAN attack during the learning phase. In this work, we propose a novel key-based collaborative leaning technique that is resilient against the GAN attack. We propose a collaborative learning technique in which class scores of each participant are protected by class-specific keys. We also introduce fixed neural network components into the proposed model in order to use high dimensional keys (for higher robustness) without increasing the model complexity. Via experiments using two popular datasets MNIST and AT\\&T Olivetti Faces, we show the robustness of the proposed technique against the GAN attack. To the best of our knowledge, the proposed technique is the first collaborative leaning technique that is resilient against an active adversary. ","pdf":"/pdf/bafff473e16c4115d8fcd80cb0d5047f430aa851.pdf","paperhash":"anonymous|key_protected_classification_for_gan_attack_resilient_collaborative_learning","_bibtex":"@article{\n  anonymous2018key,\n  title={Key Protected Classification for GAN Attack Resilient Collaborative Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk1NTfZAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper997/Authors"],"keywords":["privacy preserving deep learning","collaborative learning","adversarial attack"]}},{"tddate":null,"ddate":null,"tmdate":1510092382666,"tcdate":1509137721933,"number":997,"cdate":1510092360786,"id":"Sk1NTfZAb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Sk1NTfZAb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Key Protected Classification for GAN Attack Resilient Collaborative Learning","abstract":"Large-scale publicly available datasets accelerate deep learning studies. However they are not always available for all domains, especially for the ones in which sensitive information of subjects must be kept private. Collaborative learning techniques provide a privacy-preserving solution for the data owners who do not want to directly share their datasets with each other due to privacy concerns. Existing collaborative learning techniques (with the integration of the differential privacy concept) are shown to be resilient against a passive adversary which tries to infer the training data only from the resulting model parameters. However, recently, it has been shown that the existing collaborative learning techniques are vulnerable to an active adversary that runs a GAN attack during the learning phase. In this work, we propose a novel key-based collaborative leaning technique that is resilient against the GAN attack. We propose a collaborative learning technique in which class scores of each participant are protected by class-specific keys. We also introduce fixed neural network components into the proposed model in order to use high dimensional keys (for higher robustness) without increasing the model complexity. Via experiments using two popular datasets MNIST and AT\\&T Olivetti Faces, we show the robustness of the proposed technique against the GAN attack. To the best of our knowledge, the proposed technique is the first collaborative leaning technique that is resilient against an active adversary. ","pdf":"/pdf/bafff473e16c4115d8fcd80cb0d5047f430aa851.pdf","paperhash":"anonymous|key_protected_classification_for_gan_attack_resilient_collaborative_learning","_bibtex":"@article{\n  anonymous2018key,\n  title={Key Protected Classification for GAN Attack Resilient Collaborative Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk1NTfZAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper997/Authors"],"keywords":["privacy preserving deep learning","collaborative learning","adversarial attack"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}