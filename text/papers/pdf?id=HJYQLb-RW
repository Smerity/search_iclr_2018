Under review as a conference paper at ICLR 2018
ON THE LIMITATIONS OF FIRST-ORDER APPROXIMATION IN GAN DYNAMICS
Anonymous authors Paper under double-blind review
ABSTRACT
Generative Adversarial Networks (GANs) have been proposed as an approach to learning generative models. While GANs have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, neither in theory nor in practice. In particular, the work in this domain has been focused so far only on understanding the properties of the stationary solutions that this dynamics might converge to, and of the behavior of that dynamics in this solutions' immediate neighborhood. To address this issue, in this work we take a first step towards a principled study of the GAN dynamics itself. To this end, we propose a model that, on one hand, exhibits several of the common problematic convergence behaviors (e.g., vanishing gradient, mode collapse, diverging or oscillatory behavior), but on the other hand, is sufficiently simple to enable rigorous convergence analysis. This methodology enables us to exhibit an interesting phenomena: a GAN with an optimal discriminator provably converges, while guiding the GAN training using only a first order approximation of the discriminator leads to unstable GAN dynamics and mode collapse. This suggests that such usage of the first order approximation of the discriminator, which is a de-facto standard in all the existing GAN dynamics, might be one of the factors that makes GAN training so challenging in practice. Additionally, our convergence result constitutes the first rigorous analysis of a dynamics of a concrete parametric GAN.
1 INTRODUCTION
Generative modeling is a fundamental learning task of growing importance. As we apply machine learning to increasingly sophisticated problems, we often aim to learn functions with an output domain that is significantly more complex than simple class labels. Common examples include image "translation" (Isola et al., 2017), speech synthesis (van den Oord et al., 2016), and robot trajectory prediction (Finn et al., 2016). Due to progress in deep learning, we now have access to powerful architectures that can represent generative models over such complex domains. However, training these generative models is a key challenge. Simpler learning problems such as classification have a clear notion of "right" and "wrong," and the approaches based on minimizing the corresponding loss functions have been tremendously successful. In contrast, training a generative model is far more nuanced because it is often unclear how "good" a sample from the model is.
Generative Adversarial Networks (GANs) have recently been proposed to address this issue (Goodfellow et al., 2014). In a nutshell, the key idea of GANs is to learn both the generative model and the loss function at the same time. The resulting training dynamics are usually described as a game between a generator (the generative model) and a discriminator (the loss function). The goal of the generator is to produce realistic samples that fool the discriminator, while the discriminator is trained to distinguish between the true training data and samples from the generator. GANs have shown promising results on a variety of tasks, and there is now a large body of work that explores the power of this framework (Goodfellow, 2017).
Unfortunately, reliably training GANs is a challenging problem that often hinders further research in this area. Practitioners have encountered a variety of obstacles such as vanishing gradients, mode collapse, and diverging or oscillatory behavior (Goodfellow, 2017). At the same time, the theoretical underpinnings of GAN dynamics are not yet well understood. To date, there were no convergence
1

Under review as a conference paper at ICLR 2018

proofs for GAN models, even in very simple settings. As a result, the root cause of frequent failures of GAN dynamics in practice remains unclear.
In this paper, we take a first step towards a principled understanding of GAN dynamics. Our general methodology is to propose and examine a problem setup that exhibits all common failure cases of GAN dynamics while remaining sufficiently simple to allow for a rigorous analysis. Concretely, we introduce and study the GMM-GAN: a variant of GAN dynamics that captures learning a mixture of two univariate Gaussians. We first show experimentally that standard gradient dynamics of the GMM-GAN often fail to converge due to mode collapse or oscillatory behavior. Interestingly, this also holds for techniques that were recently proposed to improve GAN training such as unrolled GANs (Metz et al., 2017). In contrast, we then show that GAN dynamics with an optimal discriminator do converge, both experimentally and provably. To the best of our knowledge, our theoretical analysis of the GMM-GAN is the first global convergence proof for parametric and non-trivial GAN dynamics.
Our results show a clear dichotomy between the dynamics arising from applying simultaneous gradient descent and the one that is able to use an optimal discriminator. The GAN with optimal discriminator provably converges from (essentially) any starting point. On the other hand, the simultaneous gradient GAN empirically often fails to converge, even when the discriminator is allowed many more gradient steps than the generator. These findings go against the common wisdom that first order methods are sufficiently strong for all deep learning applications. By carefully inspecting our models, we are able to pinpoint some of the causes of this, and we highlight a phenomena we call discriminator collapse which often causes first order methods to fail in our setting.

2 GENERATIVE ADVERSARIAL DYNAMICS

Generative adversarial networks are commonly described as a two player game (Goodfellow et al.,
2014). Given a true distribution P , a set of generators G = {Gu, u  U}, a set of discriminators D = {Dv, v  V}, and a monotone measuring function m : R  R, the objective of GAN training is to find a generator u in

arg min
uU

max
vV

ExP [m(Dv(x))]

+

ExGu [m(1

-

Dv (x))]

.

(1)

In other words, the game is between two players called the generator and discriminator, respectively. The goal of the discriminator is to distinguish between samples from the generator and the true distribution. The goal of the generator is to fool the discriminator by generating samples that are similar to the data distribution.

By varying the choice of the measuring function and the set of discriminators, one can capture a wide variety of loss functions. Typical choices that have been previously studied include the KL divergence and the Wasserstein distance (Goodfellow et al., 2014; Arjovsky et al., 2017). This formulation can also encode other common objectives: most notably, as we will show, the total variation distance.

To optimize the objective (1), the most common approaches are variants of simultaneous gradient descent on the generator u and the discriminator v. But despite its attractive theoretical grounding, GAN training is plagued by a variety of issues in practice. Two major problems are mode collapse and vanishing gradients. Mode collapse corresponds to situations in which the generator only learns a subset (a few modes) of the true distribution P (Goodfellow, 2017; Arora & Zhang, 2017). For instance, a GAN trained on an image modeling task would only produce variations of a small number of images. Vanishing gradients (Arjovsky et al., 2017; Arjovsky & Bottou, 2017; Arora et al., 2017) are, on the other hand, a failure case where the generator updates become vanishingly small, thus making the GAN dynamics not converge to a satisfying solution. Despite many proposed explanations and approaches to solve the vanishing gradient problem, it is still often observed in practice (Goodfellow, 2017).

2.1 TOWARDS A PRINCIPLED UNDERSTANDING OF GAN DYNAMICS
GANs provide a powerful framework for generative modeling. However, there is a large gap between the theory and practice of GANs. Specifically, to the best of the authors' knowledge, all theoretical studies of GAN dynamics for parametric models simply consider global optima and stationary points of the dynamics, and there has been no rigorous study of the actual GAN dynamics. In practice,

2

Under review as a conference paper at ICLR 2018

GANs are always optimized using first order methods, and the current theory of GANs cannot tell us whether or not these methods converge to a meaningful solution. This raises a natural question, also posed as an open problem in (Goodfellow, 2017):
Our theoretical understanding of GANs is still fairly poor. In particular, to the best of the authors' knowledge, all existing analyzes of GAN dynamics for parametric models simply consider global optima and stationary points of the dynamics. There has been no rigorous study of the actual GAN dynamics, except studying it in the immediate neighborhood of such stationary points (Nagarajan & Kolter, 2017). This raises a natural question:
Can we understand the convergence behavior of GANs?
This question is difficult to tackle for many reasons. One of them is the non-convexity of the GAN objective/loss function, and of the generator and discriminator sets. Another one is that, in practice, GANs are always optimized using first order methods. That is, instead of following the "ideal" dynamics that has both the generator and discriminator always perform the optimal update, we just approximate such updates by a sequence of gradient steps. This is motivated by the fact that computing such optimal updates is, in general, algorithmically intractable, and adds an additional layer of complexity to the problem.
In this paper, we want to change this state of affairs and initiate the study of GAN dynamics from an algorithmic perspective. Specifically, we pursue the following question:
What is the impact of using first order approximation on the convergence of GAN dynamics?
Concretely, we focus on analyzing the difference between two GAN dynamics: a "first order" dynamics, in which both the generator and discriminator use first order updates; and an "optimal discriminator" dynamics, in which only the generator uses first order updates but the discriminator always makes an optimal update. Even the latter, simpler dynamics has proven to be challenging to understand. Even the question of whether using the optimal discriminator updates is the right approach has already received considerable attention. In particular, (Arjovsky & Bottou, 2017) present theoretical evidence that using the optimal discriminator at each step may not be desirable in certain settings (although these settings are very different to the one we consider in this paper).
We approach our goal by defining a simple GAN model whose dynamics, on one hand, captures many of the difficulties of real-world GANs but, on the other hand, is still simple enough to make analysis possible. We then rigorously study our questions in the context of this model. Our intention is to make the resulting understanding be the first step towards crystallizing a more general picture.

3 A SIMPLE MODEL FOR STUDYING GAN DYNAMICS

Perhaps a tempting starting place for coming up with a simple but meaningful set of GAN dynamics is to consider the generators being univariate Gaussians with fixed variance. Indeed, in the supplementary material we give a short proof that simple GAN dynamics always converge for this class of generators. However, it seems that this class of distributions is insufficiently expressive to exhibit many of the phenomena such as mode collapse mentioned above. In particular, the distributions in this class are all unimodal, and it is unclear what mode collapse would even mean in this context.

Generators. The above considerations motivate us to make our model slightly more complicated.
We assume that the true distribution and the generator distributions are all mixtures of two univariate Gaussians with unit variance, and uniform mixing weights. Formally, our generator set is G, where

11 G = 2 N (µ1, 1) + 2 N (µ2, 1) | µ1, µ2  R .

(2)

For any µ  R2, we let Gµ(x) denote the distribution in G with means at µ1 and µ2. While this is a simple change compared to a single Gaussian case, it makes a large difference in the behavior of the
dynamics. In particular, many of the pathologies present in real-world GAN training begin to appear.

Loss function. While GANs are usually viewed as a generative framework, they can also be viewed
as a general method for density estimation. We want to set up learning an unknown generator Gµ  G as a generative adversarial dynamics. To this end, we must first define the loss function

3

Under review as a conference paper at ICLR 2018

for the density estimation problem. A well-studied goal in this setting is to recover Gµ (x) in total variation (also known as L1 or statistical) distance, where the total variation distance between two

distributions P, Q is defined as

1 dTV(P, Q) = 2

|P (x) - Q(x)|dx = max P (A) - Q(A) ,
A

where the maximum is taken over all measurable events A.

(3)

Such finding the best-fit distribution in total variation distance can indeed be naturally phrased as generative adversarial dynamics. Unfortunately, for arbitrary distributions, this is algorithmically problematic, simply because the set of discriminators one would need is intractable to optimize over.

However, for distributions that are structurally simple, like mixtures of Gaussians, it turns out we

can consider a much simpler set of discriminators. In Appendix B.1 in the supplementary material,

motivated by connections to VC theory, we show that for two generators Gµ1 , Gµ2  G, we have

dTV(Gµ1 ,

Gµ2 )

=

max
E =I1 I2

Gµ1 (E)

-

Gµ2 (E)

,

(4)

where the maxima is taken over two disjoint intervals I1, I2  R. In other words, instead of
considering the difference of measure between the two generators Gµ1 , Gµ2 on arbitrary events, we may restrict our attention to unions of two disjoint intervals in R. This is a special case of a

well-studied distance measure known as the Ak-distance, for k = 2 (Devroye & Lugosi, 2012; Chan

et al., 2014). Moreover, this class of subsets has a simple parametric description.

Discriminators. Now, the above discussion motivates our definition of discriminators to be

D

= {I[

1,r1] + I[

2,r2] |

,r



2
R

s.t.

1  r1 

2  r2} .

(5)

In other words, the set of discriminators is taken to be the set of indicator functions of sets which can

be expressed as a union of at most two disjoint intervals. With this definition, finding the best fit in total variation distance to some unknown Gµ  G is equivalent to finding µ minimizing

µ = arg min max L(µ,
µ ,r

, r)

, where

L(µ,

, r) = ExGµ [D(x)] + ExGµ [1 - D(x)]

(6)

is a smooth function of all three parameters (see the supplementary material for details).

Dynamics. The objective in (6) is easily amenable to optimization at parameter level. A natural

approach for optimizing this function would be to define G(µ) = max ,r L(µ, , r), and to perform (stochastic) gradient descent on this function. This corresponds to, at each step, finding the the

optimal discriminator, and updating the current µ in that direction. We call these dynamics the optimal discriminator dynamics. Formally, given µ(0) and a stepsize g, and a true distribution Gµ  G, the optimal discriminator dynamics for Gµ , G, D starting at µ(0) are given iteratively as

(t), r(t) = arg max L(µ(t), , r) , µ(t+1) = µ(t) - gµL(µ(t), (t), r(t)) ,
,r

(7)

where the maximum is taken over , r which induce two disjoint intervals.

For more complicated generators and discriminators such as neural networks, these dynamics are

computationally difficult to perform. Therefore, instead of the updates as in (7), one resorts to

simultaneous gradient iterations on the generator and discriminator. These dynamics are called the first order dynamics. Formally, given µ(0), (0), r(0) and a stepsize g, d, and a true distribution Gµ  G, the first order dynamics for Gµ , G, D starting at µ(0) are specified as

µ(t+1) = µ(t) - gµL(µ(t), (t), r(t))

(8)

r(t+1) = r(t) + drL(µ(t), (t), r(t)) , (t+1) = (t) + d L(µ(t), (t), r(t)) .

(9)

Even for our relatively simple setting, the first order dynamics can exhibit a variety of behaviors,

depending on the starting conditions of the generators and discriminators. In particular, in Figure 1,

we see that depending on the initialization, the dynamics can either converge to optimality, exhibit

a primitive form of mode collapse, where the two generators collapse into a single generator, or

converge to the wrong value, because the gradients vanish. This provides empirical justification for

our model, and shows that these dynamics are complicated enough to model the complex behaviors

which real-world GANs exhibit. Moreover, as we show in Section 5 below, these behaviors are not

just due to very specific pathological initial conditions: indeed, when given random initial conditions,

the first order dynamics still more often than not fail to converge.

4

Under review as a conference paper at ICLR 2018

Parametrization We note here that there could be several potential GAN dynamics to consider here. Each one resulting from slightly different parametrization of the total variation distance. For instance, a completely equivalent way to define the total variation distance is

dTV(P, Q) = max |P (A) - Q(A)| ,
A

(10)

which does not change the value of the variational distance, but does change the induced dynamics. We do not focus on these induced dynamics in this paper since they do not exactly fit within the traditional GAN framework, i.e. it is not of the form (1) (see Appendix C). Nevertheless, it is an interesting set of dynamics and it is a natural question whether similar phenomena occur in these dynamics. In Appendix C, we show the the optimal discriminator dynamics are unchanged, and the induced first order dynamics have qualitatively similar behavior to the ones we consider in this paper. This also suggests that the phenomena we exhibit might be more fundamental.

First order dynamics, converging behavior
3
2
1
0

First order dynamics, mode collapse

4

left0 left1

right0

right1

2 muhat0

muhat1

0

12

2 4
30 1000 2000 3000 4000 5000 0 1000 2000 3000 4000 5000 6000 7000 8000

(a) Converging behavior

(b) Mode collapse and oscillation

Optimal discriminator dynamics
3

First order dynamics, vanishing gradient
0.2

2 0.0

1 0.2
0.4 0
0.6 1
0.8
2 1.0

30 20 40 60 80 100 1.20 1000 2000 3000 4000 5000

(c) Optimal discriminator

(d) Vanishing gradient

Figure 1: A selection of different GAN behaviors. In all plots the true distribution was Gµ with µ = (-0.5, 0.5), and step size was taken to be 0.1. The solid lines represent the two coordinates of µ, and the dotted lines represent the discriminator intervals. In order: (a) first order dynamics with initial conditions that converge to the true distribution. (b) First order dynamics with initial conditions that exhibit wild oscillation before mode collapse. (c) Optimal discriminator dynamics. (d) First order dynamics that exhibit vanishing gradients and converge to the wrong distribution. Observe that the optimal discriminator dynamics converge, and then the discriminator varies wildly, because the objective function is not differentiable at optimality. Despite this it remains roughly at optimality from step to step.

4 OPTIMAL DISCRIMINATOR VS. FIRST ORDER DYNAMICS

We now describe our results in more detail. We first consider the dynamics induced by the optimal discriminator. Our main theoretical result is1:
1We actually analyze a minor variation on the optimal discriminator dynamics. In particular, we do not rule out the existence of a measure zero set on which the dynamics are ill-behaved. Thus, we will analyze the optimal

5

Under review as a conference paper at ICLR 2018

Theorem 4.1.

Fix 

>

0 sufficiently small and C

>

0.

Let µ



2
R

so

that

|µi |



C, and

|µ1 -µ2|  . Then, for all initial points µ(0) so that |µ(i0)|  C for all i and so that |µ(10) -µ2(0)|  ,

if we let  = poly(1/, e-C2 ) and T = poly(1/, e-C2 ), then if µ(T ) is specified by the optimal

discriminator dynamics, we have dTV(Gµ , Gµ(T) )  .

In other words, if the µ are bounded by a constant, and not too close together, then in time which is polynomial in the inverse of the desired accuracy  and e-C2 , where C is a bound on how far apart the µ and µ are, the optimal discriminator dynamics converge to the ground truth in total variation distance. Note that the dependence on e-C2 is necessary, as if the µ and µ are initially very far apart,
then the initial gradients for the µ will necessarily be of this scale as well.

On the other hand, we provide simulation results that demonstrate that first order updates, or more complicated heuristics such as unrolling, all fail to consistently converge to the true distribution, even under the same sorts of conditions as in Theorem 4.1. In Figure 1, we gave some specific examples where the first order dynamics fail to converge. In Section 5 we show that this sort of divergence is common, even with random initializations for the discriminators. In particular, the probability of convergence is generally much lower than 1, for both the regular GAN dynamics, and unrolling. In general, we believe that this phenomena should occur for any natural first order dynamics for the generator. In particular, one barrier we observed for any such dynamics is something we call discriminator collapse, that we describe in Appendix A.

4.1 ANALYZING THE OPTIMAL DISCRIMINATOR DYNAMICS

We provide now a high level overview of the proof of Theorem 4.1. The key element we will need in our proof is the ability to quantify the progress our updates make on converging towards the optimal solution. This is particularly challenging as our objective function is neither convex nor smooth. The following lemma is our main tool for achieving that. Roughly stated, it says that for any Lipschitz function, even if it is non-convex and non-smooth, as long as the change in its derivative is smaller in magnitude than the value of the derivative, gradient descent makes progress on the function value. Note that this condition is much weaker than typical assumptions used to analyze gradient descent.

Lemma 4.2.

Let g

:

k
R



R be a Lipschitz function that is differentiable at some fixed x



k
R

.

For some  > 0, let x = x - f (x). Suppose there exists c < 1 so that almost all v 

L(x, x ), where L(x, y) denotes the line between x and y, g is differentiable, and moreover, we have

g(x) - g(v)

2c

g(x)

2. Then g(x ) - g(x)  -(1 - c)

g(x)

2 2

.

Here, we will use the convention that µ1  µ2, and during the analysis, we will always assume for simplicity of notation that µ1  µ2. Also, in what follows, let f (µ) = fµ (µ) = dTV(Gµ, Gµ ) and F (µ, x) = Gµ (x) - Gµ(x) be the objective function and the difference of the PDFs between the
true distribution and the generator, respectively.

For any  > 0, define the sets

Rect() = {µ : |µi - µj | <  for some i, j} , Opt() = {µ : |µi - µi | <  for all i} .

to be the set of parameter values which have at least one parameter which is not too far from optimality,
and the set of parameter values so that all parameter values are close. We also let B(C) denote the box of sidelength C around the origin, and we let Sep() = {v  R2 : |v1 - v2| > } be the set of parameter vectors which are not too close together.

Our main work lies within a set of lemmas which allow us to instantiate the bounds in Lemma 4.2. We first show a pair of lemmas which show that, explicitly excluding bad cases such as mode collapse, our dynamics satisfy the conditions of Lemma 4.2. We do so by establishing a strong (in fact, nearly constant) lower bound on the gradient when we are fairly away from optimality (Lemma 4.3). Then, we show a relatively weak bound on the smoothness of the function (Lemma 4.4), but which is sufficiently strong in combination with Lemma 4.3 to satisfy Lemma 4.2. Finally, we rule

discriminator dynamics after adding an arbitrarily small amount of Gaussian noise. It is clear that by taking this noise to be sufficiently small (say exponentially small) then we avoid this pathological set with probability 1, and moreover the noise does not otherwise affect the convergence analysis at all. For simplicity, we will ignore this issue for the rest of the paper.

6

Under review as a conference paper at ICLR 2018
out the pathological cases we explicitly excluded earlier, such as mode collapse or divergent behavior (Lemmas 4.5 and 4.6). Putting all these together appropriately yields the desired statement. Our first lemma is a lower bound on the gradient value: Lemma 4.3. Fix C  1     > 0. Suppose µ  Rect(0), and suppose µ, µ  B(C) and µ  Sep(), µ  Sep(). There is some K = (1) · (e-C2 /C)O(1) so that fµ (µ) 2  K.
The above lemma statement is slightly surprising at first glance. It says that the gradient is never 0, which would suggest there are no local optima at all. To reconcile this, one should note that the gradient is not continuous (defined) everywhere.
The second lemma states a bound on the smoothness of the function: Lemma 4.4. Fix C  1 and    > 0 so that  is sufficiently small. Let µ, µ, µ be such that L(µ, µ )  Opt() = , µ  Sep(), µ , µ  Sep(), and µ, µ, µ  B(C). Let K = (1) · (e-C2 /C)O(1) be the K for which Lemma 4.3 holds with those parameters. If we have µ - µ 2  (1) · (e-C2 /C)O(1) for appropriate choices of constants on the RHS, we get
fµ (µ ) - fµ (µ) 2  K/2  fµ (µ) 2/2.
These two lemmas almost suffice to prove progress as in Lemma 4.2, however, there is a major caveat. Specifically, Lemma 4.4 needs to assume that µ and µ are sufficiently well-separated, and that they are bounded. While the µi start out separated and bounded, it is not clear that it does not mode collapse or diverge off to infinity. However, we are able to rule these sorts of behaviors out. Formally: Lemma 4.5 (No mode collapse). Fix  > 0, and let  be sufficiently small. Let   /C for some C large. Suppose µ  Sep(). Then, if µ  Sep(), and µ = µ - fµ (µ), we have µ  Sep(). Lemma 4.6 (No diverging to infinity). Let C > 0 be sufficiently large, and let  > 0 be sufficiently small. Suppose µ  B(C), and µ  B(2C). Then, if we let µ = µ - fµ (µ), then µ  B(2C).
Together, these four lemmas together suffice to prove Theorem 4.1 by setting parameters appropriately. We refer the reader to Appendix D for more details including the proofs.
5 EXPERIMENTS
To illustrate more conclusively that the phenomena demonstrated in Figure 1 are not particularly rare, and that first order dynamics do often fail to converge, we also conducted the following heatmap experiments. We set µ = (-0.5, 0.5) as in Figure 1. We then set a grid for the µ, so that each coordinate is allowed to vary from -1 to 1. For each of these grid points, we randomly chose a set of initial discriminator intervals, and ran the first order dynamics for 3000 iterations, with constant stepsize 0.3. We then repeated this 120 times for each grid point, and plotted the probability that the generator converged to the truth, where we say the generator converged to the truth if the TV distance between the generator and optimality is < 0.1. The choice of these parameters was somewhat arbitrary, however, we did not observe any qualitative difference in the results by varying these numbers, and so we only report results for these parameters. We also did the same thing for the optimal discriminator dynamics, and for unrolled discriminator dynamics with 5 unrolling steps, as described in (Metz et al., 2017), which attempt to match the optimal discriminator dynamics.
The results of the experiment are given in Figure 2. We see that all three methods fail when we initialize the two generator means to be the same. This makes sense, since in that regime, the generator starts out mode collapsed and it is impossible for it to un-"mode collapse", so it cannot fit the true distribution well. Ignoring this pathology, we see that the optimal discriminator otherwise always converges to the ground truth, as our theory predicts. On the other hand, both regular first order dynamics and unrolled dynamics often times fail, although unrolled dynamics do succeed more often than regular first order dynamics. This suggests that the pathologies in Figure 1 are not so rare, and that these first order methods are quite often unable to emulate optimal discriminator dynamics.
6 RELATED WORK
GANs have received a tremendous amount of attention over the past two years (Goodfellow, 2017). Hence we only compare our results to the most closely related papers here.
7

Under review as a conference paper at ICLR 2018

Regular training

Unrolled Training

Optimal training

1.0 1.0 1.0 1.0 1.0 1.0

0.9 0.9 0.9

0.8 0.8 0.8 0.5 0.7 0.5 0.7 0.5 0.7

0.6 0.6 0.6

0.0 0.5 0.0 0.5 0.0 0.5 0.4 0.4 0.4

0.3 0.3 0.3 0.5 0.2 0.5 0.2 0.5 0.2

0.1 0.1 0.1

1.01.0 0.5 0.0 0.5 1.0 0.0 1.01.0 0.5 0.0 0.5 1.0 0.0 1.01.0 0.5 0.0 0.5 1.0 0.0

Figure 2: Heatmap of success probability for random discriminator initialization for regular GAN training, unrolled GAN training, and optimal discriminator dynamics.

The recent paper (Arora et al., 2017) studies generalization aspects of GANs and the existence of equilibria in the two-player game. In contrast, our paper focuses on the dynamics of GAN training. We provide the first rigorous proof of global convergence and show that a GAN with an optimal discriminator always converges to an approximate equilibrium.
One recently proposed method for improving the convergence of GAN dynamics is the unrolled GAN (Metz et al., 2017). The paper proposes to "unroll" multiple discriminator gradient steps in the generator loss function. The authors argue that this improves the GAN dynamics by bringing the discriminator closer to an optimal discriminator response. Our experiments show that this is not a perfect approximation: the unrolled GAN still fails to converge in multiple initial configurations (however, it does converge more often than a "vanilla" one-step discriminator).
The authors of (Arjovsky & Bottou, 2017) also take a theoretical view on GANs. They identify two important properties of GAN dynamics: (i) Absolute continuity of the population distribution, and (ii) overlapping support between the population and generator distribution. If these conditions do not hold, they show that the GAN dynamics fail to converge in some settings. However, they do not prove that the GAN dynamics do converge under such assumptions. We take a complementary view: we give a convergence proof for a concrete GAN dynamics. Moreover, our model shows that absolute continuity and support overlap are not the only important aspects in GAN dynamics: although our distributions clearly satisfy both of their conditions, the first-order dynamics still fail to converge.
The paper (Nagarajan & Kolter, 2017) studies the stability of equilibria in GAN training. In contrast to our work, the results focus on local stability while we establish global convergence results. Moreover, their theorems rely on fairly strong assumptions. While the authors give a concrete model for which these assumptions are satisfied (the linear quadratic Gaussian GAN), the corresponding target and generator distributions are unimodal. Hence this model cannot exhibit mode collapse. We propose the GMM-GAN specifically because it is rich enough to exhibit mode collapse.
The recent work (Grnarova et al., 2017) views GAN training through the lens of online learning. The paper gives results for the game-theoretic minimax formulation based on results from online learning. The authors give results that go beyond the convex-concave setting, but do not address generalization questions. Moreover, their algorithm is not based on gradient descent (in contrast to essentially all practical GAN training) and relies on an oracle for minimizing the highly non-convex generator loss. This viewpoint is complementary to our approach. We establish results for learning the unknown distribution and analyze the commonly used gradient descent approach for learning GANs.
7 CONCLUSIONS
We haven taken a step towards a principled understanding of GAN dynamics. We define a simple yet rich model of GAN training and prove convergence of the corresponding dynamics. To the best of our knowledge, our work is the first to establish global convergence guarantees for a parametric GAN. We find an interesting dichotomy: If we take optimal discriminator steps, the training dynamics provably converge. In contrast, we show experimentally that the dynamics often fail if we take first order discriminator steps. We believe that our results provide new insights into GAN training and point towards a rich algorithmic landscape to be explored in order to further understand GAN dynamics.
8

Under review as a conference paper at ICLR 2018
REFERENCES
Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial networks. In ICLR, 2017. URL https://arxiv.org/abs/1701.04862.
Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein GAN. arXiv preprint arXiv:1701.07875, 2017.
Sanjeev Arora and Yi Zhang. Do gans actually learn the distribution? an empirical study. arXiv preprint arXiv:1706.08224, 2017.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium in generative adversarial nets (GANs). arXiv preprint arXiv:1703.00573, 2017.
Siu-On Chan, Ilias Diakonikolas, Rocco A Servedio, and Xiaorui Sun. Efficient density estimation via piecewise polynomial approximation. In Proceedings of the 46th Annual ACM Symposium on Theory of Computing, pp. 604­613. ACM, 2014.
Luc Devroye and Gábor Lugosi. Combinatorial methods in density estimation. Springer Science & Business Media, 2012.
Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine. A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models. CoRR, abs/1611.03852, 2016. URL http://arxiv.org/abs/1611.03852.
Walter Gautschi. How (un) stable are Vandermonde systems? Lecture Notes in Pure and Applied Mathematics, 124:193­210, 1990.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672­2680, 2014.
Ian J. Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. CoRR, abs/1701.00160, 2017. URL http://arxiv.org/abs/1701.00160.
Paulina Grnarova, Kfir Y. Levy, Aurelien Lucchi, Thomas Hofmann, and Andreas Krause. An online learning approach to generative adversarial networks. arXiv preprint arXiv:1706.03269, 2017.
R.A. Hummel and B.C. Gidas. Zero Crossings and the Heat Equation. New York University., 1984.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017.
VA Markov. On functions deviating least from zero in a given interval. Izdat. Imp. Akad. Nauk, St. Petersburg, pp. 218­258, 1892.
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial networks. In ICLR, 2017. URL http://arxiv.org/abs/1611.02163.
Vaishnavh Nagarajan and J. Zico Kolter. Gradient descent gan optimization is locally stable. arXiv preprint arXiv:1706.04156, 2017.
Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. CoRR, abs/1609.03499, 2016. URL http://arxiv.org/abs/1609.03499.
9

Under review as a conference paper at ICLR 2018
(a) Initial Configuration (b) Optimal Discriminator for Initial Configuration

(c) After 1000 Discriminator Steps

(d) After 1000 Simultaneous Generator and Discriminator Steps

(e) After 1000 Simultaneous Generator and Discriminator
Steps with 100x Unrolling

Figure 3: Example of Discriminator Collapse. The initial configuration has µ = {-2, 2}, µ = {-1, 2.5}, left discriminator [-1, 0.2], and right discriminator [-1, 2.5]. The (multiplicative) step size used to generate (c), (d), and (e) was 0.3.
A DISCRIMINATOR COLLAPSE: A BARRIER FOR FIRST ORDER METHODS
As discussed above, our simple GAN dynamics are able to capture the same undesired behaviors that more sophisticated GANs exhibit. In addition to these behaviors, our dynamics enables us to discern another degenerate behavior which does not seem to have previously been observed in the literature. We call this behavior discriminator collapse.
We first explain this phenomenon using language specific to our GMM-GAN dynamics. In our dynamics, discriminator collapse occurs when a discriminator interval which originally had finite width is forced by the dynamics to have its width converge to 0. This happens whenever this interval lies entirely in a region where the generator PDF is much larger than the discriminator PDF. We will shortly argue why this is undesirable.
In Figure 3, we show an example of discriminator collapse in our dynamics. Each plot in the figure shows the true PDF minus the PDF of the generators, where the regions covered by the discriminator are shaded. Plot (a) shows the initial configuration of our example. Notice that the leftmost discriminator interval lies entirely in a region for which the true PDF minus the generators' PDF is negative. Since the discriminator is incentivized to only have mass on regions where the difference is positive, the first order dynamics will cause the discriminator interval to collapse to have length zero if it is in a negative region. We see in Plot (c) that this discriminator collapses if we run many discriminator steps for this fixed generator. In particular, these steps do not converge to the globally optimal discriminator shown in Plot (b).
This collapse also occurs when we run the dynamics. In Plots (d) and (e), we see that after running the first order dynamics ­ or even unrolled dynamics ­ for many iterations, eventually both discriminators collapse. When a discriminator interval has length zero, it can never uncollapse, and moreover, its contribution to the gradient of the generator is zero. Thus these dynamics will never converge to the ground truth.
For general GANs, we view discriminator collapse as a situation when the local optimization landscape around the current discriminator encourages it to make updates which decrease its representational power. For instance, this could happen because the first order updates are unable to wholly follow the evolution of the optimal discriminator due to attraction of local maxima, and thus only capture part of the optimal discriminator's structure. We view understanding the exact nature of discriminator collapse in more general settings and interesting research problem to explore further.
10

Under review as a conference paper at ICLR 2018
B OMITTED DETAILS FROM SECTION 2
B.1 TWO INTERVALS SUFFICE FOR G
Here we formally prove (4). In fact, we will prove a slight generalization of this fact which will be useful later on. We require the following theorem from Hummel and Gidas:
Theorem B.1 ((Hummel & Gidas, 1984)). Let f be any analytic function with at most n zeros. Then f  N (0, 2) has at most n zeros.
This allows us to prove:
Theorem B.2. Any linear combination F (x) of the probability density functions of k Gaussians with the same variance has at most k - 1 zeros, provided at least two of the Gaussians have different means. In particular, for any µ = , the function F (x) = Dµ(x) - D(x) has at most 3 zeroes.
Proof. If we have more than 1 Gaussian with the same mean, we can replace all Gaussians having that mean with an appropriate factor times a single Gaussian with that mean. Thus, we assume without loss of generality that all Gaussians have distinct means. We may also assume without loss of generality that all Gaussians have a nonzero coefficient in the definition of F . Suppose the minimum distance between the means of any of the Gaussians is . We first prove the statement when  is sufficiently large compared to everything else. Consider any pair of Gaussians with consecutive means , µ. WLOG assume that µ >  = 0. Suppose our pair of Gaussians has the same sign in the definition of F . In particular they are both strictly positive. For sufficiently large , we can make the contribution of the other Gaussians to F an arbitrarily small fraction of the whichever Gaussian in our pair is largest for all points on [, µ]. Thus, for  sufficiently large, that there are no zeros on this interval. Now suppose our pair of Gaussians have different signs in the definition of F . Without loss of generality, assume the sign of the Gaussian with mean  is positive and the sign of the Gaussian with mean µ is negative. Then the PDF of the first Gaussian is strictly decreasing on (, µ] and the PDF of the negation of the second Gaussian is decreasing on [, µ). Thus, their sum is strictly decreasing on this interval. Similarly to before, by making  sufficiently large, the magnitude of the contributions of the other Gaussians to the derivative in this region can be made an arbitrarily small fraction of the magnitude of whichever Gaussian in our pair contributes the most at each point in the interval. Thus, in this case, there is exactly one zero in the intervale [µ, ]. Also, note that there can be no zeros of F outside of the convex hull of their means. This follows by essentially the same argument as the two positive Gaussians case above. The general case (without assuming  sufficiently large) follows by considering sufficiently skinny (nonzero variance) Gaussians with the same means as the Gaussians in the definition of F , rescaling the domain so that they are sufficiently far apart, applying this argument to this new function, unscaling the domain (which doesn't change the number of zeros), then convolving the function with an appropriate (very fat) Gaussian to obtain the real F , and invoking Theorem B.1 to say that the number of zeros does not increase from this convolution.
B.2 THE FUNCTION L
In this section, we derive the form of L. By definition, we have  2L(µ, , r) = 2 ExGµ [D(x)] + ExGµ [1 - D(x)]  = 2 Gµ (x) - Gµ(x)dx + 2 ,
I
11

Under review as a conference paper at ICLR 2018

where I = [ 1, r1]  [ 2, r2]. We then have

 
2L(µ, , r) = 2 

 ri 
Gµ (x) - Gµ(x)dx + 2

i=1,2 i

=

ri

e-(x-µj )2 /2

-

e-(x-µj )2/2dx

+

 2

.

i=1,2 j=1,2 i

(11)

It is not to hard to see from the Fundamental theorem of calculus that L is indeed a smooth function of all parameters.

C ALTERNATIVE INDUCED DYNAMICS

Our focus in this paper is on the dynamics induced by, since it arises naturally from the form of the total variation distance (3) and follows the canonical form of GAN dynamics (1). However, one could consider other equivalent definitions of total variation distance too. And these definitions could, in principle, induce qualitatively different behavior of the first order dynamics.

As mentioned in Section 3, an alternative dynamics could be induced by the definition of total variation distance given in (10). The corresponding loss function would be

L (µ, , r) = |L(µ, , r)| = ExGµ [D(x)] + ExGµ [1 - D(x)] ,

(12)

i.e. the same as in (6) but with absolute values on the outside of the expression. Observe that this loss function does not actually fit the form of the general GAN dynamics presented in (1). However, it still constitutes a valid and fairly natural dynamics. Thus one could wonder whether similar behavior to the one we observe for the dynamics we actually study occurs also in this case.

To answer this question, we first observe that by the chain rule, the (sub)-gradient of L with respect to µ, , r are given by

µL (µ, , r) = sgn (L(µ, , r)) µL(µ, , r)  L (µ, , r) = sgn (L(µ, , r))  L(µ, , r) rL (µ, , r) = sgn (L(µ, , r)) rL(µ, , r) , that is, they are the same as for L except modulated by the sign of L.

We now show that the optimal discriminator dynamics is identical to the one that we analyze in the
paper (7), and hence still provably converge. This requires some thought; indeed a priori it is not
even clear that the optimal discriminator dynamics are well-defined, since the optimal discriminator is no longer unique. This is because for any µ, µ, the sets A1 = {x : Gµ (x)  Gµ(x)} and A2 = {x : Gµ(x)  Gµ (x)} both achieve the maxima in (10), since

Gµ(x) - Gµ (x)dx = - Gµ(x) - Gµ (x)dx .
A1 A2

(13)

However, we show that the optimal discriminator dynamics are still well-formed. WLOG assume that A1 Gµ(x) - Gµ (x)dx  0, so that A1 is also the optimal discriminator for the dynamics we consider in the paper. If we let (i), r(i) be the left and right endpoints of the intervals in Ai for i = 1, 2, we have that the update to µ induced by ( (1), r(1)) is given by
µL (µ, (1), r(1)) = µL(µ, (1), r(1)) ,
so the update induced by ( (1), r(1)) is the same as the one induced by the optimal discriminator dynamics in the paper. Moreover, the update to µ induced by ( (2), r(2)) is given by
µL (µ, (2), r(2)) = sgn L(µ, (2), r(2)) µL(µ, (2), r(2))
(=a) -µ(-L(µ, (1), r(1))) = µL(µ, (1), r(1)) ,

12

Under review as a conference paper at ICLR 2018

where (a) follows from the assumption that A1 Gµ(x) - Gµ (x)dx  0 and from (13), so it is also equal to the the one induced by the optimal discriminator dynamics in the paper. Hence the optimal discriminator dynamics are well-formed and unchanged from the optimal discriminator dynamics described in the paper.
Thus the question is whether the first order approximation of this dynamics and/or the unrolled first order dynamics exhibit the same qualitative behavior too. To evaluate the effectiveness, we performed for these dynamics experiments analogous to the ones summarized in Figure 2 in the case of the dynamics we actually analyzed. The results of these experiments are presented in Figure 4. Although the probability of success for these dynamics is higher, they still often do not converge. We can thus see that a similar dichotomy occurs here as in the context of the dynamics we actually study. In particular, we still observe the discriminator collapse phenomena in these first order dynamics.

1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.5 1.0 0.5 0.0 0.5 1.0 1.5

1.0 0.8 0.6 0.4 0.2 0.0

1.5 1.0 0.5 0.0 0.5 1.0 1.5 1.5 1.0 0.5 0.0 0.5 1.0 1.5

1.0 0.8 0.6 0.4 0.2 0.0

Figure 4: Heatmap of success probability for random discriminator initialization for regular GAN training, unrolled GAN training with dynamics induced by 12

C.1 WHY DOES DISCRIMINATOR COLLAPE STILL HAPPEN?
It might be somewhat surprising that even with absolute values discriminator collapse occurs. Originally the discriminator collapse occurred because if an interval was stuck in a negative region, it always subtracts from the value of the loss function, and so the discriminator is incentivized to make it disappear. Now, since the value of the loss is always nonnegative, it is not so clear that this still happens.
Despite this, we still observe discriminator collapse with these dynamics. Here we describe one simple scenario in which discriminator collapse still occurs. Suppose the discriminator intervals have left and right endpoints , r and L(µ, , r) > 0. Then, if it is the case that ri Gµ (x)-Gµ(x)dx < 0
i
for some i = 1, 2. that is, on one of the discriminator intervals the value of the loss is negative, then the discriminator is still incentivized locally to reduce this interval to zero, as doing so increases both L(µ, , r) and hence L (µ, , r). Symmetrically if L(µ, , r) < 0 and there is a discriminator interval on which the loss is positive, the discriminator is incentivized locally to reduce this interval to zero, since that increases L (µ, , r). This causes the discriminator collapse and subsequently causes the training to fail to converge.
D OMITTED PROOFS FROM SECTION 4.1
This appendix is dedicated to a proof of Theorem 4.1. We start with some remarks on the proof techniques for these main lemmas. At a high level, Lemmas 4.3, 4.5, 4.6 all follow from involved case analyses. Specifically, we are able to deduce structure about the possible discriminator intervals by reasoning about the structure of the current mean estimate µ and the true means. From there we are able to derive bounds on how these discriminator intervals affect the derivatives and hence the update functions.
To prove Lemma 4.4, we carefully study the evolution of the optimal discriminator as we make small changes to the generator. The key idea is to show that when the generator means are far from the true means, then the zero crossings of F (µ, x) cannot evolve too unpredictably as we change µ. We do so by showing that locally, in this setting F can be approximated by a low degree polynomial
13

Under review as a conference paper at ICLR 2018

with large coefficients, via bounding the condition number of a certain Hermite Vandermonde matrix. This gives us sufficient control over the local behavior of zeros to deduce the desired claim. By being sufficiently careful with the bounds, we are then able to go from this to the full generality of the lemma. We defer further details to Appendix D.

D.1 SETUP

By inspection on the form of (11), we see that the gradient of the function fµ (µ) if it is defined must be given by

fµ = 1

e-(µi-ri)2/2 - e-(µi- i)2/2

µi 2 i=1,2

.

Here Ii = [ i, ri] are the intervals which achieve the supremum in (4). While these intervals may not be unique, it is not hard to show that this value is well-defined, as long as µ = µ, that is, when the optimal discriminator intervals are unique as sets.

Recall Fµ (µ, x) = Gµ (x) - Gµ(x).

D.2 BASIC MATH FACTS

Before we begin, we require the following facts.

We first need that the Gaussian, and any fixed number of derivatives of the Gaussian, are Lipschitz

functions.

Fact D.1.

For any constant i, there exists a constant B such that for all x, µ  R,

di dxi

N (x, µ, 2

=

1)  B.

Proof. Note that every derivative of the Gaussian PDF (including the 0th) is a bounded function. Furthermore, all these derivatives eventually tend to 0 whenever the input goes towards  or -. Thus, any particular derivative is bounded by a constant for all R. Furthermore, shifting the mean of the Gaussian does not change the set of values the derivatives of its derivative takes (only their locations).

We also need the following bound on the TV distance between two Gaussians, which is folklore, and is easily proven via Pinsker's inequality. Fact D.2 (folklore). If two univariate Gaussians with unit variance have means within distance at most  then their TV distance is at most O(1) · .
This immediately implies the following, which states that fµ is Lipschitz. Corollary D.3. There is some absolute constant C so that for any µ, , we have |fµ (µ) - fµ ()|  C µ -  2.
We also need the following basic analysis fact: Fact D.4 (folklore). Suppose g : Rd  R is B-Lipschitz for some B. Then g is differentiable almost everywhere.
This implies that fµ is indeed differentiable except on a set of measure zero. As mentioned previously, we will always assume that we never land within this set during our analysis.

D.3 PROOF OF THEOREM 4.1 GIVEN LEMMATA
Before we prove the various lemmata described in the body, we show how Theorem 4.1 follows from them.

Proof of Theorem 4.1. Set  be a sufficiently small constant multiple of . Provided we make the nonzero constant factor on the step size sufficiently small (compared to  /), and the exponent on  in the magnitude step size at least one, the magnitude of our step size will be at most  . Thus, in any

14

Under review as a conference paper at ICLR 2018

step where µ  Opt( ), we end the step outside of this set but still in Opt(2 ). By Lemma D.2, for a sufficiently small choice of constant in the definition of  , the TV-distance at the end of such a step will be at most .
Contrapositively, in any step where the TV-distance at the start is more than , we will have at the start that µ  Opt( ). Then, it suffices to prove that the step decreases the total variation distance additively by at least 1/ poly(C, eC2 , 1/) in this case. For appropriate choices of constants in expression for the step size (sufficiently small multiplicative and sufficiently large in the exponent), this is immediately implied by Lemma 4.4 and Lemma 4.2 provided that µ, µ, µ  B(2C) and |µ1 - µ2|   at the beginning of each step. The condition that we always are within B(2C) at the start of each step is proven in Lemma 4.6 and the condition that the means are separated (ie., that we don't have mode collapse) is proven in Lemma 4.5.

It is interesting that a critical component of the above proof involves proving explicitly that mode collapse does not occur. This suggests the possibility that understanding mode collapse may be helpful in understanding convergence of Generative Adversarial Models and Networks.

D.4 PROOF OF LEMMA 4.3

In this section we prove Lemma 4.3. We first require the following fact:

Fact D.5 ((Markov, 1892)).

Let

p(x)

=



d i=0

cj xj

be

a

degree

d

polynomial

so

that

|p(x)|



1

for

all x  [-1, 1]. Then max0jd |cj|  ( 2 + 1)d. More generally, if |p(x)|   for all x  [-, ],

then max0jd |cjj|  O().

We also have the following, elementary lemma: Lemma D.6. Suppose µ2 > µi for all i. Then there is some x > µ2 so that Fµ (µ, x) < 0.
We are now ready to prove Lemma 4.3

Proof of Lemma 4.3. We proceed by case analysis on the arrangement of the µ and µ.

Case 1: µ1 < µ1 and µ2 < µ2 In this case we have Fµ (µ, x)  0 for all x  µ2. Hence the

optimal discriminators are both to the left of µ2. Moreover, by a symmetric logic we have

Fµ (µ, x)  0 for all x  µ1, so the optimal discriminator has an interval of the form

I1 = [-, r1] and possibly I2 = [l2, r2] where r1 < l2 < r2 < µ2. Then it is easy to see

that

f µ2

(µ2

)



1 e-(µ2-r2)2/2
2



1 e-2C2 .
2

Case 2: µ1 < µ1 and µ2 < µ2 This case is symmetric to Case (1).

Case 3: µ1 < µ1 < µ2 < µ2 By Lemma D.6, we know that Fµ (µ, x) < 0 for some x  µ2, and similarly Fµ (µ, x) < 0 for some x  µ1. Since clearly F (µ)(µ, x) > 0 for x  [µ1, µ2], by Theorem B.2 and continuity, the optimal discriminator has one interval. Denote it by I = [ , r], so that we have  µ1 and r  µ2. Suppose  µ1. Then

f µ1 (µ1)

=

1 2

e-(µ1- )2/2 - e-(µ1-r)2/2

= 1 e-(µ1- )2/2 1 - e-(µ1- )(r- )e-(r- )2/2 2

 1 e-2C2 1 - e-2/2 . 2

We

get

the

symmetric

bound

on

 fµ µ2

(µ2)

if

r



µ2.

The

final

case

is

if

< µ1 < µ2 < r.

Consider the auxiliary function

H (µ) = e-( -µ)2/2 - e-(r-µ)2/2 .

15

Under review as a conference paper at ICLR 2018

On the domain [ , r], this function is monotone decreasing. Moreover, for any µ  [ , r], we have
H (µ) = ( - µ)e-( -µ)2/2 - (r - µ)e-(r-µ)2/2  - r - e-(r- )2/8 2  -  e-2/8 . 2

In particular, this implies that H(µ1) < H(µ2) - 2e-2/8/2, so at least one of H(µ2) or

H (µ1 )

must

be

2e-2/8/4

in

absolute

value.

Since

 fµ µi

(µi)

=

H (µi ),

this

completes

the

proof in this case.

Case 4: µ1 < µ1 < µ2 < µ2 By a symmetric argument to Case 3, we know that the optimal discriminator intervals are of the form (-, r] and [ , ) for some r < µ1 < µ2 < . The form of the derivative is then exactly the same as in the last sub-case in Case 3 with signs
reversed, so the same bound holds here.

D.5 PROOF OF LEMMA 4.4

We now seek to prove Lemma 4.4. Before we do so, we need to get lower bounds on derivatives of finite sums of Gaussians with the same variance. In particular, we first show:

Lemma D.7. Fix    > 0 and C  1. Suppose we have µ, µ  B(C), µ, µ  Sep(), with

µ  Rect(), where all these vectors have constant length k. Then, for any x  [-C, C], we have

that

|

di dxi

Fµ (µ,

x)|



(1)

·

( /C )O(1) e-C 2 /2

for

some

i

=

0,

.

.

.

,

2k

-

1.

Proof. Observe that the value of the ith derivative of Fµ (µ, x) for any x is given by

di dxi Fµ (µ, x)

=

1 2

2k
wj (-1)iHi(zj )e-zj2/2
j=1

,

where wj  {-1/k, 1/k}, the zj is either x - µj or x - µj, and Hi(z) is the ith (probabilist's) Hermite polynomial. Note that the (-1)iHi are orthogonal with respect to the Gaussian measure

over R, and are orthonormal after some finite scaling that depends only on i and is therefore

constant.

Hence,

if

we

form

the

matrix

Mij

=

(-1)iHi(x - zj),

if

we

define

ui

=

di dxi

Fµ

(µ,

x)

for

i

= v

0, . . . , 2k - 
2  ( k ·

1, we have e-C2/2) =

that

Mv

=

u,

where

vj

=

1 2

wj

e-(x-zj

)2

/2

.

By

(e-C2/2). Thus, to show that some ui cannot be

assumption, too small, it

we have suffices

to show a lower bound on the smallest singular value of M . To do so, we leverage the following fact,

implicit in the arguments of (Gautschi, 1990):

Theorem D.8 ((Gautschi, 1990)). Let pr(z) be family of orthonormal polynomials with respect to a positive measure d on the real line for r = 1, 2, . . . , t and let z1, . . . , zt be arbitrary real numbers with zi = zj for i = j. Define the matrix V given by Vij = pi(zj). Then, the smallest singular value of V , denoted t(V ), is at least

min(V ) 

t -1/2

r (y )2 d (y )

,

R r=1

where r(y) =

s=r

y-zs zr -zs

is

the

Langrange

interpolating

polynomial

for

the

zr .

Set pr = Hr-1 t = 2k, and  as the Gaussian measure; then apply the theorem. Observe that for any

i, j, we have |zi - zj|  min(, )   and |zi|  C. Hence the largest coefficient of any Lagrange

interpolating

polynomial

through

the

zi

is

at

most

(

C 

)2k-1

with

degree

2k

-

1.

So,

the

square

of

16

Under review as a conference paper at ICLR 2018

any

such

polynomial

has

degree

at

most

2(2k

-

1)

and

max

coefficient

at

most

2k(

C 

)2(2k-1)

This

implies that

2k 2k

r(y)2 d(y) =

r(y)2 d(y)

R r=1

r=1 R

2k
 2(2k - 1) · 2k

C

2(2k-1)

max

 s[2(2k-1)]

r=1

C 4k

 O(1) ·

max


yse-y2/2 dy

 s[4k] -

 O(1) ·

C

O(1)
.



ysd(y)
R

Hence by Theorem D.8 we have that min(V )  (1) ·

 C

O(1). Therefore, we have that

u 2

(1) · (/C)O(1)e-C2/2, which immediately implies the desired statement.

We next show that the above Lemma can be slightly generalized, so that we can replace the condition µ  Rect() with µ  Opt().

Lemma D.9. Fix C  1       > 0. Suppose we have µ, µ  B(C), µ, µ  Sep(), with

µ



Opt().

Then

for

any

x



[-C,

C ],

we

have

that

|

di dxi

Fµ (µ,

x)|



(1)

·

(e-C2 /C)O(1)

for

some i = 0, . . . , 3.

Proof. Let  be of the form (1) · (e-C2 /C)O(1), where we will pick its precise value later.

Lemma D.7 with  in that Lemma set to  and k = 2 proves the special case when µ  Rect().

Thus, the only remaining Without loss of generality, and |µ2 - µ2|  .

case is when we assume the

µi is close first entries

to µi for some i are the close pair.

and far away Then we have

for |µ1

the other - µ1| 

i. 

There

are

four

terms

in

the

expression

for

Fdi
dxi µ

Lemma D.7 with  =  and k = 1 implies that

(µ, the

x) corresponding to contribution of the

each of µ1 µ2 and µ2

, µ2, µ1, µ2. terms to at

least one of the 0th through 3rd derivatives has magnitude at least (1) · (e-C2 /C)O(1). Fact D.2

and Lemma D.10 (below) imply that the contribution of the µ1 and µ1 terms to these derivatives

has magnitude at most O(1) · 4. Thus, there exists a  = (1) · (/C)O(1)e-C2/2 such that the

magnitude of the contribution of these second two terms is less than half that of the first two, which

gives a lower bound on the magnitude of the sum of all the terms of (1) · (/C)O(1)e-C2/2.

We now show that any function which always has at least one large enough derivative--including its 0th derivaive--on some large enough interval must have a nontrivial amount of mass on the interval.

Lemma D.10. Let 0 <  < 1 and t  N. Let F (x) : R  R be a (t + 1)-times differentiable

function such that at every point x on some interval I of length |I|  , F (x)  0 and there exists

an

i

=

i(x)



0,

.

.

.

,

t

such

that

|

di dxi

F

(x)|



B

for

some

B

.

Also

suppose

| dt+1
dxt+1

F (x)|



B

for

some B. Then,

y
F (x)dx 

B · ((1) · )t+1 · min[(B /B)t+2, 1]

.

z (t + 1)! · (t + 1)

Proof. Let 0 < a < 1 be a non-constant whose value we will choose later. If I has length more

than a, truncate it to have this length. Let z denote the midpoint of I. By assumption, we know

that

there

is

some

i



0, . . . , t

such

that

|

di dxi

F

(x)|

>

.

Thus,

by

Taylor's

theorem,

we

have

that

F (µ, x)  p(x - z) - (B/(t + 1)!) · |x - z|t+1 for some degree t polynomial p that has some

coefficient of magnitude at least B /t!.

Thus, if we let G(y) =

y z

p(x)dx,

then

G(y)

is

a

degree

t

+

1

polynomial

with

some

coefficient

which is at least B /(t! · t). By the nonnegativity of F on I, we have that G is nonnegative on

17

Under review as a conference paper at ICLR 2018

[-a/2, a/2]. By this and the contrapositive of Fact D.5 (invoked with  set to a sufficiently
small nonzero constant multiple of B), we have for some such y and some constant B > 0 that G(y) = |G(y)|  B (|I|/2)t+1B /(t! · t). Therefore, at this point, we have

yy
F (x)dx  G(y) - (B/(t + 1)!) · |x - z|t+1dx

zz

B at+1(/2)t+1B

B(a/2)t+2

-

t! · t (t + 1)! · (t + 1)

 at+1(/2)t+1(B B - Ba/2) (t + 1)! · (t + 1)

at+1(/2)t+1(B B - Ba/2)  (t + 1)! · (t + 1) .

If B B  B, we set a = B B /B  1 which gives

y
F (x)dx 
z

(B )t+2((1) · /B)t+1 (t + 1)! · (t + 1)

.

Otherwise, B B  B and we perform this substitution along with a = 1 which gives the similar bound

y
F (x)dx 

B ((1) · )t+1

.

z (t + 1)! · (t + 1)

Together, these bounds imply that we always have

y
F (x)dx 

B · ((1) · )t+1 · min[(B /B)t+2, 1]

.

z (t + 1)! · (t + 1)

This allows us to prove the following lemma, which lower bounds how much mass F can put on any interval which is moderately large. Formally: Lemma D.11. Fix C  1     > 0. Let K = (1) · (e-C2 /C)O(1) be the K for which Lemma 4.3 is always true with those parameters. Let µ, µ be so that µ  Opt(), µ, µ  Sep(), and µ, µ  B(C). Then, there is a  = (1) · (/C)O(1)e-C2 )O(1) such that for any interval I of length |I|   which satisfies I  [-C - 2 log(100/K), C + 2 log(100/K)] =  and on which F (µ, x) is nonnegative, we have
|F (µ, x)|dx  (1) · (e-C2 /C)O(1)O(1) .
I
Proof. By Lemma D.9 with C in that lemma set to C + 2 log(100/K), we get a lower bound of (1) · (e-C2 /C)O(1) on the magnitude of at least one of the 0th through 3rd derivatives of F (µ, x) with respect to x. Set  equal to a sufficiently small (nonzero) constant times this value.
By Fact D.1 there exists a constant B such that the magnitude of the fifth derivative of F (µ, x) with respect to x--which is a linear combination of four fifth derivatives of Gaussians with constant coefficients--is at most B. By Lemma D.10 applied to F (µ, x) as a function of x, we have I F (µ, x)dx  (1) · 6.
Now we can prove Lemma 4.4.
Proof of Lemma 4.4. Let A = [C - 2 log(100/K), C + 2 log(100/K)] where K = (1) · (e-C2 /C)O(1) is the K for which Lemma 4.3 is always true with those parameters.
18

Under review as a conference paper at ICLR 2018

Let Z± denote the set of all x  A for which F (µ , x) and F (µ, x) have different nonzero signs. Let Z+ denote the subset of Z± where F (µ , x) > 0 > F (µ, x) and Z- denote the subset where F (µ , x) < 0 < µ, x). Then Z± = Z+  Z- and Z+, Z- are disjoint and Lebesgue-measurable. If vol(Z+)  vol(Z-), switch µ and µ so that vol(Z+)  vol(Z-).

Note that Z+ can be obtained by making cuts in the real line at the zeros of F (µ , x), F (µ, x), and F (µ , x) - F (µ, x), then taking the union of some subset of the open intervals induced by these cuts. By Theorem B.2, the total number of such intervals is O(1). Thus, Z+ is the union of a constant number of open intervals. By similar arguments, Z- is also the union of a constant number of open
intervals.

We now prove that vol(Z+), Z-1  O(1) ·

µ

-µ

(1) 1

·

(e-C2 /C)-O(1).

Since vol(Z+)



vol(Z-), it suffices to prove vol(Z+)  O(1) ·

µ

-µ

(1) 1

·

(e-C2 /C)-O(1).

Note

also

that

by

Lemma D.2, each of these intervals has mass under F (µ , x) at most |F (µ , x) - F (µ, x)|dx 
R
O(1) · µ - µ 1. By Lemma D.11 and Lemma 4.3, each of these intervals has length at most

O(1) · µ this is also

-a bµou1n(d1)o·n(voel-(ZC2+/)C()a-ndO(v1o)l.(SZin-c)e).there

are

at

most

a

constant

number

of

such

intervals,

Let Y denote the set of x  A on which both F (µ, x) and F (µ , x) are nonnegative. Let X, X denote the x  A for which F (µ, x) and F (µ , x) are respectively positive. Let W, W denote, respectively, the sets of endpoints of the union of the optimal discriminators for µ, µ . Then the union of the optimal discriminators for µ, µ are respectively Y  Z-  X  W and Y  Z+  X  W . Furthermore, each of these two unions is given by some constant number of closed intervals and more specifically, that X, X each contain at most two intervals by Lemma B.2. Thus, we have for any i that



µ
TV(µ, µ)

µi µ

=

d e(x-µi)2/2dx -

d e(x-µi)2/2dx

dx dx

Y Z+W X

Y Z-W X



d e(x-µi)2/2dx -

d e(x-µi)2/2dx

dx dx

Y Z+W X

Y Z-W X

+ O(1) · |µi - µi| ,

19

Under review as a conference paper at ICLR 2018

by Lipschitzness, and so



µ
TV(µ, µ)

µi µ

=

d e(x-µi)2/2dx -

d e(x-µi)2/2dx

dx dx

Z + X

Z - X

+ O(1) · |µi - µi|



d e(x-µi)2/2dx ± 4 · K -

d e(x-µi)2/2dx ± 4 · K

dx 100 dx 100

Z+ Z-

+ O(1) · |µi - µi|

 d e(x-µi)2/2dx + d e(x-µi)2/2dx dx dx
Z+ Z-

8 + 100 · K + O(1) · |µi - µi|

 2vol(Z+)

sup d e(x-µi)2/2 xR dx

+

8 100

·

K

+

O(1)

·

|µi

-

µi|

 O(1) ·

µ

-µ

(1) 2

·

(e-C2 /C)-O(1)

+

8 100

·K.

This bound also upper bounds fµ (µ ) - fµ (µ) 2 up to a constant factor. Thus, if we choose our step to have magnitude µ - µ 2  (1) · (e-C2 /C)O(1) with appropriate choices of constants, we get
fµ (µ ) - fµ (µ) 2  K/2  fµ (µ) 2/2 ,
as claimed

D.6 PROOF OF LEMMA 4.5 We now prove Lemma 3.4, which forbids mode collapse.

Proof of Lemma 4.5. Since   , if |µ1 - µ2| > 2 then clearly µ  Sep(), since the gradient is at most a constant since the function is Lipschitz. Thus assume WLOG that |µ1 - µ2|  2  /50.
There are now six cases:

Case 1: µ1  µ1  µ2  µ2 This case cannot happen since we assume |µ1 - µ2|  2  /50.

Case

2:

µ1  µ1  µ2  µ2 Since clearly F  0

In this case, by Lemma D.6, we know F is negative at - and at +. when x  [µ1, µ2], by Theorem B.2 and continuity, the discriminator

intervals must to µi is (up to

be of the form (-, r], [ a constant factor of 2)

, ) for given by

some r  µ1  µ2  . Thus, the update e-( -µi)2/2 - e-(r-µi)2/2. The function

Q(x) = e-( -x)2/2 - e-(r-x)2/2 is monotone on x  [r, ], and thus µi must actually move

away from each other in this scenario.

Case 3: µ1  µ1  µ2  µ2 In this case we must have |µ2 -µ1|  2 and similarly |µ2 -µ2|  2. We claim that in this case, the discriminator must be an infinitely long interval (-, m]
for some m  µ1. This is equivalent to showing that the function F (µ, x) has only one zero, and this zero occurs at some m  µ1. This implies the lemma in this case since then the update to µ1 and µ2 are then in the same direction, and moreover, the magnitude of the update to µ1 is larger, by inspection.

20

Under review as a conference paper at ICLR 2018

We first claim that there are no zeros in the interval [µ1, µ2]. Indeed, in this interval, we have that

 2Dµ(x)



2e-(/50)2/2

= 2e-2/5000

 2 1 - 2 + O(4) 5000

 2 1 - 2 , 10

but

 2Dµ (x)



1

+

e-( -2 )2 /2

= 1 + e-(49/50)2/2

 2 - 2 . 2

Hence Gµ(x)  Gµ (x) for all x  [µ1, µ2], and so there are no zeros in this interval. Clearly there are no zeros of F when x  µ2, because in that regime e-(x-µi)2/2  e-(x-µi )2/2 for i = 1, 2. Similarly there are no zeros of F when x  µ1. Thus all zeros of F must occur in the interval [-µ1, µ1].

We now claim that there are no zeroes of F on the interval [ + 10, µ1], where  = (µ1 + µ1)/2. Indeed, on this interval, we have

 2F

(µ,

x)

=

e-(x-µ1 )2/2

-

e-(x-µ2 )2 /2

+

e-(x-µ1 )2 /2

-

e-(x-µ1 )2 /2

 e-(x-µ1)2/2 - e-(x-µ2)2/2 < 0 ,

where the first line follows since moving µ2 to µ1 only increases the value of the function

on this interval, satisfied by our the interval [µ1,

cahnodictheeofif npaalralmineetiesrsn.eBgaytiavesimasillaornlgogasicx(m>o(vµin1g+µµ2 2to)/µ22,  - 10], the function is strictly positive. Thus all zeros of

which is clearly ), we get that on F must occur in

the interval [ - 10,  + 10].

We now claim that in this interval, the function F is strictly decreasing, and thus has exactly one zero (it has at least one zero because the function changes sign). The derivative of F with respect to x is given by

 F 2 (µ, x) x
= (µ1 - x)e-(x-µ1)2/2 - (µ2 - x)e-(x-µ2)2/2
+ (µ2 - x)e-(x-µ2)2/2 - (µ2 - x)e-(x-µ1)2/2 .

By Taylor's theorem, we have

(µ1 - x)e-(x-µ1)2/2 - (µ2 - x)e-(x-µ2)2/2 = -2re-2/2 + O H2()e-(r-10)2/22 ,

where H2 is the second (probabilist's) Hermite polynomial, and r = |µ1 - |. On the other hand, by another application of Taylor's theorem, we also have
(µ2 - x)e-(x-µ2)2/2 - (µ2 - x)e-(x-µ1)2/2 = O H2()e-(r-10)2/2 .

21

Under review as a conference paper at ICLR 2018

Thus, altogether we have

 F 2 (µ, x) x
 -2re-2/2

+ O H2()e-(r-10)2/2

<0

by our choice of , and since r = /2 > /25.

Case 4: µ1  µ1  µ2  µ2 This case is symmetric to Case 3, and so we omit it.
Case 5: µ1  µ2  µ1  µ2 In this case, we proceed as in the proof of Theorem B.2. If the Gaussians were sufficiently skinny, then by the same logic as in the proof of Theorem B.2, there is exactly one zero crossing. The lemma then follows in this case by Theorem B.1.

Case 6: µ1  µ2  µ1  µ2 This case is symmetric to Case 5.

This completes the proof.

D.7 PROOF OF LEMMA 4.6
We also show that no terribly divergent behavior can occur. Formally, we show that if the true means are within some bounded box, then the generators will never leave a slightly larger box.

Proof of Lemma 4.6. If µ  B(C), then since f is Lipschitz and  is sufficiently small, clearly µ  B(C). Thus, assume that there is an i = 1, 2 so that |µi| > C, and let µ1 be the largest such i in magnitude. WLOG take µ2 > 0. In particular, this implies that µ2 > µi for all i = 1, 2. There are now 3 cases, depending on the position of µ1.
Case 1: µ1  µ2: Here, as in Case 2 in Lemma 4.5, the optimal discriminator is of the form (-, r] for some r  µ1, µ2. In particular, the update step will be
µi = µi - e-(r-µi)2/2 < µi .
Thus, in this case our update moves us in the negative direction. By our choice of , this implies that 0  µ2 < µ2. Moreover, since µ1  µ2, this implies that |µ1|  C, and thus |µ1|  2C. Therefore in this case we stay within the box.
Case 2: µ1  µ1  µ2: As in Case 1, we know that µ1 cannot leave the box after a single update, as |µ1|  C. Thus it suffices to show that µ2 moves in the negative direction. By Lemma D.6, we know there is a discriminator interval at -, and there is no discriminator interval at . Moreover, in this case, we know that F (µ, x)  0 for all x  µ2. Thus, all discriminators must be to the left of µ2. Therefore, the update to µ2 is given by
µ2 = µ2
-  e-(r2-µ2)2/2 - e-( 2-µ2)2/2 + e-(r1-µ2)2/2 ,
for some r1  2  r2  µ2. Clearly this update has the property that 0  µ2 < µ2, and so the new iterate stays within the box.
Case 3: µ1  µ2 In this case we must prove that neither µ1 nor µ2 leave the box. The two arguments are symmetric, so we will focus on µ2. Since  is small, we may assume that µ2 > 3C/2, as otherwise µ2 cannot leave the box. As in Case 1, it suffices to show that the endpoints of the discriminator intervals are all less than µ2. But in this case, we have that for all x  µ2, the value of the true distribution at x is at most 2e-(x-C)2/2, and the value of the discriminator is at e-(x-µ2)2/2  e-(x-1.5C)2/2. By direct calculation, this is satisfied for any choice of C satisfying 2e5C2/8 < e3C2/4, which is satisfied for C  3.

22

Under review as a conference paper at ICLR 2018
E SINGLE GAUSSIAN
Although our proof of the two Gaussian case implies the single Gaussian case, it is possible to prove the single Gaussian case in a somewhat simpler fashion, while still illustrating several of the high-level components of the overall proof structure. Therefore, we sketch how to do so, in hopes that it provides additional intuition for the proof for a mixture of two Gaussians. In order to prove convergence, we can use the following.
1. The fact that the gradient is only discontinuous on a measure 0 set of points. 2. An absolute lower bound on the magnitude of the gradient from below over all points that
are not close to the optimal solution that we might encounter over the course of the algorithm 3. An upper bound on how much the gradient can change if we move a certain distance. Then, as long as we take steps that are small enough to guarantee that the gradient never changes by more than half the absolute lower bound, we will get by Lemma 4.2 that we always make progress towards the optimum solution in function value unless we are already close to the optimal solution. The proof of these facts is substantially simplified in the single Gaussian case. Suppose we have a true univariate Gaussian distribution with unit variance and mean µ, along with a generator distribution with unit variance and mean µ. Then the optimal discriminator for this pair of distributions starts at the midpoint between their means and goes in the direction of the true distribution off to  or -. Therefore, unless the generator mean is within one step length of the true mean, it cannot move away from the true mean. One can also argue that the gradient of µ with respect to the optimal discriminator (ie., the gradient of total variation distance) is only discontinuous when µ = µ, and has magnitude roughly e(µ-(µ+µ)/2)2/2 for µ = µ. This implies the first two items. For the last item, note that the midpoint ez2/2, which implies the gradient is Lipschitz as long as we are not at the optimal solution, which gives bounds on how much the gradient can change if we move a certain distance. The preceding discussion implies convergence for an appropriately chosen step size, and all this can be made fully quantitative if one works out the quantitative versions of the statements in the preceding argument. This analysis is simpler the the two Gaussians analysis in several respects. In particular, the proofs of the second two items are substantially more involved and require many separate steps. For example, in the two Gaussian case, the gradient can be 0 if mode collapse happens, so we have to directly prove both that mode collapse does not happen and that the gradient is large if mode collapse doesn't happen and we aren't too close to the optimal solution, which is a substantially more involved condition to prove. Additionally, the gradient in the two Guassian case does not seem to be Lipschitz away from the optimum like it is in the single Gaussian case. Instead, we will have to use a weaker condition which is considerably more difficult to reason about. This is further complicated by the fact that the optimal discriminators can move in a discontinuous fashion when we vary the generator means.
23

