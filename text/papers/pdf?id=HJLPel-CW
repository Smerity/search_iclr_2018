Under review as a conference paper at ICLR 2018
LANGUAGE STYLE TRANSFER FROM NON-PARALLEL TEXT WITH ARBITRARY STYLES
Anonymous authors Paper under double-blind review
ABSTRACT
Language style transfer is the problem of migrating the content of a source sentence to a target style. In many applications, parallel training data are not available and source sentences to be transferred may have arbitrary and unknown styles. In this paper, we present an encoder-decoder framework under this problem setting. Each sentence is encoded into its content and style latent representations. By recombining the content with the target style, we can decode a sentence aligned in the target domain. To adequately constrain the encoding and decoding functions, we couple them with two loss functions. The first is a style discrepancy loss, enforcing that the style representation accurately encodes the style information guided by the discrepancy between the sentence style and the target style. The second is a cycle consistency loss, which ensures that the transferred sentence should preserve the content of the original sentence disentangled from its style. We validate the effectiveness of our proposed model on two tasks: sentiment modification of restaurant reviews, and dialog response revision with a romantic style.
1 INTRODUCTION
Style transfer is a long-standing research problem that aims at migrating the content of a sample from a source style to a target style. Recently, great progress has been achieved by applying deep neural networks to redraw an image in a particular style (Kulkarni et al., 2015; Liu & Tuzel, 2016; Gatys et al., 2016; Zhu et al., 2017; Luan et al., 2017). However, until now very few approaches have been proposed for style transfer of natural language sentences, i.e., changing the style or genre of a sentence while preserving its semantic content. For example, we would like a system that can convert a given text piece in the language of Shakespeare (Mueller et al., 2017); or rewrite product reviews with a favored sentiment (Shen et al., 2017).
One important issue on language style transfer is that parallel data are unavailable. For instance, considering the task of rewriting a negative review of a product to its counterpart with a positive sentiment, we can hardly find paired data that describe the same content. Yet, many text generation frameworks require parallel data, such as the popular sequence-to-sequence model in machine translation and document summarization (Sutskever et al., 2014; Rush et al., 2015), and thus are not applicable under this scenario. A few recent approaches have been proposed for style transfer with non-parallel data (Hu et al., 2017; Shen et al., 2017). Their key idea is to learn a latent representation of the content disentangled from the source style, and then recombine it with the target style to generate the corresponding sentence.
All the above approaches assume that data have only two styles, and their task is to transfer sentences from one style to the other. However, in many practical settings, we may deal with sentences in more than two styles. Taking the review sentiment modification as an example again, some reviews may be neither positive nor negative, but in a neutral style. Moreover, even reviews considered negative can be categorized into more fine-grained sentiments, such as anger, sadness, boredom and other negative styles. It may be beneficial if such styles are treated differently. As another example, consider a chatbot with a coherent persona, which has a consistent language behavior and interaction style (Li et al., 2016). A simple framework for this task is to first use human dialog data to train a chatbot system, such as a retrieval-based dialog model (Lowe et al., 2015), and then transfer the output responses with a language style transfer model so that multi-round responses always have a consistent style. Note that the human dialog sentences are collected from different users, and users'
1

Under review as a conference paper at ICLR 2018
expressions of the content and tones may be in different personalized characteristics. Thus the output responses retrieved from the dialog model may have the language style of any user. Simply treating the responses with a single style and employing the existing style transfer models would lead to unsatisfactory results. Hence, in this paper, we study the setting of language style transfer in which the source data to be transferred can have various (and possibly unknown) styles.
Another challenging problem in language style transfer is that the transferred sentence should preserve the content of the original sentence disentangled from its style. To tackle this problem, Shen et al. (2017) assumed the source domain and the target domain share the same latent content space, and trained their model by aligning these two latent spaces. Hu et al. (2017) constrained that the latent content representation of the original sentence could be inferred from the transferred sentence. However, these attempts considered content modification in the latent content space but not the sentence space.
In this work, we develop an encoder-decoder framework that can transfer a sentence from a source domain to its counterpart in a target domain. The training data in the two domains are non-parallel, and sentences in the source domain can have arbitrary language styles but those in the target domain are with a consensus style. We encode each sentence into two latent representations, one for the content disentangled from the style, and the other for the style. Intuitively, if a source sentence is considered having the target style with a high probability, its style representation should be close to the target style representation. To make use of this idea, we enforce that the discrepancy between an arbitrary style representation and the target style representation should be consistent with the closeness of its sentence style to the target style. A cycle consistency loss is further introduced to avoid content change by directly considering the transferred sentence. Its idea is that the generated sentence, when put back into the encoder and recombined with its original style representation, can recover the original sentence. We evaluate the performance of our proposed model on two tasks. The first is the sentiment modification task with its source domain containing more than one sentiments, and the second is to transfer general dialog responses to a romantic style.
2 RELATED WORK
Most style transfer approaches in the literatures focus on vision data, and some of them are also designed for the non-parallel data setting. Kulkarni et al. (2015) proposed to disentangle the content representations from image attributes, and control the image generation by manipulating the graphics code that encodes the attribute information. Gatys et al. (2016) used the Convolutional Neural Networks (CNNs) to learn separated representations of the image content and style, and then created the new image from their combination. Some approaches have been proposed to align the two data domains with the idea of the generative adversarial networks (GAN) (Goodfellow et al., 2014). Liu & Tuzel (2016) proposed the coupled GAN framework to learn a joint distribution of multidomain data by the weight-sharing constraint. Zhu et al. (2017) introduced a cycle consistency loss, which minimizes the gap between the transferred images and the original ones. However, due to the discreteness of the natural language, this loss function cannot be directly applied on text data. In our work, we show how the idea of cycle consistency can be used on text data.
Only a small number of approaches have been proposed for language style transfer. To handle the non-parallel data problem, Mueller et al. (2017) revised the latent representation of a sentence in a certain direction guided by a classifier, so that the decoded sentence imitates those favored by the classifier. Ficler & Goldberg (2017) encoded textual property values with embedding vectors, and adopted a conditioned language model to generate sentences satisfying the specified content and style properties. Hu et al. (2017) used the variational auto-encoder (VAE) to encode the sentence into a latent content representation disentangled from the source style, and then recombine it with the target style to generate its counterpart, An additional distribution is added to enforce that the generated sentence and the original sentence share the same latent content representation. Shen et al. (2017) considered transferring between two styles simultaneously. Specifically, they utilized adversarial training in the Professor-Forcing framework (Lamb et al., 2016), to align the generated sentences from one style to the data domain of the other style. We also adopt similar adversarial training in our model. However, since we assume the source domain contains data with various and possibly unknown styles, we cannot align data from the target domain to the source domain as in Shen et al. (2017).
2

Under review as a conference paper at ICLR 2018

3 MODEL

3.1 FORMULATION
We now formally present our problem formulation. Suppose there are two data domains, one source domain X1 in which each sentence may have its own language style, and one target domain X2 consisting of data with the same language style. During training, we observe n samples from X1 and m samples from X2, denoted as X1 = {x1(1), x1(2), · · · , x1(n)} and X2 = {x(21), x(22), · · · , x(2m)}. Note that we can hardly find a sentence pair (x1(i), x(2j)) that describes the same content. Our task is to design a model to learn from these non-parallel training data such that for an unseen testing sentence x  X1, we can transfer it into its counterpart x~  X2, where x~ should preserve the content of x but with the language style in X2.

3.2 ENCODER-DECODER FRAMEWORK

Similar to Shen et al. (2017); Hu et al. (2017), we assume each sentence x can be decomposed into
two representations: one is the style representation y  Y, and the other is the content representation
z  Z, which is disentangled from its style. Each sentence x(1i)  X1 has its individual style y1(i), while all the sentences x(2i)  X2 share the same style, denoted as y. Our model is built upon the encoder-decoder framework. In the encoding module, we assume that z and y of a sentence x can
be obtained through two encoding functions Ez(x) and Ey(x) respectively:

z1(i) = Ez(x(1i)), y1(i) = Ey(x1(i)), i  {1, 2, · · · , n}, z2(j) = Ez(x(2j)), y = Ey(x2(j)), j  {1, 2, · · · , m}.

(1) (2)

For the decoding module, we first employ a reconstruction loss to encourage that the sentence from the decoding function given z and y of a sentence x can well reconstruct x itself. Here, we use a probabilistic generator G as the decoding function and the reconstruction loss is:

Lrec(Ez , Ey , G) = Ex1X1 [- log pG(x1|y1, z1)] + Ex2X2 [- log pG(x2|y, z2)] , (3)

where  denotes the parameter of the corresponding module.

To enable style transfer using non-parallel training data, we enforce that for a sample x1  X1, its decoded sequence using G given its content representation z and the target style y should be in the target domain X2. We use the idea of GAN (Goodfellow et al., 2014)) and introduce an adversarial loss to be minimized in decoding. The goal of the discriminator D is to distinguish between G(z1, y) and G(z2, y), while the generator tries to bewilder the discriminator:
Ladv(D, G, Ez , Ey )= Ex1X1 [- log(1-D(G(z1, y)))]+Ex2X2 [- log D(G(z2, y))]. (4)
As discussed in Section 2, since our source domain X1 contains sentences with various unknown language styles but not a consistent style, it is impossible for us to apply a discriminator to determine whether a sentence transferred from X2 is aligned in the domain X1 as in Shen et al. (2017).

During optimization, we adopt the continuous approximation in (Hu et al., 2017) for gradients propagation in adversarial training over discrete sentences. That is, instead of feeding a single word as the input to the generator, we use the approximation averaging word embeddings by a multinomial distribution. This distribution is computed as softmax(ot/), where ot is the logit vector output by the generator at time step t,  > 0 is a temperature parameter. Next, we follow the framework of Professor-Forcing (Lamb et al., 2016), which matches two sequences of output words using a discriminator D. Specifically, we have one kind of sequences G(z2, y) teacher-forced by the ground-truth sample x2  X2, and the other one G(z1, y) with z1 obtained from samples in X1, in which the input at each time step is self-generated by the previous continuous approximation.

However, the above encoder-decoder framework is under-constrained. First, for a sample x1  X1, y1 can have an arbitrary value that minimizes the above losses in Equation 3 and 4, which may not necessarily capture the sentence style. This will affect the other decomposed part z, making it not
fully represent the content which should be invariant with the style. Second, the discriminator can only encourage the generated sentence to be aligned with the target domain X2, but cannot guarantee to keep the content of the source sentence intact. To address the first problem, we propose a style

3

Under review as a conference paper at ICLR 2018

Ez z2 x2 E y y *
Ez z1 x1 E y y1

G x^2 G ~x1 G x^1

D

style discrepancy loss

 x  log , 

cycle consistency loss

Ez z1 x1
E y y1

~x1

Ez Ey

~z1 y*

G

x1

Figure 1: Basic model with the style discrepancy Figure 2: Proposed cycle consistency loss
loss. Solid lines: encode and decode the sample (can be applied for samples in X2 similarly). itself; dash lines: transfer x1  X1 into X2.

discrepancy loss, to constrain that the learnt y should have its distance from y guided by another discriminator which evaluates the closeness of the sentence style to the target style. For the second problem, we get inspired by the idea in Zhu et al. (2017) and introduce a cycle consistency loss applicable to word sequence, which requires that the generated sentence x~ can be transferred back to the original sentence x.

3.3 STYLE DISCREPANCY LOSS

By using a portion of the training data, we can first train a discriminator Ds to predict whether a given sentence x has the target language style with an output probability, denoted as pDs (x  X2). When learning the decomposed style representation y1 for a sample x1  X1, we enforce that the discrepancy between this style representation and the target style representation y, should be
consistent with the output probability from Ds. Specifically, since the styles are represented with
embedding vectors, we measure the style discrepancy using the 2 norm:

d(y1, y) = y1 - y 2 .

(5)

Intuitively, if a sentence has a larger probability to be considered having the target style, its style

representation should be closer to the target style representation y. Thus, we would like to have

uds(ey1a,pyro)bapboisliittiyvedleyncsiotryrefulantcetdiownitqh(y11-, ypD),sa(nxd1

 X2). To incorporate this define the style discrepancy

idea loss

in our as:

model,

we

Ldis(Ey ) = Ex1X1 [-pDs (x1  X2) log q(y1, y)] , q(y1, y) = f (d(y1, y)),

(6) (7)

where f (·) is a valid probability density function. pDs (x1  X2) is pre-trained and then fixed. If

a sentence framework

x1 has a large will encourage

pDs (x1 a large

 X2), incorporating q(y1, y) and hence a

the above loss into the small d(y1, y), which

encoder-decoder means y1 would

be close to y. In our experiment, we instantiate q(y1, y) with the standard normal distribution for

simplicity:

q(y1, y)

=

1 2

exp(- d(y1, y)2 ). 2

(8)

However, better probability density functions can be used if we have some prior knowledge of the style distribution. With Equation 8, the style discrepancy loss can be equivalently minimized by:

Ldis(Ey ) = Ex1X1 [pDs (x1  X2)d(y1, y)2] .

(9)

3.4 CYCLE CONSISTENCY LOSS
Inspired by Zhu et al. (2017), we require that a sentence transferred by the generator G should preserve the content of its original sentence, and thus it should have the capacity to recover the

4

Under review as a conference paper at ICLR 2018

original sentence in a cyclic manner. For a sample x1  X1 with its transferred sentence x~1 having the target style y, we encode x~1 and combine its content z~1 with its original style y1 for decoding. We should expect that with a high probability, the original sentence x1 is generated. For a sample x2  X2, though we do not aim to change its language style in our task, we can still compute its cycle consistency loss for the purpose of additional regularization. We first choose an arbitrary style y1 obtained from a sentence in X1, and transfer x2 into this y1 style. Next, we put this generated sentence into the encoder-decoder model with the style y, and the original sentence x2 should be generated. Formally, the cycle consistency is:
Lcyc(Ez , Ey , G)= Ex1X1 [- log pG(x1|Ez(x~1), y1)]+Ex2X2 [- log pG(x2|Ez(x~2), y)]. (10)

3.5 FULL OBJECTIVE

An illustration of our basic model with the style discrepancy loss is shown in Figure 1 and the full model is combined with the cycle consistency loss shown in Figure 2. To summarize, the full loss function of our model is:

L(Ez , Ey , G, D) = Lrec - 1Ladv + 2Lcyc + 3Ldis,

(11)

where 1, 2, 3 are parameters balancing the relative importance of the different loss parts. The overall training objective is a minmax game played among the encoder Ez, Ey, generator G and discriminator D:

min
Ez ,Ey ,G

max
D

L(Ez

,

Ey

,

G,

D

)

.

(12)

We implement the encoder Ez using an RNN with the last hidden state as the content representation, and Ey using a CNN with the output representation of the last layer as the style representation. The generator G is an RNN that takes the concatenation of the content and style representation as the
initial hidden state. The discriminator D and the pre-trained discriminator Ds used in the style discrepancy loss are CNNs with the similar network structure in Ey followed by a sigmoid output layer.

4 EXPERIMENTS
4.1 DATASETS
Yelp: Raw data are from the Yelp Dataset Challenge Round 10, which are restaurant reviews on Yelp. Generally, reviews rated with 4 or 5 stars are considered positive, 1 or 2 stars are negative, and 3 stars are neutral. For positive and negative reviews, we use the processed data released by Shen et al. (2017). For neutral reviews, we follow similar steps in Shen et al. (2017) to process and select the data. We first filter out neutral reviews (rated with 3 stars and categorized with the keyword `restaurant') with the length exceeding 15 or less than 3. Then, data selection in Moore & Lewis (2010) is used to ensure a large enough vocabulary overlap between neutral data and data in Shen et al. (2017). Afterwards, we sample 500k sentences from the resulting dataset as the neutral data. We use the positive data as the target style domain. Based on the three classes of data, we construct two datasets with multiple styles:
· Positive+Negative (Pos+Neg): we add different numbers of positive data (50k, 100k, 150k) into the negative data, so that the source domain contains data with two sentiments.
· Neutral+Negative (Neu+Neg): we combine neutral (50k, 100k, 150k) and negative data together. We consider these datasets are harder to learn from. For the Pos+Neg dataset, we can make use of a pre-trained classifier to possibly filter out some positive data so that most of the source data have the same style and the model in Shen et al. (2017) can work. However, the neutral data cannot be removed in this way. Also, most of the real data may be in the neutral sentiment, and we want to see if such sentences can be transferred well.
Details about the data statistics can be found in Table 7 in the Appendix.
Chat: We use sentences from a real Chinese dialog dataset as the source domain. Users can chat with various personalized language styles, which are not easy to be classified into one of the three

5

Under review as a conference paper at ICLR 2018

sentiments as in Yelp. Romantic sentences are collected from several online novel websites and filtered by human annotators. Our task is to transfer the dialog sentences with a romantic style, characterized by the selected romantic sentences. Table 8 in the Appendix shows detailed statistics about this dataset.

4.2 CONFIGURATIONS AND COMPARED METHODS
We implement our model using Tensorflow (Abadi et al., 2016). We use GRU as the encoder and generation cells in our encoder-decoder framework. Dropout (Srivastava et al., 2014) is applied in GRUs and the dropout probability is set to 0.5. Throughout our experiments, we set the dimension of the word embedding, content representation and style representation as 200, 1000 and 500 respectively. For Ey, G and Ds, we follow the CNN architecture in Kim (2014), and use filter sizes of 200 × {1, 2, 3, 4, 5} with 100 feature maps each, so that the resulting output layer is of size 500, i.e., the dimension of the style representation. We further set the balancing parameters 1 = 2 = 1, 3 = 5, and train the model using the Adam optimizer (Kingma & Ba, 2015) with the learning rate 10-4. All input sentences are padded so that they have the same length 20 for Yelp and 35 for Chat. Furthermore, we use the pre-trained word embeddings Glove (Pennington et al., 2014) for Yelp and the Chinese word embeddings trained on a large amount of Chinese news data for Chat when training the classifier. Statistics of data used to pre-train the discriminator Ds are shown in Table 9 and Table 10 in the Appendix.
We compare our method with Shen et al. (2017) which is the state-of-the-art language style transfer model with non-parallel data, and we name as Style Transfer Baseline (STB). We keep the configurations of the modules in STB, such as the encoder, decoder and discriminator, the same as ours for a fair comparison.

4.3 EVALUATION METRICS
Following Shen et al. (2017), we use a model-based evaluation metric. Specifically, we use a pretrained evaluation classifier to classify whether the transferred sentence has the correct style. The evaluation classifier is also implemented similar to that in Kim (2014), which utilizes filter sizes 200 × {2, 3, 4, 5} with 250 feature maps each. The testing accuracy of the the pre-trained classifier is 95.82% for Yelp and 87.72% for Chat respectively. We repeat the training three times for each experiment setting, and report the mean accuracy on the testing data with their standard deviation.

4.4 RESULTS AND ANALYSIS
4.4.1 ON YELP
We first perform experiments on the source data containing both positive and negative reviews. In this setting, we specifically compare two versions of both STB and our model, one with the cycle consistency loss and one without, to validate the effectiveness of the cycle consistency loss 1. Results are shown in Table 1. It can be seen that incorporating the cycle consistency loss improves the performance for both STB and our proposed model consistently.
Table 1: Testing accuracies on Yelp with Pos+Neg source data.

#positive samples used
50k 100k 150k

STB
0.908 ± 0.060 0.703 ± 0.111 0.649 ± 0.041

STB (with Cyc)
0.917 ± 0.012 0.847 ± 0.011 0.676 ± 0.057

Ours (without Cyc)
0.854 ± 0.044 0.868 ± 0.037 0.713 ± 0.075

Ours
0.933 ± 0.002 0.928 ± 0.003 0.910 ± 0.006

We further manually examine the generated sentences for a detailed study of the various methods. Table 2 shows a few samples for the above setting with 150k positive samples used. Overall, our full model can generate grammatically correct positive reviews without changing the original content in more cases than the other methods. For some simple sentences such as the first example, all models
1Note that our proposed cycle consistency loss can be similarly added in STB.
6

Under review as a conference paper at ICLR 2018

perform well. For the second example in which the input sentence is more complex, both versions of STB and our basic model without the cycle consistency loss cannot generate fluent sentences, but our full model still succeeds. However, our model also suffers some mistakes as shown in the third example. Though it successfully makes the sentence positive, some additional information about the food is added, which is not discussed in the original sentence.

Table 2: Example sentences on Yelp transferred into a positive sentiment.

Original Sentence
STB STB (with Cyc) Ours (without Cyc)
Ours
Original Sentence
STB STB (with Cyc) Ours (without Cyc)
Ours
Original Sentence
STB STB (with Cyc) Ours (without Cyc)
Ours

service was tolerable .
service was spectacular . service was spectacular . service was spectacular . service was outstanding .
customer service manager asks what the problem is .
customer service is just what it . customer service , cares , great . customer service you everyone is like it . customer service is wonderful and great .
service has gotten worse and worse at this location .
service is great for the family and family . service has always great and at this location . service has been better than the best experience . service was super friendly and food was great .

Next, we compare the results of STB and our proposed method in Table 1. As the number of positive sentences in the source data increases, the average performance of both versions of STB decreases drastically. This is reasonable because STB introduces a discriminator to align the sentences from the target domain back to the source domain, and when the source domain contains more positive samples, it is hard to find a good alignment to the source domain. Meanwhile the performance of our model, even the basic one without the cycle consistency loss, does not fluctuate much with the increase of the number of positive samples, showing that our model is not that sensitive to the source data containing more than one sentiments. Overall, our model with the cycle consistency loss performs the best.
The above setting is not challenging enough, because we can use a pre-trained discriminator similar to Ds in our model, to remove those samples classified as positive with high probabilities, so that only sentences with a less positive sentiment remain in the source domain. Thus, we test our second dataset which combines neutral reviews and negative reviews as the source domain. In this setting, in case that some positive sentences exist in those neutral reviews, when STB is trained, we use the same pre-trained discriminator in our model to filter out samples classified as positive with probabilities larger than 0.9. In comparison, our model utilizes all the data, since it naturally allows for those data with styles similar to the target style. In the following, we report and analyze both STB and our model with the cycle consistency loss added. The experimental results in Table 3 show that STB (with Cyc) suffers a large performance drop with 150k neutral data mixed in the source domain, while our model remains stable.

Table 3: Testing accuracies on Yelp with Neu+Neg source data.

#Neural samples used
50k 100k 150k

STB (with Cyc)
0.914 ± 0.007 0.927 ± 0.024 0.865 ± 0.016

Ours
0.941 ± 0.006 0.922 ± 0.008 0.929 ± 0.007

In real applications, there may be only a small amount of data in the target domain. To simulate this scenario, we limit the amount of the target data (randomly sampled from the positive data) used for training, and evaluate the robustness of the compared methods. Table 4 shows the experimental
7

Under review as a conference paper at ICLR 2018

results. It is surprising to see that both methods obtain relatively steady accuracies with different numbers of target samples. Yet, our model surpasses STB (with Cyc) in all the cases.
Table 4: Testing accuracies on Yelp with different numbers of target samples used.

#Target samples used
100k 150k 200k

STB (with Cyc)
0.785 ± 0.021 0.780 ± 0.014 0.763 ± 0.017

Ours
0.859 ± 0.003 0.888 ± 0.005 0.880 ± 0.003

4.4.2 ON CHAT
As in the Yelp experiment, we vary the number of target sentences to test the robustness of the compared methods. The experimental results are shown in Table 5. As can be seen, STB (with Cyc) obtains a relatively low performance with only 10k target samples, and as more target samples are used, its performance increases. However, the accuracy of our model is relatively high even with 10k target samples used, and remains stable in all the cases. Thus, our model achieves better performance as well as stronger robustness on Chat. A few examples are shown in Table 6. We can see that our model generally successfully transfers the sentence into a romantic style with some romantic phrases used.
Table 5: Testing accuracies on Chat with different numbers of target samples used.

#target samples used
10k 50k 100k 150k

STB (with Cyc)
0.887 ± 0.002 0.920 ± 0.017 0.942 ± 0.003 0.955 ± 0.003

Ours
0.958 ± 0.003 0.975 ± 0.003 0.973 ± 0.001 0.966 ± 0.002

Table 6: Example sentences on Chat transferred into a romantic style. English translations are provided (* denotes that the sentence has grammar mistakes in Chinese).

Original Sentence
STB (with Cyc) Ours
Original Sentence
STB (with Cyc) Ours
Original Sentence
STB (with Cyc) Ours

   It is enough to look back and smile
    It would be just fine to look back and smile  ,   Look back and smile, please do not miss me.
  ! Just live with it!
  ,     I just take things too hard. *  ,   Love to the depths, enjoy myself wherever I am.
      Give up your happiness to others
     ,    Give up your happiness to others. *      ,    Leave some happiness to yourself, yourself.

5 CONCLUSION
In this paper, we present an encoder-decoder framework for language style transfer, which allows for the use of non-parallel data and source data with various unknown language styles. Each sentence is encoded into two latent representations, one corresponding to its content disentangled from the style and and the other representing the style only. By recombining the content with the target style, we can decode a sentence aligned in the target domain. Specifically, we propose two loss functions, i.e., the style discrepancy loss and the cycle consistency loss, to adequately constrain the encoding and decoding functions. The style discrepancy loss is to enforce a properly encoded style representation while the cycle consistency loss is used to ensure that the style-transferred sentences can be transferred back to their original sentences. Experimental results on two tasks demonstrate that our proposed method outperforms the state-of-the-art style transfer method (Shen et al., 2017).

8

Under review as a conference paper at ICLR 2018
REFERENCES
Mart´in Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467, 2016.
Jessica Ficler and Yoav Goldberg. Controlling linguistic style aspects in neural language generation. In Proceedings of the Workshop on Stylistic Variation, pp. 94­104, 2017.
Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Image style transfer using convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2414­2423, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2672­2680, 2014.
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. Toward controlled generation of text. In Proceedings of the International Conference on Machine Learning, pp. 1587­1596, 2017.
Yoon Kim. Convolutional neural networks for sentence classification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1746­1751, 2014.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings of the International Conference for Learning Representations, 2015.
Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems, pp. 2539­2547, 2015.
Alex M Lamb, Anirudh Goyal ALIAS PARTH GOYAL, Ying Zhang, Saizheng Zhang, Aaron C Courville, and Yoshua Bengio. Professor forcing: A new algorithm for training recurrent networks. In Advances in Neural Information Processing Systems, pp. 4601­4609, 2016.
Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis, Jianfeng Gao, and Bill Dolan. A persona-based neural conversation model. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 994­1003, 2016.
Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial networks. In Advances in Neural Information Processing Systems, pp. 469­477, 2016.
Ryan Lowe, Nissan Pow, Iulian V Serban, and Joelle Pineau. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. In 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pp. 285, 2015.
Fujun Luan, Sylvain Paris, Eli Shechtman, and Kavita Bala. Deep photo style transfer. arXiv preprint arXiv:1703.07511, 2017.
Robert C Moore and William Lewis. Intelligent selection of language model training data. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 220­ 224, 2010.
Jonas Mueller, David Gifford, and Tommi Jaakkola. Sequence to better sequence: continuous revision of combinatorial structures. In Proceedings of the International Conference on Machine Learning, pp. 2536­2544, 2017.
Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word representation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1532­1543, 2014.
Alexander M Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 379­389, 2015.
9

Under review as a conference paper at ICLR 2018 Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi Jaakkola. Style transfer from non-parallel text
by cross-alignment. In Advances in Neural Information Processing Systems, 2017. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. Journal of machine learning research, 15(1):1929­1958, 2014. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pp. 3104­3112, 2014. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the International Conference on Computer Vision, 2017.
10

Under review as a conference paper at ICLR 2018

6 APPENDIX

Table 7: Statistics of Yelp for the style transfer model

Positive Negative

Training
240417 151026

Test
40000 40000

Validation
20000 20000

Table 8: Statistics of Chat for the style-transfer model

Romantic General

Training
207312 514460

Test
40000 40000

Validation
40000 40000

Table 9: Statistics of Yelp for the discriminator Ds

Positive Negative

Training
75000 37500

Test
5000 5000

Validation
2500 2500

Table 10: Statistics of Chat for the discriminator Ds

Romantic General

Training
100000 200000

Test
10000 10000

Validation
10000 10000

11

