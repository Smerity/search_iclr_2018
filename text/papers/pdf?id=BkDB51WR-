Under review as a conference paper at ICLR 2018

LEARNING TEMPORAL EVOLUTION OF PROBABILITY DISTRIBUTION WITH RECURRENT NEURAL NETWORK
Anonymous authors Paper under double-blind review

ABSTRACT
We propose to tackle a time series regression problem by computing temporal evolution of a probability density function to provide a probabilisitic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of a probability density function. We use a softmax layer for a numerical discretization of a smooth probability density functions, which transforms a function approximation problem to a classification task. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A Monte Carlo procedure to compute the temporal evolution of the distribution for a multiple-step forecast is presented. The evaluation of the proposed algorithm on two synthetic and two real data sets shows advantage over the compared baselines.

1 INTRODUCTION

Application of the deep learning for manufacturing processes has attracted a great attention as one of the core technologies in Industry 4.0 (Lasi et al., 2014). In many manufacturing processes, e.g. blast furnace, smelter, and milling, the complexity of the overall system makes it almost impossible or impractical to develop a simulation model from the first principles. Hence, system identification from sensor observations has been a long-standing research topic (Wang et al., 2016). Still, when the observation is noisy and there is no prior knowledge on the underlying dynamics, there is only a very limited number of methods for the reconstruction of nonlinear dynamics.

In this work, we consider the following class of problems, where the system is driven by a complex underlying dynamical system, e.g.,

y t

=

F(y(t), y(t -  ), u(t)).

(1)

Here, y(t) is a continuous process, F is a nonlinear operator,  is a delay-time parameter, and u(t) is an exogenous forcing, such as control parameters. At time step t, we then observe a noisy measurement of y(t) which can be defined by the following noise model

y^t = y(t)t + t,

(2)

where t is a multiplicative and t is an additive noise process. In (1) and (2), we place no assumption on function F , do not assume any distributional properties of noises t and t, but assume the
knowledge of the control parameters u(t).

Since the noise components, t and t, are stochastic processes, the observation y^t is a random variable. In this work, we are interested in computing temporal evolution of the probability den-
sity function (PDF) of y^, given the observations up to time step t, i.e., p(y^t+n|Y0:t, U0:t+n-1)
for n  1, where Y0:t = (y^0, · · · , y^t) is a trajectory of the past observations and U0:t+n-1 = (u0, · · · , ut+n-1) consists of the history of the known control actions, U0:t-1, and a future control scenario, Ut:t+n-1. We show, in Section 3, a class of problems, where simple regression problem of forecasting the value of y^t+n is not sufficient or not possible, e.g., chaotic systems. Note that the computation of time evolution of a PDF has been a long-standing topic in statistical physics. For
a simple Markov process, there are well-established theories based on the Fokker-Planck equation.
However, it is very difficult to extend those theories to a more general problem, such as delay-time
dynamical systems, or apply it to complex nonlinear systems.

1

Under review as a conference paper at ICLR 2018
Modeling of the system (1) has been extensively studied in the past, in particular, under the linearity assumptions on F and certain noise models, e.g., Gaussian t and t = 1 in (2). The approaches based on auto-regressive processes (Lu¨tkepohl, 2005) and Kalman filter (Harvey, 1990) are good examples. Although these methods do estimate the predictive probability distribution and enable the computation of the forecast uncertainty, the assumptions on the noise and linearity in many cases make it challenging to model real nonlinear dynamical systems.
A recent success of deep learning created a flurry of new approaches for time series modeling and prediction. The ability of deep neural networks, such as RNN, to learn complex nonlinear spatiotemporal relationships in the data enabled these methods to outperform the classical time series approaches. For example, in the recent works of Qin et al. (2017); Hsu (2017); Dasgupta & Osogami (2017), the authors proposed different variants of the RNN-based algorithms to perform time series predictions and showed their advantage over the traditional methods. Although encouraging, these approaches lack the ability to estimate the probability distribution of the predictions since RNN is a deterministic model and unable to fully capture the stochastic nature of the data.
To enable RNN to model the stochastic properties of the data, Chung et al. (2015) augmented RNN with a latent random variable included in the hidden state and proposed to estimate the resulting model using variational inference. In a similar vein, the works of Archer et al. (2015); Krishnan et al. (2017) extend the traditional Kalman filter to handle nonlinear dynamics when the inference becomes intractable. Their approach is based on formulating the variational lower bound and optimizing it under the assumption of Gaussian posterior.
Another recent line of works enabled stochasticity in the RNN-based models by drawing a connection between Bayesian variation inference and a dropout technique. In particular, Gal & Ghahramani (2016) showed that the model parameter uncertainty (which then leads to uncertainty in model predictions), that traditionally was estimated using variational inference, can be approximated using a dropout method (a random removal of some connections in the network structure). The prediction uncertainty is then estimated by evaluating the model outputs at different realizations of the dropout weights. Following the ideas of Gal & Ghahramani (2016), Zhu & Laptev (2017) proposed additional ways (besides modeling the parameter uncertainty) to quantify the forecast uncertainty in RNN, which included the model mis-specification error and the inherent noise of the data.
1.1 OVERVIEW OF THE PROPOSED WORK
We propose an RNN-model to compute the temporal evolution of a PDF, p(y^t+n|Y0:t, U0:t+n-1). To avoid the difficulties in directly estimating the continuous function, we use a numerical discretization technique, which converts the function approximation problem to a classification task (see Section 2.2). We note that the use of the traditional cross-entropy (CE) loss in our formulated classification problem can be problematic since it is oblivious to the class ordering. To address this, we additionally propose two regularizations for CE to account for a geometric proximity between the classes (see Sections 2.2.1 and 2.2.2). The probability distribution of one-step-ahead prediction, p(y^t+1|Y0:t, U0:t) can now be simply estimated from the output softmax layer of RNN (see Section 2.2), while to propagate the probability distribution further in time, for a multiple-step forecast, we propose a sequential Monte Carlo (SMC) method (see Section 2.3). We empirically show that the proposed modeling approach enables us to represent a continuous PDF of any arbitrary shape, including the ability to handle the multiplicative data noises in (2). Since the probability distribution is computed, the RNN-model can also be used for a regression task by computing the expectation (see Section 2.3). Hereafter, we use DE-RNN for the proposed RNN model, considering the similarity with the density-estimation task.
In summary, the contributions of this work are as follows: (i) formulate the classical regression problem for time series prediction as a predictive density-estimation problem, which can be solved by a classification task (ii) propose an approach to compute the time evolution of probability distribution using SMC on the distributions from DE-RNN (iii) proposed two regularizations for CE loss to capture the ordering of the classes in the discretized PDF. We evaluated the proposed algorithm on two synthetic and two real datasets, showing its advantage over the baselines. Note that DE-RNN has a direct relevance to a wide range of problems in physics and engineering, in particular, for uncertainty quantification and propagation (Zhang & Karniadakis, 2017).
2

Under review as a conference paper at ICLR 2018

2 LSTM FOR NOISY DYNAMICAL SYSTEM

In this Section we present the details of the proposed algorithm using a specific form of RNN, called Long Short-Term Memory (LSTM) network. Although in the following presentation and experiments we used LSTM, other networks, e.g., GRU (Chung et al., 2014), can be used instead.

2.1 REVIEW OF LONG SHORT-TERM MEMORY NETWORK

The Long Short-Term Memory network (LSTM) (Hochreiter & Schmidhuber, 1997; Gers et al., 2000) consists of a set of nonlinear transformations of input variables zt  Rm;

Gating functions: Gi,f,o = S  L(zt), Internal state: st = (1 - Gf ) st-1 + Gi Output: ht = Go st.

(T  L(zt)) ,

(3) (4) (5)

Here, S and T , respectively, denote the sigmoid and hyperbolic tangent functions, L is a linear layer, which includes a bias, st  RNc is the internal state, ht  RNc is the output of the LSTM network, Nc is the number of the LSTM units, and a b denote a component-wise multiplication.

Interesting observation can be made about equation (4). We can re-write equation (4) as

st+1 = [1 - f (zt)] st + g(zt),

(6)

for some functions f and g. With a simple re-scaling, this equation can be interpreted as a first-order Euler scheme for a linear dynamical system,

ds dt

=

-f (z)s

+

g(z).

(7)

Thus, LSTM can be understood as a series expansion, where a complex nonlinear dynamical system is approximated by a combination of many simpler dynamical systems.

Usually, LSTM network is supplemented by feed-forward neural networks, e.g.,

zt = Fin(xt, ht-1), Pt+1 = Fout(ht),

(8)

in which xt is the input feature. Using (5), we can denote by e and d a collection of the operators from input to internal state (encoder) and from internal state to the output o (decoder):

st = e(xt, st-1), Pt+1 = d(st).

(9)

2.2 DISCRETE APPROXIMATION OF PROBABILITY DENSITY FUNCTION

In this Section we first consider the problem of modeling the conditional PDF, p(y^t+1|Y0:t, U0:t). Although y^t+1 has a dependence on the past trajectories of both y^ and u, using the "state space"
LSTM model argument in Section 2.1, the conditional PDF can be modeled as a Markov process

p(y^t+1|Y0:t, U0:t) = p(y^t+1|y^t, ut, st-1) = p(y^t+1|st).

(10)

Hence, to simplify the problem, we consider a task of estimating the PDF of a random variable y^, given an input x, i.e., p(y^|x). The obtained results can then be directly applied to the original problem of estimating p(y^t+1|st).
Let  = (0, · · · , K ) denote a set of real numbers, such that i-1 < i for i = 1, · · · , K, which defines K disjoint intervals, Ii = (i-1, i). Then, a discrete probability distribution can be defined

p(k|x) = p(y^|x)dy, for k = 1, . . . , K,

(11)

Ik

where it is clear that p(k|x) is a numerical discretization of the continuous PDF, p(y^|x). Using the

LSTM from Section 2.1, the discrete probability p(k|x) can be modeled by the softmax layer (P ) as

an output of d in (9) such that

p(k|x) = Pk, for k = 1, . . . , K.

(12)

3

Under review as a conference paper at ICLR 2018

Thus, the original problem of estimating a smooth function, p(y^|x), is transformed into a classification problem of estimating p(k|x) in a discrete space. Obviously, the size of the bin, |Ij|, affects the fidelity of the approximation. The effects of the bin size are presented in Section 3.1. There is a
similarity between the discretization and the idea of Lin et al. (2007). However, it should be noted
that the same discretization technique, often called "finite volume method", has been widely used in
the numerical simulations of partial differential equations for a long time.

The discretization naturally leads to the conventional cross-entropy (CE) minimization. Suppose we
have a data set, DR = {(y^i, xi); y^i  R, xi  R, and i = 1, . . . , N }. We can define a mapping C : R  N+ such that C(y^) = k, if y  Ik. Then, DR can be easily converted to a new data set for target labels, DC = {(ci, y^i, xi); ci  N+, y^i  R, xi  R, and i = 1, . . . , N }, where ci = C(y^i). DC provides a training data set for the following CE minimization problem,

NK

N

CE = -

cnk log Pkn = - log Pcnn .

n=1 k=1

n=1

(13)

Note, however, that the CE minimization does not explicitly guarantee the smoothness of the esti-

mated distribution. Since CE loss function depends only on Pi of a correct label, cnk, as a result, in the optimization problem every element Pi, except for the one corresponding to the correct label, Pcn , is penalized in the same way, which is natural in the conventional classification tasks where a
geometric proximity between the classes is not relevant. In the present study, however, the softmax

layer, or class probability, is used as a discrete approximation to a smooth function. Hence, it is

expected that Pcn and Pcn±1 (i.e., the nearby classes) should be close to each other. To address this issue, in the following Sections 2.2.1 and 2.2.2, we propose two types of regularization to impose

the class proximity structure in the CE loss.

2.2.1 EXPLICIT REGULARIZATION OF CROSS-ENTROPY LOSS

To explicitly impose the smoothness between the classes, we propose to use a regularized crossentropy (RCE) minimization, defined by the following loss function

N
RCE =

K
-cnk log Pkn +  (LP n)T LP n

n=1 k=1

where



is

a

penalty

parameter

and

the Laplacian matrix 1 -2 1 0

L ···

R0K-2,K

is

L

=

0. .

.

.

1 ..

.

.

-2 ....

.

1 ..

.

··· ....

.

.0.

.

0 · · · 0 1 -2 1

,

(14) (15)

RCE is analogous to the penalized maximum likelihood solution for density estimation (Silverman, 1986). Assuming a uniform bin size, |I0| = · · · = |IK| = y, the Laplacian of a distribution can be approximated by a Taylor expansion p (y^|x)|y=i-1/2 (Pi-1 - 2Pi + Pi+1)/y2, where i-1/2 = 0.5(i-1 + i). Then, it is clear that

(LP n)T LP n  [p (y^|x)]2 dy.

(16)

In other words, RCE aims to smooth out the distribution by penalizing local minima or maxima.

2.2.2 IMPLICIT REGULARIZATION OF CROSS-ENTROPY LOSS

Alternative to adding an explicit regularization to CE, the smoothness can be achieved by enforcing

a spatial correlation in the network output. Here, we use an one-dimensional convolution layer to enforce smoothness. Let o  RK be the input to the softmax layer in DE-DNN. We can add a convolution layer, o  RK, on top of o, such that

oi =

K

1 h

exp

-

1 2

i-j h

2

oj, for i = 1, · · · , K,

j=1

(17)

where the penalty parameter h determines the smoothness of the estimated distribution. Using (17),

the LSTM model can now be trained by the standard CE. The implicit regularization, here we call

convolution CE (CCE), is analogous to a kernel density estimation.

4

Under review as a conference paper at ICLR 2018

2.3 COMPUTING TIME EVOLUTION OF PROBABILITY DISTRIBUTION

In the next-step prediction of DE-RNN, the inputs are (y^t, ut), and the output is the probability distribution,
Pt+1 = d(st) = d  e(y^t, ut, st-1).
Note that DC is used only in the training stage. Then, the moments of the predictive distribution can be easily evaluated, e.g.,

E[y^t+1|Y0:t, U0:t] = T1/2Pt+1, V ar[y^t+1|Y0:t, U0:t] = (21/2)T Pt+1 - E[y^t+1|Y0:t, U0:t]2, (18)
where 1/2 = (1/2, 1+1/2, · · · , K-1/2)T , 21/2 = 1/2 1/2, and i-1/2 = 0.5(i-1 + i).
Next, we consider a multiple-step forecast, which corresponds to computing a temporal evolution of the probability distribution, i.e., p(y^t+n|Y0:t, U0:t+n-1) for n > 1.
Applying the results of Section 2.2, once the distribution of y^t+1 in (10) is computed, the distribution of y^t+2 can be similarly obtained as p(y^t+2|st+1). Observe that st+1 is computed from a deterministic function of st, ut+1, and y^t+1, i.e.,
st+1 = e(y^t+1, ut+1, st).
Here, ut+1 and st are already known, while y^t+1 is a random variable, whose distribution p(y^t+1|st) is computed from the deterministic function d(st). Then, st+1 is also a random variable. The distribution, p(st+1|st, ut+1), can be obtained by applying a change of variables on p(y^t+1|st) with a nonlinear mapping e. Repeating this process, the multiple-step-ahead predictive distribution can therefore be computed as

n-1
p(y^t+n|Y0:t, U0:t+n-1) = · · · p(y^t+n|st+n-1) p(st+i|st+i-1, ut+i) dst+i.
i=1

(19)

Since the high dimensional integration in (19) is intractable, we propose to approximate it by a sequential Monte Carlo method. The Monte Carlo procedure is outlined in Algorithm 1.

Algorithm 1 Sequential Monte Carlo method for LSTM multi-step-ahead prediction
Input: Y0:t, U0:t, number of Monte Carlo samples, Ns, and forecast horizon n Output: p(y^t+n|Y0:t, U0:t+n-1) (density estimation from y^t+n) Initialization: Set LSTM states to s0 = h0 = 0 Perform a sequential update of LSTM up to time t from the noisy observations (Y0:t).
si = e(y^i, ui, si-1) for i = 1, · · · , t.

Make Ns replicas of the internal state, s1t = · · · = stNs = st. repeat
Compute the predictive distribution of y^ti+1 for each sample
Pti+1 = d(sit), for i = 1, · · · , Ns.

Sample the target variable at t + 1, y^ti+1, from the distribution 1. Sample the class label from the discrete distribution: ci  Pti+1 2. Sample y^ti+1 in Ici : y^ti+1  U (ci-1, ci )
Update the internal state of LSTM sti+1 = e(y^ti+1, ut+1, sti).
until (all y^t+n are sampled)

5

Under review as a conference paper at ICLR 2018

Figure 1: NRMSE of the next-step prediction of the CIR process by RCE (a,b) and CCE (c,d). The bin size is (a,c) y = 0.08 and (b,d) 0.04. The hollow circles () denote NRMSE in the expectation (eµ) and the solid circles (·) are the standard deviation (e).

3 EXPERIMENTS

In this section, DE-RNN is tested against two synthetic and two real data sets. The LSTM architecture used in all of the numerical experiments is identical. Two feed-forward networks are used before and after the LSTM;
zt = L (T  L(yt, ut) + ht-1) , Pt+1 = SM  L(T  L(SP  L(ht))), (20)
in which SP and SM denote the softplus and softmax functions, respectively. The size of the bins is kept uniform, i.e., |I1| = · · · = |IK| = y. The LSTM is trained by using ADAM (Kingma & Ba, 2015) with a minibath size of 20 and a learning rate of  = 10-3.

3.1 COX-INGERSOLL-ROSS PROCESS

First, we consider a modified Cox-Ingersoll-Ross (CIR) process, which is represented by the following stochastic differential equation,

dy(t) = -0.5y(t)dt + 0.5 + |y(t)|dW,

(21)

in which W is the Weiner process. The original CIR process is used to model the valuation of interest rate derivatives in finance. Equation (21) is solved by the forward Euler method with the time step size t = 0.1. The simulation is performed for T = (0, 160000]t to generate the training data and T = (160000, 162000]t is used for the testing. Note that the noise component of CIR is multiplicative, which depends on y(t).
The experiments are performed for two different bin sizes, dy = 0.08 and 0.04. The DE-RNN has 64 LSTM cells. Figure 1 shows the errors in the expectation and the standard deviation with respect to the analytical solution;

EypT [yt+1|yt] = yt exp(-0.5t), sdypT [yt+1|yt] = (0.5 + |yt|)t.

(22)

Here, pT denotes the true distribution of the CIR process. The normalized root mean-square errors (NRMSE) are defined as

eµ = e =

(EypL [yt+1|yt] - EypT [yt+1|yt])2 (yt - EypT [yt+1|yt])2 1/2

1/2
,

(sdypL [yt+1|yt] - sdypT [yt+1|yt])2 sd[y]

1/2
,

(23) (24)

in which · denotes an average over the testing data, pL is the distribution from the LSTM, and sd[y] denotes the standard deviation of the data. The error in the expectation is normalized against a zeroth-order prediction, which assumes yt+1 = yt.
In Figure 1, it is clearly shown that the prediction results are improved when a regularization is used to impose a smoothness condition. Comparing Figures 1 (a) and (b), for RCE, eµ and e become smaller when a smaller y is used. As expected, e increases when  is large. But, for the smaller bin size, y = 0.04, both eµ and e are not so sensitive to . Similar to RCE, eµ and e for CCE decrease at first as the penalty parameter h increases. However, in general, RCE provides a better prediction compared to CCE.

6

Under review as a conference paper at ICLR 2018
Table 1: NRMSE of the mean and standard deviation of the next-step prediction. The DE-RNN results are compared with the first-order autoregressive model (AR) and Kalman filter (KF).
CE RCE CCE AR(1) KF eµ 0.238 0.0549 0.149 0.029 0.029 e 0.066 0.017 0.038 0.228 0.228

Figure 2: 200-step forecast of (a) expectation and (b) standard deviation of the CIR process. The circles denote the solution of Eqn (21) from a Monte Carlo method with 107 samples.

NRMEs are listed in Table 1. For a comparison, the predictions by AR(1) and KF are shown. The CIR process is essentially a first-order autoregressive process. So, it is not surprising to see that AR(1) and KF, which are designed for the first-order AR process, outperforms DE-RNN for the prediction of the expectation. However, e of AR(1) and KF are much larger than that of DE-RNN, because those models assume an additive noise. Note that e of RCE and CCE are less than 4%, suggesting that DE-RNN can model the complex noise process very well.
In Figure 2, a 200-step forecast by DE-RNN is compared with a Monte-Carlo solution of equation (21). DE-RNN is trained with y = 0.04 and  = 200. For the DE-RNN forecast, the testing data is supplied to DE-RNN for the first 100 time steps, i.e., for t = -10 to t = 0, and the SMC multiple-step forecast is performed for the next 200 time steps with 20,000 samples. It is shown that the multiple-step forecast by DE-RNN agrees very well with the MC solution of the CIR process. Note that, in Figure 2 (b), the noise process, as reflected in sd[yt], is a function of yt, and hence the multi-step forecast of the noise increases rapidly first and then decreases before reaching a plateau. The SMC forecast can accurately capture the behavior. Such kind of behavior can not be represented if a simple additive noise is assumed.

3.2 MACKEY-GLASS TIME SERIES

For the next test, we applied DE-RNN for a time series generated from the Mackey-Galss equation

(Mackey & Glass, 1977);

dy dt

=

y(t -  ) 1 + y(t -  )

- y(t).

(25)

We use the parameters adopted from Gers (2001),  = 0.2,  = 10,  = 0.1, and  = 17.

The Mackey-Glass equation is solved by using a third-order Adams-Bashforth method with a time
step size of 0.02. The time series is generated by down-sampling, such that the time interval between consecutive data is t = 1. A noisy observation is made by adding a white noise;

y^t = yt + t.
t is a zero-mean Gaussian random variable with the noise level sd[ t] = 0.3sd[y]. A time series of the length 1.6 × 105t is generated for the model trainig and another time series of length 2 × 103t is made for the validation. DE-RNN is trained for y = 0.04sd[y] and consists of 128 LSTM cells.

Figure 3 (a) shows the noisy observation and the expectation of the next-step prediction, E[y^t+1|y^t], in a phase space. It is shown that DE-RNN can filter out the noise and reconstruct the original dynamics accurately. Even though the noisy data are used as an input, E[y^t+1|y^t] accurately represents the original attractor of the chaotic system, indicating a strong de-noising capability of the LSTM.

7

Under review as a conference paper at ICLR 2018

Figure 3: (a) Next-step prediction (·) and the noisy observation () for the Mackey-Glass equation.
The solid line denotes the ground truth, y(t). (b) The next-step probability distribution, p(y^t+1|y^t), from the standard CE () and CCE (·) with h = 5.

Table 2: NRMSEs of the Mackey-Galss time series. DE-RNN results are compared with autoregressive integrated moving average (ARIMA) and Kalman filter (KF).

=0

RCE  = 50  = 100

 = 200

CCE h = 5 h = 10

ARIMA

KF

eµ 0.143 0.141 e 0.032 0.023

0.143 0.027

0.142 0.133 0.143 0.668 0.916 0.038 0.013 0.020 0.191 0.351

The estimated probability distribution is shown in Figure 3 (b). Without a regularization, the standard CE results in a noisy distribution, while the distribution from CCE shows a smooth Gaussian shape.

The prediction errors are shown in table 2. NRMSEs are defined as,

eµ =

(E[y^t+1|y^t] - yt+1)2 (y^t - yt+1)2 1/2

1/2
,

e

=

sd[y^t+1|y^t] sd[ t]

-

1,

(26)

NRMSEs are computed with respect to the ground truth. Again, eµ compares the prediction error to the zeroth-order prediction. In this example, the errors are not so sensitive to the regularization
parameters. The best result is achieved by CCE. DE-RNN can make a very good estimation of the noise. The error in the noise component, e, is only 2%  5%. Unlike the CIR process, NRMSEs from KF and ARIMA are much larger than those of DE-RNN. Because the underlying process is
a delay-time nonlinear dynamical system, those linear models can not accurately approximate the
complex dynamics.

A multiple-step forecast of the Mackey-Glass time series is shown in Figure 4. In the validation time series, the observations in t  [1, 100]t are supplied to the DE-RNN to develop the internal state, and a 500-step forecast is made for t  [101, 600]t. In Figure 4 (a), it is shown that a multiple-step forecast by a standard regression LSTM approximates y(t) very well initially, e.g, for t < 80t, but

Figure 4: (a) 500-step forecast by a regression LSTM () and the ground truth ( ). (b) The color contours denote a 500-step forecast of the probability distribution, p(y^n+s|y^s), and the dashed lines are 95%-CI. The ground truth is shown as the solid line ( ).
8

Under review as a conference paper at ICLR 2018
Figure 5: (a) Mauna Loa CO2 observation. The vertical line denotes the boundary of the training and testing data. (b) 17-year forecast of the CO2 concentration: Apr-01-2000 Sep-23-2017. The solid and dashed lines denote the expectation and 95%-CI, respectively. The observation is shown as the solid circles (·) and a regression LSTM is the hollow circles (). The time unit is a week.
eventually diverges for larger t. Because of the Mackey-Glass time series is chaotic, theoretically it is impossible to make a long time forecast. But, in the DE-RNN forecast, y(t) is bounded by the 95%-confidence interval (CI) even for the 500-step forecast. Note that the uncertainty, denoted by 95%-CI grows only at a very mild rate in time. In fact, it is observed that CI is not a monotonic function of time. In DE-RNN, the 95%-CI may grow or decrease following the dynamics of the system, while for the conventional time series models, such as ARIMA and KF, the uncertainty is a non-decreasing function of time.
3.3 MAUNA LOA CO2 OBSERVATION
In this experiments, DE-RNN is tested against the atmospheric CO2 observation at Mauna Loa Observatory, Hawaii (Keeling et al., 2001). The CO2 data set consists of weekly-average atmospheric CO2 concentration from Mar-29-1958 to Sep-23-2017 (Figure 5 a). The data from Mar-29-1958 to Apr-01-2000 is used to train DE-RNN and a 17-year forecast is made from Apr-01-2000 to Sep-232017. This CO2 data has been used in previous studies (Gal & Ghahramani, 2016; Rasmussen & Williams, 2006). In DE-RNN, 64 LSTM cells and y = 0.1sd[dyt], in which dyt = yt+1 - yt, are used. The 17-year DE-RNN forecast, with 1,000 MC samples, is shown in Figure 5 (b). DE-RNN well represents the growing trend and the oscillatory patten of the CO2 data. The CO2 data is nonstationary, where the rate of increase of CO2 is an increasing function of time. Since DE-RNN is trained against the history data, where the rate of CO2 increase is smaller than the current, it is expected that the forecast will underestimate the future CO2. E[y^n+s|y^s] agrees very well with the observation for the first 200 weeks, but eventually underestimates CO2 concentration. It is interesting to observe that the upper bound of the 95%-CI grows more rapidly than the expectation and provides a good approximation of the observation. For a comparison, the forecast by a regression LSTM is also shown. Similar to the chaotic Mackey-Glass time series, the regression LSTM makes a good prediction for a short time, e.g., t < 100 weeks, but eventually diverges from the observation. Note that the lower bound of 95%-CI encompasses the regression LSTM.
3.4 CPU TEMPERATURE FORECAST
In the last experiment, IBM Power System S822LC and NAS Parallel Benchmark (NPB) are used to generate the temperature trace. Figure 6 (a) shows the temperature of a CPU. The temperature sensor generates a discrete data, which has a resolution of 1C. The CPU temperature is controlled by three major parameters; CPU frequency, CPU utilization, and cooling fan speed. In this experiment, we have randomized the CPU frequencies and job arrival time to mimic the real workload behavior, while the fan speed is fixed to 3300RPM. The time step size is t = 2 seconds. Accurate forecast of CPU temperature for a future workload scenario is essential in developing an energy-efficient control strategy for the thermal management of a cloud system. Figure 6 (c) and (d) show multiple-step forecasts of the CPU temperature by RCE and a regression LSTM, respectively. The bin size is y = 0.18C, which is smaller than the sensor resolution. In the forecast, the future control parameters are given to DE-RNN. In other words, DE-RNN
9

Under review as a conference paper at ICLR 2018
Figure 6: (a) Temperature of a CPU in C. (b) Control parameters; CPU utilization (black) and Clock speed (blue). Multiple-step forecasts by (c) RCE and (d) regression LSTM. The solid and dashed lines in (c) denote E[y^n+s|y^s] and 95%-CI, respectively. The circles are the observations.
Table 3: l error for RCE, CCE and regression LSTM in C. RCE CCE LSTM
E[y^n+s|y^s] - y^n+s  4.61 2.70 9.48
predicts the probability distribution of future temperature with respect to a control scenario, i.e., p(y^t+n|Y0:t, U0:t+n-1). The forecast is made by using 5,000 Monte Carlo samples. Here, 1800-step forecast is made, t = 0  3, 600 sec. and only the results in t  (50, 1800) sec. is shown. While the regression LSTM makes a very noisy prediction near the local peak temperature at t 500, RCE provides a much more stable forecast. Table 3 shows the l-errors, i.e., maximum absolute difference. The maximum error is observed near the peak temperature at t 500. ARIMA and KF are also tested for the multiple-step forecast, but the results are not shown because their performance is much worse than the LSTMs. The changes in the temperature are associated with step changes of some control parameters. Such abrupt transitions seem to cause the large oscillation in the regression LSTM prediction. But, for RCE or CCE, the prediction is made from an ensemble of Monte Carlo samples, which makes it more robust to such abrupt changes. Also, note that for t < 200 sec., RCE prediction ( 53.4C) is in between the two discrete integer levels, 53C and 54C, which correctly reflects the uncertainty in the measurement, while the regression LSTM ( 53.1C) more closely follows one of the two levels.
4 CONCLUDING REMARKS
We present DE-RNN to compute the time evolution of a probability distribution for complex time series data. DE-RNN employs LSTM to learn multiscale, nonlinear dynamics from the noisy observations, which is supplemented by a softmax layer to approximate a probability density function. To assign probability to the softmax output, we use a mapping from R to N+, which leads to a cross-entropy minimization problem. To impose a geometric structure in the distribution, two regularization strategies are proposed. The regularized cross-entropy method is analogous to the penalized maximum likelihood estimate for the density estimation, while the convolution cross-entropy method is motivated by the kernel density estimation. The proposed algorithm is validated against two synthetic data set, for which we can compare with the analytical solutions, and two real data sets. In this study, for simplicity, the problem is formulated for a univariate time series. But, it is straightforward to extend the methodology to a multivariate time series.
10

Under review as a conference paper at ICLR 2018
REFERENCES
E. Archer, M. Park, L. Buesing, J. Cunningham, and L. Paninski. Black box variational inference for state space models. arXiv preprint arXiv:1511.07367, 2015.
J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.
J. Chung, K. Kastner, L. Dinh, K. Goel, A. Courville C, and Y. Bengio. A recurrent latent variable model for sequential data. In Advances in Neural Information Processing Systems, pp. 2980­ 2988, 2015.
S. Dasgupta and T. Osogami. Nonlinear dynamic boltzmann machines for time-series prediction. In AAAI Conference on Artificial Intelligence, 2017.
Y. Gal and Z. Ghahramani. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In Proceedings of the 33rd International Conference on International Conference on Machine Learning, pp. 1050­1059, 2016.
F. A. Gers. Ph.D Thesis. EPFL, 2001.
F. A. Gers, J. Schmidhuber, and F. Cummins. Learning to forget: Continual prediction with LSTM. Neural Comput., 12:2451 ­ 2471, 2000.
A. C. Harvey. Forecasting, structural time series models and the Kalman filter. Cambridge university press, 1990.
S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Comput., 9:1735 ­ 1780, 1997.
D. Hsu. Time series forecasting based on augmented long short-term memory. arXiv preprint arXiv:1707.00666, 2017.
C. D. Keeling, S. C. Piper, R. B. Bacastow, M. Wahlen, T. P. Whorf, M. Heimann, and H. A. Meijer. Exchanges of atmospheric CO2 and 13CO2 with the terrestrial biosphere and oceans from 1978 to 2000. I. Global aspects. In SIO Reference Series, pp. No. 01­06. Scripps Institution of Oceanography, 2001.
D. P. Kingma and J. L. Ba. ADAM: A method for stochastic optimization. In 3rd International Conference on Learning Representation, San Diego, CA, USA, 2015.
R. Krishnan, U. Shalit, and D. Sontag. Structured inference networks for nonlinear state space models. In AAAI Conference on Artificial Intelligence, 2017.
H. Lasi, P. Fettke, H. Kemper, T. Feldand, and M. Hoffmann. Industry 4.0. Business & Information Systems Engineering, 6(4):239­242, 2014.
J. Lin, E. Keogh, L. Wei, and S. Lonardi. Experiencing SAX: a novel symbolic representation of time series. Data Mining and knowledge discovery, 15(2):107­144, 2007.
H. Lu¨tkepohl. New introduction to multiple time series analysis. Springer Science & Business Media, 2005.
M. Mackey and L. Glass. Oscillation and chaos in physiological control systems. Science, 197: 287­289, 1977.
Y. Qin, D. Song, H. Chen, W. Cheng, G. Jiang, and G. W. Cottrell. A dual-stage attention-based recurrent neural network for time series prediction. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pp. 2627­2633, 2017.
C. E. Rasmussen and K. I. Williams. Gaussian Processes for Machine Learning. MIT Press, 2006.
B. W. Silverman. Density estimation for statistics and data analysis. Chapman & Hall, 1986.
W.-X. Wang, Y.-C. Lai, and C. Grebogi. Data based identification and prediction of nonlinear and complex dynamical systems. Phys. Reports, 644:1­76, 2016.
11

Under review as a conference paper at ICLR 2018 Z. Zhang and G. E. Karniadakis. Numerical methods for stochastic partial differential equations
with white noise. Springer, 2017. L. Zhu and N. Laptev. Deep and confident prediction for time series at Uber. arXiv preprint
arXiv:1709.01907, 2017.
12

Under review as a conference paper at ICLR 2018

A APENDIX

In this Section we present a few extra details of the proposed DE-RNN algorithm. Figure 7 shows the architecture of DE-RNN as was used during the experiments (presented in Section 3). In Figure 8 we show the process of computing one-step-ahead predictions (presented in Section 2.2). Note that since DE-RNN estimates approximation of the predictive probability distribution, the pre-
dicted value, e.g., for time step t + 1, is the discrete approximation of E[y^t+1|Y0:t, U0:t], i.e., the expectation of y^t+1 given all the observations and control inputs up to time t. Finally, in Figure 9 we show the details of the multi-step forecast (presented in Section 2.3, in Algorithm 1). Using sequential Monte Carlo method, the discrete approximation of the predictive distribution
p(y^t+n|Y0:t, U0:t+n-1) is estimated using Ns samples.

Pt+1

discreteapproximationof predictivedistributionp(y^t+1|Yb0:t, U0:t)

ht 1
LST M
zt 1

DE-RN N

L

L

st 1

L
ht
LST M
zt
L

L

sof tmax sof tplus tanh
st
tanh

ht+1
LST M
zt+1

y^t ut Figure 7: Architecture of the DE-RNN algorithm.

E

 y^t+1

|Yb0:t

,

 U0:t

 1 0 2
3 2

XK

k

1 2

Pt+1(k)

k=1

K Pt+1

E

y^t+2|Yb0:t+1,

 U0:t+1

 1 0 2
3 2

XK

k

1 2

Pt+2(k)

k=1

K Pt+2

ht 1

ht

st 1

DE-RN N

st

DE-RN N

y^t ut

y^t+1 ut+1

Figure 8: Details of the computation for the one-step-ahead predictions. At a given step the model computes a discrete approximation of the expectation for the next step observation.

13

Under review as a conference paper at ICLR 2018

replicatehidden
statesNstimes

2 66646666666666

y^tN+s3 ...
y^t3+3 y^t2+3

3

77777757777777

densityestimation
p(y^t+3|Yb0:t

,

U0:t+2)

y^t1+3

y^t1+1

samplewithin selectedbin(uniformly)

0 K sampleover
Pt1+1 allbins(usingPt1+1)

h1t 1 st1 1

DE-RN N

ht1 s1t

y^t ut

y^t1+2

0 K
Pt1+2
DE-RN N
y^t1+1 ut+1

ht1+1 st1+1

y^t1+3
0 K
Pt1+3
DE-RN N
y^t1+2 ut+2

Figure 9: Visualization of the multi-step-ahead forecast made by DE-RNN. The shown illustration
is for computing 3-step-ahead predictive probability distribution p(y^t+3|Y0:t, U0:t+2). N s independent DE-RNN instances, i = 1, . . . , Ns, are initialized identically with the hidden states from the time step of the last observation. Each DE-RNN instance i uses a two-stage sampling procedure to propagate its own value of y^i in time. At the end, Ns samples of y^ti+3 are used to compute a discrete
approximation of the predictive distribution p(y^t+3|Y0:t, U0:t+2).

14

