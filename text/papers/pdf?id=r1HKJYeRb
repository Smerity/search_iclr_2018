Under review as a conference paper at ICLR 2018
AUTOMATIC MEASUREMENT ON ETCHED STRUCTURE IN SEMICONDUCTOR USING DEEP LEARNING AP-
PROACH
Anonymous authors Paper under double-blind review
ABSTRACT
The fabrication of semiconductor involves etching process to remove selected areas from wafers. However, the measurement of etched structure in micrograph heavily relies on time-consuming manual routines. Traditional image processing usually demands a large number of annotated data and the performance is still poor. We treat this challenge as segmentation problem and use deep learning approach to detect masks of objects in etched structure of wafer. Then, we use simple image processing to carry out automatic measurement on the objects. We attempt Generative Adversarial Network (GAN) to generate more data to overcome the problem of very limited dataset. We download 10 SEM (Scanning Electron Microscope) images of 4 types from Internet, based on which we carry out our experiments. Our deep learning based method demonstrates superiority over image processing approach with mean accuracy reaching over 96% for the measurements, compared with the ground truth. To the best of our knowledge, it is the first time that deep learning has been applied in semiconductor industry for automatic measurement.
1 INTRODUCTION
Typically, massive processing phases during fabrication of semiconductor can be roughly categorized into four manufacturing steps: deposition, removal, patterning, and modification. Particularly for etching process, as one type of removal technologies, such as Reactive-ion etching (RIE) (Ephrath, 1981), aims to remove selected areas from the surface of wafer so that other materials can be deposited (Kato et al., 1999). As the density of semiconductor device are continually increasing with miniaturization tendency in highly integrated circuits, features and size between etched structure also become dramatically smaller and leads to higher aspect ratio (means ratio of height to width), which in other words narrowing the horizontal width much faster than vertical height within the structure (Chen et al., 2007). Therefore, the precision during removal and patterning phases is quite crucial for semiconductor devices to ensure ultimate quality and reliability of products.
However, how to guarantee the precision and accuracy during fabrication process remains a big challenge due to the following reasons: (1) Inaccurate measurement of critical dimensions, such as wrongly localized key points or failure of removing some material in etched process, can result in adverse consequence and impact on product yield and quality; (2) Even very slight deformation on patterns or features with irregular shape or bend line can cause some device defects, e.g., nonfunctionality or bad quality on next-generation products (Szkely & Van Bien, 1988; Iveland et al., 2013; Zhang & Auston, 1992).
Till now, although with the advent of high-resolution image using AFM (Atomic Force Microscopy) and advanced etched process like Deep Reactive-Ion Etching (DIRE) (Marty et al., 2005), the measurements, such as etch line, space depth, width, profile angle, etc., are still carried out manually by domain experts or process engineers. Such process requires considerable efforts and it is timeconsuming, subjective, and very hard to reproduce (Schroder, 2006). Traditional approaches like thresholding (Tobin et al., 1999) and edge detecting (Feng et al., 2006) are basically utilizing constraints on image intensity or object appearance which require relatively large training sets. Consequently, automatic measurement and profile characterization of etched structures in semiconductor is
1

Under review as a conference paper at ICLR 2018
Figure 1: Segmentation and object boundary detection (with red line) on SEM images of different semiconductor wafers using traditional machine learning approach. The first two and the fourth SEM images show several undetected boundaries, while the third one displays irregular shapes challenge. (circled with yellow dotted line).
highly desirable for semiconductor industry to achieve consistent, efficient, and accurate evaluation of the device quality, and at the same time reduce the demand for human beings. With evolving of machine learning techniques, such as random forest (Shotton et al., 2008), SVM (Fulkerson et al., 2009), AdaBoost (Lee et al., 2010), etc., they can be widely applied in many different domains, such as clinical, object recognition, image segmentation (Lee et al., 2010), etc. This paper conducts preliminary study on segmentation of silicon SEM image by using traditional machine learning approaches. As results demonstrated in Fig. 1, image analytics using the traditional methods are not so promising, which fail to detect several boundaries due to unknown variations in images. Another challenge lies in irregular shapes resulted from unexpected variations, as the traditional image processing searches the boundaries based on predefined patterns. Recently, explosion of interests is drawn on deep learning approaches and many state-of-the-art methods are leading the direction for automatic image segmentation and recognition in a broad fields, such as clinical like tumors detection (Chen et al., 2016), arts like music (Wang & Wang, 2014), nature language processing (Collobert & Weston, 2008), to mention a few. However, till now deep learning approach has not been used in etched structure detection for semiconductor wafer images yet. Although the aforementioned deep learning network can achieve promising performance in segmentation and classification issues, it still suffers from learning abundant data without ground truth or obtaining labeled training dataset with expensive and considerable efforts. Therefore, data augmentation is crucial to achieve excellent results by training model with desired properties and invariance with limited dataset. To address such puzzle, Goodfellow et al. (2014) designed Generative Adversarial networks (GAN) using adversarial process, which can be used to generate pseudo images to reduce demand for labeled data. In this paper, fully convolutional network, U-Net, is adopted to the new issue on profile characterization of etched structure in semiconductor SEM image. Problem from this domain is appropriate to select U-Net for object boundary detection as following reasons: Firstly, the dataset for neuronal structure segmentation (Ronneberger et al., 2015) and the SEM image used for etched structure segmentation are quite similar which are all in electron microscopic stacks. Next, replacing fully connected layers with convolutional layers can generate seamless segmentation results with smooth lines rather than jagged line (Lee & Yoo, 2008). Third, the output images generated are with high resolution which resulting from replacement with upsampling operators, and this lays the foundation of measurement on key point sets and critical dimension of chips after segmentation. Furthermore, data augmentation is performed by using GAN to acquire pseudo images for training. Other approaches for increasing sample dataset involve cropping, contrast, flipping, etc. Finally, key point localization is performed to measure critical dimensions of etched structures in wafers. Concluded from the aforementioned literatures and studies, this paper has the following contributions:
1. Unlike the traditional boundary searching based on image processing, deep learning treats the problem as a segmentation problem;
2

Under review as a conference paper at ICLR 2018
2. Many data augmentations have been explored, such as varying contrasts, flipping, rotation, adding salt-and-pepper, etc., in order to explore all potential variations;
3. Cross-validation methods are used to avoid any potential data-leakage, e.g., if there are three images of the same type, two out of three are used as training dataset and the remaining one are used for testing; if there is only one image for a type, the image is cropped into three smaller ones and again, two out of the three are used as training and the remaining one is used for testing;
4. GAN is also used to generate some data for training and around 0.5% improvement of pixel-wise accuracy on testing dataset has been observed.
The rest of the paper is organized as following. In Section 2, some related work are discussed. In section 3, we present the Network architecture of deep learning approach. Section 4, training process and data augmentation are demonstrated. In section 5, experiments and results are further discussed. Finally, conclusion has been drawn in section 6.
2 RELATED WORK
Generally, on the basis of instruments used to scan semiconductor wafers for etched structure inspection, the technologies can be classified into three categories, which broadly are applied in practice, covering optical imaging, Scanning Electron Microscope (SEM), and Optical Microscopy. Particularly, SEM with higher resolution comparing to the other two are able to observe geometric features and shapes even in extreme environments, such as high vacuum, low temperature, etc., so that it appears widely applied in semiconductor industry for inspection of wafers (Tobin et al., 1999). Conventionally, such inspection is manually done by process engineers using eyes. Due to the drawbacks of unreliability, exhaustion, and bias from different expertise for manual inspection, many research work have been carried out for automatic inspection to reduce the traditional manual inspection using eyes (Myron et al., 2006; Feng et al., 2006; Scaman & Economikos, 1995; Dom & Brecher, 1995).
The research work on wafers inspection can be classified into two categories, direct and indirect approaches. Direct approaches use reference images without flaws as benchmarks to compare with inspected images, to generate computed difference for defect identification, e.g., golden template using threshold for subtractive comparison, neighborhood template using dynamic reference image on account of neighboring structure (Tobin et al., 1999). Although direct methods are relatively fast with easy procedures, massive potential offset values can pose difficulty to adjust threshold value with appropriateness. On the other hand, indirect approaches aim to compare two segmented images with masks to indicate defect object, instead of using reference and inspected images. Such segmentation step to differentiate insulator and conductor is also one crucial pre-requisite procedure for further locating key point sets and measurement of critical dimensions in SEM images.
Regarding segmentation techniques for SEM images or within the field of semiconductor industry, although Feng et al. (2006) adopted hybrid ridge detector rather than normal approach of edge detector to avoid the effect of noise and double edge and demonstrated robustness to some extent, the method still suffers from issues of computational intensity when generating coefficients for regression in polynomial with high orders. Based on this work, Lee & Yoo (2008) further proposed a segmentation method according to global-local thresholding approach and watershed segmentation algorithms on two types of SEM images, achieving relatively high accuracy. However, this method may be efficient for semiconductor wafer inspection but can pose issues when conducting measurement of critical dimensions with jagged line instead of smooth line for object boundary. Furthermore, requiring a large number of training dataset and annotated images can be another weakness of these methods.
Referring to related deep learning networks, Krizhevsky et al. (2012) proposed a Convolutional neural network named as AlexNet and won the champion of ImageNet 2012 image segmentation and classification tasks. Later on, Long et al. (2015) presented a CNN without convolutional fully connected layers aiming to obtain coarse labeling masks and pixel-wise classifications in 2015. Ronneberger et al. (2015) proposed U-Net for biomedical image segmentation in electron microscopic stacks and won several challenges like ISBI 2015. Such network is fast with short time of
3

Under review as a conference paper at ICLR 2018
Figure 2: The architecture of U-Net with an example of 572 × 572 pixels as input.
training and appears robust in segmentation even with very limited original dataset, which leads to broad applications among different domains.
3 NETWORK ARCHITECTURE
Fully convolutional network which was proposed by Long et al. (2015) has raised extensive concerns by training end-to-end with images as both input and output, to achieve state-of-the-art performance, particularly for segmentation and semantic classification (Chen et al., 2016; Long et al., 2015; Azimi et al., 2017). The key idea of Long et al. (2015) lies in replacing the max pooling operation with up-sampling convolutional operations, which in turn supports the path of down sampling. The down-sampling path aims to capture high resolution information while up-sampling path targets at localizing features with pixel-wise manner. Inspired by Long et al. (2015), U-Net (Ronneberger et al., 2015) demonstrates superiority particularly with limited training samples but higher precision in masks. Such promising results are reached via utilizing massive feature channels in up-sampling path and the corresponding network architecture is presented in Fig. 2. The discriminating path (left half) and the localizing path (right half) together constitute the whole U-shaped framework with a total of 23 convolutional layers and massive different operations (Ronneberger et al., 2015). Referring to discriminating path in each dimension, a nonlinear activation ReLU and a 2 × 2 max pooling (stride=2) follows after 2 standard 3 × 3 convolutions. For such convolutional layers, only valid part is utilized which represents a 1-pixel border lost in each 3 × 3 convolution to allow later large image processing in individual tiles. Batch normalization using standard deviation and mean is further applied after each convolution to learn bias and scale for higher accuracy. For max pooling operation, it conducts on each channel separately and doubles the feature channels in each step. Consequently, discriminating path leads to a spatial contraction with captured abstraction information increased and spatial information decreased. Regrading localizing path, a sequence of a 2 × 2 up-sampling convolutional operation, two standard 3 × 3 convolutions each followed with a ReLU, and a shortcut connection from corresponding highresolution features in the discriminating path together constitute every step of the localizing path. The high-resolution segmentation map with two channels for foreground and background separately is generated after a 1 × 1 convolution with 64 channels as input. The overlap-tile strategy is also conducted when output segmentation maps to ensure the seamless score masks (Ronneberger et al., 2015).
4 IMPLEMENTATION
The semiconductor images with etched structures are publicly available on the official website of Oxford Instruments (DAT). The silicon wafers adopted in this paper consist of 4 types with a total of 10 raw pictures captured by Scanning Electron Microscope with diverse angels, as shown in Fig.
4

Under review as a conference paper at ICLR 2018
Figure 3: Samples of Scanning Electron Microscope (SEM) micrograph on etched structures of 4type semiconductor wafers with measuring scale displayed at the right bottom (from left to right represent Type A, B, C, D respectively), downloaded from Internet.

Figure 4: Examples of SEM images of etched structure generated using GAN.
3. For each type of etched structure, only two or three sample images are available with 8  33 objects included in one single image. Such limited training samples indicates data augmentation are significantly crucial for further experiments. Each image also follows with a manual annotated segmentation result showing ground truth of object boundary. Initial weights are known to be crucial for deep learning framework like fully convolutional networks to avoid either none or excessive contribution from network. Considering our network with ReLU activation, the initialization approach from the work of He et al. (2015) is applied to calibrate the unit variance. And such variance is concluded to be 2/N, with N equals to 576 in our case.
4.1 DATA PREPARATION AND AUGMENTATION
With very limited training dataset, data augmentation plays a crucial role in fighting overfitting while preserving robustness. In our experiments with SEM image on etch structure of wafers, both generic image augmentation approach and Generative Adversarial Net (GAN) are applied to enlarge the training dataset. For traditional method, a combination of random cropping, horizontally flipping, contrast adjusting, adding salt-and-pepper, etc., has been adopted to increase the number of training

Table 1: Preliminary experimental results using different data augmentation techniques.

Augmentation Method

Training ACC Testing ACC

Traditional Approach

0.9941

0.9699

GAN + Traditional Approach

0.9874

0.9751

5

Under review as a conference paper at ICLR 2018
Figure 5: Etched structure of semiconductor wafers recorded with SEM. (a): Raw image segmentation with ground truth; (b): Segmentation results using U-Net; (c): Measurement parameters on critical dimension and key points. The read line is the ground truth and the blue line is the predicted boundary.
images and objects to at least 44 times. GANs demonstrate efficiency in obtaining counterfeit images using generator which in turn can fool the discriminative network (Goodfellow et al., 2014). Even image with higher resolution can be generated during augmentation process. In order to choose the appropriate augmentation approach to boost performance and accuracy, preliminary experiment is conducted using both GAN and traditional augmentation approach to enlarge the dataset for U-Net training. The sample SEM data for such experiment involving 2 raw images on one type of wafers with each image containing 4 objects, and GAN would increase the original data to 2N in our case. The SEM wafers images generated by GAN are shown in Fig. 4 and preliminary experimental results are presented in Table 1. Revealing from the results, although the created pictures are quite similar to the original one, cases like disconnection in object boundary, double edge effect and some noise in background still appears frequently to impede the learning process of U-Net. From Table 1, we can observe that accuracy on training dataset decreases slightly and the result on testing dataset increases around 0.5%. With GAN, we have more in the training dataset and it is reasonable that the result decreases. However, less than 1% improvement is not significant. Besides, with dataset increasing dramatically by utilizing GAN, considerate efforts and expense are required to manually label the ground truth for newly generated images. As a consequent, further experiment on different types of semiconductor wafers only applied generic augmentation approach like clipping and flipping to extend the original dataset.
6

Under review as a conference paper at ICLR 2018

Table 2: Evaluation on U-Net performance w.r.t accuracy (ACC), IoU, and DM.

Data Category Training Strategy Training ACC Testing ACC Testing IoU Testing DM

Type A

From scratch

0.9952

0.9655

0.9824

0.9657

Type B

Fine-tuning

0.9956

0.9613

0.9503

0.9053

Type C

Fine-tuning

0.9873

0.9595

0.9711

0.9439

Type D

From scratch

0.9977

0.9957

0.9976

0.9953

Trained Together From scratch

0.9949

0.9423

0.9428

0.8929

5 EXPERIMENTAL RESULTS

The distribution of 10 images is as follows: Type A (4 images), Type B (1 image), Type C (2 images), and Type D (3 images). Cross-validation methods are used to avoid any potential data-leakage, e.g., if there are three images of the same type, two out of three are used as training dataset and the remaining one are used for testing; if there is only one image for a type, the image is cropped into three smaller ones and again, two out of the three are used as training and the remaining one is used for testing. The input image tiles for training are 400 × 400 pixels while the output segmentation maps are 400 × 400 too.

Our network is implemented under the open-source deep network library Keras, and the server for experiments is equipped with Dual 8-Core Intel@Xeon Processors 2.4GHz, 128 GB memory, 4 × 2TB SATA3 hard disk, and 4× NvidiaTitan × 12GB GDDR5 GPU cards. The OS is Ubuntu 14.04 with Keras 2.0.7 installed and Tensorflow 1.0.0 as backend. The learning rate is adjusted to be 0.0001 throughout implementation process and pixels of segmentation image are within zero to one range generated by sigmoid activation function.

The final test accuracy extracts the best score over all epochs. With the purpose of boost performance with limited dataset, transfer learning is applied to load the weights from pretrained models for further fine turning purpose so as to increase the segmentation accuracy on similar dataset. The training speed is quite fast with a single image just costing less than 1 second by our server. The corresponding segmentation results are displayed in Fig. 5, which demonstrate superiority over traditional machine learning approach compared with the results shown in Fig. 1.

In addition to the pixel-wise accuracy, Intersection over Union (IoU) (also known as Jaccard index) and Dice metric (DM) are the most popularly used metrics to perform quantitative evaluation of image segmentation results (Ronneberger et al., 2015). We also use IoU and DM to evaluate the performance as shown in Equ. 1.

AB

2(A  B)

IoU (A, B) = A  B

and

DM (A, B) =

, (A + B)

(1)

where A is the predicted mask and B is the corresponding ground truth.

After comparing the performance of the pre-trained models and the models training from scratch, the experimental results are presented in Table 2, where experiments are conducted on different types of silicon wafer images and finally implemented on the whole dataset. The Type D SEM image with a single circle is comparatively simple for learning comparing to the other 3 types to achieve the highest accuracy with 99.57%, then follows Type A wafer with 96.55% accuracy which indicates relatively clear and regular boundary. Type B ranks next as sunk object boundary appears occasionally, and Type D obvious received least accuracy of 95.59% with uneven edge and diverse ring shapes. In our case, the superiority of transfer learning is not so obvious due to diverse types of SEM image rather than in similar shapes. Results on the whole dataset have been degraded to 94.23%, since U-Net cannot handle multiple different datasets simultaneously. Regarding metrics of IoU and DM, we can observe that Type B has the worst performance and Type D has the best performance, but the results are all more than 90%. Such results prove the hypothesis that U-Net is significantly appropriate to conduct shape modeling on etched structure of semiconductor wafers with SEM image, although such efficient networks which stem from clinical segmentation have not been applied in semiconductor field yet.

Promising segmentation results laid the foundation of further measurement on critical dimensions and key points of silicon wafers. Refer to the suggestions from domain experts, Type A and Type B aim to identify the depth, width, and critical dimensions of etched structure, while diameter and

7

Under review as a conference paper at ICLR 2018

Table 3: Evaluation of results on measurement of etched structure (Pred. = Prediction, GT = Ground

Truth).

Category Measurement Max (um)

Min (um) Average (um)

Variance

GT Pred. GT Pred. GT Pred. GT Pred.

Type A

H1 0.387 0.387 0.365 0.361 0.373 0.376 0.005 0.005

W1 0.183 0.187 0.126 0.152 0.149 0.171 0.002 0.001

W2 0.265 0.269 0.234 0.226 0.248 0.250 0.001 0.002

W3 0.378 0.256 0.100 0.243 0.234 0.250 0.006 0.002

W4 0.104 0.108 0.083 0.083 0.092 0.091 0.004 0.006

Type B

H1 136.0 135.0 132.5 131.5 134.1 132.9 1.17 1.42

W1 19.5 18.5 14.5 13.5 16.63 16.51 2.29 2.12

W2 48.0 41.5 37.5 33.5 41.70 39.64 11.4 6.69

W3 43.0 43.0 37.5 38.0 40.79 40.86 2.63 2.62

W4 14.5 14.5 13.0 11.5 13.69 12.51 0.18 0.75

Type C W1 24.0 24.0 17.6 17.6 20.60 20.88 2.23 2.53

H1 22.4 24.8 16.0 16.0 20.73 21.03 1.93 2.73

W2 44.8 44.8 36.8 36.0 40.95 40.63 4.18 3.55

H2 46.4 46.4 40.0 40.0 43.61 42.83 2.72 2.40

Type D W1 25.6 24.8 22.4 20.0 23.31 22.96 0.86 0.99

H1 26.4 24.8 22.4 20.0 24.12 22.67 1.31 0.88

Table 4: Mean errors compared with ground truth measurements. Type A Type B Type C Type D Over All
Mean Error 2.68% 2.45% 3.98% 3.70% 3.2%

recess for each hole are assessed for Type C and Type D wafers. The corresponding measurement parameters are illustrated in Fig. 5. In this paper, we apply average, max, min, and variance to quantify and evaluate the measurement results, which are demonstrated in Table 3. Further more, in Table 4, we present the comparisons of our measurements with the ground truth and we can see that less than 4% mean error or more than 96% mean accuracy has been achieved for all types in our experiments.
The overall measurement results demonstrate acceptable variability based on opinions from semiconductor experts and can be further broadly applied in automatic measurement of etched structure to ensure the quality and functionality of wafer products in the domain.
6 CONCLUSION
This paper has demonstrated deep learning methodes like fully convolutional network U-Net can be further applied in the new issue of etched structure segmentation even with very limited dataset, and have broad application prospects in semiconductor industry to replace the time-consuming manual measurements. Segmentation results using deep learning approach illustrate superiority over traditional machine learning method to solve the puzzle of undetected boundary and irregular shape problems. Although GAN is state-of-the-art deep learning technique, results in this paper indicate generic data augmentation methods are even more efficient and powerful to enlarge dataset, and can avoid additional manual labeling tasks. The superiority of transfer learning is not so apparent in our case due to diverse data types. In addition to high accuracy in profile characterization, fast prediction can also be guaranteed with testing time of less than 1 second on a single image.
REFERENCES
Leading provider of high technology tools and systems for research and industry. - oxford instruments. URL https://www.oxford-instruments.com/?src=tn.
Seyed Majid Azimi, Dominik Britz, Michael Engstler, Mario Fritz, and Frank Mcklich. Advanced steel microstructure classification by deep learning methods. 2017.
8

Under review as a conference paper at ICLR 2018
Hao Chen, Xiaojuan Qi, Lequan Yu, and Pheng-Ann Heng. Dcan: Deep contour-aware networks for accurate gland segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 2487­2496, 2016.
Xiaolin Chen, Srinivas D. Nemani, and Shankar Venkataraman. Novel depositionplasma cure cycle process to enhance film quality of silicon dioxide, 2007. URL http://www.google.ch/patents/US20070281448.
Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pp. 160­167. ACM, 2008.
Byron E. Dom and Virginia Brecher. Recent advances in the automatic inspection of integrated circuits for pattern defects. 8(1):5­19, 1995.
Linda M. Ephrath. Reactive ion ctching. US Patent 4,283,249, 8, 1981.
Hanying Feng, Jun Ye, and R. Fabian Pease. Segmentation-assisted edge extraction algorithms for sem images. In Photomask Technology 2006, volume 6349, pp. 63491L. International Society for Optics and Photonics, 2006.
Brian Fulkerson, Andrea Vedaldi, and Stefano Soatto. Class segmentation and object localization with superpixel neighborhoods. In Computer Vision, 2009 IEEE 12th International Conference on, pp. 670­677. IEEE, 2009.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672­2680, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. 2015.
Justin Iveland, Lucio Martinelli, Jacques Peretti, James S. Speck, and Claude Weisbuch. Direct measurement of auger electrons emitted from a semiconductor light-emitting diode under electrical injection: identification of the dominant mechanism for efficiency droop. 110(17):177406, 2013.
Tadahiro Kato, Hisashi Masumura, Sadayuki Okuni, and Hideo Kudo. Method of manufacturing semiconductor wafers. (5942445), 1999.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097­1105, 2012.
Jang Hee Lee and Suk In Yoo. An effective image segmentation technique for the sem image. In Industrial Technology, 2008. ICIT 2008. IEEE International Conference on, pp. 1­5. IEEE, 2008.
Sang Hak Lee, Hyung Il Koo, and Nam Ik Cho. Image segmentation algorithms based on the machine learning of features. 31(14):2325­2336, 2010. ISSN 0167-8655. doi: 10.1016/j.patrec. 2010.07.004.
Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431­3440, 2015.
Frdric Marty, Lionel Rousseau, Bassam Saadany, Bruno Mercier, Olivier Franais, Yoshio Mita, and Tarik Bourouina. Advanced etching of silicon based on deep reactive ion etching for silicon high aspect ratio microstructures and three-dimensional micro-and nanostructures. 36(7):673­677, 2005.
L. Jeff Myron, Ecron Thompson, Ian McMackin, Douglas J. Resnick, Tadashi Kitamura, Toshiaki Hasebe, Shinichi Nakazawa, Toshifumi Tokumoto, Eric Ainley, and Kevin Nordquist. Defect inspection for imprint lithography using a die to database electron beam verification system. In SPIE 31st International Symposium on Advanced Lithography, pp. 61510M­61510M. International Society for Optics and Photonics, 2006.
9

Under review as a conference paper at ICLR 2018
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234­241. Springer, 2015.
Michael E. Scaman and Laertis Economikos. Computer vision for automatic inspection of complex metal patterns on multichip modules (MCM-d). 18(4):675­684, 1995.
Dieter K. Schroder. Semiconductor material and device characterization. John Wiley & Sons, 2006. Jamie Shotton, Matthew Johnson, and Roberto Cipolla. Semantic texton forests for image catego-
rization and segmentation. In Computer vision and pattern recognition, 2008. CVPR 2008. IEEE Conference on, pp. 1­8. IEEE, 2008. Vladimir Szkely and Tran Van Bien. Fine structure of heat flow path in semiconductor devices: a measurement and identification method. 31(9):1363­1368, 1988. Kenneth W. Tobin, Thomas P. Karnowski, and Regina K. Ferrell. Image retrieval in the industrial environment. In IS&T/SPIEs 11th International Symposium on Electronic Imaging: Science and Technology, San Jose Convention Center, 1999. Xinxi Wang and Ye Wang. Improving content-based and hybrid music recommendation using deep learning. In Proceedings of the 22nd ACM international conference on Multimedia, pp. 627­636. ACM, 2014. X.-C. Zhang and D. H. Auston. Optoelectronic measurement of semiconductor surfaces and interfaces with femtosecond optics. 71(1):326­338, 1992.
10

